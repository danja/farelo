/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(function webpackUniversalModuleDefinition(root, factory) {
	if(typeof exports === 'object' && typeof module === 'object')
		module.exports = factory();
	else if(typeof define === 'function' && define.amd)
		define([], factory);
	else if(typeof exports === 'object')
		exports["FormAMatic"] = factory();
	else
		root["FormAMatic"] = factory();
})(this, () => {
return /******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/@bergos/jsonparse/jsonparse.js":
/*!*****************************************************!*\
  !*** ./node_modules/@bergos/jsonparse/jsonparse.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var { Buffer } = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\n// Named constants with unique integer values\nvar C = {};\n// Tokens\nvar LEFT_BRACE    = C.LEFT_BRACE    = 0x1;\nvar RIGHT_BRACE   = C.RIGHT_BRACE   = 0x2;\nvar LEFT_BRACKET  = C.LEFT_BRACKET  = 0x3;\nvar RIGHT_BRACKET = C.RIGHT_BRACKET = 0x4;\nvar COLON         = C.COLON         = 0x5;\nvar COMMA         = C.COMMA         = 0x6;\nvar TRUE          = C.TRUE          = 0x7;\nvar FALSE         = C.FALSE         = 0x8;\nvar NULL          = C.NULL          = 0x9;\nvar STRING        = C.STRING        = 0xa;\nvar NUMBER        = C.NUMBER        = 0xb;\n// Tokenizer States\nvar START   = C.START   = 0x11;\nvar STOP    = C.STOP    = 0x12;\nvar TRUE1   = C.TRUE1   = 0x21;\nvar TRUE2   = C.TRUE2   = 0x22;\nvar TRUE3   = C.TRUE3   = 0x23;\nvar FALSE1  = C.FALSE1  = 0x31;\nvar FALSE2  = C.FALSE2  = 0x32;\nvar FALSE3  = C.FALSE3  = 0x33;\nvar FALSE4  = C.FALSE4  = 0x34;\nvar NULL1   = C.NULL1   = 0x41;\nvar NULL2   = C.NULL2   = 0x42;\nvar NULL3   = C.NULL3   = 0x43;\nvar NUMBER1 = C.NUMBER1 = 0x51;\nvar NUMBER3 = C.NUMBER3 = 0x53;\nvar STRING1 = C.STRING1 = 0x61;\nvar STRING2 = C.STRING2 = 0x62;\nvar STRING3 = C.STRING3 = 0x63;\nvar STRING4 = C.STRING4 = 0x64;\nvar STRING5 = C.STRING5 = 0x65;\nvar STRING6 = C.STRING6 = 0x66;\n// Parser States\nvar VALUE   = C.VALUE   = 0x71;\nvar KEY     = C.KEY     = 0x72;\n// Parser Modes\nvar OBJECT  = C.OBJECT  = 0x81;\nvar ARRAY   = C.ARRAY   = 0x82;\n// Character constants\nvar BACK_SLASH =      \"\\\\\".charCodeAt(0);\nvar FORWARD_SLASH =   \"\\/\".charCodeAt(0);\nvar BACKSPACE =       \"\\b\".charCodeAt(0);\nvar FORM_FEED =       \"\\f\".charCodeAt(0);\nvar NEWLINE =         \"\\n\".charCodeAt(0);\nvar CARRIAGE_RETURN = \"\\r\".charCodeAt(0);\nvar TAB =             \"\\t\".charCodeAt(0);\n\nvar STRING_BUFFER_SIZE = 64 * 1024;\n\nfunction alloc(size) {\n  return Buffer.alloc ? Buffer.alloc(size) : new Buffer(size);\n}\n\nfunction Parser() {\n  this.tState = START;\n  this.value = undefined;\n\n  this.string = undefined; // string data\n  this.stringBuffer = alloc(STRING_BUFFER_SIZE);\n  this.stringBufferOffset = 0;\n  this.unicode = undefined; // unicode escapes\n  this.highSurrogate = undefined;\n\n  this.key = undefined;\n  this.mode = undefined;\n  this.stack = [];\n  this.state = VALUE;\n  this.bytes_remaining = 0; // number of bytes remaining in multi byte utf8 char to read after split boundary\n  this.bytes_in_sequence = 0; // bytes in multi byte utf8 char to read\n  this.temp_buffs = { \"2\": alloc(2), \"3\": alloc(3), \"4\": alloc(4) }; // for rebuilding chars split before boundary is reached\n\n  // Stream offset\n  this.offset = -1;\n}\n\n// Slow code to string converter (only used when throwing syntax errors)\nParser.toknam = function (code) {\n  var keys = Object.keys(C);\n  for (var i = 0, l = keys.length; i < l; i++) {\n    var key = keys[i];\n    if (C[key] === code) { return key; }\n  }\n  return code && (\"0x\" + code.toString(16));\n};\n\nvar proto = Parser.prototype;\nproto.onError = function (err) { throw err; };\nproto.charError = function (buffer, i) {\n  this.tState = STOP;\n  this.onError(new Error(\"Unexpected \" + JSON.stringify(String.fromCharCode(buffer[i])) + \" at position \" + i + \" in state \" + Parser.toknam(this.tState)));\n};\nproto.appendStringChar = function (char) {\n  if (this.stringBufferOffset >= STRING_BUFFER_SIZE) {\n    this.string += this.stringBuffer.toString('utf8');\n    this.stringBufferOffset = 0;\n  }\n\n  this.stringBuffer[this.stringBufferOffset++] = char;\n};\nproto.appendStringBuf = function (buf, start, end) {\n  var size = buf.length;\n  if (typeof start === 'number') {\n    if (typeof end === 'number') {\n      if (end < 0) {\n        // adding a negative end decreeses the size\n        size = buf.length - start + end;\n      } else {\n        size = end - start;\n      }\n    } else {\n      size = buf.length - start;\n    }\n  }\n\n  if (size < 0) {\n    size = 0;\n  }\n\n  if (this.stringBufferOffset + size > STRING_BUFFER_SIZE) {\n    this.string += this.stringBuffer.toString('utf8', 0, this.stringBufferOffset);\n    this.stringBufferOffset = 0;\n  }\n\n  buf.copy(this.stringBuffer, this.stringBufferOffset, start, end);\n  this.stringBufferOffset += size;\n};\nproto.write = function (buffer) {\n  if (typeof buffer === \"string\") buffer = new Buffer(buffer);\n  var n;\n  for (var i = 0, l = buffer.length; i < l; i++) {\n    if (this.tState === START){\n      n = buffer[i];\n      this.offset++;\n      if(n === 0x7b){ this.onToken(LEFT_BRACE, \"{\"); // {\n      }else if(n === 0x7d){ this.onToken(RIGHT_BRACE, \"}\"); // }\n      }else if(n === 0x5b){ this.onToken(LEFT_BRACKET, \"[\"); // [\n      }else if(n === 0x5d){ this.onToken(RIGHT_BRACKET, \"]\"); // ]\n      }else if(n === 0x3a){ this.onToken(COLON, \":\");  // :\n      }else if(n === 0x2c){ this.onToken(COMMA, \",\"); // ,\n      }else if(n === 0x74){ this.tState = TRUE1;  // t\n      }else if(n === 0x66){ this.tState = FALSE1;  // f\n      }else if(n === 0x6e){ this.tState = NULL1; // n\n      }else if(n === 0x22){ // \"\n        this.string = \"\";\n        this.stringBufferOffset = 0;\n        this.tState = STRING1;\n      }else if(n === 0x2d){ this.string = \"-\"; this.tState = NUMBER1; // -\n      }else{\n        if (n >= 0x30 && n < 0x40) { // 1-9\n          this.string = String.fromCharCode(n); this.tState = NUMBER3;\n        } else if (n === 0x20 || n === 0x09 || n === 0x0a || n === 0x0d) {\n          // whitespace\n        } else {\n          return this.charError(buffer, i);\n        }\n      }\n    }else if (this.tState === STRING1){ // After open quote\n      n = buffer[i]; // get current byte from buffer\n      // check for carry over of a multi byte char split between data chunks\n      // & fill temp buffer it with start of this data chunk up to the boundary limit set in the last iteration\n      if (this.bytes_remaining > 0) {\n        for (var j = 0; j < this.bytes_remaining; j++) {\n          this.temp_buffs[this.bytes_in_sequence][this.bytes_in_sequence - this.bytes_remaining + j] = buffer[j];\n        }\n\n        this.appendStringBuf(this.temp_buffs[this.bytes_in_sequence]);\n        this.bytes_in_sequence = this.bytes_remaining = 0;\n        i = i + j - 1;\n      } else if (this.bytes_remaining === 0 && n >= 128) { // else if no remainder bytes carried over, parse multi byte (>=128) chars one at a time\n        if (n <= 193 || n > 244) {\n          return this.onError(new Error(\"Invalid UTF-8 character at position \" + i + \" in state \" + Parser.toknam(this.tState)));\n        }\n        if ((n >= 194) && (n <= 223)) this.bytes_in_sequence = 2;\n        if ((n >= 224) && (n <= 239)) this.bytes_in_sequence = 3;\n        if ((n >= 240) && (n <= 244)) this.bytes_in_sequence = 4;\n        if ((this.bytes_in_sequence + i) > buffer.length) { // if bytes needed to complete char fall outside buffer length, we have a boundary split\n          for (var k = 0; k <= (buffer.length - 1 - i); k++) {\n            this.temp_buffs[this.bytes_in_sequence][k] = buffer[i + k]; // fill temp buffer of correct size with bytes available in this chunk\n          }\n          this.bytes_remaining = (i + this.bytes_in_sequence) - buffer.length;\n          i = buffer.length - 1;\n        } else {\n          this.appendStringBuf(buffer, i, i + this.bytes_in_sequence);\n          i = i + this.bytes_in_sequence - 1;\n        }\n      } else if (n === 0x22) {\n        this.tState = START;\n        this.string += this.stringBuffer.toString('utf8', 0, this.stringBufferOffset);\n        this.stringBufferOffset = 0;\n        this.onToken(STRING, this.string);\n        this.offset += Buffer.byteLength(this.string, 'utf8') + 1;\n        this.string = undefined;\n      }\n      else if (n === 0x5c) {\n        this.tState = STRING2;\n      }\n      else if (n >= 0x20) { this.appendStringChar(n); }\n      else {\n          return this.charError(buffer, i);\n      }\n    }else if (this.tState === STRING2){ // After backslash\n      n = buffer[i];\n      if(n === 0x22){ this.appendStringChar(n); this.tState = STRING1;\n      }else if(n === 0x5c){ this.appendStringChar(BACK_SLASH); this.tState = STRING1;\n      }else if(n === 0x2f){ this.appendStringChar(FORWARD_SLASH); this.tState = STRING1;\n      }else if(n === 0x62){ this.appendStringChar(BACKSPACE); this.tState = STRING1;\n      }else if(n === 0x66){ this.appendStringChar(FORM_FEED); this.tState = STRING1;\n      }else if(n === 0x6e){ this.appendStringChar(NEWLINE); this.tState = STRING1;\n      }else if(n === 0x72){ this.appendStringChar(CARRIAGE_RETURN); this.tState = STRING1;\n      }else if(n === 0x74){ this.appendStringChar(TAB); this.tState = STRING1;\n      }else if(n === 0x75){ this.unicode = \"\"; this.tState = STRING3;\n      }else{\n        return this.charError(buffer, i);\n      }\n    }else if (this.tState === STRING3 || this.tState === STRING4 || this.tState === STRING5 || this.tState === STRING6){ // unicode hex codes\n      n = buffer[i];\n      // 0-9 A-F a-f\n      if ((n >= 0x30 && n < 0x40) || (n > 0x40 && n <= 0x46) || (n > 0x60 && n <= 0x66)) {\n        this.unicode += String.fromCharCode(n);\n        if (this.tState++ === STRING6) {\n          var intVal = parseInt(this.unicode, 16);\n          this.unicode = undefined;\n          if (this.highSurrogate !== undefined && intVal >= 0xDC00 && intVal < (0xDFFF + 1)) { //<56320,57343> - lowSurrogate\n            this.appendStringBuf(new Buffer(String.fromCharCode(this.highSurrogate, intVal)));\n            this.highSurrogate = undefined;\n          } else if (this.highSurrogate === undefined && intVal >= 0xD800 && intVal < (0xDBFF + 1)) { //<55296,56319> - highSurrogate\n            this.highSurrogate = intVal;\n          } else {\n            if (this.highSurrogate !== undefined) {\n              this.appendStringBuf(new Buffer(String.fromCharCode(this.highSurrogate)));\n              this.highSurrogate = undefined;\n            }\n            this.appendStringBuf(new Buffer(String.fromCharCode(intVal)));\n          }\n          this.tState = STRING1;\n        }\n      } else {\n        return this.charError(buffer, i);\n      }\n    } else if (this.tState === NUMBER1 || this.tState === NUMBER3) {\n        n = buffer[i];\n\n        switch (n) {\n          case 0x30: // 0\n          case 0x31: // 1\n          case 0x32: // 2\n          case 0x33: // 3\n          case 0x34: // 4\n          case 0x35: // 5\n          case 0x36: // 6\n          case 0x37: // 7\n          case 0x38: // 8\n          case 0x39: // 9\n          case 0x2e: // .\n          case 0x65: // e\n          case 0x45: // E\n          case 0x2b: // +\n          case 0x2d: // -\n            this.string += String.fromCharCode(n);\n            this.tState = NUMBER3;\n            break;\n          default:\n            this.tState = START;\n            var error = this.numberReviver(this.string);\n            if (error){\n              return error;\n            }\n\n            this.offset += this.string.length - 1;\n            this.string = undefined;\n            i--;\n            break;\n        }\n    }else if (this.tState === TRUE1){ // r\n      if (buffer[i] === 0x72) { this.tState = TRUE2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === TRUE2){ // u\n      if (buffer[i] === 0x75) { this.tState = TRUE3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === TRUE3){ // e\n      if (buffer[i] === 0x65) { this.tState = START; this.onToken(TRUE, true); this.offset+= 3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE1){ // a\n      if (buffer[i] === 0x61) { this.tState = FALSE2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE2){ // l\n      if (buffer[i] === 0x6c) { this.tState = FALSE3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE3){ // s\n      if (buffer[i] === 0x73) { this.tState = FALSE4; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE4){ // e\n      if (buffer[i] === 0x65) { this.tState = START; this.onToken(FALSE, false); this.offset+= 4; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL1){ // u\n      if (buffer[i] === 0x75) { this.tState = NULL2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL2){ // l\n      if (buffer[i] === 0x6c) { this.tState = NULL3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL3){ // l\n      if (buffer[i] === 0x6c) { this.tState = START; this.onToken(NULL, null); this.offset += 3; }\n      else { return this.charError(buffer, i); }\n    }\n  }\n};\nproto.onToken = function (token, value) {\n  // Override this to get events\n};\n\nproto.parseError = function (token, value) {\n  this.tState = STOP;\n  this.onError(new Error(\"Unexpected \" + Parser.toknam(token) + (value ? (\"(\" + JSON.stringify(value) + \")\") : \"\") + \" in state \" + Parser.toknam(this.state)));\n};\nproto.push = function () {\n  this.stack.push({value: this.value, key: this.key, mode: this.mode});\n};\nproto.pop = function () {\n  var value = this.value;\n  var parent = this.stack.pop();\n  this.value = parent.value;\n  this.key = parent.key;\n  this.mode = parent.mode;\n  this.emit(value);\n  if (!this.mode) { this.state = VALUE; }\n};\nproto.emit = function (value) {\n  if (this.mode) { this.state = COMMA; }\n  this.onValue(value);\n};\nproto.onValue = function (value) {\n  // Override me\n};\nproto.onToken = function (token, value) {\n  if(this.state === VALUE){\n    if(token === STRING || token === NUMBER || token === TRUE || token === FALSE || token === NULL){\n      if (this.value) {\n        this.value[this.key] = value;\n      }\n      this.emit(value);\n    }else if(token === LEFT_BRACE){\n      this.push();\n      if (this.value) {\n        this.value = this.value[this.key] = {};\n      } else {\n        this.value = {};\n      }\n      this.key = undefined;\n      this.state = KEY;\n      this.mode = OBJECT;\n    }else if(token === LEFT_BRACKET){\n      this.push();\n      if (this.value) {\n        this.value = this.value[this.key] = [];\n      } else {\n        this.value = [];\n      }\n      this.key = 0;\n      this.mode = ARRAY;\n      this.state = VALUE;\n    }else if(token === RIGHT_BRACE){\n      if (this.mode === OBJECT) {\n        this.pop();\n      } else {\n        return this.parseError(token, value);\n      }\n    }else if(token === RIGHT_BRACKET){\n      if (this.mode === ARRAY) {\n        this.pop();\n      } else {\n        return this.parseError(token, value);\n      }\n    }else{\n      return this.parseError(token, value);\n    }\n  }else if(this.state === KEY){\n    if (token === STRING) {\n      this.key = value;\n      this.state = COLON;\n    } else if (token === RIGHT_BRACE) {\n      this.pop();\n    } else {\n      return this.parseError(token, value);\n    }\n  }else if(this.state === COLON){\n    if (token === COLON) { this.state = VALUE; }\n    else { return this.parseError(token, value); }\n  }else if(this.state === COMMA){\n    if (token === COMMA) {\n      if (this.mode === ARRAY) { this.key++; this.state = VALUE; }\n      else if (this.mode === OBJECT) { this.state = KEY; }\n\n    } else if (token === RIGHT_BRACKET && this.mode === ARRAY || token === RIGHT_BRACE && this.mode === OBJECT) {\n      this.pop();\n    } else {\n      return this.parseError(token, value);\n    }\n  }else{\n    return this.parseError(token, value);\n  }\n};\n\n// Override to implement your own number reviver.\n// Any value returned is treated as error and will interrupt parsing.\nproto.numberReviver = function (text) {\n  var result = Number(text);\n\n  if (isNaN(result)) {\n    return this.charError(buffer, i);\n  }\n\n  if ((text.match(/[0-9]+/) == text) && (result.toString() != text)) {\n    // Long string of digits which is an ID string and not valid and/or safe JavaScript integer Number\n    this.onToken(STRING, text);\n  } else {\n    this.onToken(NUMBER, result);\n  }\n}\n\nParser.C = C;\n\nmodule.exports = Parser;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@bergos/jsonparse/jsonparse.js?");

/***/ }),

/***/ "./node_modules/@rubensworks/saxes/saxes.js":
/*!**************************************************!*\
  !*** ./node_modules/@rubensworks/saxes/saxes.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SaxesParser = exports.EVENTS = void 0;\nconst ed5 = __webpack_require__(/*! xmlchars/xml/1.0/ed5 */ \"./node_modules/xmlchars/xml/1.0/ed5.js\");\nconst ed2 = __webpack_require__(/*! xmlchars/xml/1.1/ed2 */ \"./node_modules/xmlchars/xml/1.1/ed2.js\");\nconst NSed3 = __webpack_require__(/*! xmlchars/xmlns/1.0/ed3 */ \"./node_modules/xmlchars/xmlns/1.0/ed3.js\");\nvar isS = ed5.isS;\nvar isChar10 = ed5.isChar;\nvar isNameStartChar = ed5.isNameStartChar;\nvar isNameChar = ed5.isNameChar;\nvar S_LIST = ed5.S_LIST;\nvar NAME_RE = ed5.NAME_RE;\nvar isChar11 = ed2.isChar;\nvar isNCNameStartChar = NSed3.isNCNameStartChar;\nvar isNCNameChar = NSed3.isNCNameChar;\nvar NC_NAME_RE = NSed3.NC_NAME_RE;\nconst XML_NAMESPACE = \"http://www.w3.org/XML/1998/namespace\";\nconst XMLNS_NAMESPACE = \"http://www.w3.org/2000/xmlns/\";\nconst rootNS = {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/no-unsafe-assignment\n    __proto__: null,\n    xml: XML_NAMESPACE,\n    xmlns: XMLNS_NAMESPACE,\n};\nconst XML_ENTITIES = {\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/no-unsafe-assignment\n    __proto__: null,\n    amp: \"&\",\n    gt: \">\",\n    lt: \"<\",\n    quot: \"\\\"\",\n    apos: \"'\",\n};\n// EOC: end-of-chunk\nconst EOC = -1;\nconst NL_LIKE = -2;\nconst S_BEGIN = 0; // Initial state.\nconst S_BEGIN_WHITESPACE = 1; // leading whitespace\nconst S_DOCTYPE = 2; // <!DOCTYPE\nconst S_DOCTYPE_QUOTE = 3; // <!DOCTYPE \"//blah\nconst S_DTD = 4; // <!DOCTYPE \"//blah\" [ ...\nconst S_DTD_QUOTED = 5; // <!DOCTYPE \"//blah\" [ \"foo\nconst S_DTD_OPEN_WAKA = 6;\nconst S_DTD_OPEN_WAKA_BANG = 7;\nconst S_DTD_COMMENT = 8; // <!--\nconst S_DTD_COMMENT_ENDING = 9; // <!-- blah -\nconst S_DTD_COMMENT_ENDED = 10; // <!-- blah --\nconst S_DTD_PI = 11; // <?\nconst S_DTD_PI_ENDING = 12; // <?hi \"there\" ?\nconst S_TEXT = 13; // general stuff\nconst S_ENTITY = 14; // &amp and such\nconst S_OPEN_WAKA = 15; // <\nconst S_OPEN_WAKA_BANG = 16; // <!...\nconst S_COMMENT = 17; // <!--\nconst S_COMMENT_ENDING = 18; // <!-- blah -\nconst S_COMMENT_ENDED = 19; // <!-- blah --\nconst S_CDATA = 20; // <![CDATA[ something\nconst S_CDATA_ENDING = 21; // ]\nconst S_CDATA_ENDING_2 = 22; // ]]\nconst S_PI_FIRST_CHAR = 23; // <?hi, first char\nconst S_PI_REST = 24; // <?hi, rest of the name\nconst S_PI_BODY = 25; // <?hi there\nconst S_PI_ENDING = 26; // <?hi \"there\" ?\nconst S_XML_DECL_NAME_START = 27; // <?xml\nconst S_XML_DECL_NAME = 28; // <?xml foo\nconst S_XML_DECL_EQ = 29; // <?xml foo=\nconst S_XML_DECL_VALUE_START = 30; // <?xml foo=\nconst S_XML_DECL_VALUE = 31; // <?xml foo=\"bar\"\nconst S_XML_DECL_SEPARATOR = 32; // <?xml foo=\"bar\"\nconst S_XML_DECL_ENDING = 33; // <?xml ... ?\nconst S_OPEN_TAG = 34; // <strong\nconst S_OPEN_TAG_SLASH = 35; // <strong /\nconst S_ATTRIB = 36; // <a\nconst S_ATTRIB_NAME = 37; // <a foo\nconst S_ATTRIB_NAME_SAW_WHITE = 38; // <a foo _\nconst S_ATTRIB_VALUE = 39; // <a foo=\nconst S_ATTRIB_VALUE_QUOTED = 40; // <a foo=\"bar\nconst S_ATTRIB_VALUE_CLOSED = 41; // <a foo=\"bar\"\nconst S_ATTRIB_VALUE_UNQUOTED = 42; // <a foo=bar\nconst S_CLOSE_TAG = 43; // </a\nconst S_CLOSE_TAG_SAW_WHITE = 44; // </a   >\nconst TAB = 9;\nconst NL = 0xA;\nconst CR = 0xD;\nconst SPACE = 0x20;\nconst BANG = 0x21;\nconst DQUOTE = 0x22;\nconst AMP = 0x26;\nconst SQUOTE = 0x27;\nconst MINUS = 0x2D;\nconst FORWARD_SLASH = 0x2F;\nconst SEMICOLON = 0x3B;\nconst LESS = 0x3C;\nconst EQUAL = 0x3D;\nconst GREATER = 0x3E;\nconst QUESTION = 0x3F;\nconst OPEN_BRACKET = 0x5B;\nconst CLOSE_BRACKET = 0x5D;\nconst NEL = 0x85;\nconst LS = 0x2028; // Line Separator\nconst isQuote = (c) => c === DQUOTE || c === SQUOTE;\nconst QUOTES = [DQUOTE, SQUOTE];\nconst DOCTYPE_TERMINATOR = [...QUOTES, OPEN_BRACKET, GREATER];\nconst DTD_TERMINATOR = [...QUOTES, LESS, CLOSE_BRACKET];\nconst XML_DECL_NAME_TERMINATOR = [EQUAL, QUESTION, ...S_LIST];\nconst ATTRIB_VALUE_UNQUOTED_TERMINATOR = [...S_LIST, GREATER, AMP, LESS];\nfunction nsPairCheck(parser, prefix, uri) {\n    switch (prefix) {\n        case \"xml\":\n            if (uri !== XML_NAMESPACE) {\n                parser.fail(`xml prefix must be bound to ${XML_NAMESPACE}.`);\n            }\n            break;\n        case \"xmlns\":\n            if (uri !== XMLNS_NAMESPACE) {\n                parser.fail(`xmlns prefix must be bound to ${XMLNS_NAMESPACE}.`);\n            }\n            break;\n        default:\n    }\n    switch (uri) {\n        case XMLNS_NAMESPACE:\n            parser.fail(prefix === \"\" ?\n                `the default namespace may not be set to ${uri}.` :\n                `may not assign a prefix (even \"xmlns\") to the URI \\\n${XMLNS_NAMESPACE}.`);\n            break;\n        case XML_NAMESPACE:\n            switch (prefix) {\n                case \"xml\":\n                    // Assinging the XML namespace to \"xml\" is fine.\n                    break;\n                case \"\":\n                    parser.fail(`the default namespace may not be set to ${uri}.`);\n                    break;\n                default:\n                    parser.fail(\"may not assign the xml namespace to another prefix.\");\n            }\n            break;\n        default:\n    }\n}\nfunction nsMappingCheck(parser, mapping) {\n    for (const local of Object.keys(mapping)) {\n        nsPairCheck(parser, local, mapping[local]);\n    }\n}\nconst isNCName = (name) => NC_NAME_RE.test(name);\nconst isName = (name) => NAME_RE.test(name);\nconst FORBIDDEN_START = 0;\nconst FORBIDDEN_BRACKET = 1;\nconst FORBIDDEN_BRACKET_BRACKET = 2;\n/**\n * The list of supported events.\n */\nexports.EVENTS = [\n    \"xmldecl\",\n    \"text\",\n    \"processinginstruction\",\n    \"doctype\",\n    \"comment\",\n    \"opentagstart\",\n    \"attribute\",\n    \"opentag\",\n    \"closetag\",\n    \"cdata\",\n    \"error\",\n    \"end\",\n    \"ready\",\n];\nconst EVENT_NAME_TO_HANDLER_NAME = {\n    xmldecl: \"xmldeclHandler\",\n    text: \"textHandler\",\n    processinginstruction: \"piHandler\",\n    doctype: \"doctypeHandler\",\n    comment: \"commentHandler\",\n    opentagstart: \"openTagStartHandler\",\n    attribute: \"attributeHandler\",\n    opentag: \"openTagHandler\",\n    closetag: \"closeTagHandler\",\n    cdata: \"cdataHandler\",\n    error: \"errorHandler\",\n    end: \"endHandler\",\n    ready: \"readyHandler\",\n};\n// eslint-disable-next-line @typescript-eslint/ban-types\nclass SaxesParser {\n    /**\n     * Indicates whether or not the parser is closed. If ``true``, wait for\n     * the ``ready`` event to write again.\n     */\n    get closed() {\n        return this._closed;\n    }\n    /**\n     * @param opt The parser options.\n     */\n    constructor(opt) {\n        this.opt = opt !== null && opt !== void 0 ? opt : {};\n        this.fragmentOpt = !!this.opt.fragment;\n        const xmlnsOpt = this.xmlnsOpt = !!this.opt.xmlns;\n        this.trackPosition = this.opt.position !== false;\n        this.fileName = this.opt.fileName;\n        if (xmlnsOpt) {\n            // This is the function we use to perform name checks on PIs and entities.\n            // When namespaces are used, colons are not allowed in PI target names or\n            // entity names. So the check depends on whether namespaces are used. See:\n            //\n            // https://www.w3.org/XML/xml-names-19990114-errata.html\n            // NE08\n            //\n            this.nameStartCheck = isNCNameStartChar;\n            this.nameCheck = isNCNameChar;\n            this.isName = isNCName;\n            // eslint-disable-next-line @typescript-eslint/unbound-method\n            this.processAttribs = this.processAttribsNS;\n            // eslint-disable-next-line @typescript-eslint/unbound-method\n            this.pushAttrib = this.pushAttribNS;\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/no-unsafe-assignment\n            this.ns = Object.assign({ __proto__: null }, rootNS);\n            const additional = this.opt.additionalNamespaces;\n            if (additional != null) {\n                nsMappingCheck(this, additional);\n                Object.assign(this.ns, additional);\n            }\n        }\n        else {\n            this.nameStartCheck = isNameStartChar;\n            this.nameCheck = isNameChar;\n            this.isName = isName;\n            // eslint-disable-next-line @typescript-eslint/unbound-method\n            this.processAttribs = this.processAttribsPlain;\n            // eslint-disable-next-line @typescript-eslint/unbound-method\n            this.pushAttrib = this.pushAttribPlain;\n        }\n        //\n        // The order of the members in this table needs to correspond to the state\n        // numbers given to the states that correspond to the methods being recorded\n        // here.\n        //\n        this.stateTable = [\n            /* eslint-disable @typescript-eslint/unbound-method */\n            this.sBegin,\n            this.sBeginWhitespace,\n            this.sDoctype,\n            this.sDoctypeQuote,\n            this.sDTD,\n            this.sDTDQuoted,\n            this.sDTDOpenWaka,\n            this.sDTDOpenWakaBang,\n            this.sDTDComment,\n            this.sDTDCommentEnding,\n            this.sDTDCommentEnded,\n            this.sDTDPI,\n            this.sDTDPIEnding,\n            this.sText,\n            this.sEntity,\n            this.sOpenWaka,\n            this.sOpenWakaBang,\n            this.sComment,\n            this.sCommentEnding,\n            this.sCommentEnded,\n            this.sCData,\n            this.sCDataEnding,\n            this.sCDataEnding2,\n            this.sPIFirstChar,\n            this.sPIRest,\n            this.sPIBody,\n            this.sPIEnding,\n            this.sXMLDeclNameStart,\n            this.sXMLDeclName,\n            this.sXMLDeclEq,\n            this.sXMLDeclValueStart,\n            this.sXMLDeclValue,\n            this.sXMLDeclSeparator,\n            this.sXMLDeclEnding,\n            this.sOpenTag,\n            this.sOpenTagSlash,\n            this.sAttrib,\n            this.sAttribName,\n            this.sAttribNameSawWhite,\n            this.sAttribValue,\n            this.sAttribValueQuoted,\n            this.sAttribValueClosed,\n            this.sAttribValueUnquoted,\n            this.sCloseTag,\n            this.sCloseTagSawWhite,\n            /* eslint-enable @typescript-eslint/unbound-method */\n        ];\n        this._init();\n    }\n    _init() {\n        var _a;\n        this.openWakaBang = \"\";\n        this.text = \"\";\n        this.name = \"\";\n        this.piTarget = \"\";\n        this.entity = \"\";\n        this.q = null;\n        this.tags = [];\n        this.tag = null;\n        this.topNS = null;\n        this.chunk = \"\";\n        this.chunkPosition = 0;\n        this.i = 0;\n        this.prevI = 0;\n        this.carriedFromPrevious = undefined;\n        this.forbiddenState = FORBIDDEN_START;\n        this.attribList = [];\n        // The logic is organized so as to minimize the need to check\n        // this.opt.fragment while parsing.\n        const { fragmentOpt } = this;\n        this.state = fragmentOpt ? S_TEXT : S_BEGIN;\n        // We want these to be all true if we are dealing with a fragment.\n        this.reportedTextBeforeRoot = this.reportedTextAfterRoot = this.closedRoot =\n            this.sawRoot = fragmentOpt;\n        // An XML declaration is intially possible only when parsing whole\n        // documents.\n        this.xmlDeclPossible = !fragmentOpt;\n        this.xmlDeclExpects = [\"version\"];\n        this.entityReturnState = undefined;\n        let { defaultXMLVersion } = this.opt;\n        if (defaultXMLVersion === undefined) {\n            if (this.opt.forceXMLVersion === true) {\n                throw new Error(\"forceXMLVersion set but defaultXMLVersion is not set\");\n            }\n            defaultXMLVersion = \"1.0\";\n        }\n        this.setXMLVersion(defaultXMLVersion);\n        this.positionAtNewLine = 0;\n        this.doctype = false;\n        this._closed = false;\n        this.xmlDecl = {\n            version: undefined,\n            encoding: undefined,\n            standalone: undefined,\n        };\n        this.line = 1;\n        this.column = 0;\n        this.ENTITIES = Object.create(XML_ENTITIES);\n        (_a = this.readyHandler) === null || _a === void 0 ? void 0 : _a.call(this);\n    }\n    /**\n     * The stream position the parser is currently looking at. This field is\n     * zero-based.\n     *\n     * This field is not based on counting Unicode characters but is to be\n     * interpreted as a plain index into a JavaScript string.\n     */\n    get position() {\n        return this.chunkPosition + this.i;\n    }\n    /**\n     * The column number of the next character to be read by the parser.  *\n     * This field is zero-based. (The first column in a line is 0.)\n     *\n     * This field reports the index at which the next character would be in the\n     * line if the line were represented as a JavaScript string.  Note that this\n     * *can* be different to a count based on the number of *Unicode characters*\n     * due to how JavaScript handles astral plane characters.\n     *\n     * See [[column]] for a number that corresponds to a count of Unicode\n     * characters.\n     */\n    get columnIndex() {\n        return this.position - this.positionAtNewLine;\n    }\n    /**\n     * Set an event listener on an event. The parser supports one handler per\n     * event type. If you try to set an event handler over an existing handler,\n     * the old handler is silently overwritten.\n     *\n     * @param name The event to listen to.\n     *\n     * @param handler The handler to set.\n     */\n    on(name, handler) {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/no-unsafe-member-access\n        this[EVENT_NAME_TO_HANDLER_NAME[name]] = handler;\n    }\n    /**\n     * Unset an event handler.\n     *\n     * @parma name The event to stop listening to.\n     */\n    off(name) {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/no-unsafe-member-access\n        this[EVENT_NAME_TO_HANDLER_NAME[name]] = undefined;\n    }\n    /**\n     * Make an error object. The error object will have a message that contains\n     * the ``fileName`` option passed at the creation of the parser. If position\n     * tracking was turned on, it will also have line and column number\n     * information.\n     *\n     * @param message The message describing the error to report.\n     *\n     * @returns An error object with a properly formatted message.\n     */\n    makeError(message) {\n        var _a;\n        let msg = (_a = this.fileName) !== null && _a !== void 0 ? _a : \"\";\n        if (this.trackPosition) {\n            if (msg.length > 0) {\n                msg += \":\";\n            }\n            msg += `${this.line}:${this.column}`;\n        }\n        if (msg.length > 0) {\n            msg += \": \";\n        }\n        return new Error(msg + message);\n    }\n    /**\n     * Report a parsing error. This method is made public so that client code may\n     * check for issues that are outside the scope of this project and can report\n     * errors.\n     *\n     * @param message The error to report.\n     *\n     * @returns this\n     */\n    fail(message) {\n        const err = this.makeError(message);\n        const handler = this.errorHandler;\n        if (handler === undefined) {\n            throw err;\n        }\n        else {\n            handler(err);\n        }\n        return this;\n    }\n    /**\n     * Write a XML data to the parser.\n     *\n     * @param chunk The XML data to write.\n     *\n     * @returns this\n     */\n    // We do need object for the type here. Yes, it often causes problems\n    // but not in this case.\n    write(chunk) {\n        if (this.closed) {\n            return this.fail(\"cannot write after close; assign an onready handler.\");\n        }\n        let end = false;\n        if (chunk === null) {\n            // We cannot return immediately because carriedFromPrevious may need\n            // processing.\n            end = true;\n            chunk = \"\";\n        }\n        else if (typeof chunk === \"object\") {\n            chunk = chunk.toString();\n        }\n        // We checked if performing a pre-decomposition of the string into an array\n        // of single complete characters (``Array.from(chunk)``) would be faster\n        // than the current repeated calls to ``charCodeAt``. As of August 2018, it\n        // isn't. (There may be Node-specific code that would perform faster than\n        // ``Array.from`` but don't want to be dependent on Node.)\n        if (this.carriedFromPrevious !== undefined) {\n            // The previous chunk had char we must carry over.\n            chunk = `${this.carriedFromPrevious}${chunk}`;\n            this.carriedFromPrevious = undefined;\n        }\n        let limit = chunk.length;\n        const lastCode = chunk.charCodeAt(limit - 1);\n        if (!end &&\n            // A trailing CR or surrogate must be carried over to the next\n            // chunk.\n            (lastCode === CR || (lastCode >= 0xD800 && lastCode <= 0xDBFF))) {\n            // The chunk ends with a character that must be carried over. We cannot\n            // know how to handle it until we get the next chunk or the end of the\n            // stream. So save it for later.\n            this.carriedFromPrevious = chunk[limit - 1];\n            limit--;\n            chunk = chunk.slice(0, limit);\n        }\n        const { stateTable } = this;\n        this.chunk = chunk;\n        this.i = 0;\n        while (this.i < limit) {\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/no-unsafe-argument\n            stateTable[this.state].call(this);\n        }\n        this.chunkPosition += limit;\n        return end ? this.end() : this;\n    }\n    /**\n     * Close the current stream. Perform final well-formedness checks and reset\n     * the parser tstate.\n     *\n     * @returns this\n     */\n    close() {\n        return this.write(null);\n    }\n    /**\n     * Get a single code point out of the current chunk. This updates the current\n     * position if we do position tracking.\n     *\n     * This is the algorithm to use for XML 1.0.\n     *\n     * @returns The character read.\n     */\n    getCode10() {\n        const { chunk, i } = this;\n        this.prevI = i;\n        // Yes, we do this instead of doing this.i++. Doing it this way, we do not\n        // read this.i again, which is a bit faster.\n        this.i = i + 1;\n        if (i >= chunk.length) {\n            return EOC;\n        }\n        // Using charCodeAt and handling the surrogates ourselves is faster\n        // than using codePointAt.\n        const code = chunk.charCodeAt(i);\n        this.column++;\n        if (code < 0xD800) {\n            if (code >= SPACE || code === TAB) {\n                return code;\n            }\n            switch (code) {\n                case NL:\n                    this.line++;\n                    this.column = 0;\n                    this.positionAtNewLine = this.position;\n                    return NL;\n                case CR:\n                    // We may get NaN if we read past the end of the chunk, which is fine.\n                    if (chunk.charCodeAt(i + 1) === NL) {\n                        // A \\r\\n sequence is converted to \\n so we have to skip over the\n                        // next character. We already know it has a size of 1 so ++ is fine\n                        // here.\n                        this.i = i + 2;\n                    }\n                    // Otherwise, a \\r is just converted to \\n, so we don't have to skip\n                    // ahead.\n                    // In either case, \\r becomes \\n.\n                    this.line++;\n                    this.column = 0;\n                    this.positionAtNewLine = this.position;\n                    return NL_LIKE;\n                default:\n                    // If we get here, then code < SPACE and it is not NL CR or TAB.\n                    this.fail(\"disallowed character.\");\n                    return code;\n            }\n        }\n        if (code > 0xDBFF) {\n            // This is a specialized version of isChar10 that takes into account\n            // that in this context code > 0xDBFF and code <= 0xFFFF. So it does not\n            // test cases that don't need testing.\n            if (!(code >= 0xE000 && code <= 0xFFFD)) {\n                this.fail(\"disallowed character.\");\n            }\n            return code;\n        }\n        const final = 0x10000 + ((code - 0xD800) * 0x400) +\n            (chunk.charCodeAt(i + 1) - 0xDC00);\n        this.i = i + 2;\n        // This is a specialized version of isChar10 that takes into account that in\n        // this context necessarily final >= 0x10000.\n        if (final > 0x10FFFF) {\n            this.fail(\"disallowed character.\");\n        }\n        return final;\n    }\n    /**\n     * Get a single code point out of the current chunk. This updates the current\n     * position if we do position tracking.\n     *\n     * This is the algorithm to use for XML 1.1.\n     *\n     * @returns {number} The character read.\n     */\n    getCode11() {\n        const { chunk, i } = this;\n        this.prevI = i;\n        // Yes, we do this instead of doing this.i++. Doing it this way, we do not\n        // read this.i again, which is a bit faster.\n        this.i = i + 1;\n        if (i >= chunk.length) {\n            return EOC;\n        }\n        // Using charCodeAt and handling the surrogates ourselves is faster\n        // than using codePointAt.\n        const code = chunk.charCodeAt(i);\n        this.column++;\n        if (code < 0xD800) {\n            if ((code > 0x1F && code < 0x7F) || (code > 0x9F && code !== LS) ||\n                code === TAB) {\n                return code;\n            }\n            switch (code) {\n                case NL: // 0xA\n                    this.line++;\n                    this.column = 0;\n                    this.positionAtNewLine = this.position;\n                    return NL;\n                case CR: { // 0xD\n                    // We may get NaN if we read past the end of the chunk, which is\n                    // fine.\n                    const next = chunk.charCodeAt(i + 1);\n                    if (next === NL || next === NEL) {\n                        // A CR NL or CR NEL sequence is converted to NL so we have to skip\n                        // over the next character. We already know it has a size of 1.\n                        this.i = i + 2;\n                    }\n                    // Otherwise, a CR is just converted to NL, no skip.\n                }\n                /* yes, fall through */\n                case NEL: // 0x85\n                case LS: // Ox2028\n                    this.line++;\n                    this.column = 0;\n                    this.positionAtNewLine = this.position;\n                    return NL_LIKE;\n                default:\n                    this.fail(\"disallowed character.\");\n                    return code;\n            }\n        }\n        if (code > 0xDBFF) {\n            // This is a specialized version of isCharAndNotRestricted that takes into\n            // account that in this context code > 0xDBFF and code <= 0xFFFF. So it\n            // does not test cases that don't need testing.\n            if (!(code >= 0xE000 && code <= 0xFFFD)) {\n                this.fail(\"disallowed character.\");\n            }\n            return code;\n        }\n        const final = 0x10000 + ((code - 0xD800) * 0x400) +\n            (chunk.charCodeAt(i + 1) - 0xDC00);\n        this.i = i + 2;\n        // This is a specialized version of isCharAndNotRestricted that takes into\n        // account that in this context necessarily final >= 0x10000.\n        if (final > 0x10FFFF) {\n            this.fail(\"disallowed character.\");\n        }\n        return final;\n    }\n    /**\n     * Like ``getCode`` but with the return value normalized so that ``NL`` is\n     * returned for ``NL_LIKE``.\n     */\n    getCodeNorm() {\n        const c = this.getCode();\n        return c === NL_LIKE ? NL : c;\n    }\n    unget() {\n        this.i = this.prevI;\n        this.column--;\n    }\n    /**\n     * Capture characters into a buffer until encountering one of a set of\n     * characters.\n     *\n     * @param chars An array of codepoints. Encountering a character in the array\n     * ends the capture. (``chars`` may safely contain ``NL``.)\n     *\n     * @return The character code that made the capture end, or ``EOC`` if we hit\n     * the end of the chunk. The return value cannot be NL_LIKE: NL is returned\n     * instead.\n     */\n    captureTo(chars) {\n        let { i: start } = this;\n        const { chunk } = this;\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            const c = this.getCode();\n            const isNLLike = c === NL_LIKE;\n            const final = isNLLike ? NL : c;\n            if (final === EOC || chars.includes(final)) {\n                this.text += chunk.slice(start, this.prevI);\n                return final;\n            }\n            if (isNLLike) {\n                this.text += `${chunk.slice(start, this.prevI)}\\n`;\n                start = this.i;\n            }\n        }\n    }\n    /**\n     * Capture characters into a buffer until encountering a character.\n     *\n     * @param char The codepoint that ends the capture. **NOTE ``char`` MAY NOT\n     * CONTAIN ``NL``.** Passing ``NL`` will result in buggy behavior.\n     *\n     * @return ``true`` if we ran into the character. Otherwise, we ran into the\n     * end of the current chunk.\n     */\n    captureToChar(char) {\n        let { i: start } = this;\n        const { chunk } = this;\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            let c = this.getCode();\n            switch (c) {\n                case NL_LIKE:\n                    this.text += `${chunk.slice(start, this.prevI)}\\n`;\n                    start = this.i;\n                    c = NL;\n                    break;\n                case EOC:\n                    this.text += chunk.slice(start);\n                    return false;\n                default:\n            }\n            if (c === char) {\n                this.text += chunk.slice(start, this.prevI);\n                return true;\n            }\n        }\n    }\n    /**\n     * Capture characters that satisfy ``isNameChar`` into the ``name`` field of\n     * this parser.\n     *\n     * @return The character code that made the test fail, or ``EOC`` if we hit\n     * the end of the chunk. The return value cannot be NL_LIKE: NL is returned\n     * instead.\n     */\n    captureNameChars() {\n        const { chunk, i: start } = this;\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            const c = this.getCode();\n            if (c === EOC) {\n                this.name += chunk.slice(start);\n                return EOC;\n            }\n            // NL is not a name char so we don't have to test specifically for it.\n            if (!isNameChar(c)) {\n                this.name += chunk.slice(start, this.prevI);\n                return c === NL_LIKE ? NL : c;\n            }\n        }\n    }\n    /**\n     * Skip white spaces.\n     *\n     * @return The character that ended the skip, or ``EOC`` if we hit\n     * the end of the chunk. The return value cannot be NL_LIKE: NL is returned\n     * instead.\n     */\n    skipSpaces() {\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            const c = this.getCodeNorm();\n            if (c === EOC || !isS(c)) {\n                return c;\n            }\n        }\n    }\n    setXMLVersion(version) {\n        this.currentXMLVersion = version;\n        /*  eslint-disable @typescript-eslint/unbound-method */\n        if (version === \"1.0\") {\n            this.isChar = isChar10;\n            this.getCode = this.getCode10;\n        }\n        else {\n            this.isChar = isChar11;\n            this.getCode = this.getCode11;\n        }\n        /* eslint-enable @typescript-eslint/unbound-method */\n    }\n    // STATE ENGINE METHODS\n    // This needs to be a state separate from S_BEGIN_WHITESPACE because we want\n    // to be sure never to come back to this state later.\n    sBegin() {\n        // We are essentially peeking at the first character of the chunk. Since\n        // S_BEGIN can be in effect only when we start working on the first chunk,\n        // the index at which we must look is necessarily 0. Note also that the\n        // following test does not depend on decoding surrogates.\n        // If the initial character is 0xFEFF, ignore it.\n        if (this.chunk.charCodeAt(0) === 0xFEFF) {\n            this.i++;\n            this.column++;\n        }\n        this.state = S_BEGIN_WHITESPACE;\n    }\n    sBeginWhitespace() {\n        // We need to know whether we've encountered spaces or not because as soon\n        // as we run into a space, an XML declaration is no longer possible. Rather\n        // than slow down skipSpaces even in places where we don't care whether it\n        // skipped anything or not, we check whether prevI is equal to the value of\n        // i from before we skip spaces.\n        const iBefore = this.i;\n        const c = this.skipSpaces();\n        if (this.prevI !== iBefore) {\n            this.xmlDeclPossible = false;\n        }\n        switch (c) {\n            case LESS:\n                this.state = S_OPEN_WAKA;\n                // We could naively call closeText but in this state, it is not normal\n                // to have text be filled with any data.\n                if (this.text.length !== 0) {\n                    throw new Error(\"no-empty text at start\");\n                }\n                break;\n            case EOC:\n                break;\n            default:\n                this.unget();\n                this.state = S_TEXT;\n                this.xmlDeclPossible = false;\n        }\n    }\n    sDoctype() {\n        var _a;\n        const c = this.captureTo(DOCTYPE_TERMINATOR);\n        switch (c) {\n            case GREATER: {\n                (_a = this.doctypeHandler) === null || _a === void 0 ? void 0 : _a.call(this, this.text);\n                this.text = \"\";\n                this.state = S_TEXT;\n                this.doctype = true; // just remember that we saw it.\n                break;\n            }\n            case EOC:\n                break;\n            default:\n                this.text += String.fromCodePoint(c);\n                if (c === OPEN_BRACKET) {\n                    this.state = S_DTD;\n                }\n                else if (isQuote(c)) {\n                    this.state = S_DOCTYPE_QUOTE;\n                    this.q = c;\n                }\n        }\n    }\n    sDoctypeQuote() {\n        const q = this.q;\n        if (this.captureToChar(q)) {\n            this.text += String.fromCodePoint(q);\n            this.q = null;\n            this.state = S_DOCTYPE;\n        }\n    }\n    sDTD() {\n        const c = this.captureTo(DTD_TERMINATOR);\n        if (c === EOC) {\n            return;\n        }\n        this.text += String.fromCodePoint(c);\n        if (c === CLOSE_BRACKET) {\n            this.state = S_DOCTYPE;\n        }\n        else if (c === LESS) {\n            this.state = S_DTD_OPEN_WAKA;\n        }\n        else if (isQuote(c)) {\n            this.state = S_DTD_QUOTED;\n            this.q = c;\n        }\n    }\n    sDTDQuoted() {\n        const q = this.q;\n        if (this.captureToChar(q)) {\n            this.text += String.fromCodePoint(q);\n            this.state = S_DTD;\n            this.q = null;\n        }\n    }\n    sDTDOpenWaka() {\n        const c = this.getCodeNorm();\n        this.text += String.fromCodePoint(c);\n        switch (c) {\n            case BANG:\n                this.state = S_DTD_OPEN_WAKA_BANG;\n                this.openWakaBang = \"\";\n                break;\n            case QUESTION:\n                this.state = S_DTD_PI;\n                break;\n            default:\n                this.state = S_DTD;\n        }\n    }\n    sDTDOpenWakaBang() {\n        const char = String.fromCodePoint(this.getCodeNorm());\n        const owb = this.openWakaBang += char;\n        this.text += char;\n        if (owb !== \"-\") {\n            this.state = owb === \"--\" ? S_DTD_COMMENT : S_DTD;\n            this.openWakaBang = \"\";\n        }\n    }\n    sDTDComment() {\n        if (this.captureToChar(MINUS)) {\n            this.text += \"-\";\n            this.state = S_DTD_COMMENT_ENDING;\n        }\n    }\n    sDTDCommentEnding() {\n        const c = this.getCodeNorm();\n        this.text += String.fromCodePoint(c);\n        this.state = c === MINUS ? S_DTD_COMMENT_ENDED : S_DTD_COMMENT;\n    }\n    sDTDCommentEnded() {\n        const c = this.getCodeNorm();\n        this.text += String.fromCodePoint(c);\n        if (c === GREATER) {\n            this.state = S_DTD;\n        }\n        else {\n            this.fail(\"malformed comment.\");\n            // <!-- blah -- bloo --> will be recorded as\n            // a comment of \" blah -- bloo \"\n            this.state = S_DTD_COMMENT;\n        }\n    }\n    sDTDPI() {\n        if (this.captureToChar(QUESTION)) {\n            this.text += \"?\";\n            this.state = S_DTD_PI_ENDING;\n        }\n    }\n    sDTDPIEnding() {\n        const c = this.getCodeNorm();\n        this.text += String.fromCodePoint(c);\n        if (c === GREATER) {\n            this.state = S_DTD;\n        }\n    }\n    sText() {\n        //\n        // We did try a version of saxes where the S_TEXT state was split in two\n        // states: one for text inside the root element, and one for text\n        // outside. This was avoiding having to test this.tags.length to decide\n        // what implementation to actually use.\n        //\n        // Peformance testing on gigabyte-size files did not show any advantage to\n        // using the two states solution instead of the current one. Conversely, it\n        // made the code a bit more complicated elsewhere. For instance, a comment\n        // can appear before the root element so when a comment ended it was\n        // necessary to determine whether to return to the S_TEXT state or to the\n        // new text-outside-root state.\n        //\n        if (this.tags.length !== 0) {\n            this.handleTextInRoot();\n        }\n        else {\n            this.handleTextOutsideRoot();\n        }\n    }\n    sEntity() {\n        // This is essentially a specialized version of captureToChar(SEMICOLON...)\n        let { i: start } = this;\n        const { chunk } = this;\n        // eslint-disable-next-line no-labels, no-restricted-syntax\n        loop: \n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            switch (this.getCode()) {\n                case NL_LIKE:\n                    this.entity += `${chunk.slice(start, this.prevI)}\\n`;\n                    start = this.i;\n                    break;\n                case SEMICOLON: {\n                    const { entityReturnState } = this;\n                    const entity = this.entity + chunk.slice(start, this.prevI);\n                    this.state = entityReturnState;\n                    let parsed;\n                    if (entity === \"\") {\n                        this.fail(\"empty entity name.\");\n                        parsed = \"&;\";\n                    }\n                    else {\n                        parsed = this.parseEntity(entity);\n                        this.entity = \"\";\n                    }\n                    if (entityReturnState !== S_TEXT || this.textHandler !== undefined) {\n                        this.text += parsed;\n                    }\n                    // eslint-disable-next-line no-labels\n                    break loop;\n                }\n                case EOC:\n                    this.entity += chunk.slice(start);\n                    // eslint-disable-next-line no-labels\n                    break loop;\n                default:\n            }\n        }\n    }\n    sOpenWaka() {\n        // Reminder: a state handler is called with at least one character\n        // available in the current chunk. So the first call to get code inside of\n        // a state handler cannot return ``EOC``. That's why we don't test\n        // for it.\n        const c = this.getCode();\n        // either a /, ?, !, or text is coming next.\n        if (isNameStartChar(c)) {\n            this.state = S_OPEN_TAG;\n            this.unget();\n            this.xmlDeclPossible = false;\n        }\n        else {\n            switch (c) {\n                case FORWARD_SLASH:\n                    this.state = S_CLOSE_TAG;\n                    this.xmlDeclPossible = false;\n                    break;\n                case BANG:\n                    this.state = S_OPEN_WAKA_BANG;\n                    this.openWakaBang = \"\";\n                    this.xmlDeclPossible = false;\n                    break;\n                case QUESTION:\n                    this.state = S_PI_FIRST_CHAR;\n                    break;\n                default:\n                    this.fail(\"disallowed character in tag name\");\n                    this.state = S_TEXT;\n                    this.xmlDeclPossible = false;\n            }\n        }\n    }\n    sOpenWakaBang() {\n        this.openWakaBang += String.fromCodePoint(this.getCodeNorm());\n        switch (this.openWakaBang) {\n            case \"[CDATA[\":\n                if (!this.sawRoot && !this.reportedTextBeforeRoot) {\n                    this.fail(\"text data outside of root node.\");\n                    this.reportedTextBeforeRoot = true;\n                }\n                if (this.closedRoot && !this.reportedTextAfterRoot) {\n                    this.fail(\"text data outside of root node.\");\n                    this.reportedTextAfterRoot = true;\n                }\n                this.state = S_CDATA;\n                this.openWakaBang = \"\";\n                break;\n            case \"--\":\n                this.state = S_COMMENT;\n                this.openWakaBang = \"\";\n                break;\n            case \"DOCTYPE\":\n                this.state = S_DOCTYPE;\n                if (this.doctype || this.sawRoot) {\n                    this.fail(\"inappropriately located doctype declaration.\");\n                }\n                this.openWakaBang = \"\";\n                break;\n            default:\n                // 7 happens to be the maximum length of the string that can possibly\n                // match one of the cases above.\n                if (this.openWakaBang.length >= 7) {\n                    this.fail(\"incorrect syntax.\");\n                }\n        }\n    }\n    sComment() {\n        if (this.captureToChar(MINUS)) {\n            this.state = S_COMMENT_ENDING;\n        }\n    }\n    sCommentEnding() {\n        var _a;\n        const c = this.getCodeNorm();\n        if (c === MINUS) {\n            this.state = S_COMMENT_ENDED;\n            (_a = this.commentHandler) === null || _a === void 0 ? void 0 : _a.call(this, this.text);\n            this.text = \"\";\n        }\n        else {\n            this.text += `-${String.fromCodePoint(c)}`;\n            this.state = S_COMMENT;\n        }\n    }\n    sCommentEnded() {\n        const c = this.getCodeNorm();\n        if (c !== GREATER) {\n            this.fail(\"malformed comment.\");\n            // <!-- blah -- bloo --> will be recorded as\n            // a comment of \" blah -- bloo \"\n            this.text += `--${String.fromCodePoint(c)}`;\n            this.state = S_COMMENT;\n        }\n        else {\n            this.state = S_TEXT;\n        }\n    }\n    sCData() {\n        if (this.captureToChar(CLOSE_BRACKET)) {\n            this.state = S_CDATA_ENDING;\n        }\n    }\n    sCDataEnding() {\n        const c = this.getCodeNorm();\n        if (c === CLOSE_BRACKET) {\n            this.state = S_CDATA_ENDING_2;\n        }\n        else {\n            this.text += `]${String.fromCodePoint(c)}`;\n            this.state = S_CDATA;\n        }\n    }\n    sCDataEnding2() {\n        var _a;\n        const c = this.getCodeNorm();\n        switch (c) {\n            case GREATER: {\n                (_a = this.cdataHandler) === null || _a === void 0 ? void 0 : _a.call(this, this.text);\n                this.text = \"\";\n                this.state = S_TEXT;\n                break;\n            }\n            case CLOSE_BRACKET:\n                this.text += \"]\";\n                break;\n            default:\n                this.text += `]]${String.fromCodePoint(c)}`;\n                this.state = S_CDATA;\n        }\n    }\n    // We need this separate state to check the first character fo the pi target\n    // with this.nameStartCheck which allows less characters than this.nameCheck.\n    sPIFirstChar() {\n        const c = this.getCodeNorm();\n        // This is first because in the case where the file is well-formed this is\n        // the branch taken. We optimize for well-formedness.\n        if (this.nameStartCheck(c)) {\n            this.piTarget += String.fromCodePoint(c);\n            this.state = S_PI_REST;\n        }\n        else if (c === QUESTION || isS(c)) {\n            this.fail(\"processing instruction without a target.\");\n            this.state = c === QUESTION ? S_PI_ENDING : S_PI_BODY;\n        }\n        else {\n            this.fail(\"disallowed character in processing instruction name.\");\n            this.piTarget += String.fromCodePoint(c);\n            this.state = S_PI_REST;\n        }\n    }\n    sPIRest() {\n        // Capture characters into a piTarget while ``this.nameCheck`` run on the\n        // character read returns true.\n        const { chunk, i: start } = this;\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            const c = this.getCodeNorm();\n            if (c === EOC) {\n                this.piTarget += chunk.slice(start);\n                return;\n            }\n            // NL cannot satisfy this.nameCheck so we don't have to test specifically\n            // for it.\n            if (!this.nameCheck(c)) {\n                this.piTarget += chunk.slice(start, this.prevI);\n                const isQuestion = c === QUESTION;\n                if (isQuestion || isS(c)) {\n                    if (this.piTarget === \"xml\") {\n                        if (!this.xmlDeclPossible) {\n                            this.fail(\"an XML declaration must be at the start of the document.\");\n                        }\n                        this.state = isQuestion ? S_XML_DECL_ENDING : S_XML_DECL_NAME_START;\n                    }\n                    else {\n                        this.state = isQuestion ? S_PI_ENDING : S_PI_BODY;\n                    }\n                }\n                else {\n                    this.fail(\"disallowed character in processing instruction name.\");\n                    this.piTarget += String.fromCodePoint(c);\n                }\n                break;\n            }\n        }\n    }\n    sPIBody() {\n        if (this.text.length === 0) {\n            const c = this.getCodeNorm();\n            if (c === QUESTION) {\n                this.state = S_PI_ENDING;\n            }\n            else if (!isS(c)) {\n                this.text = String.fromCodePoint(c);\n            }\n        }\n        // The question mark character is not valid inside any of the XML\n        // declaration name/value pairs.\n        else if (this.captureToChar(QUESTION)) {\n            this.state = S_PI_ENDING;\n        }\n    }\n    sPIEnding() {\n        var _a;\n        const c = this.getCodeNorm();\n        if (c === GREATER) {\n            const { piTarget } = this;\n            if (piTarget.toLowerCase() === \"xml\") {\n                this.fail(\"the XML declaration must appear at the start of the document.\");\n            }\n            (_a = this.piHandler) === null || _a === void 0 ? void 0 : _a.call(this, {\n                target: piTarget,\n                body: this.text,\n            });\n            this.piTarget = this.text = \"\";\n            this.state = S_TEXT;\n        }\n        else if (c === QUESTION) {\n            // We ran into ?? as part of a processing instruction. We initially took\n            // the first ? as a sign that the PI was ending, but it is not. So we have\n            // to add it to the body but we take the new ? as a sign that the PI is\n            // ending.\n            this.text += \"?\";\n        }\n        else {\n            this.text += `?${String.fromCodePoint(c)}`;\n            this.state = S_PI_BODY;\n        }\n        this.xmlDeclPossible = false;\n    }\n    sXMLDeclNameStart() {\n        const c = this.skipSpaces();\n        // The question mark character is not valid inside any of the XML\n        // declaration name/value pairs.\n        if (c === QUESTION) {\n            // It is valid to go to S_XML_DECL_ENDING from this state.\n            this.state = S_XML_DECL_ENDING;\n            return;\n        }\n        if (c !== EOC) {\n            this.state = S_XML_DECL_NAME;\n            this.name = String.fromCodePoint(c);\n        }\n    }\n    sXMLDeclName() {\n        const c = this.captureTo(XML_DECL_NAME_TERMINATOR);\n        // The question mark character is not valid inside any of the XML\n        // declaration name/value pairs.\n        if (c === QUESTION) {\n            this.state = S_XML_DECL_ENDING;\n            this.name += this.text;\n            this.text = \"\";\n            this.fail(\"XML declaration is incomplete.\");\n            return;\n        }\n        if (!(isS(c) || c === EQUAL)) {\n            return;\n        }\n        this.name += this.text;\n        this.text = \"\";\n        if (!this.xmlDeclExpects.includes(this.name)) {\n            switch (this.name.length) {\n                case 0:\n                    this.fail(\"did not expect any more name/value pairs.\");\n                    break;\n                case 1:\n                    this.fail(`expected the name ${this.xmlDeclExpects[0]}.`);\n                    break;\n                default:\n                    this.fail(`expected one of ${this.xmlDeclExpects.join(\", \")}`);\n            }\n        }\n        this.state = c === EQUAL ? S_XML_DECL_VALUE_START : S_XML_DECL_EQ;\n    }\n    sXMLDeclEq() {\n        const c = this.getCodeNorm();\n        // The question mark character is not valid inside any of the XML\n        // declaration name/value pairs.\n        if (c === QUESTION) {\n            this.state = S_XML_DECL_ENDING;\n            this.fail(\"XML declaration is incomplete.\");\n            return;\n        }\n        if (isS(c)) {\n            return;\n        }\n        if (c !== EQUAL) {\n            this.fail(\"value required.\");\n        }\n        this.state = S_XML_DECL_VALUE_START;\n    }\n    sXMLDeclValueStart() {\n        const c = this.getCodeNorm();\n        // The question mark character is not valid inside any of the XML\n        // declaration name/value pairs.\n        if (c === QUESTION) {\n            this.state = S_XML_DECL_ENDING;\n            this.fail(\"XML declaration is incomplete.\");\n            return;\n        }\n        if (isS(c)) {\n            return;\n        }\n        if (!isQuote(c)) {\n            this.fail(\"value must be quoted.\");\n            this.q = SPACE;\n        }\n        else {\n            this.q = c;\n        }\n        this.state = S_XML_DECL_VALUE;\n    }\n    sXMLDeclValue() {\n        const c = this.captureTo([this.q, QUESTION]);\n        // The question mark character is not valid inside any of the XML\n        // declaration name/value pairs.\n        if (c === QUESTION) {\n            this.state = S_XML_DECL_ENDING;\n            this.text = \"\";\n            this.fail(\"XML declaration is incomplete.\");\n            return;\n        }\n        if (c === EOC) {\n            return;\n        }\n        const value = this.text;\n        this.text = \"\";\n        switch (this.name) {\n            case \"version\": {\n                this.xmlDeclExpects = [\"encoding\", \"standalone\"];\n                const version = value;\n                this.xmlDecl.version = version;\n                // This is the test specified by XML 1.0 but it is fine for XML 1.1.\n                if (!/^1\\.[0-9]+$/.test(version)) {\n                    this.fail(\"version number must match /^1\\\\.[0-9]+$/.\");\n                }\n                // When forceXMLVersion is set, the XML declaration is ignored.\n                else if (!this.opt.forceXMLVersion) {\n                    this.setXMLVersion(version);\n                }\n                break;\n            }\n            case \"encoding\":\n                if (!/^[A-Za-z][A-Za-z0-9._-]*$/.test(value)) {\n                    this.fail(\"encoding value must match \\\n/^[A-Za-z0-9][A-Za-z0-9._-]*$/.\");\n                }\n                this.xmlDeclExpects = [\"standalone\"];\n                this.xmlDecl.encoding = value;\n                break;\n            case \"standalone\":\n                if (value !== \"yes\" && value !== \"no\") {\n                    this.fail(\"standalone value must match \\\"yes\\\" or \\\"no\\\".\");\n                }\n                this.xmlDeclExpects = [];\n                this.xmlDecl.standalone = value;\n                break;\n            default:\n            // We don't need to raise an error here since we've already raised one\n            // when checking what name was expected.\n        }\n        this.name = \"\";\n        this.state = S_XML_DECL_SEPARATOR;\n    }\n    sXMLDeclSeparator() {\n        const c = this.getCodeNorm();\n        // The question mark character is not valid inside any of the XML\n        // declaration name/value pairs.\n        if (c === QUESTION) {\n            // It is valid to go to S_XML_DECL_ENDING from this state.\n            this.state = S_XML_DECL_ENDING;\n            return;\n        }\n        if (!isS(c)) {\n            this.fail(\"whitespace required.\");\n            this.unget();\n        }\n        this.state = S_XML_DECL_NAME_START;\n    }\n    sXMLDeclEnding() {\n        var _a;\n        const c = this.getCodeNorm();\n        if (c === GREATER) {\n            if (this.piTarget !== \"xml\") {\n                this.fail(\"processing instructions are not allowed before root.\");\n            }\n            else if (this.name !== \"version\" &&\n                this.xmlDeclExpects.includes(\"version\")) {\n                this.fail(\"XML declaration must contain a version.\");\n            }\n            (_a = this.xmldeclHandler) === null || _a === void 0 ? void 0 : _a.call(this, this.xmlDecl);\n            this.name = \"\";\n            this.piTarget = this.text = \"\";\n            this.state = S_TEXT;\n        }\n        else {\n            // We got here because the previous character was a ?, but the question\n            // mark character is not valid inside any of the XML declaration\n            // name/value pairs.\n            this.fail(\"The character ? is disallowed anywhere in XML declarations.\");\n        }\n        this.xmlDeclPossible = false;\n    }\n    sOpenTag() {\n        var _a;\n        const c = this.captureNameChars();\n        if (c === EOC) {\n            return;\n        }\n        const tag = this.tag = {\n            name: this.name,\n            attributes: Object.create(null),\n        };\n        this.name = \"\";\n        if (this.xmlnsOpt) {\n            this.topNS = tag.ns = Object.create(null);\n        }\n        (_a = this.openTagStartHandler) === null || _a === void 0 ? void 0 : _a.call(this, tag);\n        this.sawRoot = true;\n        if (!this.fragmentOpt && this.closedRoot) {\n            this.fail(\"documents may contain only one root.\");\n        }\n        switch (c) {\n            case GREATER:\n                this.openTag();\n                break;\n            case FORWARD_SLASH:\n                this.state = S_OPEN_TAG_SLASH;\n                break;\n            default:\n                if (!isS(c)) {\n                    this.fail(\"disallowed character in tag name.\");\n                }\n                this.state = S_ATTRIB;\n        }\n    }\n    sOpenTagSlash() {\n        if (this.getCode() === GREATER) {\n            this.openSelfClosingTag();\n        }\n        else {\n            this.fail(\"forward-slash in opening tag not followed by >.\");\n            this.state = S_ATTRIB;\n        }\n    }\n    sAttrib() {\n        const c = this.skipSpaces();\n        if (c === EOC) {\n            return;\n        }\n        if (isNameStartChar(c)) {\n            this.unget();\n            this.state = S_ATTRIB_NAME;\n        }\n        else if (c === GREATER) {\n            this.openTag();\n        }\n        else if (c === FORWARD_SLASH) {\n            this.state = S_OPEN_TAG_SLASH;\n        }\n        else {\n            this.fail(\"disallowed character in attribute name.\");\n        }\n    }\n    sAttribName() {\n        const c = this.captureNameChars();\n        if (c === EQUAL) {\n            this.state = S_ATTRIB_VALUE;\n        }\n        else if (isS(c)) {\n            this.state = S_ATTRIB_NAME_SAW_WHITE;\n        }\n        else if (c === GREATER) {\n            this.fail(\"attribute without value.\");\n            this.pushAttrib(this.name, this.name);\n            this.name = this.text = \"\";\n            this.openTag();\n        }\n        else if (c !== EOC) {\n            this.fail(\"disallowed character in attribute name.\");\n        }\n    }\n    sAttribNameSawWhite() {\n        const c = this.skipSpaces();\n        switch (c) {\n            case EOC:\n                return;\n            case EQUAL:\n                this.state = S_ATTRIB_VALUE;\n                break;\n            default:\n                this.fail(\"attribute without value.\");\n                // Should we do this???\n                // this.tag.attributes[this.name] = \"\";\n                this.text = \"\";\n                this.name = \"\";\n                if (c === GREATER) {\n                    this.openTag();\n                }\n                else if (isNameStartChar(c)) {\n                    this.unget();\n                    this.state = S_ATTRIB_NAME;\n                }\n                else {\n                    this.fail(\"disallowed character in attribute name.\");\n                    this.state = S_ATTRIB;\n                }\n        }\n    }\n    sAttribValue() {\n        const c = this.getCodeNorm();\n        if (isQuote(c)) {\n            this.q = c;\n            this.state = S_ATTRIB_VALUE_QUOTED;\n        }\n        else if (!isS(c)) {\n            this.fail(\"unquoted attribute value.\");\n            this.state = S_ATTRIB_VALUE_UNQUOTED;\n            this.unget();\n        }\n    }\n    sAttribValueQuoted() {\n        // We deliberately do not use captureTo here. The specialized code we use\n        // here is faster than using captureTo.\n        const { q, chunk } = this;\n        let { i: start } = this;\n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            switch (this.getCode()) {\n                case q:\n                    this.pushAttrib(this.name, this.text + chunk.slice(start, this.prevI));\n                    this.name = this.text = \"\";\n                    this.q = null;\n                    this.state = S_ATTRIB_VALUE_CLOSED;\n                    return;\n                case AMP:\n                    this.text += chunk.slice(start, this.prevI);\n                    this.state = S_ENTITY;\n                    this.entityReturnState = S_ATTRIB_VALUE_QUOTED;\n                    return;\n                case NL:\n                case NL_LIKE:\n                case TAB:\n                    this.text += `${chunk.slice(start, this.prevI)} `;\n                    start = this.i;\n                    break;\n                case LESS:\n                    this.text += chunk.slice(start, this.prevI);\n                    this.fail(\"disallowed character.\");\n                    return;\n                case EOC:\n                    this.text += chunk.slice(start);\n                    return;\n                default:\n            }\n        }\n    }\n    sAttribValueClosed() {\n        const c = this.getCodeNorm();\n        if (isS(c)) {\n            this.state = S_ATTRIB;\n        }\n        else if (c === GREATER) {\n            this.openTag();\n        }\n        else if (c === FORWARD_SLASH) {\n            this.state = S_OPEN_TAG_SLASH;\n        }\n        else if (isNameStartChar(c)) {\n            this.fail(\"no whitespace between attributes.\");\n            this.unget();\n            this.state = S_ATTRIB_NAME;\n        }\n        else {\n            this.fail(\"disallowed character in attribute name.\");\n        }\n    }\n    sAttribValueUnquoted() {\n        // We don't do anything regarding EOL or space handling for unquoted\n        // attributes. We already have failed by the time we get here, and the\n        // contract that saxes upholds states that upon failure, it is not safe to\n        // rely on the data passed to event handlers (other than\n        // ``onerror``). Passing \"bad\" data is not a problem.\n        const c = this.captureTo(ATTRIB_VALUE_UNQUOTED_TERMINATOR);\n        switch (c) {\n            case AMP:\n                this.state = S_ENTITY;\n                this.entityReturnState = S_ATTRIB_VALUE_UNQUOTED;\n                break;\n            case LESS:\n                this.fail(\"disallowed character.\");\n                break;\n            case EOC:\n                break;\n            default:\n                if (this.text.includes(\"]]>\")) {\n                    this.fail(\"the string \\\"]]>\\\" is disallowed in char data.\");\n                }\n                this.pushAttrib(this.name, this.text);\n                this.name = this.text = \"\";\n                if (c === GREATER) {\n                    this.openTag();\n                }\n                else {\n                    this.state = S_ATTRIB;\n                }\n        }\n    }\n    sCloseTag() {\n        const c = this.captureNameChars();\n        if (c === GREATER) {\n            this.closeTag();\n        }\n        else if (isS(c)) {\n            this.state = S_CLOSE_TAG_SAW_WHITE;\n        }\n        else if (c !== EOC) {\n            this.fail(\"disallowed character in closing tag.\");\n        }\n    }\n    sCloseTagSawWhite() {\n        switch (this.skipSpaces()) {\n            case GREATER:\n                this.closeTag();\n                break;\n            case EOC:\n                break;\n            default:\n                this.fail(\"disallowed character in closing tag.\");\n        }\n    }\n    // END OF STATE ENGINE METHODS\n    handleTextInRoot() {\n        // This is essentially a specialized version of captureTo which is optimized\n        // for performing the ]]> check. A previous version of this code, checked\n        // ``this.text`` for the presence of ]]>. It simplified the code but was\n        // very costly when character data contained a lot of entities to be parsed.\n        //\n        // Since we are using a specialized loop, we also keep track of the presence\n        // of ]]> in text data. The sequence ]]> is forbidden to appear as-is.\n        //\n        let { i: start, forbiddenState } = this;\n        const { chunk, textHandler: handler } = this;\n        // eslint-disable-next-line no-labels, no-restricted-syntax\n        scanLoop: \n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            switch (this.getCode()) {\n                case LESS: {\n                    this.state = S_OPEN_WAKA;\n                    if (handler !== undefined) {\n                        const { text } = this;\n                        const slice = chunk.slice(start, this.prevI);\n                        if (text.length !== 0) {\n                            handler(text + slice);\n                            this.text = \"\";\n                        }\n                        else if (slice.length !== 0) {\n                            handler(slice);\n                        }\n                    }\n                    forbiddenState = FORBIDDEN_START;\n                    // eslint-disable-next-line no-labels\n                    break scanLoop;\n                }\n                case AMP:\n                    this.state = S_ENTITY;\n                    this.entityReturnState = S_TEXT;\n                    if (handler !== undefined) {\n                        this.text += chunk.slice(start, this.prevI);\n                    }\n                    forbiddenState = FORBIDDEN_START;\n                    // eslint-disable-next-line no-labels\n                    break scanLoop;\n                case CLOSE_BRACKET:\n                    switch (forbiddenState) {\n                        case FORBIDDEN_START:\n                            forbiddenState = FORBIDDEN_BRACKET;\n                            break;\n                        case FORBIDDEN_BRACKET:\n                            forbiddenState = FORBIDDEN_BRACKET_BRACKET;\n                            break;\n                        case FORBIDDEN_BRACKET_BRACKET:\n                            break;\n                        default:\n                            throw new Error(\"impossible state\");\n                    }\n                    break;\n                case GREATER:\n                    if (forbiddenState === FORBIDDEN_BRACKET_BRACKET) {\n                        this.fail(\"the string \\\"]]>\\\" is disallowed in char data.\");\n                    }\n                    forbiddenState = FORBIDDEN_START;\n                    break;\n                case NL_LIKE:\n                    if (handler !== undefined) {\n                        this.text += `${chunk.slice(start, this.prevI)}\\n`;\n                    }\n                    start = this.i;\n                    forbiddenState = FORBIDDEN_START;\n                    break;\n                case EOC:\n                    if (handler !== undefined) {\n                        this.text += chunk.slice(start);\n                    }\n                    // eslint-disable-next-line no-labels\n                    break scanLoop;\n                default:\n                    forbiddenState = FORBIDDEN_START;\n            }\n        }\n        this.forbiddenState = forbiddenState;\n    }\n    handleTextOutsideRoot() {\n        // This is essentially a specialized version of captureTo which is optimized\n        // for a specialized task. We keep track of the presence of non-space\n        // characters in the text since these are errors when appearing outside the\n        // document root element.\n        let { i: start } = this;\n        const { chunk, textHandler: handler } = this;\n        let nonSpace = false;\n        // eslint-disable-next-line no-labels, no-restricted-syntax\n        outRootLoop: \n        // eslint-disable-next-line no-constant-condition\n        while (true) {\n            const code = this.getCode();\n            switch (code) {\n                case LESS: {\n                    this.state = S_OPEN_WAKA;\n                    if (handler !== undefined) {\n                        const { text } = this;\n                        const slice = chunk.slice(start, this.prevI);\n                        if (text.length !== 0) {\n                            handler(text + slice);\n                            this.text = \"\";\n                        }\n                        else if (slice.length !== 0) {\n                            handler(slice);\n                        }\n                    }\n                    // eslint-disable-next-line no-labels\n                    break outRootLoop;\n                }\n                case AMP:\n                    this.state = S_ENTITY;\n                    this.entityReturnState = S_TEXT;\n                    if (handler !== undefined) {\n                        this.text += chunk.slice(start, this.prevI);\n                    }\n                    nonSpace = true;\n                    // eslint-disable-next-line no-labels\n                    break outRootLoop;\n                case NL_LIKE:\n                    if (handler !== undefined) {\n                        this.text += `${chunk.slice(start, this.prevI)}\\n`;\n                    }\n                    start = this.i;\n                    break;\n                case EOC:\n                    if (handler !== undefined) {\n                        this.text += chunk.slice(start);\n                    }\n                    // eslint-disable-next-line no-labels\n                    break outRootLoop;\n                default:\n                    if (!isS(code)) {\n                        nonSpace = true;\n                    }\n            }\n        }\n        if (!nonSpace) {\n            return;\n        }\n        // We use the reportedTextBeforeRoot and reportedTextAfterRoot flags\n        // to avoid reporting errors for every single character that is out of\n        // place.\n        if (!this.sawRoot && !this.reportedTextBeforeRoot) {\n            this.fail(\"text data outside of root node.\");\n            this.reportedTextBeforeRoot = true;\n        }\n        if (this.closedRoot && !this.reportedTextAfterRoot) {\n            this.fail(\"text data outside of root node.\");\n            this.reportedTextAfterRoot = true;\n        }\n    }\n    pushAttribNS(name, value) {\n        var _a;\n        const { prefix, local } = this.qname(name);\n        const attr = { name, prefix, local, value };\n        this.attribList.push(attr);\n        (_a = this.attributeHandler) === null || _a === void 0 ? void 0 : _a.call(this, attr);\n        if (prefix === \"xmlns\") {\n            const trimmed = value.trim();\n            if (this.currentXMLVersion === \"1.0\" && trimmed === \"\") {\n                this.fail(\"invalid attempt to undefine prefix in XML 1.0\");\n            }\n            this.topNS[local] = trimmed;\n            nsPairCheck(this, local, trimmed);\n        }\n        else if (name === \"xmlns\") {\n            const trimmed = value.trim();\n            this.topNS[\"\"] = trimmed;\n            nsPairCheck(this, \"\", trimmed);\n        }\n    }\n    pushAttribPlain(name, value) {\n        var _a;\n        const attr = { name, value };\n        this.attribList.push(attr);\n        (_a = this.attributeHandler) === null || _a === void 0 ? void 0 : _a.call(this, attr);\n    }\n    /**\n     * End parsing. This performs final well-formedness checks and resets the\n     * parser to a clean state.\n     *\n     * @returns this\n     */\n    end() {\n        var _a, _b;\n        if (!this.sawRoot) {\n            this.fail(\"document must contain a root element.\");\n        }\n        const { tags } = this;\n        while (tags.length > 0) {\n            const tag = tags.pop();\n            this.fail(`unclosed tag: ${tag.name}`);\n        }\n        if ((this.state !== S_BEGIN) && (this.state !== S_TEXT)) {\n            this.fail(\"unexpected end.\");\n        }\n        const { text } = this;\n        if (text.length !== 0) {\n            (_a = this.textHandler) === null || _a === void 0 ? void 0 : _a.call(this, text);\n            this.text = \"\";\n        }\n        this._closed = true;\n        (_b = this.endHandler) === null || _b === void 0 ? void 0 : _b.call(this);\n        this._init();\n        return this;\n    }\n    /**\n     * Resolve a namespace prefix.\n     *\n     * @param prefix The prefix to resolve.\n     *\n     * @returns The namespace URI or ``undefined`` if the prefix is not defined.\n     */\n    resolve(prefix) {\n        var _a, _b;\n        let uri = this.topNS[prefix];\n        if (uri !== undefined) {\n            return uri;\n        }\n        const { tags } = this;\n        for (let index = tags.length - 1; index >= 0; index--) {\n            uri = tags[index].ns[prefix];\n            if (uri !== undefined) {\n                return uri;\n            }\n        }\n        uri = this.ns[prefix];\n        if (uri !== undefined) {\n            return uri;\n        }\n        return (_b = (_a = this.opt).resolvePrefix) === null || _b === void 0 ? void 0 : _b.call(_a, prefix);\n    }\n    /**\n     * Parse a qname into its prefix and local name parts.\n     *\n     * @param name The name to parse\n     *\n     * @returns\n     */\n    qname(name) {\n        // This is faster than using name.split(\":\").\n        const colon = name.indexOf(\":\");\n        if (colon === -1) {\n            return { prefix: \"\", local: name };\n        }\n        const local = name.slice(colon + 1);\n        const prefix = name.slice(0, colon);\n        if (prefix === \"\" || local === \"\" || local.includes(\":\")) {\n            this.fail(`malformed name: ${name}.`);\n        }\n        return { prefix, local };\n    }\n    processAttribsNS() {\n        var _a;\n        const { attribList } = this;\n        const tag = this.tag;\n        {\n            // add namespace info to tag\n            const { prefix, local } = this.qname(tag.name);\n            tag.prefix = prefix;\n            tag.local = local;\n            const uri = tag.uri = (_a = this.resolve(prefix)) !== null && _a !== void 0 ? _a : \"\";\n            if (prefix !== \"\") {\n                if (prefix === \"xmlns\") {\n                    this.fail(\"tags may not have \\\"xmlns\\\" as prefix.\");\n                }\n                if (uri === \"\") {\n                    this.fail(`unbound namespace prefix: ${JSON.stringify(prefix)}.`);\n                    tag.uri = prefix;\n                }\n            }\n        }\n        if (attribList.length === 0) {\n            return;\n        }\n        const { attributes } = tag;\n        const seen = new Set();\n        // Note: do not apply default ns to attributes:\n        //   http://www.w3.org/TR/REC-xml-names/#defaulting\n        for (const attr of attribList) {\n            const { name, prefix, local } = attr;\n            let uri;\n            let eqname;\n            if (prefix === \"\") {\n                uri = name === \"xmlns\" ? XMLNS_NAMESPACE : \"\";\n                eqname = name;\n            }\n            else {\n                uri = this.resolve(prefix);\n                // if there's any attributes with an undefined namespace,\n                // then fail on them now.\n                if (uri === undefined) {\n                    this.fail(`unbound namespace prefix: ${JSON.stringify(prefix)}.`);\n                    uri = prefix;\n                }\n                eqname = `{${uri}}${local}`;\n            }\n            if (seen.has(eqname)) {\n                this.fail(`duplicate attribute: ${eqname}.`);\n            }\n            seen.add(eqname);\n            attr.uri = uri;\n            attributes[name] = attr;\n        }\n        this.attribList = [];\n    }\n    processAttribsPlain() {\n        const { attribList } = this;\n        // eslint-disable-next-line prefer-destructuring\n        const attributes = this.tag.attributes;\n        for (const { name, value } of attribList) {\n            if (attributes[name] !== undefined) {\n                this.fail(`duplicate attribute: ${name}.`);\n            }\n            attributes[name] = value;\n        }\n        this.attribList = [];\n    }\n    /**\n     * Handle a complete open tag. This parser code calls this once it has seen\n     * the whole tag. This method checks for well-formeness and then emits\n     * ``onopentag``.\n     */\n    openTag() {\n        var _a;\n        this.processAttribs();\n        const { tags } = this;\n        const tag = this.tag;\n        tag.isSelfClosing = false;\n        // There cannot be any pending text here due to the onopentagstart that was\n        // necessarily emitted before we get here. So we do not check text.\n        (_a = this.openTagHandler) === null || _a === void 0 ? void 0 : _a.call(this, tag);\n        tags.push(tag);\n        this.state = S_TEXT;\n        this.name = \"\";\n    }\n    /**\n     * Handle a complete self-closing tag. This parser code calls this once it has\n     * seen the whole tag. This method checks for well-formeness and then emits\n     * ``onopentag`` and ``onclosetag``.\n     */\n    openSelfClosingTag() {\n        var _a, _b, _c;\n        this.processAttribs();\n        const { tags } = this;\n        const tag = this.tag;\n        tag.isSelfClosing = true;\n        // There cannot be any pending text here due to the onopentagstart that was\n        // necessarily emitted before we get here. So we do not check text.\n        (_a = this.openTagHandler) === null || _a === void 0 ? void 0 : _a.call(this, tag);\n        (_b = this.closeTagHandler) === null || _b === void 0 ? void 0 : _b.call(this, tag);\n        const top = this.tag = (_c = tags[tags.length - 1]) !== null && _c !== void 0 ? _c : null;\n        if (top === null) {\n            this.closedRoot = true;\n        }\n        this.state = S_TEXT;\n        this.name = \"\";\n    }\n    /**\n     * Handle a complete close tag. This parser code calls this once it has seen\n     * the whole tag. This method checks for well-formeness and then emits\n     * ``onclosetag``.\n     */\n    closeTag() {\n        const { tags, name } = this;\n        // Our state after this will be S_TEXT, no matter what, and we can clear\n        // tagName now.\n        this.state = S_TEXT;\n        this.name = \"\";\n        if (name === \"\") {\n            this.fail(\"weird empty close tag.\");\n            this.text += \"</>\";\n            return;\n        }\n        const handler = this.closeTagHandler;\n        let l = tags.length;\n        while (l-- > 0) {\n            const tag = this.tag = tags.pop();\n            this.topNS = tag.ns;\n            handler === null || handler === void 0 ? void 0 : handler(tag);\n            if (tag.name === name) {\n                break;\n            }\n            this.fail(\"unexpected close tag.\");\n        }\n        if (l === 0) {\n            this.closedRoot = true;\n        }\n        else if (l < 0) {\n            this.fail(`unmatched closing tag: ${name}.`);\n            this.text += `</${name}>`;\n        }\n    }\n    /**\n     * Resolves an entity. Makes any necessary well-formedness checks.\n     *\n     * @param entity The entity to resolve.\n     *\n     * @returns The parsed entity.\n     */\n    parseEntity(entity) {\n        // startsWith would be significantly slower for this test.\n        if (entity[0] !== \"#\") {\n            const defined = this.ENTITIES[entity];\n            if (defined !== undefined) {\n                return defined;\n            }\n            this.fail(this.isName(entity) ? \"undefined entity.\" :\n                \"disallowed character in entity name.\");\n            return `&${entity};`;\n        }\n        let num = NaN;\n        if (entity[1] === \"x\" && /^#x[0-9a-f]+$/i.test(entity)) {\n            num = parseInt(entity.slice(2), 16);\n        }\n        else if (/^#[0-9]+$/.test(entity)) {\n            num = parseInt(entity.slice(1), 10);\n        }\n        // The character reference is required to match the CHAR production.\n        if (!this.isChar(num)) {\n            this.fail(\"malformed character entity.\");\n            return `&${entity};`;\n        }\n        return String.fromCodePoint(num);\n    }\n}\nexports.SaxesParser = SaxesParser;\n//# sourceMappingURL=saxes.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rubensworks/saxes/saxes.js?");

/***/ }),

/***/ "./node_modules/abort-controller/browser.js":
/*!**************************************************!*\
  !*** ./node_modules/abort-controller/browser.js ***!
  \**************************************************/
/***/ ((module) => {

"use strict";
eval("/*globals self, window */\n\n\n/*eslint-disable @mysticatea/prettier */\nconst { AbortController, AbortSignal } =\n    typeof self !== \"undefined\" ? self :\n    typeof window !== \"undefined\" ? window :\n    /* otherwise */ undefined\n/*eslint-enable @mysticatea/prettier */\n\nmodule.exports = AbortController\nmodule.exports.AbortSignal = AbortSignal\nmodule.exports[\"default\"] = AbortController\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/abort-controller/browser.js?");

/***/ }),

/***/ "./node_modules/base64-js/index.js":
/*!*****************************************!*\
  !*** ./node_modules/base64-js/index.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\nexports.byteLength = byteLength\nexports.toByteArray = toByteArray\nexports.fromByteArray = fromByteArray\n\nvar lookup = []\nvar revLookup = []\nvar Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array\n\nvar code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\nfor (var i = 0, len = code.length; i < len; ++i) {\n  lookup[i] = code[i]\n  revLookup[code.charCodeAt(i)] = i\n}\n\n// Support decoding URL-safe base64 strings, as Node.js does.\n// See: https://en.wikipedia.org/wiki/Base64#URL_applications\nrevLookup['-'.charCodeAt(0)] = 62\nrevLookup['_'.charCodeAt(0)] = 63\n\nfunction getLens (b64) {\n  var len = b64.length\n\n  if (len % 4 > 0) {\n    throw new Error('Invalid string. Length must be a multiple of 4')\n  }\n\n  // Trim off extra bytes after placeholder bytes are found\n  // See: https://github.com/beatgammit/base64-js/issues/42\n  var validLen = b64.indexOf('=')\n  if (validLen === -1) validLen = len\n\n  var placeHoldersLen = validLen === len\n    ? 0\n    : 4 - (validLen % 4)\n\n  return [validLen, placeHoldersLen]\n}\n\n// base64 is 4/3 + up to two characters of the original data\nfunction byteLength (b64) {\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction _byteLength (b64, validLen, placeHoldersLen) {\n  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen\n}\n\nfunction toByteArray (b64) {\n  var tmp\n  var lens = getLens(b64)\n  var validLen = lens[0]\n  var placeHoldersLen = lens[1]\n\n  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))\n\n  var curByte = 0\n\n  // if there are placeholders, only get up to the last complete 4 chars\n  var len = placeHoldersLen > 0\n    ? validLen - 4\n    : validLen\n\n  var i\n  for (i = 0; i < len; i += 4) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 18) |\n      (revLookup[b64.charCodeAt(i + 1)] << 12) |\n      (revLookup[b64.charCodeAt(i + 2)] << 6) |\n      revLookup[b64.charCodeAt(i + 3)]\n    arr[curByte++] = (tmp >> 16) & 0xFF\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 2) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 2) |\n      (revLookup[b64.charCodeAt(i + 1)] >> 4)\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  if (placeHoldersLen === 1) {\n    tmp =\n      (revLookup[b64.charCodeAt(i)] << 10) |\n      (revLookup[b64.charCodeAt(i + 1)] << 4) |\n      (revLookup[b64.charCodeAt(i + 2)] >> 2)\n    arr[curByte++] = (tmp >> 8) & 0xFF\n    arr[curByte++] = tmp & 0xFF\n  }\n\n  return arr\n}\n\nfunction tripletToBase64 (num) {\n  return lookup[num >> 18 & 0x3F] +\n    lookup[num >> 12 & 0x3F] +\n    lookup[num >> 6 & 0x3F] +\n    lookup[num & 0x3F]\n}\n\nfunction encodeChunk (uint8, start, end) {\n  var tmp\n  var output = []\n  for (var i = start; i < end; i += 3) {\n    tmp =\n      ((uint8[i] << 16) & 0xFF0000) +\n      ((uint8[i + 1] << 8) & 0xFF00) +\n      (uint8[i + 2] & 0xFF)\n    output.push(tripletToBase64(tmp))\n  }\n  return output.join('')\n}\n\nfunction fromByteArray (uint8) {\n  var tmp\n  var len = uint8.length\n  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes\n  var parts = []\n  var maxChunkLength = 16383 // must be multiple of 3\n\n  // go through the array every three bytes, we'll deal with trailing stuff later\n  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {\n    parts.push(encodeChunk(uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)))\n  }\n\n  // pad the end with zeros, but make sure to not forget the extra bytes\n  if (extraBytes === 1) {\n    tmp = uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 2] +\n      lookup[(tmp << 4) & 0x3F] +\n      '=='\n    )\n  } else if (extraBytes === 2) {\n    tmp = (uint8[len - 2] << 8) + uint8[len - 1]\n    parts.push(\n      lookup[tmp >> 10] +\n      lookup[(tmp >> 4) & 0x3F] +\n      lookup[(tmp << 2) & 0x3F] +\n      '='\n    )\n  }\n\n  return parts.join('')\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/base64-js/index.js?");

/***/ }),

/***/ "./node_modules/buffer/index.js":
/*!**************************************!*\
  !*** ./node_modules/buffer/index.js ***!
  \**************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("/*!\n * The buffer module from node.js, for the browser.\n *\n * @author   Feross Aboukhadijeh <https://feross.org>\n * @license  MIT\n */\n/* eslint-disable no-proto */\n\n\n\nconst base64 = __webpack_require__(/*! base64-js */ \"./node_modules/base64-js/index.js\")\nconst ieee754 = __webpack_require__(/*! ieee754 */ \"./node_modules/ieee754/index.js\")\nconst customInspectSymbol =\n  (typeof Symbol === 'function' && typeof Symbol['for'] === 'function') // eslint-disable-line dot-notation\n    ? Symbol['for']('nodejs.util.inspect.custom') // eslint-disable-line dot-notation\n    : null\n\nexports.Buffer = Buffer\nexports.SlowBuffer = SlowBuffer\nexports.INSPECT_MAX_BYTES = 50\n\nconst K_MAX_LENGTH = 0x7fffffff\nexports.kMaxLength = K_MAX_LENGTH\n\n/**\n * If `Buffer.TYPED_ARRAY_SUPPORT`:\n *   === true    Use Uint8Array implementation (fastest)\n *   === false   Print warning and recommend using `buffer` v4.x which has an Object\n *               implementation (most compatible, even IE6)\n *\n * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,\n * Opera 11.6+, iOS 4.2+.\n *\n * We report that the browser does not support typed arrays if the are not subclassable\n * using __proto__. Firefox 4-29 lacks support for adding new properties to `Uint8Array`\n * (See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438). IE 10 lacks support\n * for __proto__ and has a buggy typed array implementation.\n */\nBuffer.TYPED_ARRAY_SUPPORT = typedArraySupport()\n\nif (!Buffer.TYPED_ARRAY_SUPPORT && typeof console !== 'undefined' &&\n    typeof console.error === 'function') {\n  console.error(\n    'This browser lacks typed array (Uint8Array) support which is required by ' +\n    '`buffer` v5.x. Use `buffer` v4.x if you require old browser support.'\n  )\n}\n\nfunction typedArraySupport () {\n  // Can typed array instances can be augmented?\n  try {\n    const arr = new Uint8Array(1)\n    const proto = { foo: function () { return 42 } }\n    Object.setPrototypeOf(proto, Uint8Array.prototype)\n    Object.setPrototypeOf(arr, proto)\n    return arr.foo() === 42\n  } catch (e) {\n    return false\n  }\n}\n\nObject.defineProperty(Buffer.prototype, 'parent', {\n  enumerable: true,\n  get: function () {\n    if (!Buffer.isBuffer(this)) return undefined\n    return this.buffer\n  }\n})\n\nObject.defineProperty(Buffer.prototype, 'offset', {\n  enumerable: true,\n  get: function () {\n    if (!Buffer.isBuffer(this)) return undefined\n    return this.byteOffset\n  }\n})\n\nfunction createBuffer (length) {\n  if (length > K_MAX_LENGTH) {\n    throw new RangeError('The value \"' + length + '\" is invalid for option \"size\"')\n  }\n  // Return an augmented `Uint8Array` instance\n  const buf = new Uint8Array(length)\n  Object.setPrototypeOf(buf, Buffer.prototype)\n  return buf\n}\n\n/**\n * The Buffer constructor returns instances of `Uint8Array` that have their\n * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of\n * `Uint8Array`, so the returned instances will have all the node `Buffer` methods\n * and the `Uint8Array` methods. Square bracket notation works as expected -- it\n * returns a single octet.\n *\n * The `Uint8Array` prototype remains unmodified.\n */\n\nfunction Buffer (arg, encodingOrOffset, length) {\n  // Common case.\n  if (typeof arg === 'number') {\n    if (typeof encodingOrOffset === 'string') {\n      throw new TypeError(\n        'The \"string\" argument must be of type string. Received type number'\n      )\n    }\n    return allocUnsafe(arg)\n  }\n  return from(arg, encodingOrOffset, length)\n}\n\nBuffer.poolSize = 8192 // not used by this implementation\n\nfunction from (value, encodingOrOffset, length) {\n  if (typeof value === 'string') {\n    return fromString(value, encodingOrOffset)\n  }\n\n  if (ArrayBuffer.isView(value)) {\n    return fromArrayView(value)\n  }\n\n  if (value == null) {\n    throw new TypeError(\n      'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +\n      'or Array-like Object. Received type ' + (typeof value)\n    )\n  }\n\n  if (isInstance(value, ArrayBuffer) ||\n      (value && isInstance(value.buffer, ArrayBuffer))) {\n    return fromArrayBuffer(value, encodingOrOffset, length)\n  }\n\n  if (typeof SharedArrayBuffer !== 'undefined' &&\n      (isInstance(value, SharedArrayBuffer) ||\n      (value && isInstance(value.buffer, SharedArrayBuffer)))) {\n    return fromArrayBuffer(value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'number') {\n    throw new TypeError(\n      'The \"value\" argument must not be of type number. Received type number'\n    )\n  }\n\n  const valueOf = value.valueOf && value.valueOf()\n  if (valueOf != null && valueOf !== value) {\n    return Buffer.from(valueOf, encodingOrOffset, length)\n  }\n\n  const b = fromObject(value)\n  if (b) return b\n\n  if (typeof Symbol !== 'undefined' && Symbol.toPrimitive != null &&\n      typeof value[Symbol.toPrimitive] === 'function') {\n    return Buffer.from(value[Symbol.toPrimitive]('string'), encodingOrOffset, length)\n  }\n\n  throw new TypeError(\n    'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +\n    'or Array-like Object. Received type ' + (typeof value)\n  )\n}\n\n/**\n * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError\n * if value is a number.\n * Buffer.from(str[, encoding])\n * Buffer.from(array)\n * Buffer.from(buffer)\n * Buffer.from(arrayBuffer[, byteOffset[, length]])\n **/\nBuffer.from = function (value, encodingOrOffset, length) {\n  return from(value, encodingOrOffset, length)\n}\n\n// Note: Change prototype *after* Buffer.from is defined to workaround Chrome bug:\n// https://github.com/feross/buffer/pull/148\nObject.setPrototypeOf(Buffer.prototype, Uint8Array.prototype)\nObject.setPrototypeOf(Buffer, Uint8Array)\n\nfunction assertSize (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('\"size\" argument must be of type number')\n  } else if (size < 0) {\n    throw new RangeError('The value \"' + size + '\" is invalid for option \"size\"')\n  }\n}\n\nfunction alloc (size, fill, encoding) {\n  assertSize(size)\n  if (size <= 0) {\n    return createBuffer(size)\n  }\n  if (fill !== undefined) {\n    // Only pay attention to encoding if it's a string. This\n    // prevents accidentally sending in a number that would\n    // be interpreted as a start offset.\n    return typeof encoding === 'string'\n      ? createBuffer(size).fill(fill, encoding)\n      : createBuffer(size).fill(fill)\n  }\n  return createBuffer(size)\n}\n\n/**\n * Creates a new filled Buffer instance.\n * alloc(size[, fill[, encoding]])\n **/\nBuffer.alloc = function (size, fill, encoding) {\n  return alloc(size, fill, encoding)\n}\n\nfunction allocUnsafe (size) {\n  assertSize(size)\n  return createBuffer(size < 0 ? 0 : checked(size) | 0)\n}\n\n/**\n * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.\n * */\nBuffer.allocUnsafe = function (size) {\n  return allocUnsafe(size)\n}\n/**\n * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.\n */\nBuffer.allocUnsafeSlow = function (size) {\n  return allocUnsafe(size)\n}\n\nfunction fromString (string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('Unknown encoding: ' + encoding)\n  }\n\n  const length = byteLength(string, encoding) | 0\n  let buf = createBuffer(length)\n\n  const actual = buf.write(string, encoding)\n\n  if (actual !== length) {\n    // Writing a hex string, for example, that contains invalid characters will\n    // cause everything after the first invalid character to be ignored. (e.g.\n    // 'abxxcd' will be treated as 'ab')\n    buf = buf.slice(0, actual)\n  }\n\n  return buf\n}\n\nfunction fromArrayLike (array) {\n  const length = array.length < 0 ? 0 : checked(array.length) | 0\n  const buf = createBuffer(length)\n  for (let i = 0; i < length; i += 1) {\n    buf[i] = array[i] & 255\n  }\n  return buf\n}\n\nfunction fromArrayView (arrayView) {\n  if (isInstance(arrayView, Uint8Array)) {\n    const copy = new Uint8Array(arrayView)\n    return fromArrayBuffer(copy.buffer, copy.byteOffset, copy.byteLength)\n  }\n  return fromArrayLike(arrayView)\n}\n\nfunction fromArrayBuffer (array, byteOffset, length) {\n  if (byteOffset < 0 || array.byteLength < byteOffset) {\n    throw new RangeError('\"offset\" is outside of buffer bounds')\n  }\n\n  if (array.byteLength < byteOffset + (length || 0)) {\n    throw new RangeError('\"length\" is outside of buffer bounds')\n  }\n\n  let buf\n  if (byteOffset === undefined && length === undefined) {\n    buf = new Uint8Array(array)\n  } else if (length === undefined) {\n    buf = new Uint8Array(array, byteOffset)\n  } else {\n    buf = new Uint8Array(array, byteOffset, length)\n  }\n\n  // Return an augmented `Uint8Array` instance\n  Object.setPrototypeOf(buf, Buffer.prototype)\n\n  return buf\n}\n\nfunction fromObject (obj) {\n  if (Buffer.isBuffer(obj)) {\n    const len = checked(obj.length) | 0\n    const buf = createBuffer(len)\n\n    if (buf.length === 0) {\n      return buf\n    }\n\n    obj.copy(buf, 0, 0, len)\n    return buf\n  }\n\n  if (obj.length !== undefined) {\n    if (typeof obj.length !== 'number' || numberIsNaN(obj.length)) {\n      return createBuffer(0)\n    }\n    return fromArrayLike(obj)\n  }\n\n  if (obj.type === 'Buffer' && Array.isArray(obj.data)) {\n    return fromArrayLike(obj.data)\n  }\n}\n\nfunction checked (length) {\n  // Note: cannot use `length < K_MAX_LENGTH` here because that fails when\n  // length is NaN (which is otherwise coerced to zero.)\n  if (length >= K_MAX_LENGTH) {\n    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +\n                         'size: 0x' + K_MAX_LENGTH.toString(16) + ' bytes')\n  }\n  return length | 0\n}\n\nfunction SlowBuffer (length) {\n  if (+length != length) { // eslint-disable-line eqeqeq\n    length = 0\n  }\n  return Buffer.alloc(+length)\n}\n\nBuffer.isBuffer = function isBuffer (b) {\n  return b != null && b._isBuffer === true &&\n    b !== Buffer.prototype // so Buffer.isBuffer(Buffer.prototype) will be false\n}\n\nBuffer.compare = function compare (a, b) {\n  if (isInstance(a, Uint8Array)) a = Buffer.from(a, a.offset, a.byteLength)\n  if (isInstance(b, Uint8Array)) b = Buffer.from(b, b.offset, b.byteLength)\n  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {\n    throw new TypeError(\n      'The \"buf1\", \"buf2\" arguments must be one of type Buffer or Uint8Array'\n    )\n  }\n\n  if (a === b) return 0\n\n  let x = a.length\n  let y = b.length\n\n  for (let i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (a[i] !== b[i]) {\n      x = a[i]\n      y = b[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\nBuffer.isEncoding = function isEncoding (encoding) {\n  switch (String(encoding).toLowerCase()) {\n    case 'hex':\n    case 'utf8':\n    case 'utf-8':\n    case 'ascii':\n    case 'latin1':\n    case 'binary':\n    case 'base64':\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return true\n    default:\n      return false\n  }\n}\n\nBuffer.concat = function concat (list, length) {\n  if (!Array.isArray(list)) {\n    throw new TypeError('\"list\" argument must be an Array of Buffers')\n  }\n\n  if (list.length === 0) {\n    return Buffer.alloc(0)\n  }\n\n  let i\n  if (length === undefined) {\n    length = 0\n    for (i = 0; i < list.length; ++i) {\n      length += list[i].length\n    }\n  }\n\n  const buffer = Buffer.allocUnsafe(length)\n  let pos = 0\n  for (i = 0; i < list.length; ++i) {\n    let buf = list[i]\n    if (isInstance(buf, Uint8Array)) {\n      if (pos + buf.length > buffer.length) {\n        if (!Buffer.isBuffer(buf)) buf = Buffer.from(buf)\n        buf.copy(buffer, pos)\n      } else {\n        Uint8Array.prototype.set.call(\n          buffer,\n          buf,\n          pos\n        )\n      }\n    } else if (!Buffer.isBuffer(buf)) {\n      throw new TypeError('\"list\" argument must be an Array of Buffers')\n    } else {\n      buf.copy(buffer, pos)\n    }\n    pos += buf.length\n  }\n  return buffer\n}\n\nfunction byteLength (string, encoding) {\n  if (Buffer.isBuffer(string)) {\n    return string.length\n  }\n  if (ArrayBuffer.isView(string) || isInstance(string, ArrayBuffer)) {\n    return string.byteLength\n  }\n  if (typeof string !== 'string') {\n    throw new TypeError(\n      'The \"string\" argument must be one of type string, Buffer, or ArrayBuffer. ' +\n      'Received type ' + typeof string\n    )\n  }\n\n  const len = string.length\n  const mustMatch = (arguments.length > 2 && arguments[2] === true)\n  if (!mustMatch && len === 0) return 0\n\n  // Use a for loop to avoid recursion\n  let loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'ascii':\n      case 'latin1':\n      case 'binary':\n        return len\n      case 'utf8':\n      case 'utf-8':\n        return utf8ToBytes(string).length\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return len * 2\n      case 'hex':\n        return len >>> 1\n      case 'base64':\n        return base64ToBytes(string).length\n      default:\n        if (loweredCase) {\n          return mustMatch ? -1 : utf8ToBytes(string).length // assume utf8\n        }\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\nBuffer.byteLength = byteLength\n\nfunction slowToString (encoding, start, end) {\n  let loweredCase = false\n\n  // No need to verify that \"this.length <= MAX_UINT32\" since it's a read-only\n  // property of a typed array.\n\n  // This behaves neither like String nor Uint8Array in that we set start/end\n  // to their upper/lower bounds if the value passed is out of range.\n  // undefined is handled specially as per ECMA-262 6th Edition,\n  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.\n  if (start === undefined || start < 0) {\n    start = 0\n  }\n  // Return early if start > this.length. Done here to prevent potential uint32\n  // coercion fail below.\n  if (start > this.length) {\n    return ''\n  }\n\n  if (end === undefined || end > this.length) {\n    end = this.length\n  }\n\n  if (end <= 0) {\n    return ''\n  }\n\n  // Force coercion to uint32. This will also coerce falsey/NaN values to 0.\n  end >>>= 0\n  start >>>= 0\n\n  if (end <= start) {\n    return ''\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  while (true) {\n    switch (encoding) {\n      case 'hex':\n        return hexSlice(this, start, end)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Slice(this, start, end)\n\n      case 'ascii':\n        return asciiSlice(this, start, end)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Slice(this, start, end)\n\n      case 'base64':\n        return base64Slice(this, start, end)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return utf16leSlice(this, start, end)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = (encoding + '').toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\n// This property is used by `Buffer.isBuffer` (and the `is-buffer` npm package)\n// to detect a Buffer instance. It's not possible to use `instanceof Buffer`\n// reliably in a browserify context because there could be multiple different\n// copies of the 'buffer' package in use. This method works even for Buffer\n// instances that were created from another copy of the `buffer` package.\n// See: https://github.com/feross/buffer/issues/154\nBuffer.prototype._isBuffer = true\n\nfunction swap (b, n, m) {\n  const i = b[n]\n  b[n] = b[m]\n  b[m] = i\n}\n\nBuffer.prototype.swap16 = function swap16 () {\n  const len = this.length\n  if (len % 2 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 16-bits')\n  }\n  for (let i = 0; i < len; i += 2) {\n    swap(this, i, i + 1)\n  }\n  return this\n}\n\nBuffer.prototype.swap32 = function swap32 () {\n  const len = this.length\n  if (len % 4 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 32-bits')\n  }\n  for (let i = 0; i < len; i += 4) {\n    swap(this, i, i + 3)\n    swap(this, i + 1, i + 2)\n  }\n  return this\n}\n\nBuffer.prototype.swap64 = function swap64 () {\n  const len = this.length\n  if (len % 8 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 64-bits')\n  }\n  for (let i = 0; i < len; i += 8) {\n    swap(this, i, i + 7)\n    swap(this, i + 1, i + 6)\n    swap(this, i + 2, i + 5)\n    swap(this, i + 3, i + 4)\n  }\n  return this\n}\n\nBuffer.prototype.toString = function toString () {\n  const length = this.length\n  if (length === 0) return ''\n  if (arguments.length === 0) return utf8Slice(this, 0, length)\n  return slowToString.apply(this, arguments)\n}\n\nBuffer.prototype.toLocaleString = Buffer.prototype.toString\n\nBuffer.prototype.equals = function equals (b) {\n  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')\n  if (this === b) return true\n  return Buffer.compare(this, b) === 0\n}\n\nBuffer.prototype.inspect = function inspect () {\n  let str = ''\n  const max = exports.INSPECT_MAX_BYTES\n  str = this.toString('hex', 0, max).replace(/(.{2})/g, '$1 ').trim()\n  if (this.length > max) str += ' ... '\n  return '<Buffer ' + str + '>'\n}\nif (customInspectSymbol) {\n  Buffer.prototype[customInspectSymbol] = Buffer.prototype.inspect\n}\n\nBuffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {\n  if (isInstance(target, Uint8Array)) {\n    target = Buffer.from(target, target.offset, target.byteLength)\n  }\n  if (!Buffer.isBuffer(target)) {\n    throw new TypeError(\n      'The \"target\" argument must be one of type Buffer or Uint8Array. ' +\n      'Received type ' + (typeof target)\n    )\n  }\n\n  if (start === undefined) {\n    start = 0\n  }\n  if (end === undefined) {\n    end = target ? target.length : 0\n  }\n  if (thisStart === undefined) {\n    thisStart = 0\n  }\n  if (thisEnd === undefined) {\n    thisEnd = this.length\n  }\n\n  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {\n    throw new RangeError('out of range index')\n  }\n\n  if (thisStart >= thisEnd && start >= end) {\n    return 0\n  }\n  if (thisStart >= thisEnd) {\n    return -1\n  }\n  if (start >= end) {\n    return 1\n  }\n\n  start >>>= 0\n  end >>>= 0\n  thisStart >>>= 0\n  thisEnd >>>= 0\n\n  if (this === target) return 0\n\n  let x = thisEnd - thisStart\n  let y = end - start\n  const len = Math.min(x, y)\n\n  const thisCopy = this.slice(thisStart, thisEnd)\n  const targetCopy = target.slice(start, end)\n\n  for (let i = 0; i < len; ++i) {\n    if (thisCopy[i] !== targetCopy[i]) {\n      x = thisCopy[i]\n      y = targetCopy[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\n// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,\n// OR the last index of `val` in `buffer` at offset <= `byteOffset`.\n//\n// Arguments:\n// - buffer - a Buffer to search\n// - val - a string, Buffer, or number\n// - byteOffset - an index into `buffer`; will be clamped to an int32\n// - encoding - an optional encoding, relevant is val is a string\n// - dir - true for indexOf, false for lastIndexOf\nfunction bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {\n  // Empty buffer means no match\n  if (buffer.length === 0) return -1\n\n  // Normalize byteOffset\n  if (typeof byteOffset === 'string') {\n    encoding = byteOffset\n    byteOffset = 0\n  } else if (byteOffset > 0x7fffffff) {\n    byteOffset = 0x7fffffff\n  } else if (byteOffset < -0x80000000) {\n    byteOffset = -0x80000000\n  }\n  byteOffset = +byteOffset // Coerce to Number.\n  if (numberIsNaN(byteOffset)) {\n    // byteOffset: it it's undefined, null, NaN, \"foo\", etc, search whole buffer\n    byteOffset = dir ? 0 : (buffer.length - 1)\n  }\n\n  // Normalize byteOffset: negative offsets start from the end of the buffer\n  if (byteOffset < 0) byteOffset = buffer.length + byteOffset\n  if (byteOffset >= buffer.length) {\n    if (dir) return -1\n    else byteOffset = buffer.length - 1\n  } else if (byteOffset < 0) {\n    if (dir) byteOffset = 0\n    else return -1\n  }\n\n  // Normalize val\n  if (typeof val === 'string') {\n    val = Buffer.from(val, encoding)\n  }\n\n  // Finally, search either indexOf (if dir is true) or lastIndexOf\n  if (Buffer.isBuffer(val)) {\n    // Special case: looking for empty string/buffer always fails\n    if (val.length === 0) {\n      return -1\n    }\n    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)\n  } else if (typeof val === 'number') {\n    val = val & 0xFF // Search for a byte value [0-255]\n    if (typeof Uint8Array.prototype.indexOf === 'function') {\n      if (dir) {\n        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)\n      } else {\n        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)\n      }\n    }\n    return arrayIndexOf(buffer, [val], byteOffset, encoding, dir)\n  }\n\n  throw new TypeError('val must be string, number or Buffer')\n}\n\nfunction arrayIndexOf (arr, val, byteOffset, encoding, dir) {\n  let indexSize = 1\n  let arrLength = arr.length\n  let valLength = val.length\n\n  if (encoding !== undefined) {\n    encoding = String(encoding).toLowerCase()\n    if (encoding === 'ucs2' || encoding === 'ucs-2' ||\n        encoding === 'utf16le' || encoding === 'utf-16le') {\n      if (arr.length < 2 || val.length < 2) {\n        return -1\n      }\n      indexSize = 2\n      arrLength /= 2\n      valLength /= 2\n      byteOffset /= 2\n    }\n  }\n\n  function read (buf, i) {\n    if (indexSize === 1) {\n      return buf[i]\n    } else {\n      return buf.readUInt16BE(i * indexSize)\n    }\n  }\n\n  let i\n  if (dir) {\n    let foundIndex = -1\n    for (i = byteOffset; i < arrLength; i++) {\n      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {\n        if (foundIndex === -1) foundIndex = i\n        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize\n      } else {\n        if (foundIndex !== -1) i -= i - foundIndex\n        foundIndex = -1\n      }\n    }\n  } else {\n    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength\n    for (i = byteOffset; i >= 0; i--) {\n      let found = true\n      for (let j = 0; j < valLength; j++) {\n        if (read(arr, i + j) !== read(val, j)) {\n          found = false\n          break\n        }\n      }\n      if (found) return i\n    }\n  }\n\n  return -1\n}\n\nBuffer.prototype.includes = function includes (val, byteOffset, encoding) {\n  return this.indexOf(val, byteOffset, encoding) !== -1\n}\n\nBuffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)\n}\n\nBuffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)\n}\n\nfunction hexWrite (buf, string, offset, length) {\n  offset = Number(offset) || 0\n  const remaining = buf.length - offset\n  if (!length) {\n    length = remaining\n  } else {\n    length = Number(length)\n    if (length > remaining) {\n      length = remaining\n    }\n  }\n\n  const strLen = string.length\n\n  if (length > strLen / 2) {\n    length = strLen / 2\n  }\n  let i\n  for (i = 0; i < length; ++i) {\n    const parsed = parseInt(string.substr(i * 2, 2), 16)\n    if (numberIsNaN(parsed)) return i\n    buf[offset + i] = parsed\n  }\n  return i\n}\n\nfunction utf8Write (buf, string, offset, length) {\n  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nfunction asciiWrite (buf, string, offset, length) {\n  return blitBuffer(asciiToBytes(string), buf, offset, length)\n}\n\nfunction base64Write (buf, string, offset, length) {\n  return blitBuffer(base64ToBytes(string), buf, offset, length)\n}\n\nfunction ucs2Write (buf, string, offset, length) {\n  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nBuffer.prototype.write = function write (string, offset, length, encoding) {\n  // Buffer#write(string)\n  if (offset === undefined) {\n    encoding = 'utf8'\n    length = this.length\n    offset = 0\n  // Buffer#write(string, encoding)\n  } else if (length === undefined && typeof offset === 'string') {\n    encoding = offset\n    length = this.length\n    offset = 0\n  // Buffer#write(string, offset[, length][, encoding])\n  } else if (isFinite(offset)) {\n    offset = offset >>> 0\n    if (isFinite(length)) {\n      length = length >>> 0\n      if (encoding === undefined) encoding = 'utf8'\n    } else {\n      encoding = length\n      length = undefined\n    }\n  } else {\n    throw new Error(\n      'Buffer.write(string, encoding, offset[, length]) is no longer supported'\n    )\n  }\n\n  const remaining = this.length - offset\n  if (length === undefined || length > remaining) length = remaining\n\n  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {\n    throw new RangeError('Attempt to write outside buffer bounds')\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  let loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'hex':\n        return hexWrite(this, string, offset, length)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Write(this, string, offset, length)\n\n      case 'ascii':\n      case 'latin1':\n      case 'binary':\n        return asciiWrite(this, string, offset, length)\n\n      case 'base64':\n        // Warning: maxLength not taken into account in base64Write\n        return base64Write(this, string, offset, length)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return ucs2Write(this, string, offset, length)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\nBuffer.prototype.toJSON = function toJSON () {\n  return {\n    type: 'Buffer',\n    data: Array.prototype.slice.call(this._arr || this, 0)\n  }\n}\n\nfunction base64Slice (buf, start, end) {\n  if (start === 0 && end === buf.length) {\n    return base64.fromByteArray(buf)\n  } else {\n    return base64.fromByteArray(buf.slice(start, end))\n  }\n}\n\nfunction utf8Slice (buf, start, end) {\n  end = Math.min(buf.length, end)\n  const res = []\n\n  let i = start\n  while (i < end) {\n    const firstByte = buf[i]\n    let codePoint = null\n    let bytesPerSequence = (firstByte > 0xEF)\n      ? 4\n      : (firstByte > 0xDF)\n          ? 3\n          : (firstByte > 0xBF)\n              ? 2\n              : 1\n\n    if (i + bytesPerSequence <= end) {\n      let secondByte, thirdByte, fourthByte, tempCodePoint\n\n      switch (bytesPerSequence) {\n        case 1:\n          if (firstByte < 0x80) {\n            codePoint = firstByte\n          }\n          break\n        case 2:\n          secondByte = buf[i + 1]\n          if ((secondByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)\n            if (tempCodePoint > 0x7F) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 3:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)\n            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 4:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          fourthByte = buf[i + 3]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)\n            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {\n              codePoint = tempCodePoint\n            }\n          }\n      }\n    }\n\n    if (codePoint === null) {\n      // we did not generate a valid codePoint so insert a\n      // replacement char (U+FFFD) and advance only 1 byte\n      codePoint = 0xFFFD\n      bytesPerSequence = 1\n    } else if (codePoint > 0xFFFF) {\n      // encode to utf16 (surrogate pair dance)\n      codePoint -= 0x10000\n      res.push(codePoint >>> 10 & 0x3FF | 0xD800)\n      codePoint = 0xDC00 | codePoint & 0x3FF\n    }\n\n    res.push(codePoint)\n    i += bytesPerSequence\n  }\n\n  return decodeCodePointsArray(res)\n}\n\n// Based on http://stackoverflow.com/a/22747272/680742, the browser with\n// the lowest limit is Chrome, with 0x10000 args.\n// We go 1 magnitude less, for safety\nconst MAX_ARGUMENTS_LENGTH = 0x1000\n\nfunction decodeCodePointsArray (codePoints) {\n  const len = codePoints.length\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()\n  }\n\n  // Decode in chunks to avoid \"call stack size exceeded\".\n  let res = ''\n  let i = 0\n  while (i < len) {\n    res += String.fromCharCode.apply(\n      String,\n      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)\n    )\n  }\n  return res\n}\n\nfunction asciiSlice (buf, start, end) {\n  let ret = ''\n  end = Math.min(buf.length, end)\n\n  for (let i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i] & 0x7F)\n  }\n  return ret\n}\n\nfunction latin1Slice (buf, start, end) {\n  let ret = ''\n  end = Math.min(buf.length, end)\n\n  for (let i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i])\n  }\n  return ret\n}\n\nfunction hexSlice (buf, start, end) {\n  const len = buf.length\n\n  if (!start || start < 0) start = 0\n  if (!end || end < 0 || end > len) end = len\n\n  let out = ''\n  for (let i = start; i < end; ++i) {\n    out += hexSliceLookupTable[buf[i]]\n  }\n  return out\n}\n\nfunction utf16leSlice (buf, start, end) {\n  const bytes = buf.slice(start, end)\n  let res = ''\n  // If bytes.length is odd, the last 8 bits must be ignored (same as node.js)\n  for (let i = 0; i < bytes.length - 1; i += 2) {\n    res += String.fromCharCode(bytes[i] + (bytes[i + 1] * 256))\n  }\n  return res\n}\n\nBuffer.prototype.slice = function slice (start, end) {\n  const len = this.length\n  start = ~~start\n  end = end === undefined ? len : ~~end\n\n  if (start < 0) {\n    start += len\n    if (start < 0) start = 0\n  } else if (start > len) {\n    start = len\n  }\n\n  if (end < 0) {\n    end += len\n    if (end < 0) end = 0\n  } else if (end > len) {\n    end = len\n  }\n\n  if (end < start) end = start\n\n  const newBuf = this.subarray(start, end)\n  // Return an augmented `Uint8Array` instance\n  Object.setPrototypeOf(newBuf, Buffer.prototype)\n\n  return newBuf\n}\n\n/*\n * Need to make sure that buffer isn't trying to write out of bounds.\n */\nfunction checkOffset (offset, ext, length) {\n  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')\n  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')\n}\n\nBuffer.prototype.readUintLE =\nBuffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {\n  offset = offset >>> 0\n  byteLength = byteLength >>> 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  let val = this[offset]\n  let mul = 1\n  let i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUintBE =\nBuffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {\n  offset = offset >>> 0\n  byteLength = byteLength >>> 0\n  if (!noAssert) {\n    checkOffset(offset, byteLength, this.length)\n  }\n\n  let val = this[offset + --byteLength]\n  let mul = 1\n  while (byteLength > 0 && (mul *= 0x100)) {\n    val += this[offset + --byteLength] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUint8 =\nBuffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  return this[offset]\n}\n\nBuffer.prototype.readUint16LE =\nBuffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return this[offset] | (this[offset + 1] << 8)\n}\n\nBuffer.prototype.readUint16BE =\nBuffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return (this[offset] << 8) | this[offset + 1]\n}\n\nBuffer.prototype.readUint32LE =\nBuffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return ((this[offset]) |\n      (this[offset + 1] << 8) |\n      (this[offset + 2] << 16)) +\n      (this[offset + 3] * 0x1000000)\n}\n\nBuffer.prototype.readUint32BE =\nBuffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] * 0x1000000) +\n    ((this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    this[offset + 3])\n}\n\nBuffer.prototype.readBigUInt64LE = defineBigIntMethod(function readBigUInt64LE (offset) {\n  offset = offset >>> 0\n  validateNumber(offset, 'offset')\n  const first = this[offset]\n  const last = this[offset + 7]\n  if (first === undefined || last === undefined) {\n    boundsError(offset, this.length - 8)\n  }\n\n  const lo = first +\n    this[++offset] * 2 ** 8 +\n    this[++offset] * 2 ** 16 +\n    this[++offset] * 2 ** 24\n\n  const hi = this[++offset] +\n    this[++offset] * 2 ** 8 +\n    this[++offset] * 2 ** 16 +\n    last * 2 ** 24\n\n  return BigInt(lo) + (BigInt(hi) << BigInt(32))\n})\n\nBuffer.prototype.readBigUInt64BE = defineBigIntMethod(function readBigUInt64BE (offset) {\n  offset = offset >>> 0\n  validateNumber(offset, 'offset')\n  const first = this[offset]\n  const last = this[offset + 7]\n  if (first === undefined || last === undefined) {\n    boundsError(offset, this.length - 8)\n  }\n\n  const hi = first * 2 ** 24 +\n    this[++offset] * 2 ** 16 +\n    this[++offset] * 2 ** 8 +\n    this[++offset]\n\n  const lo = this[++offset] * 2 ** 24 +\n    this[++offset] * 2 ** 16 +\n    this[++offset] * 2 ** 8 +\n    last\n\n  return (BigInt(hi) << BigInt(32)) + BigInt(lo)\n})\n\nBuffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {\n  offset = offset >>> 0\n  byteLength = byteLength >>> 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  let val = this[offset]\n  let mul = 1\n  let i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {\n  offset = offset >>> 0\n  byteLength = byteLength >>> 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  let i = byteLength\n  let mul = 1\n  let val = this[offset + --i]\n  while (i > 0 && (mul *= 0x100)) {\n    val += this[offset + --i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readInt8 = function readInt8 (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  if (!(this[offset] & 0x80)) return (this[offset])\n  return ((0xff - this[offset] + 1) * -1)\n}\n\nBuffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  const val = this[offset] | (this[offset + 1] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  const val = this[offset + 1] | (this[offset] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset]) |\n    (this[offset + 1] << 8) |\n    (this[offset + 2] << 16) |\n    (this[offset + 3] << 24)\n}\n\nBuffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] << 24) |\n    (this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    (this[offset + 3])\n}\n\nBuffer.prototype.readBigInt64LE = defineBigIntMethod(function readBigInt64LE (offset) {\n  offset = offset >>> 0\n  validateNumber(offset, 'offset')\n  const first = this[offset]\n  const last = this[offset + 7]\n  if (first === undefined || last === undefined) {\n    boundsError(offset, this.length - 8)\n  }\n\n  const val = this[offset + 4] +\n    this[offset + 5] * 2 ** 8 +\n    this[offset + 6] * 2 ** 16 +\n    (last << 24) // Overflow\n\n  return (BigInt(val) << BigInt(32)) +\n    BigInt(first +\n    this[++offset] * 2 ** 8 +\n    this[++offset] * 2 ** 16 +\n    this[++offset] * 2 ** 24)\n})\n\nBuffer.prototype.readBigInt64BE = defineBigIntMethod(function readBigInt64BE (offset) {\n  offset = offset >>> 0\n  validateNumber(offset, 'offset')\n  const first = this[offset]\n  const last = this[offset + 7]\n  if (first === undefined || last === undefined) {\n    boundsError(offset, this.length - 8)\n  }\n\n  const val = (first << 24) + // Overflow\n    this[++offset] * 2 ** 16 +\n    this[++offset] * 2 ** 8 +\n    this[++offset]\n\n  return (BigInt(val) << BigInt(32)) +\n    BigInt(this[++offset] * 2 ** 24 +\n    this[++offset] * 2 ** 16 +\n    this[++offset] * 2 ** 8 +\n    last)\n})\n\nBuffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, true, 23, 4)\n}\n\nBuffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, false, 23, 4)\n}\n\nBuffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, true, 52, 8)\n}\n\nBuffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {\n  offset = offset >>> 0\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, false, 52, 8)\n}\n\nfunction checkInt (buf, value, offset, ext, max, min) {\n  if (!Buffer.isBuffer(buf)) throw new TypeError('\"buffer\" argument must be a Buffer instance')\n  if (value > max || value < min) throw new RangeError('\"value\" argument is out of bounds')\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n}\n\nBuffer.prototype.writeUintLE =\nBuffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  byteLength = byteLength >>> 0\n  if (!noAssert) {\n    const maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  let mul = 1\n  let i = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUintBE =\nBuffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  byteLength = byteLength >>> 0\n  if (!noAssert) {\n    const maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  let i = byteLength - 1\n  let mul = 1\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUint8 =\nBuffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nBuffer.prototype.writeUint16LE =\nBuffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  this[offset] = (value & 0xff)\n  this[offset + 1] = (value >>> 8)\n  return offset + 2\n}\n\nBuffer.prototype.writeUint16BE =\nBuffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  this[offset] = (value >>> 8)\n  this[offset + 1] = (value & 0xff)\n  return offset + 2\n}\n\nBuffer.prototype.writeUint32LE =\nBuffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  this[offset + 3] = (value >>> 24)\n  this[offset + 2] = (value >>> 16)\n  this[offset + 1] = (value >>> 8)\n  this[offset] = (value & 0xff)\n  return offset + 4\n}\n\nBuffer.prototype.writeUint32BE =\nBuffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  this[offset] = (value >>> 24)\n  this[offset + 1] = (value >>> 16)\n  this[offset + 2] = (value >>> 8)\n  this[offset + 3] = (value & 0xff)\n  return offset + 4\n}\n\nfunction wrtBigUInt64LE (buf, value, offset, min, max) {\n  checkIntBI(value, min, max, buf, offset, 7)\n\n  let lo = Number(value & BigInt(0xffffffff))\n  buf[offset++] = lo\n  lo = lo >> 8\n  buf[offset++] = lo\n  lo = lo >> 8\n  buf[offset++] = lo\n  lo = lo >> 8\n  buf[offset++] = lo\n  let hi = Number(value >> BigInt(32) & BigInt(0xffffffff))\n  buf[offset++] = hi\n  hi = hi >> 8\n  buf[offset++] = hi\n  hi = hi >> 8\n  buf[offset++] = hi\n  hi = hi >> 8\n  buf[offset++] = hi\n  return offset\n}\n\nfunction wrtBigUInt64BE (buf, value, offset, min, max) {\n  checkIntBI(value, min, max, buf, offset, 7)\n\n  let lo = Number(value & BigInt(0xffffffff))\n  buf[offset + 7] = lo\n  lo = lo >> 8\n  buf[offset + 6] = lo\n  lo = lo >> 8\n  buf[offset + 5] = lo\n  lo = lo >> 8\n  buf[offset + 4] = lo\n  let hi = Number(value >> BigInt(32) & BigInt(0xffffffff))\n  buf[offset + 3] = hi\n  hi = hi >> 8\n  buf[offset + 2] = hi\n  hi = hi >> 8\n  buf[offset + 1] = hi\n  hi = hi >> 8\n  buf[offset] = hi\n  return offset + 8\n}\n\nBuffer.prototype.writeBigUInt64LE = defineBigIntMethod(function writeBigUInt64LE (value, offset = 0) {\n  return wrtBigUInt64LE(this, value, offset, BigInt(0), BigInt('0xffffffffffffffff'))\n})\n\nBuffer.prototype.writeBigUInt64BE = defineBigIntMethod(function writeBigUInt64BE (value, offset = 0) {\n  return wrtBigUInt64BE(this, value, offset, BigInt(0), BigInt('0xffffffffffffffff'))\n})\n\nBuffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) {\n    const limit = Math.pow(2, (8 * byteLength) - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  let i = 0\n  let mul = 1\n  let sub = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) {\n    const limit = Math.pow(2, (8 * byteLength) - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  let i = byteLength - 1\n  let mul = 1\n  let sub = 0\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)\n  if (value < 0) value = 0xff + value + 1\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nBuffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  this[offset] = (value & 0xff)\n  this[offset + 1] = (value >>> 8)\n  return offset + 2\n}\n\nBuffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  this[offset] = (value >>> 8)\n  this[offset + 1] = (value & 0xff)\n  return offset + 2\n}\n\nBuffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  this[offset] = (value & 0xff)\n  this[offset + 1] = (value >>> 8)\n  this[offset + 2] = (value >>> 16)\n  this[offset + 3] = (value >>> 24)\n  return offset + 4\n}\n\nBuffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (value < 0) value = 0xffffffff + value + 1\n  this[offset] = (value >>> 24)\n  this[offset + 1] = (value >>> 16)\n  this[offset + 2] = (value >>> 8)\n  this[offset + 3] = (value & 0xff)\n  return offset + 4\n}\n\nBuffer.prototype.writeBigInt64LE = defineBigIntMethod(function writeBigInt64LE (value, offset = 0) {\n  return wrtBigUInt64LE(this, value, offset, -BigInt('0x8000000000000000'), BigInt('0x7fffffffffffffff'))\n})\n\nBuffer.prototype.writeBigInt64BE = defineBigIntMethod(function writeBigInt64BE (value, offset = 0) {\n  return wrtBigUInt64BE(this, value, offset, -BigInt('0x8000000000000000'), BigInt('0x7fffffffffffffff'))\n})\n\nfunction checkIEEE754 (buf, value, offset, ext, max, min) {\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n  if (offset < 0) throw new RangeError('Index out of range')\n}\n\nfunction writeFloat (buf, value, offset, littleEndian, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 23, 4)\n  return offset + 4\n}\n\nBuffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, false, noAssert)\n}\n\nfunction writeDouble (buf, value, offset, littleEndian, noAssert) {\n  value = +value\n  offset = offset >>> 0\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 52, 8)\n  return offset + 8\n}\n\nBuffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, false, noAssert)\n}\n\n// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)\nBuffer.prototype.copy = function copy (target, targetStart, start, end) {\n  if (!Buffer.isBuffer(target)) throw new TypeError('argument should be a Buffer')\n  if (!start) start = 0\n  if (!end && end !== 0) end = this.length\n  if (targetStart >= target.length) targetStart = target.length\n  if (!targetStart) targetStart = 0\n  if (end > 0 && end < start) end = start\n\n  // Copy 0 bytes; we're done\n  if (end === start) return 0\n  if (target.length === 0 || this.length === 0) return 0\n\n  // Fatal error conditions\n  if (targetStart < 0) {\n    throw new RangeError('targetStart out of bounds')\n  }\n  if (start < 0 || start >= this.length) throw new RangeError('Index out of range')\n  if (end < 0) throw new RangeError('sourceEnd out of bounds')\n\n  // Are we oob?\n  if (end > this.length) end = this.length\n  if (target.length - targetStart < end - start) {\n    end = target.length - targetStart + start\n  }\n\n  const len = end - start\n\n  if (this === target && typeof Uint8Array.prototype.copyWithin === 'function') {\n    // Use built-in when available, missing from IE11\n    this.copyWithin(targetStart, start, end)\n  } else {\n    Uint8Array.prototype.set.call(\n      target,\n      this.subarray(start, end),\n      targetStart\n    )\n  }\n\n  return len\n}\n\n// Usage:\n//    buffer.fill(number[, offset[, end]])\n//    buffer.fill(buffer[, offset[, end]])\n//    buffer.fill(string[, offset[, end]][, encoding])\nBuffer.prototype.fill = function fill (val, start, end, encoding) {\n  // Handle string cases:\n  if (typeof val === 'string') {\n    if (typeof start === 'string') {\n      encoding = start\n      start = 0\n      end = this.length\n    } else if (typeof end === 'string') {\n      encoding = end\n      end = this.length\n    }\n    if (encoding !== undefined && typeof encoding !== 'string') {\n      throw new TypeError('encoding must be a string')\n    }\n    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {\n      throw new TypeError('Unknown encoding: ' + encoding)\n    }\n    if (val.length === 1) {\n      const code = val.charCodeAt(0)\n      if ((encoding === 'utf8' && code < 128) ||\n          encoding === 'latin1') {\n        // Fast path: If `val` fits into a single byte, use that numeric value.\n        val = code\n      }\n    }\n  } else if (typeof val === 'number') {\n    val = val & 255\n  } else if (typeof val === 'boolean') {\n    val = Number(val)\n  }\n\n  // Invalid ranges are not set to a default, so can range check early.\n  if (start < 0 || this.length < start || this.length < end) {\n    throw new RangeError('Out of range index')\n  }\n\n  if (end <= start) {\n    return this\n  }\n\n  start = start >>> 0\n  end = end === undefined ? this.length : end >>> 0\n\n  if (!val) val = 0\n\n  let i\n  if (typeof val === 'number') {\n    for (i = start; i < end; ++i) {\n      this[i] = val\n    }\n  } else {\n    const bytes = Buffer.isBuffer(val)\n      ? val\n      : Buffer.from(val, encoding)\n    const len = bytes.length\n    if (len === 0) {\n      throw new TypeError('The value \"' + val +\n        '\" is invalid for argument \"value\"')\n    }\n    for (i = 0; i < end - start; ++i) {\n      this[i + start] = bytes[i % len]\n    }\n  }\n\n  return this\n}\n\n// CUSTOM ERRORS\n// =============\n\n// Simplified versions from Node, changed for Buffer-only usage\nconst errors = {}\nfunction E (sym, getMessage, Base) {\n  errors[sym] = class NodeError extends Base {\n    constructor () {\n      super()\n\n      Object.defineProperty(this, 'message', {\n        value: getMessage.apply(this, arguments),\n        writable: true,\n        configurable: true\n      })\n\n      // Add the error code to the name to include it in the stack trace.\n      this.name = `${this.name} [${sym}]`\n      // Access the stack to generate the error message including the error code\n      // from the name.\n      this.stack // eslint-disable-line no-unused-expressions\n      // Reset the name to the actual name.\n      delete this.name\n    }\n\n    get code () {\n      return sym\n    }\n\n    set code (value) {\n      Object.defineProperty(this, 'code', {\n        configurable: true,\n        enumerable: true,\n        value,\n        writable: true\n      })\n    }\n\n    toString () {\n      return `${this.name} [${sym}]: ${this.message}`\n    }\n  }\n}\n\nE('ERR_BUFFER_OUT_OF_BOUNDS',\n  function (name) {\n    if (name) {\n      return `${name} is outside of buffer bounds`\n    }\n\n    return 'Attempt to access memory outside buffer bounds'\n  }, RangeError)\nE('ERR_INVALID_ARG_TYPE',\n  function (name, actual) {\n    return `The \"${name}\" argument must be of type number. Received type ${typeof actual}`\n  }, TypeError)\nE('ERR_OUT_OF_RANGE',\n  function (str, range, input) {\n    let msg = `The value of \"${str}\" is out of range.`\n    let received = input\n    if (Number.isInteger(input) && Math.abs(input) > 2 ** 32) {\n      received = addNumericalSeparator(String(input))\n    } else if (typeof input === 'bigint') {\n      received = String(input)\n      if (input > BigInt(2) ** BigInt(32) || input < -(BigInt(2) ** BigInt(32))) {\n        received = addNumericalSeparator(received)\n      }\n      received += 'n'\n    }\n    msg += ` It must be ${range}. Received ${received}`\n    return msg\n  }, RangeError)\n\nfunction addNumericalSeparator (val) {\n  let res = ''\n  let i = val.length\n  const start = val[0] === '-' ? 1 : 0\n  for (; i >= start + 4; i -= 3) {\n    res = `_${val.slice(i - 3, i)}${res}`\n  }\n  return `${val.slice(0, i)}${res}`\n}\n\n// CHECK FUNCTIONS\n// ===============\n\nfunction checkBounds (buf, offset, byteLength) {\n  validateNumber(offset, 'offset')\n  if (buf[offset] === undefined || buf[offset + byteLength] === undefined) {\n    boundsError(offset, buf.length - (byteLength + 1))\n  }\n}\n\nfunction checkIntBI (value, min, max, buf, offset, byteLength) {\n  if (value > max || value < min) {\n    const n = typeof min === 'bigint' ? 'n' : ''\n    let range\n    if (byteLength > 3) {\n      if (min === 0 || min === BigInt(0)) {\n        range = `>= 0${n} and < 2${n} ** ${(byteLength + 1) * 8}${n}`\n      } else {\n        range = `>= -(2${n} ** ${(byteLength + 1) * 8 - 1}${n}) and < 2 ** ` +\n                `${(byteLength + 1) * 8 - 1}${n}`\n      }\n    } else {\n      range = `>= ${min}${n} and <= ${max}${n}`\n    }\n    throw new errors.ERR_OUT_OF_RANGE('value', range, value)\n  }\n  checkBounds(buf, offset, byteLength)\n}\n\nfunction validateNumber (value, name) {\n  if (typeof value !== 'number') {\n    throw new errors.ERR_INVALID_ARG_TYPE(name, 'number', value)\n  }\n}\n\nfunction boundsError (value, length, type) {\n  if (Math.floor(value) !== value) {\n    validateNumber(value, type)\n    throw new errors.ERR_OUT_OF_RANGE(type || 'offset', 'an integer', value)\n  }\n\n  if (length < 0) {\n    throw new errors.ERR_BUFFER_OUT_OF_BOUNDS()\n  }\n\n  throw new errors.ERR_OUT_OF_RANGE(type || 'offset',\n                                    `>= ${type ? 1 : 0} and <= ${length}`,\n                                    value)\n}\n\n// HELPER FUNCTIONS\n// ================\n\nconst INVALID_BASE64_RE = /[^+/0-9A-Za-z-_]/g\n\nfunction base64clean (str) {\n  // Node takes equal signs as end of the Base64 encoding\n  str = str.split('=')[0]\n  // Node strips out invalid characters like \\n and \\t from the string, base64-js does not\n  str = str.trim().replace(INVALID_BASE64_RE, '')\n  // Node converts strings with length < 2 to ''\n  if (str.length < 2) return ''\n  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not\n  while (str.length % 4 !== 0) {\n    str = str + '='\n  }\n  return str\n}\n\nfunction utf8ToBytes (string, units) {\n  units = units || Infinity\n  let codePoint\n  const length = string.length\n  let leadSurrogate = null\n  const bytes = []\n\n  for (let i = 0; i < length; ++i) {\n    codePoint = string.charCodeAt(i)\n\n    // is surrogate component\n    if (codePoint > 0xD7FF && codePoint < 0xE000) {\n      // last char was a lead\n      if (!leadSurrogate) {\n        // no lead yet\n        if (codePoint > 0xDBFF) {\n          // unexpected trail\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        } else if (i + 1 === length) {\n          // unpaired lead\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        }\n\n        // valid lead\n        leadSurrogate = codePoint\n\n        continue\n      }\n\n      // 2 leads in a row\n      if (codePoint < 0xDC00) {\n        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n        leadSurrogate = codePoint\n        continue\n      }\n\n      // valid surrogate pair\n      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000\n    } else if (leadSurrogate) {\n      // valid bmp char, but last char was a lead\n      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n    }\n\n    leadSurrogate = null\n\n    // encode utf8\n    if (codePoint < 0x80) {\n      if ((units -= 1) < 0) break\n      bytes.push(codePoint)\n    } else if (codePoint < 0x800) {\n      if ((units -= 2) < 0) break\n      bytes.push(\n        codePoint >> 0x6 | 0xC0,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x10000) {\n      if ((units -= 3) < 0) break\n      bytes.push(\n        codePoint >> 0xC | 0xE0,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x110000) {\n      if ((units -= 4) < 0) break\n      bytes.push(\n        codePoint >> 0x12 | 0xF0,\n        codePoint >> 0xC & 0x3F | 0x80,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else {\n      throw new Error('Invalid code point')\n    }\n  }\n\n  return bytes\n}\n\nfunction asciiToBytes (str) {\n  const byteArray = []\n  for (let i = 0; i < str.length; ++i) {\n    // Node's code seems to be doing this and not & 0x7F..\n    byteArray.push(str.charCodeAt(i) & 0xFF)\n  }\n  return byteArray\n}\n\nfunction utf16leToBytes (str, units) {\n  let c, hi, lo\n  const byteArray = []\n  for (let i = 0; i < str.length; ++i) {\n    if ((units -= 2) < 0) break\n\n    c = str.charCodeAt(i)\n    hi = c >> 8\n    lo = c % 256\n    byteArray.push(lo)\n    byteArray.push(hi)\n  }\n\n  return byteArray\n}\n\nfunction base64ToBytes (str) {\n  return base64.toByteArray(base64clean(str))\n}\n\nfunction blitBuffer (src, dst, offset, length) {\n  let i\n  for (i = 0; i < length; ++i) {\n    if ((i + offset >= dst.length) || (i >= src.length)) break\n    dst[i + offset] = src[i]\n  }\n  return i\n}\n\n// ArrayBuffer or Uint8Array objects from other contexts (i.e. iframes) do not pass\n// the `instanceof` check but they should be treated as of that type.\n// See: https://github.com/feross/buffer/issues/166\nfunction isInstance (obj, type) {\n  return obj instanceof type ||\n    (obj != null && obj.constructor != null && obj.constructor.name != null &&\n      obj.constructor.name === type.name)\n}\nfunction numberIsNaN (obj) {\n  // For IE11 support\n  return obj !== obj // eslint-disable-line no-self-compare\n}\n\n// Create lookup table for `toString('hex')`\n// See: https://github.com/feross/buffer/issues/219\nconst hexSliceLookupTable = (function () {\n  const alphabet = '0123456789abcdef'\n  const table = new Array(256)\n  for (let i = 0; i < 16; ++i) {\n    const i16 = i * 16\n    for (let j = 0; j < 16; ++j) {\n      table[i16 + j] = alphabet[i] + alphabet[j]\n    }\n  }\n  return table\n})()\n\n// Return not function with Error if BigInt not supported\nfunction defineBigIntMethod (fn) {\n  return typeof BigInt === 'undefined' ? BufferBigIntNotDefined : fn\n}\n\nfunction BufferBigIntNotDefined () {\n  throw new Error('BigInt not supported')\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/buffer/index.js?");

/***/ }),

/***/ "./node_modules/canonicalize/lib/canonicalize.js":
/*!*******************************************************!*\
  !*** ./node_modules/canonicalize/lib/canonicalize.js ***!
  \*******************************************************/
/***/ ((module) => {

"use strict";
eval("/* jshint esversion: 6 */\n/* jslint node: true */\n\n\nmodule.exports = function serialize (object) {\n  if (object === null || typeof object !== 'object' || object.toJSON != null) {\n    return JSON.stringify(object);\n  }\n\n  if (Array.isArray(object)) {\n    return '[' + object.reduce((t, cv, ci) => {\n      const comma = ci === 0 ? '' : ',';\n      const value = cv === undefined || typeof cv === 'symbol' ? null : cv;\n      return t + comma + serialize(value);\n    }, '') + ']';\n  }\n\n  return '{' + Object.keys(object).sort().reduce((t, cv, ci) => {\n    if (object[cv] === undefined ||\n        typeof object[cv] === 'symbol') {\n      return t;\n    }\n    const comma = t.length === 0 ? '' : ',';\n    return t + comma + serialize(cv) + ':' + serialize(object[cv]);\n  }, '') + '}';\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/canonicalize/lib/canonicalize.js?");

/***/ }),

/***/ "./node_modules/cross-fetch/dist/browser-polyfill.js":
/*!***********************************************************!*\
  !*** ./node_modules/cross-fetch/dist/browser-polyfill.js ***!
  \***********************************************************/
/***/ (function() {

eval("(function(self) {\n\nvar irrelevant = (function (exports) {\n\n  var support = {\n    searchParams: 'URLSearchParams' in self,\n    iterable: 'Symbol' in self && 'iterator' in Symbol,\n    blob:\n      'FileReader' in self &&\n      'Blob' in self &&\n      (function() {\n        try {\n          new Blob();\n          return true\n        } catch (e) {\n          return false\n        }\n      })(),\n    formData: 'FormData' in self,\n    arrayBuffer: 'ArrayBuffer' in self\n  };\n\n  function isDataView(obj) {\n    return obj && DataView.prototype.isPrototypeOf(obj)\n  }\n\n  if (support.arrayBuffer) {\n    var viewClasses = [\n      '[object Int8Array]',\n      '[object Uint8Array]',\n      '[object Uint8ClampedArray]',\n      '[object Int16Array]',\n      '[object Uint16Array]',\n      '[object Int32Array]',\n      '[object Uint32Array]',\n      '[object Float32Array]',\n      '[object Float64Array]'\n    ];\n\n    var isArrayBufferView =\n      ArrayBuffer.isView ||\n      function(obj) {\n        return obj && viewClasses.indexOf(Object.prototype.toString.call(obj)) > -1\n      };\n  }\n\n  function normalizeName(name) {\n    if (typeof name !== 'string') {\n      name = String(name);\n    }\n    if (/[^a-z0-9\\-#$%&'*+.^_`|~]/i.test(name)) {\n      throw new TypeError('Invalid character in header field name')\n    }\n    return name.toLowerCase()\n  }\n\n  function normalizeValue(value) {\n    if (typeof value !== 'string') {\n      value = String(value);\n    }\n    return value\n  }\n\n  // Build a destructive iterator for the value list\n  function iteratorFor(items) {\n    var iterator = {\n      next: function() {\n        var value = items.shift();\n        return {done: value === undefined, value: value}\n      }\n    };\n\n    if (support.iterable) {\n      iterator[Symbol.iterator] = function() {\n        return iterator\n      };\n    }\n\n    return iterator\n  }\n\n  function Headers(headers) {\n    this.map = {};\n\n    if (headers instanceof Headers) {\n      headers.forEach(function(value, name) {\n        this.append(name, value);\n      }, this);\n    } else if (Array.isArray(headers)) {\n      headers.forEach(function(header) {\n        this.append(header[0], header[1]);\n      }, this);\n    } else if (headers) {\n      Object.getOwnPropertyNames(headers).forEach(function(name) {\n        this.append(name, headers[name]);\n      }, this);\n    }\n  }\n\n  Headers.prototype.append = function(name, value) {\n    name = normalizeName(name);\n    value = normalizeValue(value);\n    var oldValue = this.map[name];\n    this.map[name] = oldValue ? oldValue + ', ' + value : value;\n  };\n\n  Headers.prototype['delete'] = function(name) {\n    delete this.map[normalizeName(name)];\n  };\n\n  Headers.prototype.get = function(name) {\n    name = normalizeName(name);\n    return this.has(name) ? this.map[name] : null\n  };\n\n  Headers.prototype.has = function(name) {\n    return this.map.hasOwnProperty(normalizeName(name))\n  };\n\n  Headers.prototype.set = function(name, value) {\n    this.map[normalizeName(name)] = normalizeValue(value);\n  };\n\n  Headers.prototype.forEach = function(callback, thisArg) {\n    for (var name in this.map) {\n      if (this.map.hasOwnProperty(name)) {\n        callback.call(thisArg, this.map[name], name, this);\n      }\n    }\n  };\n\n  Headers.prototype.keys = function() {\n    var items = [];\n    this.forEach(function(value, name) {\n      items.push(name);\n    });\n    return iteratorFor(items)\n  };\n\n  Headers.prototype.values = function() {\n    var items = [];\n    this.forEach(function(value) {\n      items.push(value);\n    });\n    return iteratorFor(items)\n  };\n\n  Headers.prototype.entries = function() {\n    var items = [];\n    this.forEach(function(value, name) {\n      items.push([name, value]);\n    });\n    return iteratorFor(items)\n  };\n\n  if (support.iterable) {\n    Headers.prototype[Symbol.iterator] = Headers.prototype.entries;\n  }\n\n  function consumed(body) {\n    if (body.bodyUsed) {\n      return Promise.reject(new TypeError('Already read'))\n    }\n    body.bodyUsed = true;\n  }\n\n  function fileReaderReady(reader) {\n    return new Promise(function(resolve, reject) {\n      reader.onload = function() {\n        resolve(reader.result);\n      };\n      reader.onerror = function() {\n        reject(reader.error);\n      };\n    })\n  }\n\n  function readBlobAsArrayBuffer(blob) {\n    var reader = new FileReader();\n    var promise = fileReaderReady(reader);\n    reader.readAsArrayBuffer(blob);\n    return promise\n  }\n\n  function readBlobAsText(blob) {\n    var reader = new FileReader();\n    var promise = fileReaderReady(reader);\n    reader.readAsText(blob);\n    return promise\n  }\n\n  function readArrayBufferAsText(buf) {\n    var view = new Uint8Array(buf);\n    var chars = new Array(view.length);\n\n    for (var i = 0; i < view.length; i++) {\n      chars[i] = String.fromCharCode(view[i]);\n    }\n    return chars.join('')\n  }\n\n  function bufferClone(buf) {\n    if (buf.slice) {\n      return buf.slice(0)\n    } else {\n      var view = new Uint8Array(buf.byteLength);\n      view.set(new Uint8Array(buf));\n      return view.buffer\n    }\n  }\n\n  function Body() {\n    this.bodyUsed = false;\n\n    this._initBody = function(body) {\n      this._bodyInit = body;\n      if (!body) {\n        this._bodyText = '';\n      } else if (typeof body === 'string') {\n        this._bodyText = body;\n      } else if (support.blob && Blob.prototype.isPrototypeOf(body)) {\n        this._bodyBlob = body;\n      } else if (support.formData && FormData.prototype.isPrototypeOf(body)) {\n        this._bodyFormData = body;\n      } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n        this._bodyText = body.toString();\n      } else if (support.arrayBuffer && support.blob && isDataView(body)) {\n        this._bodyArrayBuffer = bufferClone(body.buffer);\n        // IE 10-11 can't handle a DataView body.\n        this._bodyInit = new Blob([this._bodyArrayBuffer]);\n      } else if (support.arrayBuffer && (ArrayBuffer.prototype.isPrototypeOf(body) || isArrayBufferView(body))) {\n        this._bodyArrayBuffer = bufferClone(body);\n      } else {\n        this._bodyText = body = Object.prototype.toString.call(body);\n      }\n\n      if (!this.headers.get('content-type')) {\n        if (typeof body === 'string') {\n          this.headers.set('content-type', 'text/plain;charset=UTF-8');\n        } else if (this._bodyBlob && this._bodyBlob.type) {\n          this.headers.set('content-type', this._bodyBlob.type);\n        } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n          this.headers.set('content-type', 'application/x-www-form-urlencoded;charset=UTF-8');\n        }\n      }\n    };\n\n    if (support.blob) {\n      this.blob = function() {\n        var rejected = consumed(this);\n        if (rejected) {\n          return rejected\n        }\n\n        if (this._bodyBlob) {\n          return Promise.resolve(this._bodyBlob)\n        } else if (this._bodyArrayBuffer) {\n          return Promise.resolve(new Blob([this._bodyArrayBuffer]))\n        } else if (this._bodyFormData) {\n          throw new Error('could not read FormData body as blob')\n        } else {\n          return Promise.resolve(new Blob([this._bodyText]))\n        }\n      };\n\n      this.arrayBuffer = function() {\n        if (this._bodyArrayBuffer) {\n          return consumed(this) || Promise.resolve(this._bodyArrayBuffer)\n        } else {\n          return this.blob().then(readBlobAsArrayBuffer)\n        }\n      };\n    }\n\n    this.text = function() {\n      var rejected = consumed(this);\n      if (rejected) {\n        return rejected\n      }\n\n      if (this._bodyBlob) {\n        return readBlobAsText(this._bodyBlob)\n      } else if (this._bodyArrayBuffer) {\n        return Promise.resolve(readArrayBufferAsText(this._bodyArrayBuffer))\n      } else if (this._bodyFormData) {\n        throw new Error('could not read FormData body as text')\n      } else {\n        return Promise.resolve(this._bodyText)\n      }\n    };\n\n    if (support.formData) {\n      this.formData = function() {\n        return this.text().then(decode)\n      };\n    }\n\n    this.json = function() {\n      return this.text().then(JSON.parse)\n    };\n\n    return this\n  }\n\n  // HTTP methods whose capitalization should be normalized\n  var methods = ['DELETE', 'GET', 'HEAD', 'OPTIONS', 'POST', 'PUT'];\n\n  function normalizeMethod(method) {\n    var upcased = method.toUpperCase();\n    return methods.indexOf(upcased) > -1 ? upcased : method\n  }\n\n  function Request(input, options) {\n    options = options || {};\n    var body = options.body;\n\n    if (input instanceof Request) {\n      if (input.bodyUsed) {\n        throw new TypeError('Already read')\n      }\n      this.url = input.url;\n      this.credentials = input.credentials;\n      if (!options.headers) {\n        this.headers = new Headers(input.headers);\n      }\n      this.method = input.method;\n      this.mode = input.mode;\n      this.signal = input.signal;\n      if (!body && input._bodyInit != null) {\n        body = input._bodyInit;\n        input.bodyUsed = true;\n      }\n    } else {\n      this.url = String(input);\n    }\n\n    this.credentials = options.credentials || this.credentials || 'same-origin';\n    if (options.headers || !this.headers) {\n      this.headers = new Headers(options.headers);\n    }\n    this.method = normalizeMethod(options.method || this.method || 'GET');\n    this.mode = options.mode || this.mode || null;\n    this.signal = options.signal || this.signal;\n    this.referrer = null;\n\n    if ((this.method === 'GET' || this.method === 'HEAD') && body) {\n      throw new TypeError('Body not allowed for GET or HEAD requests')\n    }\n    this._initBody(body);\n  }\n\n  Request.prototype.clone = function() {\n    return new Request(this, {body: this._bodyInit})\n  };\n\n  function decode(body) {\n    var form = new FormData();\n    body\n      .trim()\n      .split('&')\n      .forEach(function(bytes) {\n        if (bytes) {\n          var split = bytes.split('=');\n          var name = split.shift().replace(/\\+/g, ' ');\n          var value = split.join('=').replace(/\\+/g, ' ');\n          form.append(decodeURIComponent(name), decodeURIComponent(value));\n        }\n      });\n    return form\n  }\n\n  function parseHeaders(rawHeaders) {\n    var headers = new Headers();\n    // Replace instances of \\r\\n and \\n followed by at least one space or horizontal tab with a space\n    // https://tools.ietf.org/html/rfc7230#section-3.2\n    var preProcessedHeaders = rawHeaders.replace(/\\r?\\n[\\t ]+/g, ' ');\n    preProcessedHeaders.split(/\\r?\\n/).forEach(function(line) {\n      var parts = line.split(':');\n      var key = parts.shift().trim();\n      if (key) {\n        var value = parts.join(':').trim();\n        headers.append(key, value);\n      }\n    });\n    return headers\n  }\n\n  Body.call(Request.prototype);\n\n  function Response(bodyInit, options) {\n    if (!options) {\n      options = {};\n    }\n\n    this.type = 'default';\n    this.status = options.status === undefined ? 200 : options.status;\n    this.ok = this.status >= 200 && this.status < 300;\n    this.statusText = 'statusText' in options ? options.statusText : 'OK';\n    this.headers = new Headers(options.headers);\n    this.url = options.url || '';\n    this._initBody(bodyInit);\n  }\n\n  Body.call(Response.prototype);\n\n  Response.prototype.clone = function() {\n    return new Response(this._bodyInit, {\n      status: this.status,\n      statusText: this.statusText,\n      headers: new Headers(this.headers),\n      url: this.url\n    })\n  };\n\n  Response.error = function() {\n    var response = new Response(null, {status: 0, statusText: ''});\n    response.type = 'error';\n    return response\n  };\n\n  var redirectStatuses = [301, 302, 303, 307, 308];\n\n  Response.redirect = function(url, status) {\n    if (redirectStatuses.indexOf(status) === -1) {\n      throw new RangeError('Invalid status code')\n    }\n\n    return new Response(null, {status: status, headers: {location: url}})\n  };\n\n  exports.DOMException = self.DOMException;\n  try {\n    new exports.DOMException();\n  } catch (err) {\n    exports.DOMException = function(message, name) {\n      this.message = message;\n      this.name = name;\n      var error = Error(message);\n      this.stack = error.stack;\n    };\n    exports.DOMException.prototype = Object.create(Error.prototype);\n    exports.DOMException.prototype.constructor = exports.DOMException;\n  }\n\n  function fetch(input, init) {\n    return new Promise(function(resolve, reject) {\n      var request = new Request(input, init);\n\n      if (request.signal && request.signal.aborted) {\n        return reject(new exports.DOMException('Aborted', 'AbortError'))\n      }\n\n      var xhr = new XMLHttpRequest();\n\n      function abortXhr() {\n        xhr.abort();\n      }\n\n      xhr.onload = function() {\n        var options = {\n          status: xhr.status,\n          statusText: xhr.statusText,\n          headers: parseHeaders(xhr.getAllResponseHeaders() || '')\n        };\n        options.url = 'responseURL' in xhr ? xhr.responseURL : options.headers.get('X-Request-URL');\n        var body = 'response' in xhr ? xhr.response : xhr.responseText;\n        resolve(new Response(body, options));\n      };\n\n      xhr.onerror = function() {\n        reject(new TypeError('Network request failed'));\n      };\n\n      xhr.ontimeout = function() {\n        reject(new TypeError('Network request failed'));\n      };\n\n      xhr.onabort = function() {\n        reject(new exports.DOMException('Aborted', 'AbortError'));\n      };\n\n      xhr.open(request.method, request.url, true);\n\n      if (request.credentials === 'include') {\n        xhr.withCredentials = true;\n      } else if (request.credentials === 'omit') {\n        xhr.withCredentials = false;\n      }\n\n      if ('responseType' in xhr && support.blob) {\n        xhr.responseType = 'blob';\n      }\n\n      request.headers.forEach(function(value, name) {\n        xhr.setRequestHeader(name, value);\n      });\n\n      if (request.signal) {\n        request.signal.addEventListener('abort', abortXhr);\n\n        xhr.onreadystatechange = function() {\n          // DONE (success or failure)\n          if (xhr.readyState === 4) {\n            request.signal.removeEventListener('abort', abortXhr);\n          }\n        };\n      }\n\n      xhr.send(typeof request._bodyInit === 'undefined' ? null : request._bodyInit);\n    })\n  }\n\n  fetch.polyfill = true;\n\n  if (!self.fetch) {\n    self.fetch = fetch;\n    self.Headers = Headers;\n    self.Request = Request;\n    self.Response = Response;\n  }\n\n  exports.Headers = Headers;\n  exports.Request = Request;\n  exports.Response = Response;\n  exports.fetch = fetch;\n\n  Object.defineProperty(exports, '__esModule', { value: true });\n\n  return exports;\n\n})({});\n})(typeof self !== 'undefined' ? self : this);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/cross-fetch/dist/browser-polyfill.js?");

/***/ }),

/***/ "./node_modules/events/events.js":
/*!***************************************!*\
  !*** ./node_modules/events/events.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar R = typeof Reflect === 'object' ? Reflect : null\nvar ReflectApply = R && typeof R.apply === 'function'\n  ? R.apply\n  : function ReflectApply(target, receiver, args) {\n    return Function.prototype.apply.call(target, receiver, args);\n  }\n\nvar ReflectOwnKeys\nif (R && typeof R.ownKeys === 'function') {\n  ReflectOwnKeys = R.ownKeys\n} else if (Object.getOwnPropertySymbols) {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target)\n      .concat(Object.getOwnPropertySymbols(target));\n  };\n} else {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target);\n  };\n}\n\nfunction ProcessEmitWarning(warning) {\n  if (console && console.warn) console.warn(warning);\n}\n\nvar NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {\n  return value !== value;\n}\n\nfunction EventEmitter() {\n  EventEmitter.init.call(this);\n}\nmodule.exports = EventEmitter;\nmodule.exports.once = once;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._eventsCount = 0;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nvar defaultMaxListeners = 10;\n\nfunction checkListener(listener) {\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n}\n\nObject.defineProperty(EventEmitter, 'defaultMaxListeners', {\n  enumerable: true,\n  get: function() {\n    return defaultMaxListeners;\n  },\n  set: function(arg) {\n    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {\n      throw new RangeError('The value of \"defaultMaxListeners\" is out of range. It must be a non-negative number. Received ' + arg + '.');\n    }\n    defaultMaxListeners = arg;\n  }\n});\n\nEventEmitter.init = function() {\n\n  if (this._events === undefined ||\n      this._events === Object.getPrototypeOf(this)._events) {\n    this._events = Object.create(null);\n    this._eventsCount = 0;\n  }\n\n  this._maxListeners = this._maxListeners || undefined;\n};\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {\n  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {\n    throw new RangeError('The value of \"n\" is out of range. It must be a non-negative number. Received ' + n + '.');\n  }\n  this._maxListeners = n;\n  return this;\n};\n\nfunction _getMaxListeners(that) {\n  if (that._maxListeners === undefined)\n    return EventEmitter.defaultMaxListeners;\n  return that._maxListeners;\n}\n\nEventEmitter.prototype.getMaxListeners = function getMaxListeners() {\n  return _getMaxListeners(this);\n};\n\nEventEmitter.prototype.emit = function emit(type) {\n  var args = [];\n  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);\n  var doError = (type === 'error');\n\n  var events = this._events;\n  if (events !== undefined)\n    doError = (doError && events.error === undefined);\n  else if (!doError)\n    return false;\n\n  // If there is no 'error' event listener then throw.\n  if (doError) {\n    var er;\n    if (args.length > 0)\n      er = args[0];\n    if (er instanceof Error) {\n      // Note: The comments on the `throw` lines are intentional, they show\n      // up in Node's output if this results in an unhandled exception.\n      throw er; // Unhandled 'error' event\n    }\n    // At least give some kind of context to the user\n    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));\n    err.context = er;\n    throw err; // Unhandled 'error' event\n  }\n\n  var handler = events[type];\n\n  if (handler === undefined)\n    return false;\n\n  if (typeof handler === 'function') {\n    ReflectApply(handler, this, args);\n  } else {\n    var len = handler.length;\n    var listeners = arrayClone(handler, len);\n    for (var i = 0; i < len; ++i)\n      ReflectApply(listeners[i], this, args);\n  }\n\n  return true;\n};\n\nfunction _addListener(target, type, listener, prepend) {\n  var m;\n  var events;\n  var existing;\n\n  checkListener(listener);\n\n  events = target._events;\n  if (events === undefined) {\n    events = target._events = Object.create(null);\n    target._eventsCount = 0;\n  } else {\n    // To avoid recursion in the case that type === \"newListener\"! Before\n    // adding it to the listeners, first emit \"newListener\".\n    if (events.newListener !== undefined) {\n      target.emit('newListener', type,\n                  listener.listener ? listener.listener : listener);\n\n      // Re-assign `events` because a newListener handler could have caused the\n      // this._events to be assigned to a new object\n      events = target._events;\n    }\n    existing = events[type];\n  }\n\n  if (existing === undefined) {\n    // Optimize the case of one listener. Don't need the extra array object.\n    existing = events[type] = listener;\n    ++target._eventsCount;\n  } else {\n    if (typeof existing === 'function') {\n      // Adding the second element, need to change to array.\n      existing = events[type] =\n        prepend ? [listener, existing] : [existing, listener];\n      // If we've already got an array, just append.\n    } else if (prepend) {\n      existing.unshift(listener);\n    } else {\n      existing.push(listener);\n    }\n\n    // Check for listener leak\n    m = _getMaxListeners(target);\n    if (m > 0 && existing.length > m && !existing.warned) {\n      existing.warned = true;\n      // No error code for this since it is a Warning\n      // eslint-disable-next-line no-restricted-syntax\n      var w = new Error('Possible EventEmitter memory leak detected. ' +\n                          existing.length + ' ' + String(type) + ' listeners ' +\n                          'added. Use emitter.setMaxListeners() to ' +\n                          'increase limit');\n      w.name = 'MaxListenersExceededWarning';\n      w.emitter = target;\n      w.type = type;\n      w.count = existing.length;\n      ProcessEmitWarning(w);\n    }\n  }\n\n  return target;\n}\n\nEventEmitter.prototype.addListener = function addListener(type, listener) {\n  return _addListener(this, type, listener, false);\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.prependListener =\n    function prependListener(type, listener) {\n      return _addListener(this, type, listener, true);\n    };\n\nfunction onceWrapper() {\n  if (!this.fired) {\n    this.target.removeListener(this.type, this.wrapFn);\n    this.fired = true;\n    if (arguments.length === 0)\n      return this.listener.call(this.target);\n    return this.listener.apply(this.target, arguments);\n  }\n}\n\nfunction _onceWrap(target, type, listener) {\n  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };\n  var wrapped = onceWrapper.bind(state);\n  wrapped.listener = listener;\n  state.wrapFn = wrapped;\n  return wrapped;\n}\n\nEventEmitter.prototype.once = function once(type, listener) {\n  checkListener(listener);\n  this.on(type, _onceWrap(this, type, listener));\n  return this;\n};\n\nEventEmitter.prototype.prependOnceListener =\n    function prependOnceListener(type, listener) {\n      checkListener(listener);\n      this.prependListener(type, _onceWrap(this, type, listener));\n      return this;\n    };\n\n// Emits a 'removeListener' event if and only if the listener was removed.\nEventEmitter.prototype.removeListener =\n    function removeListener(type, listener) {\n      var list, events, position, i, originalListener;\n\n      checkListener(listener);\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      list = events[type];\n      if (list === undefined)\n        return this;\n\n      if (list === listener || list.listener === listener) {\n        if (--this._eventsCount === 0)\n          this._events = Object.create(null);\n        else {\n          delete events[type];\n          if (events.removeListener)\n            this.emit('removeListener', type, list.listener || listener);\n        }\n      } else if (typeof list !== 'function') {\n        position = -1;\n\n        for (i = list.length - 1; i >= 0; i--) {\n          if (list[i] === listener || list[i].listener === listener) {\n            originalListener = list[i].listener;\n            position = i;\n            break;\n          }\n        }\n\n        if (position < 0)\n          return this;\n\n        if (position === 0)\n          list.shift();\n        else {\n          spliceOne(list, position);\n        }\n\n        if (list.length === 1)\n          events[type] = list[0];\n\n        if (events.removeListener !== undefined)\n          this.emit('removeListener', type, originalListener || listener);\n      }\n\n      return this;\n    };\n\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\nEventEmitter.prototype.removeAllListeners =\n    function removeAllListeners(type) {\n      var listeners, events, i;\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      // not listening for removeListener, no need to emit\n      if (events.removeListener === undefined) {\n        if (arguments.length === 0) {\n          this._events = Object.create(null);\n          this._eventsCount = 0;\n        } else if (events[type] !== undefined) {\n          if (--this._eventsCount === 0)\n            this._events = Object.create(null);\n          else\n            delete events[type];\n        }\n        return this;\n      }\n\n      // emit removeListener for all listeners on all events\n      if (arguments.length === 0) {\n        var keys = Object.keys(events);\n        var key;\n        for (i = 0; i < keys.length; ++i) {\n          key = keys[i];\n          if (key === 'removeListener') continue;\n          this.removeAllListeners(key);\n        }\n        this.removeAllListeners('removeListener');\n        this._events = Object.create(null);\n        this._eventsCount = 0;\n        return this;\n      }\n\n      listeners = events[type];\n\n      if (typeof listeners === 'function') {\n        this.removeListener(type, listeners);\n      } else if (listeners !== undefined) {\n        // LIFO order\n        for (i = listeners.length - 1; i >= 0; i--) {\n          this.removeListener(type, listeners[i]);\n        }\n      }\n\n      return this;\n    };\n\nfunction _listeners(target, type, unwrap) {\n  var events = target._events;\n\n  if (events === undefined)\n    return [];\n\n  var evlistener = events[type];\n  if (evlistener === undefined)\n    return [];\n\n  if (typeof evlistener === 'function')\n    return unwrap ? [evlistener.listener || evlistener] : [evlistener];\n\n  return unwrap ?\n    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);\n}\n\nEventEmitter.prototype.listeners = function listeners(type) {\n  return _listeners(this, type, true);\n};\n\nEventEmitter.prototype.rawListeners = function rawListeners(type) {\n  return _listeners(this, type, false);\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  if (typeof emitter.listenerCount === 'function') {\n    return emitter.listenerCount(type);\n  } else {\n    return listenerCount.call(emitter, type);\n  }\n};\n\nEventEmitter.prototype.listenerCount = listenerCount;\nfunction listenerCount(type) {\n  var events = this._events;\n\n  if (events !== undefined) {\n    var evlistener = events[type];\n\n    if (typeof evlistener === 'function') {\n      return 1;\n    } else if (evlistener !== undefined) {\n      return evlistener.length;\n    }\n  }\n\n  return 0;\n}\n\nEventEmitter.prototype.eventNames = function eventNames() {\n  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];\n};\n\nfunction arrayClone(arr, n) {\n  var copy = new Array(n);\n  for (var i = 0; i < n; ++i)\n    copy[i] = arr[i];\n  return copy;\n}\n\nfunction spliceOne(list, index) {\n  for (; index + 1 < list.length; index++)\n    list[index] = list[index + 1];\n  list.pop();\n}\n\nfunction unwrapListeners(arr) {\n  var ret = new Array(arr.length);\n  for (var i = 0; i < ret.length; ++i) {\n    ret[i] = arr[i].listener || arr[i];\n  }\n  return ret;\n}\n\nfunction once(emitter, name) {\n  return new Promise(function (resolve, reject) {\n    function errorListener(err) {\n      emitter.removeListener(name, resolver);\n      reject(err);\n    }\n\n    function resolver() {\n      if (typeof emitter.removeListener === 'function') {\n        emitter.removeListener('error', errorListener);\n      }\n      resolve([].slice.call(arguments));\n    };\n\n    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });\n    if (name !== 'error') {\n      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });\n    }\n  });\n}\n\nfunction addErrorHandlerIfEventEmitter(emitter, handler, flags) {\n  if (typeof emitter.on === 'function') {\n    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);\n  }\n}\n\nfunction eventTargetAgnosticAddListener(emitter, name, listener, flags) {\n  if (typeof emitter.on === 'function') {\n    if (flags.once) {\n      emitter.once(name, listener);\n    } else {\n      emitter.on(name, listener);\n    }\n  } else if (typeof emitter.addEventListener === 'function') {\n    // EventTarget does not have `error` event semantics like Node\n    // EventEmitters, we do not listen for `error` events here.\n    emitter.addEventListener(name, function wrapListener(arg) {\n      // IE does not have builtin `{ once: true }` support so we\n      // have to do it manually.\n      if (flags.once) {\n        emitter.removeEventListener(name, wrapListener);\n      }\n      listener(arg);\n    });\n  } else {\n    throw new TypeError('The \"emitter\" argument must be of type EventEmitter. Received type ' + typeof emitter);\n  }\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/events/events.js?");

/***/ }),

/***/ "./node_modules/http-link-header/lib/link.js":
/*!***************************************************!*\
  !*** ./node_modules/http-link-header/lib/link.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/* provided dependency */ var Buffer = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")[\"Buffer\"];\n\n\nvar COMPATIBLE_ENCODING_PATTERN = /^utf-?8|ascii|utf-?16-?le|ucs-?2|base-?64|latin-?1$/i\nvar WS_TRIM_PATTERN = /^[\\s\\uFEFF\\xA0]+|[\\s\\uFEFF\\xA0]+$/g\nvar WS_CHAR_PATTERN = /\\s|\\uFEFF|\\xA0/\nvar WS_FOLD_PATTERN = /\\r?\\n[\\x20\\x09]+/g\nvar DELIMITER_PATTERN = /[;,\"]/\nvar WS_DELIMITER_PATTERN = /[;,\"]|\\s/\n\n/**\n * Token character pattern\n * @type {RegExp}\n * @see https://tools.ietf.org/html/rfc7230#section-3.2.6\n */\nvar TOKEN_PATTERN = /^[!#$%&'*+\\-\\.^_`|~\\da-zA-Z]+$/\n\nvar STATE = {\n  IDLE: 1 << 0,\n  URI: 1 << 1,\n  ATTR: 1 << 2,\n}\n\nfunction trim( value ) {\n  return value.replace( WS_TRIM_PATTERN, '' )\n}\n\nfunction hasWhitespace( value ) {\n  return WS_CHAR_PATTERN.test( value )\n}\n\nfunction skipWhitespace( value, offset ) {\n  while( hasWhitespace( value[offset] ) ) {\n    offset++\n  }\n  return offset\n}\n\nfunction needsQuotes( value ) {\n  return WS_DELIMITER_PATTERN.test( value ) ||\n    !TOKEN_PATTERN.test( value )\n}\n\n/**\n * Shallow compares two objects to check if their properties match.\n * @param {object} object1 First object to compare.\n * @param {object} object2 Second object to compare.\n * @returns {boolean} Do the objects have matching properties.\n */\nfunction shallowCompareObjects( object1, object2 ) {\n  return (\n    Object.keys( object1 ).length === Object.keys( object2 ).length &&\n    Object.keys( object1 ).every(\n      ( key ) => key in object2 && object1[ key ] === object2[ key ]\n    )\n  );\n}\n\nclass Link {\n\n  /**\n   * Link\n   * @constructor\n   * @param {String} [value]\n   * @returns {Link}\n   */\n  constructor( value ) {\n\n    /** @type {Array} URI references */\n    this.refs = []\n\n    if( value ) {\n      this.parse( value )\n    }\n\n  }\n\n  /**\n   * Get refs with given relation type\n   * @param {String} value\n   * @returns {Array<Object>}\n   */\n  rel( value ) {\n\n    var links = []\n    var type = value.toLowerCase()\n\n    for( var i = 0; i < this.refs.length; i++ ) {\n      if( typeof this.refs[ i ].rel === 'string' && this.refs[ i ].rel.toLowerCase() === type ) {\n        links.push( this.refs[ i ] )\n      }\n    }\n\n    return links\n\n  }\n\n  /**\n   * Get refs where given attribute has a given value\n   * @param {String} attr\n   * @param {String} value\n   * @returns {Array<Object>}\n   */\n  get( attr, value ) {\n\n    attr = attr.toLowerCase()\n    value = value.toLowerCase()\n\n    var links = []\n\n    for( var i = 0; i < this.refs.length; i++ ) {\n      if( typeof this.refs[ i ][ attr ] === 'string' && this.refs[ i ][ attr ].toLowerCase() === value ) {\n        links.push( this.refs[ i ] )\n      }\n    }\n\n    return links\n\n  }\n\n  /** Sets a reference. */\n  set( link ) {\n    this.refs.push( link )\n    return this\n  }\n\n  /**\n   * Sets a reference if a reference with similar properties isn’t already set.\n   */\n  setUnique( link ) {\n\n    if( !this.refs.some(( ref ) => shallowCompareObjects( ref, link )) ) {\n      this.refs.push( link )\n    }\n\n    return this\n\n  }\n\n  has( attr, value ) {\n\n    attr = attr.toLowerCase()\n    value = value.toLowerCase()\n\n    for( var i = 0; i < this.refs.length; i++ ) {\n      if( typeof this.refs[ i ][ attr ] === 'string' && this.refs[ i ][ attr ].toLowerCase() === value ) {\n        return true\n      }\n    }\n\n    return false\n\n  }\n\n  parse( value, offset ) {\n\n    offset = offset || 0\n    value = offset ? value.slice( offset ) : value\n\n    // Trim & unfold folded lines\n    value = trim( value ).replace( WS_FOLD_PATTERN, '' )\n\n    var state = STATE.IDLE\n    var length = value.length\n    var offset = 0\n    var ref = null\n\n    while( offset < length ) {\n      if( state === STATE.IDLE ) {\n        if( hasWhitespace( value[offset] ) ) {\n          offset++\n          continue\n        } else if( value[offset] === '<' ) {\n          if( ref != null ) {\n            ref.rel != null ?\n              this.refs.push( ...Link.expandRelations( ref ) ) :\n              this.refs.push( ref )\n          }\n          var end = value.indexOf( '>', offset )\n          if( end === -1 ) throw new Error( 'Expected end of URI delimiter at offset ' + offset )\n          ref = { uri: value.slice( offset + 1, end ) }\n          // this.refs.push( ref )\n          offset = end\n          state = STATE.URI\n        } else {\n          throw new Error( 'Unexpected character \"' + value[offset] + '\" at offset ' + offset )\n        }\n        offset++\n      } else if( state === STATE.URI ) {\n        if( hasWhitespace( value[offset] ) ) {\n          offset++\n          continue\n        } else if( value[offset] === ';' ) {\n          state = STATE.ATTR\n          offset++\n        } else if( value[offset] === ',' ) {\n          state = STATE.IDLE\n          offset++\n        } else {\n          throw new Error( 'Unexpected character \"' + value[offset] + '\" at offset ' + offset )\n        }\n      } else if( state === STATE.ATTR ) {\n        if( value[offset] ===';' || hasWhitespace( value[offset] ) ) {\n          offset++\n          continue\n        }\n        var end = value.indexOf( '=', offset )\n        if( end === -1 ) end = value.indexOf( ';', offset )\n        if( end === -1 ) end = value.length\n        var attr = trim( value.slice( offset, end ) ).toLowerCase()\n        var attrValue = ''\n        offset = end + 1\n        offset = skipWhitespace( value, offset )\n        if( value[offset] === '\"' ) {\n          offset++\n          while( offset < length ) {\n            if( value[offset] === '\"' ) {\n              offset++; break\n            }\n            if( value[offset] === '\\\\' ) {\n              offset++\n            }\n            attrValue += value[offset]\n            offset++\n          }\n        } else {\n          var end = offset + 1\n          while( !DELIMITER_PATTERN.test( value[end] ) && end < length ) {\n            end++\n          }\n          attrValue = value.slice( offset, end )\n          offset = end\n        }\n        if( ref[ attr ] && Link.isSingleOccurenceAttr( attr ) ) {\n          // Ignore multiples of attributes which may only appear once\n        } else if( attr[ attr.length - 1 ] === '*' ) {\n          ref[ attr ] = Link.parseExtendedValue( attrValue )\n        } else {\n          attrValue = attr === 'type' ?\n            attrValue.toLowerCase() : attrValue\n          if( ref[ attr ] != null ) {\n            if( Array.isArray( ref[ attr ] ) ) {\n              ref[ attr ].push( attrValue )\n            } else {\n              ref[ attr ] = [ ref[ attr ], attrValue ]\n            }\n          } else {\n            ref[ attr ] = attrValue\n          }\n        }\n        switch( value[offset] ) {\n          case ',': state = STATE.IDLE; break\n          case ';': state = STATE.ATTR; break\n        }\n        offset++\n      } else {\n        throw new Error( 'Unknown parser state \"' + state + '\"' )\n      }\n    }\n\n    if( ref != null ) {\n      ref.rel != null ?\n        this.refs.push( ...Link.expandRelations( ref ) ) :\n        this.refs.push( ref )\n    }\n\n    ref = null\n\n    return this\n\n  }\n\n  toString() {\n\n    var refs = []\n    var link = ''\n    var ref = null\n\n    for( var i = 0; i < this.refs.length; i++ ) {\n      ref = this.refs[i]\n      link = Object.keys( this.refs[i] ).reduce( function( link, attr ) {\n        if( attr === 'uri' ) return link\n        return link + '; ' + Link.formatAttribute( attr, ref[ attr ] )\n      }, '<' + ref.uri + '>' )\n      refs.push( link )\n    }\n\n    return refs.join( ', ' )\n\n  }\n\n}\n\n/**\n * Determines whether an encoding can be\n * natively handled with a `Buffer`\n * @param {String} value\n * @returns {Boolean}\n */\nLink.isCompatibleEncoding = function( value ) {\n  return COMPATIBLE_ENCODING_PATTERN.test( value )\n}\n\nLink.parse = function( value, offset ) {\n  return new Link().parse( value, offset )\n}\n\nLink.isSingleOccurenceAttr = function( attr ) {\n  return attr === 'rel' || attr === 'type' || attr === 'media' ||\n    attr === 'title' || attr === 'title*'\n}\n\nLink.isTokenAttr = function( attr ) {\n  return attr === 'rel' || attr === 'type' || attr === 'anchor'\n}\n\nLink.escapeQuotes = function( value ) {\n  return value.replace( /\"/g, '\\\\\"' )\n}\n\nLink.expandRelations = function( ref ) {\n  var rels = ref.rel.split( ' ' )\n  return rels.map( function( rel ) {\n    var value = Object.assign( {}, ref )\n    value.rel = rel\n    return value\n  })\n}\n\n/**\n * Parses an extended value and attempts to decode it\n * @internal\n * @param {String} value\n * @return {Object}\n */\nLink.parseExtendedValue = function( value ) {\n  var parts = /([^']+)?(?:'([^']*)')?(.+)/.exec( value )\n  return {\n    language: parts[2].toLowerCase(),\n    encoding: Link.isCompatibleEncoding( parts[1] ) ?\n      null : parts[1].toLowerCase(),\n    value: Link.isCompatibleEncoding( parts[1] ) ?\n      decodeURIComponent( parts[3] ) : parts[3]\n  }\n}\n\n/**\n * Format a given extended attribute and it's value\n * @param {String} attr\n * @param {Object} data\n * @return {String}\n */\nLink.formatExtendedAttribute = function( attr, data ) {\n\n  var encoding = ( data.encoding || 'utf-8' ).toUpperCase()\n  var language = data.language || 'en'\n\n  var encodedValue = ''\n\n  if( Buffer.isBuffer( data.value ) && Link.isCompatibleEncoding( encoding ) ) {\n    encodedValue = data.value.toString( encoding )\n  } else if( Buffer.isBuffer( data.value ) ) {\n    encodedValue = data.value.toString( 'hex' )\n      .replace( /[0-9a-f]{2}/gi, '%$1' )\n  } else {\n    encodedValue = encodeURIComponent( data.value )\n  }\n\n  return attr + '=' + encoding + '\\'' +\n    language + '\\'' + encodedValue\n\n}\n\n/**\n * Format a given attribute and it's value\n * @param {String} attr\n * @param {String|Object} value\n * @return {String}\n */\nLink.formatAttribute = function( attr, value ) {\n\n  if( Array.isArray( value ) ) {\n    return value.map(( item ) => {\n      return Link.formatAttribute( attr, item )\n    }).join( '; ' )\n  }\n\n  if( attr[ attr.length - 1 ] === '*' || typeof value !== 'string' ) {\n    return Link.formatExtendedAttribute( attr, value )\n  }\n\n  if( Link.isTokenAttr( attr ) ) {\n    value = needsQuotes( value ) ?\n      '\"' + Link.escapeQuotes( value ) + '\"' :\n      Link.escapeQuotes( value )\n  } else if( needsQuotes( value ) ) {\n    value = encodeURIComponent( value )\n    // We don't need to escape <SP> <,> <;> within quotes\n    value = value\n      .replace( /%20/g, ' ' )\n      .replace( /%2C/g, ',' )\n      .replace( /%3B/g, ';' )\n\n    value = '\"' + value + '\"'\n  }\n\n  return attr + '=' + value\n\n}\n\nmodule.exports = Link\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/http-link-header/lib/link.js?");

/***/ }),

/***/ "./node_modules/ieee754/index.js":
/*!***************************************!*\
  !*** ./node_modules/ieee754/index.js ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports) => {

eval("/*! ieee754. BSD-3-Clause License. Feross Aboukhadijeh <https://feross.org/opensource> */\nexports.read = function (buffer, offset, isLE, mLen, nBytes) {\n  var e, m\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var nBits = -7\n  var i = isLE ? (nBytes - 1) : 0\n  var d = isLE ? -1 : 1\n  var s = buffer[offset + i]\n\n  i += d\n\n  e = s & ((1 << (-nBits)) - 1)\n  s >>= (-nBits)\n  nBits += eLen\n  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  m = e & ((1 << (-nBits)) - 1)\n  e >>= (-nBits)\n  nBits += mLen\n  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  if (e === 0) {\n    e = 1 - eBias\n  } else if (e === eMax) {\n    return m ? NaN : ((s ? -1 : 1) * Infinity)\n  } else {\n    m = m + Math.pow(2, mLen)\n    e = e - eBias\n  }\n  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)\n}\n\nexports.write = function (buffer, value, offset, isLE, mLen, nBytes) {\n  var e, m, c\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)\n  var i = isLE ? 0 : (nBytes - 1)\n  var d = isLE ? 1 : -1\n  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0\n\n  value = Math.abs(value)\n\n  if (isNaN(value) || value === Infinity) {\n    m = isNaN(value) ? 1 : 0\n    e = eMax\n  } else {\n    e = Math.floor(Math.log(value) / Math.LN2)\n    if (value * (c = Math.pow(2, -e)) < 1) {\n      e--\n      c *= 2\n    }\n    if (e + eBias >= 1) {\n      value += rt / c\n    } else {\n      value += rt * Math.pow(2, 1 - eBias)\n    }\n    if (value * c >= 2) {\n      e++\n      c /= 2\n    }\n\n    if (e + eBias >= eMax) {\n      m = 0\n      e = eMax\n    } else if (e + eBias >= 1) {\n      m = ((value * c) - 1) * Math.pow(2, mLen)\n      e = e + eBias\n    } else {\n      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)\n      e = 0\n    }\n  }\n\n  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}\n\n  e = (e << mLen) | m\n  eLen += mLen\n  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}\n\n  buffer[offset + i - d] |= s * 128\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/ieee754/index.js?");

/***/ }),

/***/ "./node_modules/jsonld-context-parser/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/jsonld-context-parser/index.js ***!
  \*****************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n__exportStar(__webpack_require__(/*! ./lib/ContextParser */ \"./node_modules/jsonld-context-parser/lib/ContextParser.js\"), exports);\n__exportStar(__webpack_require__(/*! ./lib/ErrorCoded */ \"./node_modules/jsonld-context-parser/lib/ErrorCoded.js\"), exports);\n__exportStar(__webpack_require__(/*! ./lib/FetchDocumentLoader */ \"./node_modules/jsonld-context-parser/lib/FetchDocumentLoader.js\"), exports);\n__exportStar(__webpack_require__(/*! ./lib/IDocumentLoader */ \"./node_modules/jsonld-context-parser/lib/IDocumentLoader.js\"), exports);\n__exportStar(__webpack_require__(/*! ./lib/JsonLdContext */ \"./node_modules/jsonld-context-parser/lib/JsonLdContext.js\"), exports);\n__exportStar(__webpack_require__(/*! ./lib/JsonLdContextNormalized */ \"./node_modules/jsonld-context-parser/lib/JsonLdContextNormalized.js\"), exports);\n__exportStar(__webpack_require__(/*! ./lib/Util */ \"./node_modules/jsonld-context-parser/lib/Util.js\"), exports);\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-context-parser/index.js?");

/***/ }),

/***/ "./node_modules/jsonld-context-parser/lib/ContextParser.js":
/*!*****************************************************************!*\
  !*** ./node_modules/jsonld-context-parser/lib/ContextParser.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ContextParser = void 0;\n__webpack_require__(/*! cross-fetch/polyfill */ \"./node_modules/cross-fetch/dist/browser-polyfill.js\");\nconst relative_to_absolute_iri_1 = __webpack_require__(/*! relative-to-absolute-iri */ \"./node_modules/relative-to-absolute-iri/index.js\");\nconst ErrorCoded_1 = __webpack_require__(/*! ./ErrorCoded */ \"./node_modules/jsonld-context-parser/lib/ErrorCoded.js\");\nconst FetchDocumentLoader_1 = __webpack_require__(/*! ./FetchDocumentLoader */ \"./node_modules/jsonld-context-parser/lib/FetchDocumentLoader.js\");\nconst JsonLdContextNormalized_1 = __webpack_require__(/*! ./JsonLdContextNormalized */ \"./node_modules/jsonld-context-parser/lib/JsonLdContextNormalized.js\");\nconst Util_1 = __webpack_require__(/*! ./Util */ \"./node_modules/jsonld-context-parser/lib/Util.js\");\n/**\n * Parses JSON-LD contexts.\n */\nclass ContextParser {\n    constructor(options) {\n        options = options || {};\n        this.documentLoader = options.documentLoader || new FetchDocumentLoader_1.FetchDocumentLoader();\n        this.documentCache = {};\n        this.validateContext = !options.skipValidation;\n        this.expandContentTypeToBase = !!options.expandContentTypeToBase;\n        this.remoteContextsDepthLimit = options.remoteContextsDepthLimit || 32;\n        this.redirectSchemaOrgHttps = 'redirectSchemaOrgHttps' in options ? !!options.redirectSchemaOrgHttps : true;\n    }\n    /**\n     * Validate the given @language value.\n     * An error will be thrown if it is invalid.\n     * @param value An @language value.\n     * @param {boolean} strictRange If the string value should be strictly checked against a regex.\n     * @param {string} errorCode The error code to emit on errors.\n     * @return {boolean} If validation passed.\n     *                   Can only be false if strictRange is false and the string value did not pass the regex.\n     */\n    static validateLanguage(value, strictRange, errorCode) {\n        if (typeof value !== 'string') {\n            throw new ErrorCoded_1.ErrorCoded(`The value of an '@language' must be a string, got '${JSON.stringify(value)}'`, errorCode);\n        }\n        if (!Util_1.Util.REGEX_LANGUAGE_TAG.test(value)) {\n            if (strictRange) {\n                throw new ErrorCoded_1.ErrorCoded(`The value of an '@language' must be a valid language tag, got '${JSON.stringify(value)}'`, errorCode);\n            }\n            else {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Validate the given @direction value.\n     * An error will be thrown if it is invalid.\n     * @param value An @direction value.\n     * @param {boolean} strictValues If the string value should be strictly checked against a regex.\n     * @return {boolean} If validation passed.\n     *                   Can only be false if strictRange is false and the string value did not pass the regex.\n     */\n    static validateDirection(value, strictValues) {\n        if (typeof value !== 'string') {\n            throw new ErrorCoded_1.ErrorCoded(`The value of an '@direction' must be a string, got '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_BASE_DIRECTION);\n        }\n        if (!Util_1.Util.REGEX_DIRECTION_TAG.test(value)) {\n            if (strictValues) {\n                throw new ErrorCoded_1.ErrorCoded(`The value of an '@direction' must be 'ltr' or 'rtl', got '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_BASE_DIRECTION);\n            }\n            else {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Add an @id term for all @reverse terms.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @return {IJsonLdContextNormalizedRaw} The mutated input context.\n     */\n    idifyReverseTerms(context) {\n        for (const key of Object.keys(context)) {\n            let value = context[key];\n            if (value && typeof value === 'object') {\n                if (value['@reverse'] && !value['@id']) {\n                    if (typeof value['@reverse'] !== 'string' || Util_1.Util.isValidKeyword(value['@reverse'])) {\n                        throw new ErrorCoded_1.ErrorCoded(`Invalid @reverse value, must be absolute IRI or blank node: '${value['@reverse']}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                    }\n                    value = context[key] = Object.assign(Object.assign({}, value), { '@id': value['@reverse'] });\n                    value['@id'] = value['@reverse'];\n                    if (Util_1.Util.isPotentialKeyword(value['@reverse'])) {\n                        delete value['@reverse'];\n                    }\n                    else {\n                        value['@reverse'] = true;\n                    }\n                }\n            }\n        }\n        return context;\n    }\n    /**\n     * Expand all prefixed terms in the given context.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {boolean} expandContentTypeToBase If @type inside the context may be expanded\n     *                                          via @base if @vocab is set to null.\n     * @param {string[]} keys Optional set of keys from the context to expand. If left undefined, all\n     * keys in the context will be expanded.\n     */\n    expandPrefixedTerms(context, expandContentTypeToBase, keys) {\n        const contextRaw = context.getContextRaw();\n        for (const key of (keys || Object.keys(contextRaw))) {\n            // Only expand allowed keys\n            if (Util_1.Util.EXPAND_KEYS_BLACKLIST.indexOf(key) < 0 && !Util_1.Util.isReservedInternalKeyword(key)) {\n                // Error if we try to alias a keyword to something else.\n                const keyValue = contextRaw[key];\n                if (Util_1.Util.isPotentialKeyword(key) && Util_1.Util.ALIAS_DOMAIN_BLACKLIST.indexOf(key) >= 0) {\n                    if (key !== '@type' || typeof contextRaw[key] === 'object'\n                        && !(contextRaw[key]['@protected'] || contextRaw[key]['@container'] === '@set')) {\n                        throw new ErrorCoded_1.ErrorCoded(`Keywords can not be aliased to something else.\nTried mapping ${key} to ${JSON.stringify(keyValue)}`, ErrorCoded_1.ERROR_CODES.KEYWORD_REDEFINITION);\n                    }\n                }\n                // Error if we try to alias to an illegal keyword\n                if (Util_1.Util.ALIAS_RANGE_BLACKLIST.indexOf(Util_1.Util.getContextValueId(keyValue)) >= 0) {\n                    throw new ErrorCoded_1.ErrorCoded(`Aliasing to certain keywords is not allowed.\nTried mapping ${key} to ${JSON.stringify(keyValue)}`, ErrorCoded_1.ERROR_CODES.INVALID_KEYWORD_ALIAS);\n                }\n                // Error if this term was marked as prefix as well\n                if (keyValue && Util_1.Util.isPotentialKeyword(Util_1.Util.getContextValueId(keyValue))\n                    && keyValue['@prefix'] === true) {\n                    throw new ErrorCoded_1.ErrorCoded(`Tried to use keyword aliases as prefix: '${key}': '${JSON.stringify(keyValue)}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                // Loop because prefixes might be nested\n                while (Util_1.Util.isPrefixValue(contextRaw[key])) {\n                    const value = contextRaw[key];\n                    let changed = false;\n                    if (typeof value === 'string') {\n                        contextRaw[key] = context.expandTerm(value, true);\n                        changed = changed || value !== contextRaw[key];\n                    }\n                    else {\n                        const id = value['@id'];\n                        const type = value['@type'];\n                        // If @id is missing, don't allow @id to be added if @prefix: true and key not being a valid IRI.\n                        const canAddIdEntry = !('@prefix' in value) || Util_1.Util.isValidIri(key);\n                        if ('@id' in value) {\n                            // Use @id value for expansion\n                            if (id !== undefined && id !== null && typeof id === 'string') {\n                                contextRaw[key] = Object.assign(Object.assign({}, contextRaw[key]), { '@id': context.expandTerm(id, true) });\n                                changed = changed || id !== contextRaw[key]['@id'];\n                            }\n                        }\n                        else if (!Util_1.Util.isPotentialKeyword(key) && canAddIdEntry) {\n                            // Add an explicit @id value based on the expanded key value\n                            const newId = context.expandTerm(key, true);\n                            if (newId !== key) {\n                                // Don't set @id if expansion failed\n                                contextRaw[key] = Object.assign(Object.assign({}, contextRaw[key]), { '@id': newId });\n                                changed = true;\n                            }\n                        }\n                        if (type && typeof type === 'string' && type !== '@vocab'\n                            && (!value['@container'] || !value['@container']['@type'])\n                            && canAddIdEntry) {\n                            // First check @vocab, then fallback to @base\n                            let expandedType = context.expandTerm(type, true);\n                            if (expandContentTypeToBase && type === expandedType) {\n                                expandedType = context.expandTerm(type, false);\n                            }\n                            if (expandedType !== type) {\n                                changed = true;\n                                contextRaw[key] = Object.assign(Object.assign({}, contextRaw[key]), { '@type': expandedType });\n                            }\n                        }\n                    }\n                    if (!changed) {\n                        break;\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Normalize the @language entries in the given context to lowercase.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {IParseOptions} parseOptions The parsing options.\n     */\n    normalize(context, { processingMode, normalizeLanguageTags }) {\n        // Lowercase language keys in 1.0\n        if (normalizeLanguageTags || processingMode === 1.0) {\n            for (const key of Object.keys(context)) {\n                if (key === '@language' && typeof context[key] === 'string') {\n                    context[key] = context[key].toLowerCase();\n                }\n                else {\n                    const value = context[key];\n                    if (value && typeof value === 'object') {\n                        if (typeof value['@language'] === 'string') {\n                            const lowercase = value['@language'].toLowerCase();\n                            if (lowercase !== value['@language']) {\n                                context[key] = Object.assign(Object.assign({}, value), { '@language': lowercase });\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Convert all @container strings and array values to hash-based values.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     */\n    containersToHash(context) {\n        for (const key of Object.keys(context)) {\n            const value = context[key];\n            if (value && typeof value === 'object') {\n                if (typeof value['@container'] === 'string') {\n                    context[key] = Object.assign(Object.assign({}, value), { '@container': { [value['@container']]: true } });\n                }\n                else if (Array.isArray(value['@container'])) {\n                    const newValue = {};\n                    for (const containerValue of value['@container']) {\n                        newValue[containerValue] = true;\n                    }\n                    context[key] = Object.assign(Object.assign({}, value), { '@container': newValue });\n                }\n            }\n        }\n    }\n    /**\n     * Normalize and apply context-level @protected terms onto each term separately.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {number} processingMode The processing mode.\n     */\n    applyScopedProtected(context, { processingMode }, expandOptions) {\n        if (processingMode && processingMode >= 1.1) {\n            if (context['@protected']) {\n                for (const key of Object.keys(context)) {\n                    if (Util_1.Util.isReservedInternalKeyword(key)) {\n                        continue;\n                    }\n                    if (!Util_1.Util.isPotentialKeyword(key) && !Util_1.Util.isTermProtected(context, key)) {\n                        const value = context[key];\n                        if (value && typeof value === 'object') {\n                            if (!('@protected' in context[key])) {\n                                // Mark terms with object values as protected if they don't have an @protected: false annotation\n                                context[key] = Object.assign(Object.assign({}, context[key]), { '@protected': true });\n                            }\n                        }\n                        else {\n                            // Convert string-based term values to object-based values with @protected: true\n                            context[key] = {\n                                '@id': value,\n                                '@protected': true,\n                            };\n                            if (Util_1.Util.isSimpleTermDefinitionPrefix(value, expandOptions)) {\n                                context[key] = Object.assign(Object.assign({}, context[key]), { '@prefix': true });\n                            }\n                        }\n                    }\n                }\n                delete context['@protected'];\n            }\n        }\n    }\n    /**\n     * Check if the given context inheritance does not contain any overrides of protected terms.\n     * @param {IJsonLdContextNormalizedRaw} contextBefore The context that may contain some protected terms.\n     * @param {IJsonLdContextNormalizedRaw} contextAfter A new context that is being applied on the first one.\n     * @param {IExpandOptions} expandOptions Options that are needed for any expansions during this validation.\n     * @param {string[]} keys Optional set of keys from the context to validate. If left undefined, all\n     * keys defined in contextAfter will be checked.\n     */\n    validateKeywordRedefinitions(contextBefore, contextAfter, expandOptions, keys) {\n        for (const key of (keys !== null && keys !== void 0 ? keys : Object.keys(contextAfter))) {\n            if (Util_1.Util.isTermProtected(contextBefore, key)) {\n                // The entry in the context before will always be in object-mode\n                // If the new entry is in string-mode, convert it to object-mode\n                // before checking if it is identical.\n                if (typeof contextAfter[key] === 'string') {\n                    contextAfter[key] = { '@id': contextAfter[key], '@protected': true };\n                }\n                else {\n                    // We modify this deliberately,\n                    // as we need it for the value comparison (they must be identical modulo '@protected')),\n                    // and for the fact that this new value will override the first one.\n                    contextAfter[key] = Object.assign(Object.assign({}, contextAfter[key]), { '@protected': true });\n                }\n                // Error if they are not identical\n                if (!Util_1.Util.deepEqual(contextBefore[key], contextAfter[key])) {\n                    throw new ErrorCoded_1.ErrorCoded(`Attempted to override the protected keyword ${key} from ${JSON.stringify(Util_1.Util.getContextValueId(contextBefore[key]))} to ${JSON.stringify(Util_1.Util.getContextValueId(contextAfter[key]))}`, ErrorCoded_1.ERROR_CODES.PROTECTED_TERM_REDEFINITION);\n                }\n            }\n        }\n    }\n    /**\n     * Validate the entries of the given context.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {IParseOptions} options The parse options.\n     */\n    validate(context, { processingMode }) {\n        for (const key of Object.keys(context)) {\n            // Ignore reserved internal keywords.\n            if (Util_1.Util.isReservedInternalKeyword(key)) {\n                continue;\n            }\n            // Do not allow empty term\n            if (key === '') {\n                throw new ErrorCoded_1.ErrorCoded(`The empty term is not allowed, got: '${key}': '${JSON.stringify(context[key])}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n            }\n            const value = context[key];\n            const valueType = typeof value;\n            // First check if the key is a keyword\n            if (Util_1.Util.isPotentialKeyword(key)) {\n                switch (key.substr(1)) {\n                    case 'vocab':\n                        if (value !== null && valueType !== 'string') {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an invalid @vocab IRI: ${value}`, ErrorCoded_1.ERROR_CODES.INVALID_VOCAB_MAPPING);\n                        }\n                        break;\n                    case 'base':\n                        if (value !== null && valueType !== 'string') {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an invalid @base IRI: ${context[key]}`, ErrorCoded_1.ERROR_CODES.INVALID_BASE_IRI);\n                        }\n                        break;\n                    case 'language':\n                        if (value !== null) {\n                            ContextParser.validateLanguage(value, true, ErrorCoded_1.ERROR_CODES.INVALID_DEFAULT_LANGUAGE);\n                        }\n                        break;\n                    case 'version':\n                        if (value !== null && valueType !== 'number') {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an invalid @version number: ${value}`, ErrorCoded_1.ERROR_CODES.INVALID_VERSION_VALUE);\n                        }\n                        break;\n                    case 'direction':\n                        if (value !== null) {\n                            ContextParser.validateDirection(value, true);\n                        }\n                        break;\n                    case 'propagate':\n                        if (processingMode === 1.0) {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an illegal @propagate keyword: ${value}`, ErrorCoded_1.ERROR_CODES.INVALID_CONTEXT_ENTRY);\n                        }\n                        if (value !== null && valueType !== 'boolean') {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an invalid @propagate value: ${value}`, ErrorCoded_1.ERROR_CODES.INVALID_PROPAGATE_VALUE);\n                        }\n                        break;\n                }\n                // Don't allow keywords to be overridden\n                if (Util_1.Util.isValidKeyword(key) && Util_1.Util.isValidKeyword(Util_1.Util.getContextValueId(value))) {\n                    throw new ErrorCoded_1.ErrorCoded(`Illegal keyword alias in term value, found: '${key}': '${Util_1.Util\n                        .getContextValueId(value)}'`, ErrorCoded_1.ERROR_CODES.KEYWORD_REDEFINITION);\n                }\n                continue;\n            }\n            // Otherwise, consider the key a term\n            if (value !== null) {\n                switch (valueType) {\n                    case 'string':\n                        if (Util_1.Util.getPrefix(value, context) === key) {\n                            throw new ErrorCoded_1.ErrorCoded(`Detected cyclical IRI mapping in context entry: '${key}': '${JSON\n                                .stringify(value)}'`, ErrorCoded_1.ERROR_CODES.CYCLIC_IRI_MAPPING);\n                        }\n                        if (Util_1.Util.isValidIriWeak(key)) {\n                            if (value === '@type') {\n                                throw new ErrorCoded_1.ErrorCoded(`IRIs can not be mapped to @type, found: '${key}': '${value}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                            }\n                            else if (Util_1.Util.isValidIri(value) && value !== new JsonLdContextNormalized_1.JsonLdContextNormalized(context).expandTerm(key)) {\n                                throw new ErrorCoded_1.ErrorCoded(`IRIs can not be mapped to other IRIs, found: '${key}': '${value}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                            }\n                        }\n                        break;\n                    case 'object':\n                        if (!Util_1.Util.isCompactIri(key) && !('@id' in value)\n                            && (value['@type'] === '@id' ? !context['@base'] : !context['@vocab'])) {\n                            throw new ErrorCoded_1.ErrorCoded(`Missing @id in context entry: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                        }\n                        for (const objectKey of Object.keys(value)) {\n                            const objectValue = value[objectKey];\n                            if (!objectValue) {\n                                continue;\n                            }\n                            switch (objectKey) {\n                                case '@id':\n                                    if (Util_1.Util.isValidKeyword(objectValue)\n                                        && objectValue !== '@type' && objectValue !== '@id' && objectValue !== '@graph' && objectValue !== '@nest') {\n                                        throw new ErrorCoded_1.ErrorCoded(`Illegal keyword alias in term value, found: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                                    }\n                                    if (Util_1.Util.isValidIriWeak(key)) {\n                                        if (objectValue === '@type') {\n                                            throw new ErrorCoded_1.ErrorCoded(`IRIs can not be mapped to @type, found: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                                        }\n                                        else if (Util_1.Util.isValidIri(objectValue)\n                                            && objectValue !== new JsonLdContextNormalized_1.JsonLdContextNormalized(context).expandTerm(key)) {\n                                            throw new ErrorCoded_1.ErrorCoded(`IRIs can not be mapped to other IRIs, found: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                                        }\n                                    }\n                                    if (typeof objectValue !== 'string') {\n                                        throw new ErrorCoded_1.ErrorCoded(`Detected non-string @id in context entry: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                                    }\n                                    if (Util_1.Util.getPrefix(objectValue, context) === key) {\n                                        throw new ErrorCoded_1.ErrorCoded(`Detected cyclical IRI mapping in context entry: '${key}': '${JSON\n                                            .stringify(value)}'`, ErrorCoded_1.ERROR_CODES.CYCLIC_IRI_MAPPING);\n                                    }\n                                    break;\n                                case '@type':\n                                    if (value['@container'] === '@type' && objectValue !== '@id' && objectValue !== '@vocab') {\n                                        throw new ErrorCoded_1.ErrorCoded(`@container: @type only allows @type: @id or @vocab, but got: '${key}': '${objectValue}'`, ErrorCoded_1.ERROR_CODES.INVALID_TYPE_MAPPING);\n                                    }\n                                    if (typeof objectValue !== 'string') {\n                                        throw new ErrorCoded_1.ErrorCoded(`The value of an '@type' must be a string, got '${JSON.stringify(valueType)}'`, ErrorCoded_1.ERROR_CODES.INVALID_TYPE_MAPPING);\n                                    }\n                                    if (objectValue !== '@id' && objectValue !== '@vocab'\n                                        && (processingMode === 1.0 || objectValue !== '@json')\n                                        && (processingMode === 1.0 || objectValue !== '@none')\n                                        && (objectValue[0] === '_' || !Util_1.Util.isValidIri(objectValue))) {\n                                        throw new ErrorCoded_1.ErrorCoded(`A context @type must be an absolute IRI, found: '${key}': '${objectValue}'`, ErrorCoded_1.ERROR_CODES.INVALID_TYPE_MAPPING);\n                                    }\n                                    break;\n                                case '@reverse':\n                                    if (typeof objectValue === 'string' && value['@id'] && value['@id'] !== objectValue) {\n                                        throw new ErrorCoded_1.ErrorCoded(`Found non-matching @id and @reverse term values in '${key}':\\\n'${objectValue}' and '${value['@id']}'`, ErrorCoded_1.ERROR_CODES.INVALID_REVERSE_PROPERTY);\n                                    }\n                                    if ('@nest' in value) {\n                                        throw new ErrorCoded_1.ErrorCoded(`@nest is not allowed in the reverse property '${key}'`, ErrorCoded_1.ERROR_CODES.INVALID_REVERSE_PROPERTY);\n                                    }\n                                    break;\n                                case '@container':\n                                    if (processingMode === 1.0) {\n                                        if (Object.keys(objectValue).length > 1\n                                            || Util_1.Util.CONTAINERS_1_0.indexOf(Object.keys(objectValue)[0]) < 0) {\n                                            throw new ErrorCoded_1.ErrorCoded(`Invalid term @container for '${key}' ('${Object.keys(objectValue)}') in 1.0, \\\nmust be only one of ${Util_1.Util.CONTAINERS_1_0.join(', ')}`, ErrorCoded_1.ERROR_CODES.INVALID_CONTAINER_MAPPING);\n                                        }\n                                    }\n                                    for (const containerValue of Object.keys(objectValue)) {\n                                        if (containerValue === '@list' && value['@reverse']) {\n                                            throw new ErrorCoded_1.ErrorCoded(`Term value can not be @container: @list and @reverse at the same time on '${key}'`, ErrorCoded_1.ERROR_CODES.INVALID_REVERSE_PROPERTY);\n                                        }\n                                        if (Util_1.Util.CONTAINERS.indexOf(containerValue) < 0) {\n                                            throw new ErrorCoded_1.ErrorCoded(`Invalid term @container for '${key}' ('${containerValue}'), \\\nmust be one of ${Util_1.Util.CONTAINERS.join(', ')}`, ErrorCoded_1.ERROR_CODES.INVALID_CONTAINER_MAPPING);\n                                        }\n                                    }\n                                    break;\n                                case '@language':\n                                    ContextParser.validateLanguage(objectValue, true, ErrorCoded_1.ERROR_CODES.INVALID_LANGUAGE_MAPPING);\n                                    break;\n                                case '@direction':\n                                    ContextParser.validateDirection(objectValue, true);\n                                    break;\n                                case '@prefix':\n                                    if (objectValue !== null && typeof objectValue !== 'boolean') {\n                                        throw new ErrorCoded_1.ErrorCoded(`Found an invalid term @prefix boolean in: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_PREFIX_VALUE);\n                                    }\n                                    if (!('@id' in value) && !Util_1.Util.isValidIri(key)) {\n                                        throw new ErrorCoded_1.ErrorCoded(`Invalid @prefix definition for '${key}' ('${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                                    }\n                                    break;\n                                case '@index':\n                                    if (processingMode === 1.0 || !value['@container'] || !value['@container']['@index']) {\n                                        throw new ErrorCoded_1.ErrorCoded(`Attempt to add illegal key to value object: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                                    }\n                                    break;\n                                case '@nest':\n                                    if (Util_1.Util.isPotentialKeyword(objectValue) && objectValue !== '@nest') {\n                                        throw new ErrorCoded_1.ErrorCoded(`Found an invalid term @nest value in: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_NEST_VALUE);\n                                    }\n                            }\n                        }\n                        break;\n                    default:\n                        throw new ErrorCoded_1.ErrorCoded(`Found an invalid term value: '${key}': '${value}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n            }\n        }\n    }\n    /**\n     * Apply the @base context entry to the given context under certain circumstances.\n     * @param context A context.\n     * @param options Parsing options.\n     * @param inheritFromParent If the @base value from the parent context can be inherited.\n     * @return The given context.\n     */\n    applyBaseEntry(context, options, inheritFromParent) {\n        // In some special cases, this can be a string, so ignore those.\n        if (typeof context === 'string') {\n            return context;\n        }\n        // Give priority to @base in the parent context\n        if (inheritFromParent && !('@base' in context) && options.parentContext\n            && typeof options.parentContext === 'object' && '@base' in options.parentContext) {\n            context['@base'] = options.parentContext['@base'];\n            if (options.parentContext['@__baseDocument']) {\n                context['@__baseDocument'] = true;\n            }\n        }\n        // Override the base IRI if provided.\n        if (options.baseIRI && !options.external) {\n            if (!('@base' in context)) {\n                // The context base is the document base\n                context['@base'] = options.baseIRI;\n                context['@__baseDocument'] = true;\n            }\n            else if (context['@base'] !== null && typeof context['@base'] === 'string'\n                && !Util_1.Util.isValidIri(context['@base'])) {\n                // The context base is relative to the document base\n                context['@base'] = (0, relative_to_absolute_iri_1.resolve)(context['@base'], options.parentContext && options.parentContext['@base'] || options.baseIRI);\n            }\n        }\n        return context;\n    }\n    /**\n     * Resolve relative context IRIs, or return full IRIs as-is.\n     * @param {string} contextIri A context IRI.\n     * @param {string} baseIRI A base IRI.\n     * @return {string} The normalized context IRI.\n     */\n    normalizeContextIri(contextIri, baseIRI) {\n        if (!Util_1.Util.isValidIri(contextIri)) {\n            try {\n                contextIri = (0, relative_to_absolute_iri_1.resolve)(contextIri, baseIRI);\n            }\n            catch (_a) {\n                throw new Error(`Invalid context IRI: ${contextIri}`);\n            }\n        }\n        // TODO: Temporary workaround for fixing schema.org CORS issues (https://github.com/schemaorg/schemaorg/issues/2578#issuecomment-652324465)\n        if (this.redirectSchemaOrgHttps && contextIri.startsWith('http://schema.org')) {\n            contextIri = 'https://schema.org/';\n        }\n        return contextIri;\n    }\n    /**\n     * Parse scoped contexts in the given context.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {IParseOptions} options Parsing options.\n     * @return {IJsonLdContextNormalizedRaw} The mutated input context.\n     * @param {string[]} keys Optional set of keys from the context to parseInnerContexts of. If left undefined, all\n     * keys in the context will be iterated over.\n     */\n    async parseInnerContexts(context, options, keys) {\n        for (const key of (keys !== null && keys !== void 0 ? keys : Object.keys(context))) {\n            const value = context[key];\n            if (value && typeof value === 'object') {\n                if ('@context' in value && value['@context'] !== null && !options.ignoreScopedContexts) {\n                    // Simulate a processing based on the parent context to check if there are any (potential errors).\n                    // Honestly, I find it a bit weird to do this here, as the context may be unused,\n                    // and the final effective context may differ based on any other embedded/scoped contexts.\n                    // But hey, it's part of the spec, so we have no choice...\n                    // https://w3c.github.io/json-ld-api/#h-note-10\n                    if (this.validateContext) {\n                        try {\n                            const parentContext = Object.assign(Object.assign({}, context), { [key]: Object.assign({}, context[key]) });\n                            delete parentContext[key]['@context'];\n                            await this.parse(value['@context'], Object.assign(Object.assign({}, options), { external: false, parentContext, ignoreProtection: true, ignoreRemoteScopedContexts: true, ignoreScopedContexts: true }));\n                        }\n                        catch (e) {\n                            throw new ErrorCoded_1.ErrorCoded(e.message, ErrorCoded_1.ERROR_CODES.INVALID_SCOPED_CONTEXT);\n                        }\n                    }\n                    context[key] = Object.assign(Object.assign({}, value), { '@context': (await this.parse(value['@context'], Object.assign(Object.assign({}, options), { external: false, minimalProcessing: true, ignoreRemoteScopedContexts: true, parentContext: context })))\n                            .getContextRaw() });\n                }\n            }\n        }\n        return context;\n    }\n    async parse(context, options = {}, \n    // These options are only for internal use on recursive calls and should not be used by\n    // libraries consuming this function\n    internalOptions = {}) {\n        const { baseIRI, parentContext, external, processingMode = ContextParser.DEFAULT_PROCESSING_MODE, normalizeLanguageTags, ignoreProtection, minimalProcessing, } = options;\n        const remoteContexts = options.remoteContexts || {};\n        // Avoid remote context overflows\n        if (Object.keys(remoteContexts).length >= this.remoteContextsDepthLimit) {\n            throw new ErrorCoded_1.ErrorCoded('Detected an overflow in remote context inclusions: ' + Object.keys(remoteContexts), ErrorCoded_1.ERROR_CODES.CONTEXT_OVERFLOW);\n        }\n        if (context === null || context === undefined) {\n            // Don't allow context nullification and there are protected terms\n            if (!ignoreProtection && parentContext && Util_1.Util.hasProtectedTerms(parentContext)) {\n                throw new ErrorCoded_1.ErrorCoded('Illegal context nullification when terms are protected', ErrorCoded_1.ERROR_CODES.INVALID_CONTEXT_NULLIFICATION);\n            }\n            // Context that are explicitly set to null are empty.\n            return new JsonLdContextNormalized_1.JsonLdContextNormalized(this.applyBaseEntry({}, options, false));\n        }\n        else if (typeof context === 'string') {\n            const contextIri = this.normalizeContextIri(context, baseIRI);\n            const overriddenLoad = this.getOverriddenLoad(contextIri, options);\n            if (overriddenLoad) {\n                return new JsonLdContextNormalized_1.JsonLdContextNormalized(overriddenLoad);\n            }\n            const parsedStringContext = await this.parse(await this.load(contextIri), Object.assign(Object.assign({}, options), { baseIRI: contextIri, external: true, remoteContexts: Object.assign(Object.assign({}, remoteContexts), { [contextIri]: true }) }));\n            this.applyBaseEntry(parsedStringContext.getContextRaw(), options, true);\n            return parsedStringContext;\n        }\n        else if (Array.isArray(context)) {\n            // As a performance consideration, first load all external contexts in parallel.\n            const contextIris = [];\n            const contexts = await Promise.all(context.map((subContext, i) => {\n                if (typeof subContext === 'string') {\n                    const contextIri = this.normalizeContextIri(subContext, baseIRI);\n                    contextIris[i] = contextIri;\n                    const overriddenLoad = this.getOverriddenLoad(contextIri, options);\n                    if (overriddenLoad) {\n                        return overriddenLoad;\n                    }\n                    return this.load(contextIri);\n                }\n                else {\n                    return subContext;\n                }\n            }));\n            // Don't apply inheritance logic on minimal processing\n            if (minimalProcessing) {\n                return new JsonLdContextNormalized_1.JsonLdContextNormalized(contexts);\n            }\n            const reducedContexts = await contexts.reduce((accContextPromise, contextEntry, i) => accContextPromise\n                .then((accContext) => this.parse(contextEntry, Object.assign(Object.assign({}, options), { baseIRI: contextIris[i] || options.baseIRI, external: !!contextIris[i] || options.external, parentContext: accContext.getContextRaw(), remoteContexts: contextIris[i] ? Object.assign(Object.assign({}, remoteContexts), { [contextIris[i]]: true }) : remoteContexts }), \n            // @ts-expect-error: This third argument causes a type error because we have hidden it from consumers\n            {\n                skipValidation: i < contexts.length - 1,\n            })), Promise.resolve(new JsonLdContextNormalized_1.JsonLdContextNormalized(parentContext || {})));\n            // Override the base IRI if provided.\n            this.applyBaseEntry(reducedContexts.getContextRaw(), options, true);\n            return reducedContexts;\n        }\n        else if (typeof context === 'object') {\n            if ('@context' in context) {\n                return await this.parse(context['@context'], options);\n            }\n            // Make a deep clone of the given context, to avoid modifying it.\n            context = Object.assign({}, context);\n            // According to the JSON-LD spec, @base must be ignored from external contexts.\n            if (external) {\n                delete context['@base'];\n            }\n            // Override the base IRI if provided.\n            this.applyBaseEntry(context, options, true);\n            // Hashify container entries\n            // Do this before protected term validation as that influences term format\n            this.containersToHash(context);\n            // Don't perform any other modifications if only minimal processing is needed.\n            if (minimalProcessing) {\n                return new JsonLdContextNormalized_1.JsonLdContextNormalized(context);\n            }\n            // In JSON-LD 1.1, load @import'ed context prior to processing.\n            let importContext = {};\n            if ('@import' in context) {\n                if (processingMode >= 1.1) {\n                    // Only accept string values\n                    if (typeof context['@import'] !== 'string') {\n                        throw new ErrorCoded_1.ErrorCoded('An @import value must be a string, but got ' + typeof context['@import'], ErrorCoded_1.ERROR_CODES.INVALID_IMPORT_VALUE);\n                    }\n                    // Load context\n                    importContext = await this.loadImportContext(this.normalizeContextIri(context['@import'], baseIRI));\n                    delete context['@import'];\n                }\n                else {\n                    throw new ErrorCoded_1.ErrorCoded('Context importing is not supported in JSON-LD 1.0', ErrorCoded_1.ERROR_CODES.INVALID_CONTEXT_ENTRY);\n                }\n            }\n            this.applyScopedProtected(importContext, { processingMode }, JsonLdContextNormalized_1.defaultExpandOptions);\n            const newContext = Object.assign(importContext, context);\n            // Handle terms (before protection checks)\n            this.idifyReverseTerms(newContext);\n            this.normalize(newContext, { processingMode, normalizeLanguageTags });\n            this.applyScopedProtected(newContext, { processingMode }, JsonLdContextNormalized_1.defaultExpandOptions);\n            const keys = Object.keys(newContext);\n            const overlappingKeys = [];\n            if (typeof parentContext === 'object') {\n                // Merge different parts of the final context in order\n                for (const key in parentContext) {\n                    if (key in newContext) {\n                        overlappingKeys.push(key);\n                    }\n                    else {\n                        newContext[key] = parentContext[key];\n                    }\n                }\n            }\n            // Parse inner contexts with minimal processing\n            await this.parseInnerContexts(newContext, options, keys);\n            const newContextWrapped = new JsonLdContextNormalized_1.JsonLdContextNormalized(newContext);\n            // In JSON-LD 1.1, @vocab can be relative to @vocab in the parent context, or a compact IRI.\n            if ((newContext && newContext['@version'] || ContextParser.DEFAULT_PROCESSING_MODE) >= 1.1\n                && ((context['@vocab'] && typeof context['@vocab'] === 'string') || context['@vocab'] === '')) {\n                if (parentContext && '@vocab' in parentContext && context['@vocab'].indexOf(':') < 0) {\n                    newContext['@vocab'] = parentContext['@vocab'] + context['@vocab'];\n                }\n                else if (Util_1.Util.isCompactIri(context['@vocab']) || context['@vocab'] in newContext) {\n                    // @vocab is a compact IRI or refers exactly to a prefix\n                    newContext['@vocab'] = newContextWrapped.expandTerm(context['@vocab'], true);\n                }\n            }\n            this.expandPrefixedTerms(newContextWrapped, this.expandContentTypeToBase, keys);\n            // In JSON-LD 1.1, check if we are not redefining any protected keywords\n            if (!ignoreProtection && parentContext && processingMode >= 1.1) {\n                this.validateKeywordRedefinitions(parentContext, newContext, JsonLdContextNormalized_1.defaultExpandOptions, overlappingKeys);\n            }\n            if (this.validateContext && !internalOptions.skipValidation) {\n                this.validate(newContext, { processingMode });\n            }\n            return newContextWrapped;\n        }\n        else {\n            throw new ErrorCoded_1.ErrorCoded(`Tried parsing a context that is not a string, array or object, but got ${context}`, ErrorCoded_1.ERROR_CODES.INVALID_LOCAL_CONTEXT);\n        }\n    }\n    /**\n     * Fetch the given URL as a raw JSON-LD context.\n     * @param url An URL.\n     * @return A promise resolving to a raw JSON-LD context.\n     */\n    async load(url) {\n        // First try to retrieve the context from cache\n        const cached = this.documentCache[url];\n        if (cached) {\n            return cached;\n        }\n        // If not in cache, load it\n        let document;\n        try {\n            document = await this.documentLoader.load(url);\n        }\n        catch (e) {\n            throw new ErrorCoded_1.ErrorCoded(`Failed to load remote context ${url}: ${e.message}`, ErrorCoded_1.ERROR_CODES.LOADING_REMOTE_CONTEXT_FAILED);\n        }\n        // Validate the context\n        if (!('@context' in document)) {\n            throw new ErrorCoded_1.ErrorCoded(`Missing @context in remote context at ${url}`, ErrorCoded_1.ERROR_CODES.INVALID_REMOTE_CONTEXT);\n        }\n        return this.documentCache[url] = document['@context'];\n    }\n    /**\n     * Override the given context that may be loaded.\n     *\n     * This will check whether or not the url is recursively being loaded.\n     * @param url An URL.\n     * @param options Parsing options.\n     * @return An overridden context, or null.\n     *         Optionally an error can be thrown if a cyclic context is detected.\n     */\n    getOverriddenLoad(url, options) {\n        if (url in (options.remoteContexts || {})) {\n            if (options.ignoreRemoteScopedContexts) {\n                return url;\n            }\n            else {\n                throw new ErrorCoded_1.ErrorCoded('Detected a cyclic context inclusion of ' + url, ErrorCoded_1.ERROR_CODES.RECURSIVE_CONTEXT_INCLUSION);\n            }\n        }\n        return null;\n    }\n    /**\n     * Load an @import'ed context.\n     * @param importContextIri The full URI of an @import value.\n     */\n    async loadImportContext(importContextIri) {\n        // Load the context - and do a deep clone since we are about to mutate it\n        let importContext = await this.load(importContextIri);\n        // Require the context to be a non-array object\n        if (typeof importContext !== 'object' || Array.isArray(importContext)) {\n            throw new ErrorCoded_1.ErrorCoded('An imported context must be a single object: ' + importContextIri, ErrorCoded_1.ERROR_CODES.INVALID_REMOTE_CONTEXT);\n        }\n        // Error if the context contains another @import\n        if ('@import' in importContext) {\n            throw new ErrorCoded_1.ErrorCoded('An imported context can not import another context: ' + importContextIri, ErrorCoded_1.ERROR_CODES.INVALID_CONTEXT_ENTRY);\n        }\n        importContext = Object.assign({}, importContext);\n        // Containers have to be converted into hash values the same way as for the importing context\n        // Otherwise context validation will fail for container values\n        this.containersToHash(importContext);\n        return importContext;\n    }\n}\nContextParser.DEFAULT_PROCESSING_MODE = 1.1;\nexports.ContextParser = ContextParser;\n//# sourceMappingURL=ContextParser.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-context-parser/lib/ContextParser.js?");

/***/ }),

/***/ "./node_modules/jsonld-context-parser/lib/ErrorCoded.js":
/*!**************************************************************!*\
  !*** ./node_modules/jsonld-context-parser/lib/ErrorCoded.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ERROR_CODES = exports.ErrorCoded = void 0;\n/**\n * An error that has a certain error code.\n *\n * The error code can be any string.\n * All standardized error codes are listed in {@link ERROR_CODES}.\n */\nclass ErrorCoded extends Error {\n    /* istanbul ignore next */\n    constructor(message, code) {\n        super(message);\n        this.code = code;\n    }\n}\nexports.ErrorCoded = ErrorCoded;\n/**\n * All standardized JSON-LD error codes.\n * @see https://w3c.github.io/json-ld-api/#dom-jsonlderrorcode\n */\n// tslint:disable:object-literal-sort-keys\nvar ERROR_CODES;\n(function (ERROR_CODES) {\n    ERROR_CODES[\"COLLIDING_KEYWORDS\"] = \"colliding keywords\";\n    ERROR_CODES[\"CONFLICTING_INDEXES\"] = \"conflicting indexes\";\n    ERROR_CODES[\"CYCLIC_IRI_MAPPING\"] = \"cyclic IRI mapping\";\n    ERROR_CODES[\"INVALID_ID_VALUE\"] = \"invalid @id value\";\n    ERROR_CODES[\"INVALID_INDEX_VALUE\"] = \"invalid @index value\";\n    ERROR_CODES[\"INVALID_NEST_VALUE\"] = \"invalid @nest value\";\n    ERROR_CODES[\"INVALID_PREFIX_VALUE\"] = \"invalid @prefix value\";\n    ERROR_CODES[\"INVALID_PROPAGATE_VALUE\"] = \"invalid @propagate value\";\n    ERROR_CODES[\"INVALID_REVERSE_VALUE\"] = \"invalid @reverse value\";\n    ERROR_CODES[\"INVALID_IMPORT_VALUE\"] = \"invalid @import value\";\n    ERROR_CODES[\"INVALID_VERSION_VALUE\"] = \"invalid @version value\";\n    ERROR_CODES[\"INVALID_BASE_IRI\"] = \"invalid base IRI\";\n    ERROR_CODES[\"INVALID_CONTAINER_MAPPING\"] = \"invalid container mapping\";\n    ERROR_CODES[\"INVALID_CONTEXT_ENTRY\"] = \"invalid context entry\";\n    ERROR_CODES[\"INVALID_CONTEXT_NULLIFICATION\"] = \"invalid context nullification\";\n    ERROR_CODES[\"INVALID_DEFAULT_LANGUAGE\"] = \"invalid default language\";\n    ERROR_CODES[\"INVALID_INCLUDED_VALUE\"] = \"invalid @included value\";\n    ERROR_CODES[\"INVALID_IRI_MAPPING\"] = \"invalid IRI mapping\";\n    ERROR_CODES[\"INVALID_JSON_LITERAL\"] = \"invalid JSON literal\";\n    ERROR_CODES[\"INVALID_KEYWORD_ALIAS\"] = \"invalid keyword alias\";\n    ERROR_CODES[\"INVALID_LANGUAGE_MAP_VALUE\"] = \"invalid language map value\";\n    ERROR_CODES[\"INVALID_LANGUAGE_MAPPING\"] = \"invalid language mapping\";\n    ERROR_CODES[\"INVALID_LANGUAGE_TAGGED_STRING\"] = \"invalid language-tagged string\";\n    ERROR_CODES[\"INVALID_LANGUAGE_TAGGED_VALUE\"] = \"invalid language-tagged value\";\n    ERROR_CODES[\"INVALID_LOCAL_CONTEXT\"] = \"invalid local context\";\n    ERROR_CODES[\"INVALID_REMOTE_CONTEXT\"] = \"invalid remote context\";\n    ERROR_CODES[\"INVALID_REVERSE_PROPERTY\"] = \"invalid reverse property\";\n    ERROR_CODES[\"INVALID_REVERSE_PROPERTY_MAP\"] = \"invalid reverse property map\";\n    ERROR_CODES[\"INVALID_REVERSE_PROPERTY_VALUE\"] = \"invalid reverse property value\";\n    ERROR_CODES[\"INVALID_SCOPED_CONTEXT\"] = \"invalid scoped context\";\n    ERROR_CODES[\"INVALID_SCRIPT_ELEMENT\"] = \"invalid script element\";\n    ERROR_CODES[\"INVALID_SET_OR_LIST_OBJECT\"] = \"invalid set or list object\";\n    ERROR_CODES[\"INVALID_TERM_DEFINITION\"] = \"invalid term definition\";\n    ERROR_CODES[\"INVALID_TYPE_MAPPING\"] = \"invalid type mapping\";\n    ERROR_CODES[\"INVALID_TYPE_VALUE\"] = \"invalid type value\";\n    ERROR_CODES[\"INVALID_TYPED_VALUE\"] = \"invalid typed value\";\n    ERROR_CODES[\"INVALID_VALUE_OBJECT\"] = \"invalid value object\";\n    ERROR_CODES[\"INVALID_VALUE_OBJECT_VALUE\"] = \"invalid value object value\";\n    ERROR_CODES[\"INVALID_VOCAB_MAPPING\"] = \"invalid vocab mapping\";\n    ERROR_CODES[\"IRI_CONFUSED_WITH_PREFIX\"] = \"IRI confused with prefix\";\n    ERROR_CODES[\"KEYWORD_REDEFINITION\"] = \"keyword redefinition\";\n    ERROR_CODES[\"LOADING_DOCUMENT_FAILED\"] = \"loading document failed\";\n    ERROR_CODES[\"LOADING_REMOTE_CONTEXT_FAILED\"] = \"loading remote context failed\";\n    ERROR_CODES[\"MULTIPLE_CONTEXT_LINK_HEADERS\"] = \"multiple context link headers\";\n    ERROR_CODES[\"PROCESSING_MODE_CONFLICT\"] = \"processing mode conflict\";\n    ERROR_CODES[\"PROTECTED_TERM_REDEFINITION\"] = \"protected term redefinition\";\n    ERROR_CODES[\"CONTEXT_OVERFLOW\"] = \"context overflow\";\n    ERROR_CODES[\"INVALID_BASE_DIRECTION\"] = \"invalid base direction\";\n    ERROR_CODES[\"RECURSIVE_CONTEXT_INCLUSION\"] = \"recursive context inclusion\";\n    ERROR_CODES[\"INVALID_STREAMING_KEY_ORDER\"] = \"invalid streaming key order\";\n    /**\n     * JSON-LD-star\n     */\n    ERROR_CODES[\"INVALID_EMBEDDED_NODE\"] = \"invalid embedded node\";\n    ERROR_CODES[\"INVALID_ANNOTATION\"] = \"invalid annotation\";\n})(ERROR_CODES = exports.ERROR_CODES || (exports.ERROR_CODES = {}));\n//# sourceMappingURL=ErrorCoded.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-context-parser/lib/ErrorCoded.js?");

/***/ }),

/***/ "./node_modules/jsonld-context-parser/lib/FetchDocumentLoader.js":
/*!***********************************************************************!*\
  !*** ./node_modules/jsonld-context-parser/lib/FetchDocumentLoader.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FetchDocumentLoader = void 0;\n__webpack_require__(/*! cross-fetch/polyfill */ \"./node_modules/cross-fetch/dist/browser-polyfill.js\");\nconst ErrorCoded_1 = __webpack_require__(/*! ./ErrorCoded */ \"./node_modules/jsonld-context-parser/lib/ErrorCoded.js\");\nconst http_link_header_1 = __webpack_require__(/*! http-link-header */ \"./node_modules/http-link-header/lib/link.js\");\nconst relative_to_absolute_iri_1 = __webpack_require__(/*! relative-to-absolute-iri */ \"./node_modules/relative-to-absolute-iri/index.js\");\n/**\n * Loads documents via the fetch API.\n */\nclass FetchDocumentLoader {\n    constructor(fetcher) {\n        this.fetcher = fetcher;\n    }\n    async load(url) {\n        const response = await (this.fetcher || fetch)(url, { headers: new Headers({ accept: 'application/ld+json' }) });\n        if (response.ok && response.headers) {\n            let mediaType = response.headers.get('Content-Type');\n            if (mediaType) {\n                const colonPos = mediaType.indexOf(';');\n                if (colonPos > 0) {\n                    mediaType = mediaType.substr(0, colonPos);\n                }\n            }\n            if (mediaType === 'application/ld+json') {\n                // Return JSON-LD if proper content type was returned\n                return (await response.json());\n            }\n            else {\n                // Check for alternate link for a non-JSON-LD response\n                if (response.headers.has('Link')) {\n                    let alternateUrl;\n                    response.headers.forEach((value, key) => {\n                        if (key === 'link') {\n                            const linkHeader = (0, http_link_header_1.parse)(value);\n                            for (const link of linkHeader.get('type', 'application/ld+json')) {\n                                if (link.rel === 'alternate') {\n                                    if (alternateUrl) {\n                                        throw new Error('Multiple JSON-LD alternate links were found on ' + url);\n                                    }\n                                    alternateUrl = (0, relative_to_absolute_iri_1.resolve)(link.uri, url);\n                                }\n                            }\n                        }\n                    });\n                    if (alternateUrl) {\n                        return this.load(alternateUrl);\n                    }\n                }\n                throw new ErrorCoded_1.ErrorCoded(`Unsupported JSON-LD media type ${mediaType}`, ErrorCoded_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n        }\n        else {\n            throw new Error(response.statusText || `Status code: ${response.status}`);\n        }\n    }\n}\nexports.FetchDocumentLoader = FetchDocumentLoader;\n//# sourceMappingURL=FetchDocumentLoader.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-context-parser/lib/FetchDocumentLoader.js?");

/***/ }),

/***/ "./node_modules/jsonld-context-parser/lib/IDocumentLoader.js":
/*!*******************************************************************!*\
  !*** ./node_modules/jsonld-context-parser/lib/IDocumentLoader.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n//# sourceMappingURL=IDocumentLoader.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-context-parser/lib/IDocumentLoader.js?");

/***/ }),

/***/ "./node_modules/jsonld-context-parser/lib/JsonLdContext.js":
/*!*****************************************************************!*\
  !*** ./node_modules/jsonld-context-parser/lib/JsonLdContext.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// tslint:disable:max-line-length\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n//# sourceMappingURL=JsonLdContext.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-context-parser/lib/JsonLdContext.js?");

/***/ }),

/***/ "./node_modules/jsonld-context-parser/lib/JsonLdContextNormalized.js":
/*!***************************************************************************!*\
  !*** ./node_modules/jsonld-context-parser/lib/JsonLdContextNormalized.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.defaultExpandOptions = exports.JsonLdContextNormalized = void 0;\nconst relative_to_absolute_iri_1 = __webpack_require__(/*! relative-to-absolute-iri */ \"./node_modules/relative-to-absolute-iri/index.js\");\nconst ErrorCoded_1 = __webpack_require__(/*! ./ErrorCoded */ \"./node_modules/jsonld-context-parser/lib/ErrorCoded.js\");\nconst Util_1 = __webpack_require__(/*! ./Util */ \"./node_modules/jsonld-context-parser/lib/Util.js\");\n/**\n * A class exposing operations over a normalized JSON-LD context.\n */\nclass JsonLdContextNormalized {\n    constructor(contextRaw) {\n        this.contextRaw = contextRaw;\n    }\n    /**\n     * @return The raw inner context.\n     */\n    getContextRaw() {\n        return this.contextRaw;\n    }\n    /**\n     * Expand the term or prefix of the given term if it has one,\n     * otherwise return the term as-is.\n     *\n     * This will try to expand the IRI as much as possible.\n     *\n     * Iff in vocab-mode, then other references to other terms in the context can be used,\n     * such as to `myTerm`:\n     * ```\n     * {\n     *   \"myTerm\": \"http://example.org/myLongTerm\"\n     * }\n     * ```\n     *\n     * @param {string} term A term that is an URL or a prefixed URL.\n     * @param {boolean} expandVocab If the term is a predicate or type and should be expanded based on @vocab,\n     *                              otherwise it is considered a regular term that is expanded based on @base.\n     * @param {IExpandOptions} options Options that define the way how expansion must be done.\n     * @return {string} The expanded term, the term as-is, or null if it was explicitly disabled in the context.\n     * @throws If the term is aliased to an invalid value (not a string, IRI or keyword).\n     */\n    expandTerm(term, expandVocab, options = exports.defaultExpandOptions) {\n        const contextValue = this.contextRaw[term];\n        // Immediately return if the term was disabled in the context\n        if (contextValue === null || (contextValue && contextValue['@id'] === null)) {\n            return null;\n        }\n        // Check the @id\n        let validIriMapping = true;\n        if (contextValue && expandVocab) {\n            const value = Util_1.Util.getContextValueId(contextValue);\n            if (value && value !== term) {\n                if (typeof value !== 'string' || (!Util_1.Util.isValidIri(value) && !Util_1.Util.isValidKeyword(value))) {\n                    // Don't mark this mapping as invalid if we have an unknown keyword, but of the correct form.\n                    if (!Util_1.Util.isPotentialKeyword(value)) {\n                        validIriMapping = false;\n                    }\n                }\n                else {\n                    return value;\n                }\n            }\n        }\n        // Check if the term is prefixed\n        const prefix = Util_1.Util.getPrefix(term, this.contextRaw);\n        const vocab = this.contextRaw['@vocab'];\n        const vocabRelative = (!!vocab || vocab === '') && vocab.indexOf(':') < 0;\n        const base = this.contextRaw['@base'];\n        const potentialKeyword = Util_1.Util.isPotentialKeyword(term);\n        if (prefix) {\n            const contextPrefixValue = this.contextRaw[prefix];\n            const value = Util_1.Util.getContextValueId(contextPrefixValue);\n            if (value) {\n                if (typeof contextPrefixValue === 'string' || !options.allowPrefixForcing) {\n                    // If we have a simple term definition,\n                    // check the last character of the prefix to determine whether or not it is a prefix.\n                    // Validate that prefix ends with gen-delim character, unless @prefix is true\n                    if (!Util_1.Util.isSimpleTermDefinitionPrefix(value, options)) {\n                        // Treat the term as an absolute IRI\n                        return term;\n                    }\n                }\n                else {\n                    // If we have an expanded term definition, default to @prefix: false\n                    if (value[0] !== '_' && !potentialKeyword && !contextPrefixValue['@prefix'] && !(term in this.contextRaw)) {\n                        // Treat the term as an absolute IRI\n                        return term;\n                    }\n                }\n                return value + term.substr(prefix.length + 1);\n            }\n        }\n        else if (expandVocab && ((vocab || vocab === '') || (options.allowVocabRelativeToBase && (base && vocabRelative)))\n            && !potentialKeyword && !Util_1.Util.isCompactIri(term)) {\n            if (vocabRelative) {\n                if (options.allowVocabRelativeToBase) {\n                    return ((vocab || base) ? (0, relative_to_absolute_iri_1.resolve)(vocab, base) : '') + term;\n                }\n                else {\n                    throw new ErrorCoded_1.ErrorCoded(`Relative vocab expansion for term '${term}' with vocab '${vocab}' is not allowed.`, ErrorCoded_1.ERROR_CODES.INVALID_VOCAB_MAPPING);\n                }\n            }\n            else {\n                return vocab + term;\n            }\n        }\n        else if (!expandVocab && base && !potentialKeyword && !Util_1.Util.isCompactIri(term)) {\n            return (0, relative_to_absolute_iri_1.resolve)(term, base);\n        }\n        // Return the term as-is, unless we discovered an invalid IRI mapping for this term in the context earlier.\n        if (validIriMapping) {\n            return term;\n        }\n        else {\n            throw new ErrorCoded_1.ErrorCoded(`Invalid IRI mapping found for context entry '${term}': '${JSON.stringify(contextValue)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n        }\n    }\n    /**\n     * Compact the given term using @base, @vocab, an aliased term, or a prefixed term.\n     *\n     * This will try to compact the IRI as much as possible.\n     *\n     * @param {string} iri An IRI to compact.\n     * @param {boolean} vocab If the term is a predicate or type and should be compacted based on @vocab,\n     *                        otherwise it is considered a regular term that is compacted based on @base.\n     * @return {string} The compacted term or the IRI as-is.\n     */\n    compactIri(iri, vocab) {\n        // Try @vocab compacting\n        if (vocab && this.contextRaw['@vocab'] && iri.startsWith(this.contextRaw['@vocab'])) {\n            return iri.substr(this.contextRaw['@vocab'].length);\n        }\n        // Try @base compacting\n        if (!vocab && this.contextRaw['@base'] && iri.startsWith(this.contextRaw['@base'])) {\n            return iri.substr(this.contextRaw['@base'].length);\n        }\n        // Loop over all terms in the context\n        // This will try to prefix as short as possible.\n        // Once a fully compacted alias is found, return immediately, as we can not go any shorter.\n        const shortestPrefixing = { prefix: '', suffix: iri };\n        for (const key in this.contextRaw) {\n            const value = this.contextRaw[key];\n            if (value && !Util_1.Util.isPotentialKeyword(key)) {\n                const contextIri = Util_1.Util.getContextValueId(value);\n                if (iri.startsWith(contextIri)) {\n                    const suffix = iri.substr(contextIri.length);\n                    if (!suffix) {\n                        if (vocab) {\n                            // Immediately return on compacted alias\n                            return key;\n                        }\n                    }\n                    else if (suffix.length < shortestPrefixing.suffix.length) {\n                        // Overwrite the shortest prefix\n                        shortestPrefixing.prefix = key;\n                        shortestPrefixing.suffix = suffix;\n                    }\n                }\n            }\n        }\n        // Return the shortest prefix\n        if (shortestPrefixing.prefix) {\n            return shortestPrefixing.prefix + ':' + shortestPrefixing.suffix;\n        }\n        return iri;\n    }\n}\nexports.JsonLdContextNormalized = JsonLdContextNormalized;\nexports.defaultExpandOptions = {\n    allowPrefixForcing: true,\n    allowPrefixNonGenDelims: false,\n    allowVocabRelativeToBase: true,\n};\n//# sourceMappingURL=JsonLdContextNormalized.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-context-parser/lib/JsonLdContextNormalized.js?");

/***/ }),

/***/ "./node_modules/jsonld-context-parser/lib/Util.js":
/*!********************************************************!*\
  !*** ./node_modules/jsonld-context-parser/lib/Util.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Util = void 0;\nclass Util {\n    /**\n     * Check if the given term is a valid compact IRI.\n     * Otherwise, it may be an IRI.\n     * @param {string} term A term.\n     * @return {boolean} If it is a compact IRI.\n     */\n    static isCompactIri(term) {\n        return term.indexOf(':') > 0 && !(term && term[0] === '#');\n    }\n    /**\n     * Get the prefix from the given term.\n     * @see https://json-ld.org/spec/latest/json-ld/#compact-iris\n     * @param {string} term A term that is an URL or a prefixed URL.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @return {string} The prefix or null.\n     */\n    static getPrefix(term, context) {\n        // Do not consider relative IRIs starting with a hash as compact IRIs\n        if (term && term[0] === '#') {\n            return null;\n        }\n        const separatorPos = term.indexOf(':');\n        if (separatorPos >= 0) {\n            // Suffix can not begin with two slashes\n            if (term.length > separatorPos + 1\n                && term.charAt(separatorPos + 1) === '/'\n                && term.charAt(separatorPos + 2) === '/') {\n                return null;\n            }\n            const prefix = term.substr(0, separatorPos);\n            // Prefix can not be an underscore (this is a blank node)\n            if (prefix === '_') {\n                return null;\n            }\n            // Prefix must match a term in the active context\n            if (context[prefix]) {\n                return prefix;\n            }\n        }\n        return null;\n    }\n    /**\n     * From a given context entry value, get the string value, or the @id field.\n     * @param contextValue A value for a term in a context.\n     * @return {string} The id value, or null.\n     */\n    static getContextValueId(contextValue) {\n        if (contextValue === null || typeof contextValue === 'string') {\n            return contextValue;\n        }\n        const id = contextValue['@id'];\n        return id ? id : null;\n    }\n    /**\n     * Check if the given simple term definition (string-based value of a context term)\n     * should be considered a prefix.\n     * @param value A simple term definition value.\n     * @param options Options that define the way how expansion must be done.\n     */\n    static isSimpleTermDefinitionPrefix(value, options) {\n        return !Util.isPotentialKeyword(value)\n            && (options.allowPrefixNonGenDelims || (typeof value === 'string' && (value[0] === '_' || Util.isPrefixIriEndingWithGenDelim(value))));\n    }\n    /**\n     * Check if the given keyword is of the keyword format \"@\"1*ALPHA.\n     * @param {string} keyword A potential keyword.\n     * @return {boolean} If the given keyword is of the keyword format.\n     */\n    static isPotentialKeyword(keyword) {\n        return typeof keyword === 'string' && Util.KEYWORD_REGEX.test(keyword);\n    }\n    /**\n     * Check if the given prefix ends with a gen-delim character.\n     * @param {string} prefixIri A prefix IRI.\n     * @return {boolean} If the given prefix IRI is valid.\n     */\n    static isPrefixIriEndingWithGenDelim(prefixIri) {\n        return Util.ENDS_WITH_GEN_DELIM.test(prefixIri);\n    }\n    /**\n     * Check if the given context value can be a prefix value.\n     * @param value A context value.\n     * @return {boolean} If it can be a prefix value.\n     */\n    static isPrefixValue(value) {\n        return value && (typeof value === 'string' || (value && typeof value === 'object'));\n    }\n    /**\n     * Check if the given IRI is valid.\n     * @param {string} iri A potential IRI.\n     * @return {boolean} If the given IRI is valid.\n     */\n    static isValidIri(iri) {\n        return Boolean(iri && Util.IRI_REGEX.test(iri));\n    }\n    /**\n     * Check if the given IRI is valid, this includes the possibility of being a relative IRI.\n     * @param {string} iri A potential IRI.\n     * @return {boolean} If the given IRI is valid.\n     */\n    static isValidIriWeak(iri) {\n        return !!iri && iri[0] !== ':' && Util.IRI_REGEX_WEAK.test(iri);\n    }\n    /**\n     * Check if the given keyword is a defined according to the JSON-LD specification.\n     * @param {string} keyword A potential keyword.\n     * @return {boolean} If the given keyword is valid.\n     */\n    static isValidKeyword(keyword) {\n        return Util.VALID_KEYWORDS[keyword];\n    }\n    /**\n     * Check if the given term is protected in the context.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {string} key A context term.\n     * @return {boolean} If the given term has an @protected flag.\n     */\n    static isTermProtected(context, key) {\n        const value = context[key];\n        return !(typeof value === 'string') && value && value['@protected'];\n    }\n    /**\n     * Check if the given context has at least one protected term.\n     * @param context A context.\n     * @return If the context has a protected term.\n     */\n    static hasProtectedTerms(context) {\n        for (const key of Object.keys(context)) {\n            if (Util.isTermProtected(context, key)) {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Check if the given key is an internal reserved keyword.\n     * @param key A context key.\n     */\n    static isReservedInternalKeyword(key) {\n        return key.startsWith('@__');\n    }\n    /**\n     * Check if two objects are deepEqual to on another.\n     * @param object1 The first object to test.\n     * @param object2 The second object to test.\n     */\n    static deepEqual(object1, object2) {\n        const objKeys1 = Object.keys(object1);\n        const objKeys2 = Object.keys(object2);\n        if (objKeys1.length !== objKeys2.length)\n            return false;\n        return objKeys1.every((key) => {\n            const value1 = object1[key];\n            const value2 = object2[key];\n            return (value1 === value2) || (value1 !== null &&\n                value2 !== null &&\n                typeof value1 === \"object\" &&\n                typeof value2 === \"object\" &&\n                this.deepEqual(value1, value2));\n        });\n    }\n    ;\n}\n// Regex for valid IRIs\nUtil.IRI_REGEX = /^([A-Za-z][A-Za-z0-9+-.]*|_):[^ \"<>{}|\\\\\\[\\]`#]*(#[^#]*)?$/;\n// Weaker regex for valid IRIs, this includes relative IRIs\nUtil.IRI_REGEX_WEAK = /(?::[^:])|\\//;\n// Regex for keyword form\nUtil.KEYWORD_REGEX = /^@[a-z]+$/i;\n// Regex to see if an IRI ends with a gen-delim character (see RFC 3986)\nUtil.ENDS_WITH_GEN_DELIM = /[:/?#\\[\\]@]$/;\n// Regex for language tags\nUtil.REGEX_LANGUAGE_TAG = /^[a-zA-Z]+(-[a-zA-Z0-9]+)*$/;\n// Regex for base directions\nUtil.REGEX_DIRECTION_TAG = /^(ltr)|(rtl)$/;\n// All known valid JSON-LD keywords\n// @see https://www.w3.org/TR/json-ld11/#keywords\nUtil.VALID_KEYWORDS = {\n    '@annotation': true,\n    '@base': true,\n    '@container': true,\n    '@context': true,\n    '@direction': true,\n    '@graph': true,\n    '@id': true,\n    '@import': true,\n    '@included': true,\n    '@index': true,\n    '@json': true,\n    '@language': true,\n    '@list': true,\n    '@nest': true,\n    '@none': true,\n    '@prefix': true,\n    '@propagate': true,\n    '@protected': true,\n    '@reverse': true,\n    '@set': true,\n    '@type': true,\n    '@value': true,\n    '@version': true,\n    '@vocab': true,\n};\n// Keys in the contexts that will not be expanded based on the base IRI\nUtil.EXPAND_KEYS_BLACKLIST = [\n    '@base',\n    '@vocab',\n    '@language',\n    '@version',\n    '@direction',\n];\n// Keys in the contexts that may not be aliased from\nUtil.ALIAS_DOMAIN_BLACKLIST = [\n    '@container',\n    '@graph',\n    '@id',\n    '@index',\n    '@list',\n    '@nest',\n    '@none',\n    '@prefix',\n    '@reverse',\n    '@set',\n    '@type',\n    '@value',\n    '@version',\n];\n// Keys in the contexts that may not be aliased to\nUtil.ALIAS_RANGE_BLACKLIST = [\n    '@context',\n    '@preserve',\n];\n// All valid @container values\nUtil.CONTAINERS = [\n    '@list',\n    '@set',\n    '@index',\n    '@language',\n    '@graph',\n    '@id',\n    '@type',\n];\n// All valid @container values under processing mode 1.0\nUtil.CONTAINERS_1_0 = [\n    '@list',\n    '@set',\n    '@index',\n];\nexports.Util = Util;\n//# sourceMappingURL=Util.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-context-parser/lib/Util.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/index.js ***!
  \*******************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n__exportStar(__webpack_require__(/*! ./lib/JsonLdParser */ \"./node_modules/jsonld-streaming-parser/lib/JsonLdParser.js\"), exports);\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/index.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/ContextTree.js":
/*!*****************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/ContextTree.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ContextTree = void 0;\n/**\n * A tree structure that holds all contexts,\n * based on their position in the JSON object.\n *\n * Positions are identified by a path of keys.\n */\nclass ContextTree {\n    constructor() {\n        this.subTrees = {};\n    }\n    getContext(keys) {\n        if (keys.length > 0) {\n            const [head, ...tail] = keys;\n            const subTree = this.subTrees[head];\n            if (subTree) {\n                const subContext = subTree.getContext(tail);\n                if (subContext) {\n                    return subContext.then(({ context, depth }) => ({ context, depth: depth + 1 }));\n                }\n            }\n        }\n        return this.context ? this.context.then((context) => ({ context, depth: 0 })) : null;\n    }\n    setContext(keys, context) {\n        if (keys.length === 0) {\n            this.context = context;\n        }\n        else {\n            const [head, ...tail] = keys;\n            let subTree = this.subTrees[head];\n            if (!subTree) {\n                subTree = this.subTrees[head] = new ContextTree();\n            }\n            subTree.setContext(tail, context);\n        }\n    }\n    removeContext(path) {\n        this.setContext(path, null);\n    }\n}\nexports.ContextTree = ContextTree;\n//# sourceMappingURL=ContextTree.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/ContextTree.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/JsonLdParser.js":
/*!******************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/JsonLdParser.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.JsonLdParser = void 0;\n// tslint:disable-next-line:no-var-requires\nconst Parser = __webpack_require__(/*! @bergos/jsonparse */ \"./node_modules/@bergos/jsonparse/jsonparse.js\");\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\nconst readable_stream_1 = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\nconst EntryHandlerArrayValue_1 = __webpack_require__(/*! ./entryhandler/EntryHandlerArrayValue */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerArrayValue.js\");\nconst EntryHandlerContainer_1 = __webpack_require__(/*! ./entryhandler/EntryHandlerContainer */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerContainer.js\");\nconst EntryHandlerInvalidFallback_1 = __webpack_require__(/*! ./entryhandler/EntryHandlerInvalidFallback */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerInvalidFallback.js\");\nconst EntryHandlerPredicate_1 = __webpack_require__(/*! ./entryhandler/EntryHandlerPredicate */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerPredicate.js\");\nconst EntryHandlerKeywordContext_1 = __webpack_require__(/*! ./entryhandler/keyword/EntryHandlerKeywordContext */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordContext.js\");\nconst EntryHandlerKeywordGraph_1 = __webpack_require__(/*! ./entryhandler/keyword/EntryHandlerKeywordGraph */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordGraph.js\");\nconst EntryHandlerKeywordId_1 = __webpack_require__(/*! ./entryhandler/keyword/EntryHandlerKeywordId */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordId.js\");\nconst EntryHandlerKeywordIncluded_1 = __webpack_require__(/*! ./entryhandler/keyword/EntryHandlerKeywordIncluded */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordIncluded.js\");\nconst EntryHandlerKeywordNest_1 = __webpack_require__(/*! ./entryhandler/keyword/EntryHandlerKeywordNest */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordNest.js\");\nconst EntryHandlerKeywordType_1 = __webpack_require__(/*! ./entryhandler/keyword/EntryHandlerKeywordType */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordType.js\");\nconst EntryHandlerKeywordUnknownFallback_1 = __webpack_require__(/*! ./entryhandler/keyword/EntryHandlerKeywordUnknownFallback */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordUnknownFallback.js\");\nconst EntryHandlerKeywordValue_1 = __webpack_require__(/*! ./entryhandler/keyword/EntryHandlerKeywordValue */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordValue.js\");\nconst ParsingContext_1 = __webpack_require__(/*! ./ParsingContext */ \"./node_modules/jsonld-streaming-parser/lib/ParsingContext.js\");\nconst Util_1 = __webpack_require__(/*! ./Util */ \"./node_modules/jsonld-streaming-parser/lib/Util.js\");\nconst http_link_header_1 = __webpack_require__(/*! http-link-header */ \"./node_modules/http-link-header/lib/link.js\");\nconst EntryHandlerKeywordAnnotation_1 = __webpack_require__(/*! ./entryhandler/keyword/EntryHandlerKeywordAnnotation */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordAnnotation.js\");\n/**\n * A stream transformer that parses JSON-LD (text) streams to an {@link RDF.Stream}.\n */\nclass JsonLdParser extends readable_stream_1.Transform {\n    constructor(options) {\n        super({ readableObjectMode: true });\n        options = options || {};\n        this.options = options;\n        this.parsingContext = new ParsingContext_1.ParsingContext(Object.assign({ parser: this }, options));\n        this.util = new Util_1.Util({ dataFactory: options.dataFactory, parsingContext: this.parsingContext });\n        this.jsonParser = new Parser();\n        this.contextJobs = [];\n        this.typeJobs = [];\n        this.contextAwaitingJobs = [];\n        this.lastDepth = 0;\n        this.lastKeys = [];\n        this.lastOnValueJob = Promise.resolve();\n        this.attachJsonParserListeners();\n        this.on('end', () => {\n            if (typeof this.jsonParser.mode !== 'undefined') {\n                this.emit('error', new Error('Unclosed document'));\n            }\n        });\n    }\n    /**\n     * Construct a JsonLdParser from the given HTTP response.\n     *\n     * This will throw an error if no valid JSON response is received\n     * (application/ld+json, application/json, or something+json).\n     *\n     * For raw JSON responses, exactly one link header pointing to a JSON-LD context is required.\n     *\n     * This method is not responsible for handling redirects.\n     *\n     * @param baseIRI The URI of the received response.\n     * @param mediaType The received content type.\n     * @param headers Optional HTTP headers.\n     * @param options Optional parser options.\n     */\n    static fromHttpResponse(baseIRI, mediaType, headers, options) {\n        let context;\n        let wellKnownMediaTypes = ['application/activity+json'];\n        if (options && options.wellKnownMediaTypes) {\n            wellKnownMediaTypes = options.wellKnownMediaTypes;\n        }\n        // Special cases when receiving something else than the JSON-LD media type or the wellKnownMediaTypes\n        if (mediaType !== 'application/ld+json' && !wellKnownMediaTypes.includes(mediaType)) {\n            // Only accept JSON or JSON extension types\n            if (mediaType !== 'application/json' && !mediaType.endsWith('+json')) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Unsupported JSON-LD media type ${mediaType}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n            // We need exactly one JSON-LD context in the link header\n            if (headers && headers.has('Link')) {\n                headers.forEach((value, key) => {\n                    if (key === 'link') {\n                        const linkHeader = (0, http_link_header_1.parse)(value);\n                        for (const link of linkHeader.get('rel', 'http://www.w3.org/ns/json-ld#context')) {\n                            if (context) {\n                                throw new jsonld_context_parser_1.ErrorCoded('Multiple JSON-LD context link headers were found on ' + baseIRI, jsonld_context_parser_1.ERROR_CODES.MULTIPLE_CONTEXT_LINK_HEADERS);\n                            }\n                            context = link.uri;\n                        }\n                    }\n                });\n            }\n            if (!context && !(options === null || options === void 0 ? void 0 : options.ignoreMissingContextLinkHeader)) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Missing context link header for media type ${mediaType} on ${baseIRI}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n        }\n        // Check if the streaming profile is present\n        let streamingProfile;\n        if (headers && headers.has('Content-Type')) {\n            const contentType = headers.get('Content-Type');\n            const match = /; *profile=([^\"]*)/.exec(contentType);\n            if (match && match[1] === 'http://www.w3.org/ns/json-ld#streaming') {\n                streamingProfile = true;\n            }\n        }\n        return new JsonLdParser(Object.assign({ baseIRI,\n            context,\n            streamingProfile }, options ? options : {}));\n    }\n    /**\n     * Parses the given text stream into a quad stream.\n     * @param {NodeJS.EventEmitter} stream A text stream.\n     * @return {RDF.Stream} A quad stream.\n     */\n    import(stream) {\n        if ('pipe' in stream) {\n            stream.on('error', (error) => parsed.emit('error', error));\n            const parsed = stream.pipe(new JsonLdParser(this.options));\n            return parsed;\n        }\n        else {\n            const output = new readable_stream_1.PassThrough({ readableObjectMode: true });\n            stream.on('error', (error) => parsed.emit('error', error));\n            stream.on('data', (data) => output.push(data));\n            stream.on('end', () => output.push(null));\n            const parsed = output.pipe(new JsonLdParser(this.options));\n            return parsed;\n        }\n    }\n    _transform(chunk, encoding, callback) {\n        this.jsonParser.write(chunk);\n        this.lastOnValueJob\n            .then(() => callback(), (error) => callback(error));\n    }\n    /**\n     * Start a new job for parsing the given value.\n     *\n     * This will let the first valid {@link IEntryHandler} handle the entry.\n     *\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        let flushStacks = true;\n        // When we go up the stack, emit all unidentified values\n        // We need to do this before the new job, because the new job may require determined values from the flushed jobs.\n        if (lastDepthCheck && depth < this.lastDepth) {\n            // Check if we had any RDF lists that need to be terminated with an rdf:nil\n            const listPointer = this.parsingContext.listPointerStack[this.lastDepth];\n            if (listPointer) {\n                // Terminate the list if the had at least one value\n                if (listPointer.value) {\n                    this.push(this.util.dataFactory.quad(listPointer.value, this.util.rdfRest, this.util.rdfNil, this.util.getDefaultGraph()));\n                }\n                // Add the list id to the id stack, so it can be used higher up in the stack\n                listPointer.listId.listHead = true;\n                this.parsingContext.idStack[listPointer.listRootDepth + 1] = [listPointer.listId];\n                this.parsingContext.listPointerStack.splice(this.lastDepth, 1);\n            }\n            // Flush the buffer for lastDepth\n            // If the parent key is a special type of container, postpone flushing until that parent is handled.\n            if (await EntryHandlerContainer_1.EntryHandlerContainer.isBufferableContainerHandler(this.parsingContext, this.lastKeys, this.lastDepth)) {\n                this.parsingContext.pendingContainerFlushBuffers\n                    .push({ depth: this.lastDepth, keys: this.lastKeys.slice(0, this.lastKeys.length) });\n                flushStacks = false;\n            }\n            else {\n                await this.flushBuffer(this.lastDepth, this.lastKeys);\n            }\n        }\n        const key = await this.util.unaliasKeyword(keys[depth], keys, depth);\n        const parentKey = await this.util.unaliasKeywordParent(keys, depth);\n        this.parsingContext.emittedStack[depth] = true;\n        let handleKey = true;\n        // Keywords inside @reverse is not allowed apart from @context\n        if (jsonld_context_parser_1.Util.isValidKeyword(key) && parentKey === '@reverse' && key !== '@context') {\n            this.emit('error', new jsonld_context_parser_1.ErrorCoded(`Found the @id '${value}' inside an @reverse property`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_MAP));\n        }\n        // Skip further processing if one of the parent nodes are invalid.\n        // We use the validationStack to reuse validation results that were produced before with common key stacks.\n        let inProperty = false;\n        if (this.parsingContext.validationStack.length > 1) {\n            inProperty = this.parsingContext.validationStack[this.parsingContext.validationStack.length - 1].property;\n        }\n        for (let i = Math.max(1, this.parsingContext.validationStack.length - 1); i < keys.length - 1; i++) {\n            const validationResult = this.parsingContext.validationStack[i]\n                || (this.parsingContext.validationStack[i] = await this.validateKey(keys.slice(0, i + 1), i, inProperty));\n            if (!validationResult.valid) {\n                this.parsingContext.emittedStack[depth] = false;\n                handleKey = false;\n                break;\n            }\n            else if (!inProperty && validationResult.property) {\n                inProperty = true;\n            }\n        }\n        // Skip further processing if this node is part of a literal\n        if (await this.util.isLiteral(keys, depth)) {\n            handleKey = false;\n        }\n        // Get handler\n        if (handleKey) {\n            for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n                const testResult = await entryHandler.test(this.parsingContext, this.util, key, keys, depth);\n                if (testResult) {\n                    // Pass processing over to the handler\n                    await entryHandler.handle(this.parsingContext, this.util, key, keys, value, depth, testResult);\n                    // Flag that this depth is processed\n                    if (entryHandler.isStackProcessor()) {\n                        this.parsingContext.processingStack[depth] = true;\n                    }\n                    break;\n                }\n            }\n        }\n        // Validate value indexes on the root.\n        if (depth === 0 && Array.isArray(value)) {\n            await this.util.validateValueIndexes(value);\n        }\n        // When we go up the stack, flush the old stack\n        if (flushStacks && depth < this.lastDepth) {\n            // Reset our stacks\n            this.flushStacks(this.lastDepth);\n        }\n        this.lastDepth = depth;\n        this.lastKeys = keys;\n        // Clear the keyword cache at this depth, and everything underneath.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(depth - 1);\n    }\n    /**\n     * Flush the processing stacks at the given depth.\n     * @param {number} depth A depth.\n     */\n    flushStacks(depth) {\n        this.parsingContext.processingStack.splice(depth, 1);\n        this.parsingContext.processingType.splice(depth, 1);\n        this.parsingContext.emittedStack.splice(depth, 1);\n        this.parsingContext.idStack.splice(depth, 1);\n        this.parsingContext.graphStack.splice(depth + 1, 1);\n        this.parsingContext.graphContainerTermStack.splice(depth, 1);\n        this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        this.parsingContext.validationStack.splice(depth - 1, 2);\n        this.parsingContext.literalStack.splice(depth, this.parsingContext.literalStack.length - depth);\n        this.parsingContext.annotationsBuffer.splice(depth, 1);\n        // TODO: just like the literal stack, splice all other stack until the end as well?\n    }\n    /**\n     * Flush buffers for the given depth.\n     *\n     * This should be called after the last entry at a given depth was processed.\n     *\n     * @param {number} depth A depth.\n     * @param {any[]} keys A stack of keys.\n     * @return {Promise<void>} A promise resolving if flushing is done.\n     */\n    async flushBuffer(depth, keys) {\n        let subjects = this.parsingContext.idStack[depth];\n        const subjectsWasDefined = !!subjects;\n        if (!subjectsWasDefined) {\n            subjects = this.parsingContext.idStack[depth] = [this.util.dataFactory.blankNode()];\n        }\n        // Flush values at this level\n        const valueBuffer = this.parsingContext.unidentifiedValuesBuffer[depth];\n        if (valueBuffer) {\n            for (const subject of subjects) {\n                const depthOffsetGraph = await this.util.getDepthOffsetGraph(depth, keys);\n                const graphs = (this.parsingContext.graphStack[depth] || depthOffsetGraph >= 0)\n                    ? this.parsingContext.idStack[depth - depthOffsetGraph - 1]\n                    : [await this.util.getGraphContainerValue(keys, depth)];\n                if (graphs) {\n                    for (const graph of graphs) {\n                        // Flush values to stream if the graph @id is known\n                        this.parsingContext.emittedStack[depth] = true;\n                        for (const bufferedValue of valueBuffer) {\n                            this.util.emitQuadChecked(depth, subject, bufferedValue.predicate, bufferedValue.object, graph, bufferedValue.reverse, bufferedValue.isEmbedded);\n                        }\n                    }\n                }\n                else {\n                    // Place the values in the graphs buffer if the graph @id is not yet known\n                    const subGraphBuffer = this.parsingContext.getUnidentifiedGraphBufferSafe(depth - await this.util.getDepthOffsetGraph(depth, keys) - 1);\n                    for (const bufferedValue of valueBuffer) {\n                        if (bufferedValue.reverse) {\n                            subGraphBuffer.push({\n                                object: subject,\n                                predicate: bufferedValue.predicate,\n                                subject: bufferedValue.object,\n                                isEmbedded: bufferedValue.isEmbedded,\n                            });\n                        }\n                        else {\n                            subGraphBuffer.push({\n                                object: bufferedValue.object,\n                                predicate: bufferedValue.predicate,\n                                subject,\n                                isEmbedded: bufferedValue.isEmbedded,\n                            });\n                        }\n                    }\n                }\n            }\n            this.parsingContext.unidentifiedValuesBuffer.splice(depth, 1);\n            this.parsingContext.literalStack.splice(depth, 1);\n            this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        }\n        // Flush graphs at this level\n        const graphBuffer = this.parsingContext.unidentifiedGraphsBuffer[depth];\n        if (graphBuffer) {\n            for (const subject of subjects) {\n                // A @graph statement at the root without @id relates to the default graph,\n                // unless there are top-level properties,\n                // others relate to blank nodes.\n                const graph = depth === 1 && subject.termType === 'BlankNode'\n                    && !this.parsingContext.topLevelProperties ? this.util.getDefaultGraph() : subject;\n                this.parsingContext.emittedStack[depth] = true;\n                for (const bufferedValue of graphBuffer) {\n                    this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.subject, bufferedValue.predicate, bufferedValue.object, graph));\n                }\n            }\n            this.parsingContext.unidentifiedGraphsBuffer.splice(depth, 1);\n        }\n        // Push unhandled annotations up the stack as nested annotations\n        const annotationsBuffer = this.parsingContext.annotationsBuffer[depth];\n        if (annotationsBuffer) {\n            // Throw an error if we reach the top, and still have annotations\n            if (annotationsBuffer.length > 0 && depth === 1) {\n                this.parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Annotations can not be made on top-level nodes`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n            }\n            // Pass the annotations buffer up one level in the stack\n            const annotationsBufferParent = this.parsingContext.getAnnotationsBufferSafe(depth - 1);\n            for (const annotation of annotationsBuffer) {\n                annotationsBufferParent.push(annotation);\n            }\n            delete this.parsingContext.annotationsBuffer[depth];\n        }\n    }\n    /**\n     * Check if at least one {@link IEntryHandler} validates the entry to true.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth A depth.\n     * @param {boolean} inProperty If the current depth is part of a valid property node.\n     * @return {Promise<{ valid: boolean, property: boolean }>} A promise resolving to true or false.\n     */\n    async validateKey(keys, depth, inProperty) {\n        for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n            if (await entryHandler.validate(this.parsingContext, this.util, keys, depth, inProperty)) {\n                return { valid: true, property: inProperty || entryHandler.isPropertyHandler() };\n            }\n        }\n        return { valid: false, property: false };\n    }\n    /**\n     * Attach all required listeners to the JSON parser.\n     *\n     * This should only be called once.\n     */\n    attachJsonParserListeners() {\n        // Listen to json parser events\n        this.jsonParser.onValue = (value) => {\n            const depth = this.jsonParser.stack.length;\n            const keys = (new Array(depth + 1).fill(0)).map((v, i) => {\n                return i === depth ? this.jsonParser.key : this.jsonParser.stack[i].key;\n            });\n            if (!this.isParsingContextInner(depth)) { // Don't parse inner nodes inside @context\n                const valueJobCb = () => this.newOnValueJob(keys, value, depth, true);\n                if (!this.parsingContext.streamingProfile\n                    && !this.parsingContext.contextTree.getContext(keys.slice(0, -1))) {\n                    // If an out-of-order context is allowed,\n                    // we have to buffer everything.\n                    // We store jobs for @context's and @type's separately,\n                    // because at the end, we have to process them first.\n                    // We also handle @type because these *could* introduce a type-scoped context.\n                    if (keys[depth] === '@context') {\n                        let jobs = this.contextJobs[depth];\n                        if (!jobs) {\n                            jobs = this.contextJobs[depth] = [];\n                        }\n                        jobs.push(valueJobCb);\n                    }\n                    else {\n                        this.contextAwaitingJobs.push({ job: valueJobCb, keys, depth });\n                    }\n                }\n                else {\n                    // Make sure that our value jobs are chained synchronously\n                    this.lastOnValueJob = this.lastOnValueJob.then(valueJobCb);\n                }\n                // Execute all buffered jobs on deeper levels\n                if (!this.parsingContext.streamingProfile && depth === 0) {\n                    this.lastOnValueJob = this.lastOnValueJob\n                        .then(() => this.executeBufferedJobs());\n                }\n            }\n        };\n        this.jsonParser.onError = (error) => {\n            this.emit('error', error);\n        };\n    }\n    /**\n     * Check if the parser is currently parsing an element that is part of an @context entry.\n     * @param {number} depth A depth.\n     * @return {boolean} A boolean.\n     */\n    isParsingContextInner(depth) {\n        for (let i = depth; i > 0; i--) {\n            if (this.jsonParser.stack[i - 1].key === '@context') {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Execute all buffered jobs.\n     * @return {Promise<void>} A promise resolving if all jobs are finished.\n     */\n    async executeBufferedJobs() {\n        // Handle context jobs\n        for (const jobs of this.contextJobs) {\n            if (jobs) {\n                for (const job of jobs) {\n                    await job();\n                }\n            }\n        }\n        // Clear the keyword cache.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(0);\n        const contextAwaitingJobs = [];\n        for (const job of this.contextAwaitingJobs) {\n            if ((await this.util.unaliasKeyword(job.keys[job.depth], job.keys, job.depth, true)) === '@type'\n                || typeof job.keys[job.depth] === 'number' && (await this.util.unaliasKeyword(job.keys[job.depth - 1], job.keys, job.depth - 1, true)) === '@type') { // Also capture @type with array values\n                // Remove @type from keys, because we want it to apply to parent later on\n                this.typeJobs.push({ job: job.job, keys: job.keys.slice(0, job.keys.length - 1) });\n            }\n            else {\n                contextAwaitingJobs.push(job);\n            }\n        }\n        // Handle non-context jobs\n        for (const job of contextAwaitingJobs) {\n            // Check if we have a type (with possible type-scoped context) that should be handled before.\n            // We check all possible parent nodes for the current job, from root to leaves.\n            if (this.typeJobs.length > 0) {\n                // First collect all applicable type jobs\n                const applicableTypeJobs = [];\n                const applicableTypeJobIds = [];\n                for (let i = 0; i < this.typeJobs.length; i++) {\n                    const typeJob = this.typeJobs[i];\n                    if (Util_1.Util.isPrefixArray(typeJob.keys, job.keys)) {\n                        applicableTypeJobs.push(typeJob);\n                        applicableTypeJobIds.push(i);\n                    }\n                }\n                // Next, sort the jobs from short to long key length (to ensure types higher up in the tree to be handled first)\n                const sortedTypeJobs = applicableTypeJobs.sort((job1, job2) => job1.keys.length - job2.keys.length);\n                // Finally, execute the jobs in order\n                for (const typeJob of sortedTypeJobs) {\n                    await typeJob.job();\n                }\n                // Remove the executed type jobs\n                // Sort first, so we can efficiently splice\n                const sortedApplicableTypeJobIds = applicableTypeJobIds.sort().reverse();\n                for (const jobId of sortedApplicableTypeJobIds) {\n                    this.typeJobs.splice(jobId, 1);\n                }\n            }\n            await job.job();\n        }\n    }\n}\nJsonLdParser.DEFAULT_PROCESSING_MODE = '1.1';\nJsonLdParser.ENTRY_HANDLERS = [\n    new EntryHandlerArrayValue_1.EntryHandlerArrayValue(),\n    new EntryHandlerKeywordContext_1.EntryHandlerKeywordContext(),\n    new EntryHandlerKeywordId_1.EntryHandlerKeywordId(),\n    new EntryHandlerKeywordIncluded_1.EntryHandlerKeywordIncluded(),\n    new EntryHandlerKeywordGraph_1.EntryHandlerKeywordGraph(),\n    new EntryHandlerKeywordNest_1.EntryHandlerKeywordNest(),\n    new EntryHandlerKeywordType_1.EntryHandlerKeywordType(),\n    new EntryHandlerKeywordValue_1.EntryHandlerKeywordValue(),\n    new EntryHandlerKeywordAnnotation_1.EntryHandlerKeywordAnnotation(),\n    new EntryHandlerContainer_1.EntryHandlerContainer(),\n    new EntryHandlerKeywordUnknownFallback_1.EntryHandlerKeywordUnknownFallback(),\n    new EntryHandlerPredicate_1.EntryHandlerPredicate(),\n    new EntryHandlerInvalidFallback_1.EntryHandlerInvalidFallback(),\n];\nexports.JsonLdParser = JsonLdParser;\n//# sourceMappingURL=JsonLdParser.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/JsonLdParser.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/ParsingContext.js":
/*!********************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/ParsingContext.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ParsingContext = void 0;\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\nconst ErrorCoded_1 = __webpack_require__(/*! jsonld-context-parser/lib/ErrorCoded */ \"./node_modules/jsonld-context-parser/lib/ErrorCoded.js\");\nconst ContextTree_1 = __webpack_require__(/*! ./ContextTree */ \"./node_modules/jsonld-streaming-parser/lib/ContextTree.js\");\nconst JsonLdParser_1 = __webpack_require__(/*! ./JsonLdParser */ \"./node_modules/jsonld-streaming-parser/lib/JsonLdParser.js\");\n/**\n * Data holder for parsing information.\n */\nclass ParsingContext {\n    constructor(options) {\n        // Initialize settings\n        this.contextParser = new jsonld_context_parser_1.ContextParser({ documentLoader: options.documentLoader, skipValidation: options.skipContextValidation });\n        this.streamingProfile = !!options.streamingProfile;\n        this.baseIRI = options.baseIRI;\n        this.produceGeneralizedRdf = !!options.produceGeneralizedRdf;\n        this.allowSubjectList = !!options.allowSubjectList;\n        this.processingMode = options.processingMode || JsonLdParser_1.JsonLdParser.DEFAULT_PROCESSING_MODE;\n        this.strictValues = !!options.strictValues;\n        this.validateValueIndexes = !!options.validateValueIndexes;\n        this.defaultGraph = options.defaultGraph;\n        this.rdfDirection = options.rdfDirection;\n        this.normalizeLanguageTags = options.normalizeLanguageTags;\n        this.streamingProfileAllowOutOfOrderPlainType = options.streamingProfileAllowOutOfOrderPlainType;\n        this.rdfstar = options.rdfstar !== false;\n        this.rdfstarReverseInEmbedded = options.rdfstarReverseInEmbedded;\n        this.topLevelProperties = false;\n        this.activeProcessingMode = parseFloat(this.processingMode);\n        // Initialize stacks\n        this.processingStack = [];\n        this.processingType = [];\n        this.emittedStack = [];\n        this.idStack = [];\n        this.graphStack = [];\n        this.graphContainerTermStack = [];\n        this.listPointerStack = [];\n        this.contextTree = new ContextTree_1.ContextTree();\n        this.literalStack = [];\n        this.validationStack = [];\n        this.unaliasedKeywordCacheStack = [];\n        this.jsonLiteralStack = [];\n        this.unidentifiedValuesBuffer = [];\n        this.unidentifiedGraphsBuffer = [];\n        this.annotationsBuffer = [];\n        this.pendingContainerFlushBuffers = [];\n        this.parser = options.parser;\n        if (options.context) {\n            this.rootContext = this.parseContext(options.context);\n            this.rootContext.then((context) => this.validateContext(context));\n        }\n        else {\n            this.rootContext = Promise.resolve(new jsonld_context_parser_1.JsonLdContextNormalized(this.baseIRI ? { '@base': this.baseIRI, '@__baseDocument': true } : {}));\n        }\n    }\n    /**\n     * Parse the given context with the configured options.\n     * @param {JsonLdContext} context A context to parse.\n     * @param {JsonLdContextNormalized} parentContext An optional parent context.\n     * @param {boolean} ignoreProtection If @protected term checks should be ignored.\n     * @return {Promise<JsonLdContextNormalized>} A promise resolving to the parsed context.\n     */\n    async parseContext(context, parentContext, ignoreProtection) {\n        return this.contextParser.parse(context, {\n            baseIRI: this.baseIRI,\n            ignoreProtection,\n            normalizeLanguageTags: this.normalizeLanguageTags,\n            parentContext,\n            processingMode: this.activeProcessingMode,\n        });\n    }\n    /**\n     * Check if the given context is valid.\n     * If not, an error will be thrown.\n     * @param {JsonLdContextNormalized} context A context.\n     */\n    validateContext(context) {\n        const activeVersion = context.getContextRaw()['@version'];\n        if (activeVersion) {\n            if (this.activeProcessingMode && activeVersion > this.activeProcessingMode) {\n                throw new ErrorCoded_1.ErrorCoded(`Unsupported JSON-LD version '${activeVersion}' under active processing mode ${this.activeProcessingMode}.`, ErrorCoded_1.ERROR_CODES.PROCESSING_MODE_CONFLICT);\n            }\n            else {\n                if (this.activeProcessingMode && activeVersion < this.activeProcessingMode) {\n                    throw new ErrorCoded_1.ErrorCoded(`Invalid JSON-LD version ${activeVersion} under active processing mode ${this.activeProcessingMode}.`, ErrorCoded_1.ERROR_CODES.INVALID_VERSION_VALUE);\n                }\n                this.activeProcessingMode = activeVersion;\n            }\n        }\n    }\n    /**\n     * Get the context at the given path.\n     * @param {keys} keys The path of keys to get the context at.\n     * @param {number} offset The path offset, defaults to 1.\n     * @return {Promise<JsonLdContextNormalized>} A promise resolving to a context.\n     */\n    async getContext(keys, offset = 1) {\n        const keysOriginal = keys;\n        // Ignore array keys at the end\n        while (typeof keys[keys.length - 1] === 'number') {\n            keys = keys.slice(0, keys.length - 1);\n        }\n        // Handle offset on keys\n        if (offset) {\n            keys = keys.slice(0, -offset);\n        }\n        // Determine the closest context\n        const contextData = await this.getContextPropagationAware(keys);\n        const context = contextData.context;\n        // Process property-scoped contexts (high-to-low)\n        let contextRaw = context.getContextRaw();\n        for (let i = contextData.depth; i < keysOriginal.length - offset; i++) {\n            const key = keysOriginal[i];\n            const contextKeyEntry = contextRaw[key];\n            if (contextKeyEntry && typeof contextKeyEntry === 'object' && '@context' in contextKeyEntry) {\n                const scopedContext = (await this.parseContext(contextKeyEntry, contextRaw, true)).getContextRaw();\n                const propagate = !(key in scopedContext)\n                    || scopedContext[key]['@context']['@propagate']; // Propagation is true by default\n                if (propagate !== false || i === keysOriginal.length - 1 - offset) {\n                    contextRaw = Object.assign({}, scopedContext);\n                    // Clean up final context\n                    delete contextRaw['@propagate'];\n                    contextRaw[key] = Object.assign({}, contextRaw[key]);\n                    if ('@id' in contextKeyEntry) {\n                        contextRaw[key]['@id'] = contextKeyEntry['@id'];\n                    }\n                    delete contextRaw[key]['@context'];\n                    if (propagate !== false) {\n                        this.contextTree.setContext(keysOriginal.slice(0, i + offset), Promise.resolve(new jsonld_context_parser_1.JsonLdContextNormalized(contextRaw)));\n                    }\n                }\n            }\n        }\n        return new jsonld_context_parser_1.JsonLdContextNormalized(contextRaw);\n    }\n    /**\n     * Get the context at the given path.\n     * Non-propagating contexts will be skipped,\n     * unless the context at that exact depth is retrieved.\n     *\n     * This ONLY takes into account context propagation logic,\n     * so this should usually not be called directly,\n     * call {@link #getContext} instead.\n     *\n     * @param keys The path of keys to get the context at.\n     * @return {Promise<{ context: JsonLdContextNormalized, depth: number }>} A context and its depth.\n     */\n    async getContextPropagationAware(keys) {\n        const originalDepth = keys.length;\n        let contextData = null;\n        let hasApplicablePropertyScopedContext;\n        do {\n            hasApplicablePropertyScopedContext = false;\n            if (contextData && '@__propagateFallback' in contextData.context.getContextRaw()) {\n                // If a propagation fallback context has been set,\n                // fallback to that context and retry for the same depth.\n                contextData.context = new jsonld_context_parser_1.JsonLdContextNormalized(contextData.context.getContextRaw()['@__propagateFallback']);\n            }\n            else {\n                if (contextData) {\n                    // If we had a previous iteration, jump to the parent of context depth.\n                    // We must do this because once we get here, last context had propagation disabled,\n                    // so we check its first parent instead.\n                    keys = keys.slice(0, contextData.depth - 1);\n                }\n                contextData = await this.contextTree.getContext(keys) || { context: await this.rootContext, depth: 0 };\n            }\n            // Allow non-propagating contexts to propagate one level deeper\n            // if it defines a property-scoped context that is applicable for the current key.\n            // @see https://w3c.github.io/json-ld-api/tests/toRdf-manifest#tc012\n            const lastKey = keys[keys.length - 1];\n            if (lastKey in contextData.context.getContextRaw()) {\n                const lastKeyValue = contextData.context.getContextRaw()[lastKey];\n                if (lastKeyValue && typeof lastKeyValue === 'object' && '@context' in lastKeyValue) {\n                    hasApplicablePropertyScopedContext = true;\n                }\n            }\n        } while (contextData.depth > 0 // Root context has a special case\n            && contextData.context.getContextRaw()['@propagate'] === false // Stop loop if propagation is true\n            && contextData.depth !== originalDepth // Stop loop if requesting exact depth of non-propagating\n            && !hasApplicablePropertyScopedContext);\n        // Special case for root context that does not allow propagation.\n        // Fallback to empty context in that case.\n        if (contextData.depth === 0\n            && contextData.context.getContextRaw()['@propagate'] === false\n            && contextData.depth !== originalDepth) {\n            contextData.context = new jsonld_context_parser_1.JsonLdContextNormalized({});\n        }\n        return contextData;\n    }\n    /**\n     * Start a new job for parsing the given value.\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        await this.parser.newOnValueJob(keys, value, depth, lastDepthCheck);\n    }\n    /**\n     * Flush the pending container flush buffers\n     * @return {boolean} If any pending buffers were flushed.\n     */\n    async handlePendingContainerFlushBuffers() {\n        if (this.pendingContainerFlushBuffers.length > 0) {\n            for (const pendingFlushBuffer of this.pendingContainerFlushBuffers) {\n                await this.parser.flushBuffer(pendingFlushBuffer.depth, pendingFlushBuffer.keys);\n                this.parser.flushStacks(pendingFlushBuffer.depth);\n            }\n            this.pendingContainerFlushBuffers.splice(0, this.pendingContainerFlushBuffers.length);\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n    /**\n     * Emit the given quad into the output stream.\n     * @param {number} depth The depth the quad was generated at.\n     * @param {Quad} quad A quad to emit.\n     */\n    emitQuad(depth, quad) {\n        if (depth === 1) {\n            this.topLevelProperties = true;\n        }\n        this.parser.push(quad);\n    }\n    /**\n     * Emit the given error into the output stream.\n     * @param {Error} error An error to emit.\n     */\n    emitError(error) {\n        this.parser.emit('error', error);\n    }\n    /**\n     * Emit the given context into the output stream under the 'context' event.\n     * @param {JsonLdContext} context A context to emit.\n     */\n    emitContext(context) {\n        this.parser.emit('context', context);\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.unidentifiedValuesBuffer}.\n     * @param {number} depth A depth.\n     * @return {{predicate: Term; object: Term; reverse: boolean}[]} An element of\n     *                                                               {@link ParsingContext.unidentifiedValuesBuffer}.\n     */\n    getUnidentifiedValueBufferSafe(depth) {\n        let buffer = this.unidentifiedValuesBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.unidentifiedValuesBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.unidentifiedGraphsBuffer}.\n     * @param {number} depth A depth.\n     * @return {{predicate: Term; object: Term; reverse: boolean}[]} An element of\n     *                                                               {@link ParsingContext.unidentifiedGraphsBuffer}.\n     */\n    getUnidentifiedGraphBufferSafe(depth) {\n        let buffer = this.unidentifiedGraphsBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.unidentifiedGraphsBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.annotationsBuffer}.\n     * @param {number} depth A depth.\n     * @return {} An element of {@link ParsingContext.annotationsBuffer}.\n     */\n    getAnnotationsBufferSafe(depth) {\n        let buffer = this.annotationsBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.annotationsBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * @return IExpandOptions The expand options for the active processing mode.\n     */\n    getExpandOptions() {\n        return ParsingContext.EXPAND_OPTIONS[this.activeProcessingMode];\n    }\n    /**\n     * Shift the stack at the given offset to the given depth.\n     *\n     * This will override anything in the stack at `depth`,\n     * and this will remove anything at `depth + depthOffset`\n     *\n     * @param depth The target depth.\n     * @param depthOffset The origin depth, relative to `depth`.\n     */\n    shiftStack(depth, depthOffset) {\n        // Copy the id stack value up one level so that the next job can access the id.\n        const deeperIdStack = this.idStack[depth + depthOffset];\n        if (deeperIdStack) {\n            this.idStack[depth] = deeperIdStack;\n            this.emittedStack[depth] = true;\n            delete this.idStack[depth + depthOffset];\n        }\n        // Shorten key stack\n        if (this.pendingContainerFlushBuffers.length) {\n            for (const buffer of this.pendingContainerFlushBuffers) {\n                if (buffer.depth >= depth + depthOffset) {\n                    buffer.depth -= depthOffset;\n                    buffer.keys.splice(depth, depthOffset);\n                }\n            }\n        }\n        // Splice stacks\n        if (this.unidentifiedValuesBuffer[depth + depthOffset]) {\n            this.unidentifiedValuesBuffer[depth] = this.unidentifiedValuesBuffer[depth + depthOffset];\n            delete this.unidentifiedValuesBuffer[depth + depthOffset];\n        }\n        if (this.annotationsBuffer[depth + depthOffset - 1]) {\n            if (!this.annotationsBuffer[depth - 1]) {\n                this.annotationsBuffer[depth - 1] = [];\n            }\n            this.annotationsBuffer[depth - 1] = [\n                ...this.annotationsBuffer[depth - 1],\n                ...this.annotationsBuffer[depth + depthOffset - 1],\n            ];\n            delete this.annotationsBuffer[depth + depthOffset - 1];\n        }\n        // TODO: also do the same for other stacks\n    }\n}\nParsingContext.EXPAND_OPTIONS = {\n    1.0: {\n        allowPrefixForcing: false,\n        allowPrefixNonGenDelims: false,\n        allowVocabRelativeToBase: false,\n    },\n    1.1: {\n        allowPrefixForcing: true,\n        allowPrefixNonGenDelims: false,\n        allowVocabRelativeToBase: true,\n    },\n};\nexports.ParsingContext = ParsingContext;\n//# sourceMappingURL=ParsingContext.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/ParsingContext.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/Util.js":
/*!**********************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/Util.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Util = void 0;\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\nconst rdf_data_factory_1 = __webpack_require__(/*! rdf-data-factory */ \"./node_modules/rdf-data-factory/index.js\");\nconst EntryHandlerContainer_1 = __webpack_require__(/*! ./entryhandler/EntryHandlerContainer */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerContainer.js\");\n// tslint:disable-next-line:no-var-requires\nconst canonicalizeJson = __webpack_require__(/*! canonicalize */ \"./node_modules/canonicalize/lib/canonicalize.js\");\n/**\n * Utility functions and methods.\n */\nclass Util {\n    constructor(options) {\n        this.parsingContext = options.parsingContext;\n        this.dataFactory = options.dataFactory || new rdf_data_factory_1.DataFactory();\n        this.rdfFirst = this.dataFactory.namedNode(Util.RDF + 'first');\n        this.rdfRest = this.dataFactory.namedNode(Util.RDF + 'rest');\n        this.rdfNil = this.dataFactory.namedNode(Util.RDF + 'nil');\n        this.rdfType = this.dataFactory.namedNode(Util.RDF + 'type');\n        this.rdfJson = this.dataFactory.namedNode(Util.RDF + 'JSON');\n    }\n    /**\n     * Helper function to get the value of a context entry,\n     * or fallback to a certain value.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} contextKey A pre-defined JSON-LD key in context entries.\n     * @param {string} key A context entry key.\n     * @param {string} fallback A fallback value for when the given contextKey\n     *                          could not be found in the value with the given key.\n     * @return {string} The value of the given contextKey in the entry behind key in the given context,\n     *                  or the given fallback value.\n     */\n    static getContextValue(context, contextKey, key, fallback) {\n        const entry = context.getContextRaw()[key];\n        if (!entry) {\n            return fallback;\n        }\n        const type = entry[contextKey];\n        return type === undefined ? fallback : type;\n    }\n    /**\n     * Get the container type of the given key in the context.\n     *\n     * Should any context-scoping bugs should occur related to this in the future,\n     * it may be required to increase the offset from the depth at which the context is retrieved by one (to 2).\n     * This is because containers act 2 levels deep.\n     *\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The container type.\n     */\n    static getContextValueContainer(context, key) {\n        return Util.getContextValue(context, '@container', key, { '@set': true });\n    }\n    /**\n     * Get the value type of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueType(context, key) {\n        const valueType = Util.getContextValue(context, '@type', key, null);\n        if (valueType === '@none') {\n            return null;\n        }\n        return valueType;\n    }\n    /**\n     * Get the language of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueLanguage(context, key) {\n        return Util.getContextValue(context, '@language', key, context.getContextRaw()['@language'] || null);\n    }\n    /**\n     * Get the direction of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueDirection(context, key) {\n        return Util.getContextValue(context, '@direction', key, context.getContextRaw()['@direction'] || null);\n    }\n    /**\n     * Check if the given key in the context is a reversed property.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {boolean} If the context value has a @reverse key.\n     */\n    static isContextValueReverse(context, key) {\n        return !!Util.getContextValue(context, '@reverse', key, null);\n    }\n    /**\n     * Get the @index of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The index.\n     */\n    static getContextValueIndex(context, key) {\n        return Util.getContextValue(context, '@index', key, context.getContextRaw()['@index'] || null);\n    }\n    /**\n     * Check if the given key refers to a reversed property.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The property key.\n     * @param {string} parentKey The parent key.\n     * @return {boolean} If the property must be reversed.\n     */\n    static isPropertyReverse(context, key, parentKey) {\n        // '!==' is needed because reversed properties in a @reverse container should cancel each other out.\n        return parentKey === '@reverse' !== Util.isContextValueReverse(context, key);\n    }\n    /**\n     * Check if the given key exists inside an embedded node as direct child.\n     * @param {string} parentKey The parent key.\n     * @return {boolean} If the property is embedded.\n     */\n    static isPropertyInEmbeddedNode(parentKey) {\n        return parentKey === '@id';\n    }\n    /**\n     * Check if the given key exists inside an annotation object as direct child.\n     * @param {string} parentKey The parent key.\n     * @return {boolean} If the property is an annotation.\n     */\n    static isPropertyInAnnotationObject(parentKey) {\n        return parentKey === '@annotation';\n    }\n    /**\n     * Check if the given IRI is valid.\n     * @param {string} iri A potential IRI.\n     * @return {boolean} If the given IRI is valid.\n     */\n    static isValidIri(iri) {\n        return iri !== null && jsonld_context_parser_1.Util.isValidIri(iri);\n    }\n    /**\n     * Check if the given first array (needle) is a prefix of the given second array (haystack).\n     * @param needle An array to check if it is a prefix.\n     * @param haystack An array to look in.\n     */\n    static isPrefixArray(needle, haystack) {\n        if (needle.length > haystack.length) {\n            return false;\n        }\n        for (let i = 0; i < needle.length; i++) {\n            if (needle[i] !== haystack[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Make sure that @id-@index pairs are equal over all array values.\n     * Reject otherwise.\n     * @param {any[]} value An array value.\n     * @return {Promise<void>} A promise rejecting if conflicts are present.\n     */\n    async validateValueIndexes(value) {\n        if (this.parsingContext.validateValueIndexes) {\n            const indexHashes = {};\n            for (const entry of value) {\n                if (entry && typeof entry === 'object') {\n                    const id = entry['@id'];\n                    const index = entry['@index'];\n                    if (id && index) {\n                        const existingIndexValue = indexHashes[id];\n                        if (existingIndexValue && existingIndexValue !== index) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Conflicting @index value for ${id}`, jsonld_context_parser_1.ERROR_CODES.CONFLICTING_INDEXES);\n                        }\n                        indexHashes[id] = index;\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Convert a given JSON value to an RDF term.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The current JSON key.\n     * @param value A JSON value.\n     * @param {number} depth The depth the value is at.\n     * @param {string[]} keys The path of keys.\n     * @return {Promise<RDF.Term[]>} An RDF term array.\n     */\n    async valueToTerm(context, key, value, depth, keys) {\n        // Skip further processing if we have an @type: @json\n        if (Util.getContextValueType(context, key) === '@json') {\n            return [this.dataFactory.literal(this.valueToJsonString(value), this.rdfJson)];\n        }\n        const type = typeof value;\n        switch (type) {\n            case 'object':\n                // Skip if we have a null or undefined object\n                if (value === null || value === undefined) {\n                    return [];\n                }\n                // Special case for arrays\n                if (Array.isArray(value)) {\n                    // We handle arrays at value level so we can emit earlier, so this is handled already when we get here.\n                    // Empty context-based lists are emitted at this place, because our streaming algorithm doesn't detect those.\n                    if ('@list' in Util.getContextValueContainer(context, key)) {\n                        if (value.length === 0) {\n                            return [this.rdfNil];\n                        }\n                        else {\n                            return this.parsingContext.idStack[depth + 1] || [];\n                        }\n                    }\n                    await this.validateValueIndexes(value);\n                    return [];\n                }\n                // Handle property-scoped contexts\n                context = await this.getContextSelfOrPropertyScoped(context, key);\n                // Handle local context in the value\n                if ('@context' in value) {\n                    context = await this.parsingContext.parseContext(value['@context'], (await this.parsingContext.getContext(keys, 0)).getContextRaw());\n                }\n                // In all other cases, we have a hash\n                value = await this.unaliasKeywords(value, keys, depth, context); // Un-alias potential keywords in this hash\n                if ('@value' in value) {\n                    let val;\n                    let valueLanguage;\n                    let valueDirection;\n                    let valueType;\n                    let valueIndex; // We don't use the index, but we need to check its type for spec-compliance\n                    for (key in value) {\n                        const subValue = value[key];\n                        switch (key) {\n                            case '@value':\n                                val = subValue;\n                                break;\n                            case '@language':\n                                valueLanguage = subValue;\n                                break;\n                            case '@direction':\n                                valueDirection = subValue;\n                                break;\n                            case '@type':\n                                valueType = subValue;\n                                break;\n                            case '@index':\n                                valueIndex = subValue;\n                                break;\n                            case '@annotation':\n                                // This keyword is allowed, but is processed like normal nodes\n                                break;\n                            default:\n                                throw new jsonld_context_parser_1.ErrorCoded(`Unknown value entry '${key}' in @value: ${JSON.stringify(value)}`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                    }\n                    // Skip further processing if we have an @type: @json\n                    if (await this.unaliasKeyword(valueType, keys, depth, true, context) === '@json') {\n                        return [this.dataFactory.literal(this.valueToJsonString(val), this.rdfJson)];\n                    }\n                    // Validate @value\n                    if (val === null) {\n                        return [];\n                    }\n                    if (typeof val === 'object') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@value' can not be an object, got '${JSON.stringify(val)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT_VALUE);\n                    }\n                    // Validate @index\n                    if (this.parsingContext.validateValueIndexes && valueIndex && typeof valueIndex !== 'string') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@index' must be a string, got '${JSON.stringify(valueIndex)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INDEX_VALUE);\n                    }\n                    // Validate @language and @direction\n                    if (valueLanguage) {\n                        if (typeof val !== 'string') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`When an '@language' is set, the value of '@value' must be a string, got '${JSON.stringify(val)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_TAGGED_VALUE);\n                        }\n                        if (!jsonld_context_parser_1.ContextParser.validateLanguage(valueLanguage, this.parsingContext.strictValues, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_TAGGED_STRING)) {\n                            return [];\n                        }\n                        // Language tags are always normalized to lowercase in 1.0.\n                        if (this.parsingContext.normalizeLanguageTags || this.parsingContext.activeProcessingMode === 1.0) {\n                            valueLanguage = valueLanguage.toLowerCase();\n                        }\n                    }\n                    if (valueDirection) {\n                        if (typeof val !== 'string') {\n                            throw new Error(`When an '@direction' is set, the value of '@value' must be a string, got '${JSON.stringify(val)}'`);\n                        }\n                        if (!jsonld_context_parser_1.ContextParser.validateDirection(valueDirection, this.parsingContext.strictValues)) {\n                            return [];\n                        }\n                    }\n                    // Check @language and @direction\n                    if (valueLanguage && valueDirection && this.parsingContext.rdfDirection) {\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have '@language', '@direction' and '@type' in a value: '${JSON\n                                .stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return this.nullableTermToArray(this\n                            .createLanguageDirectionLiteral(depth, val, valueLanguage, valueDirection));\n                    }\n                    else if (valueLanguage) { // Check @language\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have both '@language' and '@type' in a value: '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return [this.dataFactory.literal(val, valueLanguage)];\n                    }\n                    else if (valueDirection && this.parsingContext.rdfDirection) { // Check @direction\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have both '@direction' and '@type' in a value: '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return this.nullableTermToArray(this\n                            .createLanguageDirectionLiteral(depth, val, valueLanguage, valueDirection));\n                    }\n                    else if (valueType) { // Validate @type\n                        if (typeof valueType !== 'string') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@type' must be a string, got '${JSON.stringify(valueType)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        const typeTerm = this.createVocabOrBaseTerm(context, valueType);\n                        if (!typeTerm) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Invalid '@type' value, got '${JSON.stringify(valueType)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        if (typeTerm.termType !== 'NamedNode') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Illegal value type (${typeTerm.termType}): ${valueType}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        return [this.dataFactory.literal(val, typeTerm)];\n                    }\n                    // We don't pass the context, because context-based things like @language should be ignored\n                    return await this.valueToTerm(new jsonld_context_parser_1.JsonLdContextNormalized({}), key, val, depth, keys);\n                }\n                else if ('@set' in value) {\n                    // No other entries are allow in this value\n                    if (Object.keys(value).length > 1) {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @set for key: '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT);\n                    }\n                    // No need to do anything here, this is handled at the deeper level.\n                    return [];\n                }\n                else if ('@list' in value) {\n                    // No other entries are allowed in this value\n                    if (Object.keys(value).length > 1) {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @list for key: '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT);\n                    }\n                    const listValue = value[\"@list\"];\n                    // We handle lists at value level so we can emit earlier, so this is handled already when we get here.\n                    // Empty anonymous lists are emitted at this place, because our streaming algorithm doesn't detect those.\n                    if (Array.isArray(listValue)) {\n                        if (listValue.length === 0) {\n                            return [this.rdfNil];\n                        }\n                        else {\n                            return this.parsingContext.idStack[depth + 1] || [];\n                        }\n                    }\n                    else {\n                        // We only have a single list element here, so emit this directly as single element\n                        return await this.valueToTerm(await this.parsingContext.getContext(keys), key, listValue, depth - 1, keys.slice(0, -1));\n                    }\n                }\n                else if ('@reverse' in value && typeof value['@reverse'] === 'boolean') {\n                    // We handle reverse properties at value level so we can emit earlier,\n                    // so this is handled already when we get here.\n                    return [];\n                }\n                else if ('@graph' in Util.getContextValueContainer(await this.parsingContext.getContext(keys), key)) {\n                    // We are processing a graph container\n                    const graphContainerEntries = this.parsingContext.graphContainerTermStack[depth + 1];\n                    return graphContainerEntries ? Object.values(graphContainerEntries) : [this.dataFactory.blankNode()];\n                }\n                else if (\"@id\" in value) {\n                    // Use deeper context if the value node contains other properties next to @id.\n                    if (Object.keys(value).length > 1) {\n                        context = await this.parsingContext.getContext(keys, 0);\n                    }\n                    // Handle local context in the value\n                    if ('@context' in value) {\n                        context = await this.parsingContext.parseContext(value['@context'], context.getContextRaw());\n                    }\n                    if (value[\"@type\"] === '@vocab') {\n                        return this.nullableTermToArray(this.createVocabOrBaseTerm(context, value[\"@id\"]));\n                    }\n                    else {\n                        const valueId = value[\"@id\"];\n                        let valueTerm;\n                        if (typeof valueId === 'object') {\n                            if (this.parsingContext.rdfstar) {\n                                valueTerm = this.parsingContext.idStack[depth + 1][0];\n                            }\n                            else {\n                                throw new jsonld_context_parser_1.ErrorCoded(`Found illegal @id '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_ID_VALUE);\n                            }\n                        }\n                        else {\n                            valueTerm = this.resourceToTerm(context, valueId);\n                        }\n                        return this.nullableTermToArray(valueTerm);\n                    }\n                }\n                else {\n                    // Only make a blank node if at least one triple was emitted at the value's level.\n                    if (this.parsingContext.emittedStack[depth + 1]\n                        || (value && typeof value === 'object' && Object.keys(value).length === 0)) {\n                        return (this.parsingContext.idStack[depth + 1]\n                            || (this.parsingContext.idStack[depth + 1] = [this.dataFactory.blankNode()]));\n                    }\n                    else {\n                        return [];\n                    }\n                }\n            case 'string':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, value, null));\n            case 'boolean':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, Boolean(value).toString(), this.dataFactory.namedNode(Util.XSD_BOOLEAN)));\n            case 'number':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, value, this.dataFactory.namedNode(value % 1 === 0 && value < 1e21 ? Util.XSD_INTEGER : Util.XSD_DOUBLE)));\n            default:\n                this.parsingContext.emitError(new Error(`Could not determine the RDF type of a ${type}`));\n                return [];\n        }\n    }\n    /**\n     * If the context defines a property-scoped context for the given key,\n     * that context will be returned.\n     * Otherwise, the given context will be returned as-is.\n     *\n     * This should be used for valueToTerm cases that are not objects.\n     * @param context A context.\n     * @param key A JSON key.\n     */\n    async getContextSelfOrPropertyScoped(context, key) {\n        const contextKeyEntry = context.getContextRaw()[key];\n        if (contextKeyEntry && typeof contextKeyEntry === 'object' && '@context' in contextKeyEntry) {\n            context = await this.parsingContext.parseContext(contextKeyEntry, context.getContextRaw(), true);\n        }\n        return context;\n    }\n    /**\n     * If the given term is null, return an empty array, otherwise return an array with the single given term.\n     * @param term A term.\n     */\n    nullableTermToArray(term) {\n        return term ? [term] : [];\n    }\n    /**\n     * Convert a given JSON key to an RDF predicate term,\n     * based on @vocab.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node.\n     */\n    predicateToTerm(context, key) {\n        const expanded = context.expandTerm(key, true, this.parsingContext.getExpandOptions());\n        // Immediately return if the predicate was disabled in the context\n        if (!expanded) {\n            return null;\n        }\n        // Check if the predicate is a blank node\n        if (expanded[0] === '_' && expanded[1] === ':') {\n            if (this.parsingContext.produceGeneralizedRdf) {\n                return this.dataFactory.blankNode(expanded.substr(2));\n            }\n            else {\n                return null;\n            }\n        }\n        // Check if the predicate is a valid IRI\n        if (Util.isValidIri(expanded)) {\n            return this.dataFactory.namedNode(expanded);\n        }\n        else {\n            if (expanded && this.parsingContext.strictValues) {\n                this.parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid predicate IRI: ${expanded}`, jsonld_context_parser_1.ERROR_CODES.INVALID_IRI_MAPPING));\n            }\n            else {\n                return null;\n            }\n        }\n        return null;\n    }\n    /**\n     * Convert a given JSON key to an RDF resource term or blank node,\n     * based on @base.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node or null.\n     */\n    resourceToTerm(context, key) {\n        if (key.startsWith('_:')) {\n            return this.dataFactory.blankNode(key.substr(2));\n        }\n        const iri = context.expandTerm(key, false, this.parsingContext.getExpandOptions());\n        if (!Util.isValidIri(iri)) {\n            if (iri && this.parsingContext.strictValues) {\n                this.parsingContext.emitError(new Error(`Invalid resource IRI: ${iri}`));\n            }\n            else {\n                return null;\n            }\n        }\n        return this.dataFactory.namedNode(iri);\n    }\n    /**\n     * Convert a given JSON key to an RDF resource term.\n     * It will do this based on the @vocab,\n     * and fallback to @base.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node or null.\n     */\n    createVocabOrBaseTerm(context, key) {\n        if (key.startsWith('_:')) {\n            return this.dataFactory.blankNode(key.substr(2));\n        }\n        const expandOptions = this.parsingContext.getExpandOptions();\n        let expanded = context.expandTerm(key, true, expandOptions);\n        if (expanded === key) {\n            expanded = context.expandTerm(key, false, expandOptions);\n        }\n        if (!Util.isValidIri(expanded)) {\n            if (expanded && this.parsingContext.strictValues && !expanded.startsWith('@')) {\n                this.parsingContext.emitError(new Error(`Invalid term IRI: ${expanded}`));\n            }\n            else {\n                return null;\n            }\n        }\n        return this.dataFactory.namedNode(expanded);\n    }\n    /**\n     * Ensure that the given value becomes a string.\n     * @param {string | number} value A string or number.\n     * @param {NamedNode} datatype The intended datatype.\n     * @return {string} The returned string.\n     */\n    intToString(value, datatype) {\n        if (typeof value === 'number') {\n            if (Number.isFinite(value)) {\n                const isInteger = value % 1 === 0;\n                if (isInteger && (!datatype || datatype.value !== Util.XSD_DOUBLE)) {\n                    return Number(value).toString();\n                }\n                else {\n                    return value.toExponential(15).replace(/(\\d)0*e\\+?/, '$1E');\n                }\n            }\n            else {\n                return value > 0 ? 'INF' : '-INF';\n            }\n        }\n        else {\n            return value;\n        }\n    }\n    /**\n     * Convert a given JSON string value to an RDF term.\n     * @param {number} depth The current stack depth.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The current JSON key.\n     * @param {string} value A JSON value.\n     * @param {NamedNode} defaultDatatype The default datatype for the given value.\n     * @return {RDF.Term} An RDF term or null.\n     */\n    stringValueToTerm(depth, context, key, value, defaultDatatype) {\n        // Check the datatype from the context\n        const contextType = Util.getContextValueType(context, key);\n        if (contextType) {\n            if (contextType === '@id') {\n                if (!defaultDatatype) {\n                    return this.resourceToTerm(context, this.intToString(value, defaultDatatype));\n                }\n            }\n            else if (contextType === '@vocab') {\n                if (!defaultDatatype) {\n                    return this.createVocabOrBaseTerm(context, this.intToString(value, defaultDatatype));\n                }\n            }\n            else {\n                defaultDatatype = this.dataFactory.namedNode(contextType);\n            }\n        }\n        // If we don't find such a datatype, check the language from the context\n        if (!defaultDatatype) {\n            const contextLanguage = Util.getContextValueLanguage(context, key);\n            const contextDirection = Util.getContextValueDirection(context, key);\n            if (contextDirection && this.parsingContext.rdfDirection) {\n                return this.createLanguageDirectionLiteral(depth, this.intToString(value, defaultDatatype), contextLanguage, contextDirection);\n            }\n            else {\n                return this.dataFactory.literal(this.intToString(value, defaultDatatype), contextLanguage);\n            }\n        }\n        // If all else fails, make a literal based on the default content type\n        return this.dataFactory.literal(this.intToString(value, defaultDatatype), defaultDatatype);\n    }\n    /**\n     * Create a literal for the given value with the given language and direction.\n     * Auxiliary quads may be emitted.\n     * @param {number} depth The current stack depth.\n     * @param {string} value A string value.\n     * @param {string} language A language tag.\n     * @param {string} direction A direction.\n     * @return {Term} An RDF term.\n     */\n    createLanguageDirectionLiteral(depth, value, language, direction) {\n        if (this.parsingContext.rdfDirection === 'i18n-datatype') {\n            // Create a datatyped literal, by encoding the language and direction into https://www.w3.org/ns/i18n#.\n            if (!language) {\n                language = '';\n            }\n            return this.dataFactory.literal(value, this.dataFactory.namedNode(`https://www.w3.org/ns/i18n#${language}_${direction}`));\n        }\n        else {\n            // Reify the literal.\n            const valueNode = this.dataFactory.blankNode();\n            const graph = this.getDefaultGraph();\n            this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'value'), this.dataFactory.literal(value), graph));\n            if (language) {\n                this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'language'), this.dataFactory.literal(language), graph));\n            }\n            this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'direction'), this.dataFactory.literal(direction), graph));\n            return valueNode;\n        }\n    }\n    /**\n     * Stringify the given JSON object to a canonical JSON string.\n     * @param value Any valid JSON value.\n     * @return {string} A canonical JSON string.\n     */\n    valueToJsonString(value) {\n        return canonicalizeJson(value);\n    }\n    /**\n     * If the key is not a keyword, try to check if it is an alias for a keyword,\n     * and if so, un-alias it.\n     * @param {string} key A key, can be falsy.\n     * @param {string[]} keys The path of keys.\n     * @param {number} depth The depth to\n     * @param {boolean} disableCache If the cache should be disabled\n     * @param {JsonLdContextNormalized} context A context to unalias with,\n     *                                           will fallback to retrieving the context for the given keys.\n     * @return {Promise<string>} A promise resolving to the key itself, or another key.\n     */\n    async unaliasKeyword(key, keys, depth, disableCache, context) {\n        // Numbers can not be an alias\n        if (Number.isInteger(key)) {\n            return key;\n        }\n        // Try to grab from cache if it was already un-aliased before.\n        if (!disableCache) {\n            const cachedUnaliasedKeyword = this.parsingContext.unaliasedKeywordCacheStack[depth];\n            if (cachedUnaliasedKeyword) {\n                return cachedUnaliasedKeyword;\n            }\n        }\n        if (!jsonld_context_parser_1.Util.isPotentialKeyword(key)) {\n            context = context || await this.parsingContext.getContext(keys);\n            let unliased = context.getContextRaw()[key];\n            if (unliased && typeof unliased === 'object') {\n                unliased = unliased['@id'];\n            }\n            if (jsonld_context_parser_1.Util.isValidKeyword(unliased)) {\n                key = unliased;\n            }\n        }\n        return disableCache ? key : (this.parsingContext.unaliasedKeywordCacheStack[depth] = key);\n    }\n    /**\n     * Unalias the keyword of the parent.\n     * This adds a safety check if no parent exist.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<any>} A promise resolving to the parent key, or another key.\n     */\n    async unaliasKeywordParent(keys, depth) {\n        return await this.unaliasKeyword(depth > 0 && keys[depth - 1], keys, depth - 1);\n    }\n    /**\n     * Un-alias all keywords in the given hash.\n     * @param {{[p: string]: any}} hash A hash object.\n     * @param {string[]} keys The path of keys.\n     * @param {number} depth The depth.\n     * @param {JsonLdContextNormalized} context A context to unalias with,\n     *                                           will fallback to retrieving the context for the given keys.\n     * @return {Promise<{[p: string]: any}>} A promise resolving to the new hash.\n     */\n    async unaliasKeywords(hash, keys, depth, context) {\n        const newHash = {};\n        for (const key in hash) {\n            newHash[await this.unaliasKeyword(key, keys, depth + 1, true, context)] = hash[key];\n        }\n        return newHash;\n    }\n    /**\n     * Check if we are processing a literal (including JSON literals) at the given depth.\n     * This will also check higher levels,\n     * because if a parent is a literal,\n     * then the deeper levels are definitely a literal as well.\n     * @param {any[]} keys The keys.\n     * @param {number} depth The depth.\n     * @return {boolean} If we are processing a literal.\n     */\n    async isLiteral(keys, depth) {\n        for (let i = depth; i >= 0; i--) {\n            if (await this.unaliasKeyword(keys[i], keys, i) === '@annotation') {\n                // Literals may have annotations, which require processing of inner nodes.\n                return false;\n            }\n            if (this.parsingContext.literalStack[i] || this.parsingContext.jsonLiteralStack[i]) {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Check how many parents should be skipped for checking the @graph for the given node.\n     *\n     * @param {number} depth The depth of the node.\n     * @param {any[]} keys An array of keys.\n     * @return {number} The graph depth offset.\n     */\n    async getDepthOffsetGraph(depth, keys) {\n        for (let i = depth - 1; i > 0; i--) {\n            if (await this.unaliasKeyword(keys[i], keys, i) === '@graph') {\n                // Skip further processing if we are already in an @graph-@id or @graph-@index container\n                const containers = (await EntryHandlerContainer_1.EntryHandlerContainer.getContainerHandler(this.parsingContext, keys, i)).containers;\n                if (EntryHandlerContainer_1.EntryHandlerContainer.isComplexGraphContainer(containers)) {\n                    return -1;\n                }\n                return depth - i - 1;\n            }\n        }\n        return -1;\n    }\n    /**\n     * Check if the given subject is of a valid type.\n     * This should be called when applying @reverse'd properties.\n     * @param {Term} subject A subject.\n     */\n    validateReverseSubject(subject) {\n        if (subject.termType === 'Literal') {\n            throw new jsonld_context_parser_1.ErrorCoded(`Found illegal literal in subject position: ${subject.value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_VALUE);\n        }\n    }\n    /**\n     * Get the default graph.\n     * @return {Term} An RDF term.\n     */\n    getDefaultGraph() {\n        return this.parsingContext.defaultGraph || this.dataFactory.defaultGraph();\n    }\n    /**\n     * Get the current graph, while taking into account a graph that can be defined via @container: @graph.\n     * If not within a graph container, the default graph will be returned.\n     * @param keys The current keys.\n     * @param depth The current depth.\n     */\n    async getGraphContainerValue(keys, depth) {\n        // Default to default graph\n        let graph = this.getDefaultGraph();\n        // Check if we are in an @container: @graph.\n        const { containers, depth: depthContainer } = await EntryHandlerContainer_1.EntryHandlerContainer\n            .getContainerHandler(this.parsingContext, keys, depth);\n        if ('@graph' in containers) {\n            // Get the graph from the stack.\n            const graphContainerIndex = EntryHandlerContainer_1.EntryHandlerContainer.getContainerGraphIndex(containers, depthContainer, keys);\n            const entry = this.parsingContext.graphContainerTermStack[depthContainer];\n            graph = entry ? entry[graphContainerIndex] : null;\n            // Set the graph in the stack if none has been set yet.\n            if (!graph) {\n                let graphId = null;\n                if ('@id' in containers) {\n                    const keyUnaliased = await this.getContainerKey(keys[depthContainer], keys, depthContainer);\n                    if (keyUnaliased !== null) {\n                        graphId = await this.resourceToTerm(await this.parsingContext.getContext(keys), keyUnaliased);\n                    }\n                }\n                if (!graphId) {\n                    graphId = this.dataFactory.blankNode();\n                }\n                if (!this.parsingContext.graphContainerTermStack[depthContainer]) {\n                    this.parsingContext.graphContainerTermStack[depthContainer] = {};\n                }\n                graph = this.parsingContext.graphContainerTermStack[depthContainer][graphContainerIndex] = graphId;\n            }\n        }\n        return graph;\n    }\n    /**\n     * Get the properties depth for retrieving properties.\n     *\n     * Typically, the properties depth will be identical to the given depth.\n     *\n     * The following exceptions apply:\n     * * When the parent is @reverse, the depth is decremented by one.\n     * * When @nest parents are found, the depth is decremented by the number of @nest parents.\n     * If in combination with the exceptions above an intermediary array is discovered,\n     * the depth is also decremented by this number of arrays.\n     *\n     * @param keys The current key chain.\n     * @param depth The current depth.\n     */\n    async getPropertiesDepth(keys, depth) {\n        let lastValidDepth = depth;\n        for (let i = depth - 1; i > 0; i--) {\n            if (typeof keys[i] !== 'number') { // Skip array keys\n                const parentKey = await this.unaliasKeyword(keys[i], keys, i);\n                if (parentKey === '@reverse') {\n                    return i;\n                }\n                else if (parentKey === '@nest') {\n                    lastValidDepth = i;\n                }\n                else {\n                    return lastValidDepth;\n                }\n            }\n        }\n        return lastValidDepth;\n    }\n    /**\n     * Get the key for the current container entry.\n     * @param key A key, can be falsy.\n     * @param keys The key chain.\n     * @param depth The current depth to get the key from.\n     * @return Promise resolving to the key.\n     *         Null will be returned for @none entries, with aliasing taken into account.\n     */\n    async getContainerKey(key, keys, depth) {\n        const keyUnaliased = await this.unaliasKeyword(key, keys, depth);\n        return keyUnaliased === '@none' ? null : keyUnaliased;\n    }\n    /**\n     * Check if no reverse properties are present in embedded nodes.\n     * @param key The current key.\n     * @param reverse If a reverse property is active.\n     * @param isEmbedded If we're in an embedded node.\n     */\n    validateReverseInEmbeddedNode(key, reverse, isEmbedded) {\n        if (isEmbedded && reverse && !this.parsingContext.rdfstarReverseInEmbedded) {\n            throw new jsonld_context_parser_1.ErrorCoded(`Illegal reverse property in embedded node in ${key}`, jsonld_context_parser_1.ERROR_CODES.INVALID_EMBEDDED_NODE);\n        }\n    }\n    /**\n     * Emit a quad, with checks.\n     * @param depth The current depth.\n     * @param subject S\n     * @param predicate P\n     * @param object O\n     * @param graph G\n     * @param reverse If a reverse property is active.\n     * @param isEmbedded If we're in an embedded node.\n     */\n    emitQuadChecked(depth, subject, predicate, object, graph, reverse, isEmbedded) {\n        // Create a quad\n        let quad;\n        if (reverse) {\n            this.validateReverseSubject(object);\n            quad = this.dataFactory.quad(object, predicate, subject, graph);\n        }\n        else {\n            quad = this.dataFactory.quad(subject, predicate, object, graph);\n        }\n        // Emit the quad, unless it was created in an embedded node\n        if (isEmbedded) {\n            // Embedded nodes don't inherit the active graph\n            if (quad.graph.termType !== 'DefaultGraph') {\n                quad = this.dataFactory.quad(quad.subject, quad.predicate, quad.object);\n            }\n            // Multiple embedded nodes are not allowed\n            if (this.parsingContext.idStack[depth - 1]) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Illegal multiple properties in an embedded node`, jsonld_context_parser_1.ERROR_CODES.INVALID_EMBEDDED_NODE);\n            }\n            this.parsingContext.idStack[depth - 1] = [quad];\n        }\n        else {\n            this.parsingContext.emitQuad(depth, quad);\n        }\n        // Flush annotations\n        const annotationsBuffer = this.parsingContext.annotationsBuffer[depth];\n        if (annotationsBuffer) {\n            for (const annotation of annotationsBuffer) {\n                this.emitAnnotation(depth, quad, annotation);\n            }\n            delete this.parsingContext.annotationsBuffer[depth];\n        }\n    }\n    // This is a separate function to enable recursion\n    emitAnnotation(depth, quad, annotation) {\n        // Construct annotation quad\n        let annotationQuad;\n        if (annotation.reverse) {\n            this.validateReverseSubject(annotation.object);\n            annotationQuad = this.dataFactory.quad(annotation.object, annotation.predicate, quad);\n        }\n        else {\n            annotationQuad = this.dataFactory.quad(quad, annotation.predicate, annotation.object);\n        }\n        // Emit annotated quad\n        this.parsingContext.emitQuad(depth, annotationQuad);\n        // Also emit nested annotations\n        for (const nestedAnnotation of annotation.nestedAnnotations) {\n            this.emitAnnotation(depth, annotationQuad, nestedAnnotation);\n        }\n    }\n}\nUtil.XSD = 'http://www.w3.org/2001/XMLSchema#';\nUtil.XSD_BOOLEAN = Util.XSD + 'boolean';\nUtil.XSD_INTEGER = Util.XSD + 'integer';\nUtil.XSD_DOUBLE = Util.XSD + 'double';\nUtil.RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\nexports.Util = Util;\n//# sourceMappingURL=Util.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/Util.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIdentifier.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIdentifier.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ContainerHandlerIdentifier = void 0;\n/**\n * Container handler for @id.\n *\n * It assumes that the current key is the identifier of the current value.\n * This will add this value to the parent node.\n */\nclass ContainerHandlerIdentifier {\n    canCombineWithGraph() {\n        return true;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        let id;\n        // First check if the child node already has a defined id.\n        if (parsingContext.emittedStack[depth + 1] && parsingContext.idStack[depth + 1]) {\n            // Use the existing identifier\n            id = parsingContext.idStack[depth + 1][0];\n        }\n        else {\n            // Create the identifier\n            const keyUnaliased = await util.getContainerKey(keys[depth], keys, depth);\n            const maybeId = keyUnaliased !== null\n                ? await util.resourceToTerm(await parsingContext.getContext(keys), keys[depth])\n                : util.dataFactory.blankNode();\n            // Do nothing if the id is invalid\n            if (!maybeId) {\n                parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n                return;\n            }\n            id = maybeId;\n            // Insert the id into the stack so that buffered children can make us of it.\n            parsingContext.idStack[depth + 1] = [id];\n        }\n        // Insert the id into the stack so that parents can make use of it.\n        // Insert it as an array because multiple id container entries may exist\n        let ids = parsingContext.idStack[depth];\n        if (!ids) {\n            ids = parsingContext.idStack[depth] = [];\n        }\n        // Only insert the term if it does not exist yet in the array.\n        if (!ids.some((term) => term.equals(id))) {\n            ids.push(id);\n        }\n        // Flush any pending flush buffers\n        if (!await parsingContext.handlePendingContainerFlushBuffers()) {\n            parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n        }\n    }\n}\nexports.ContainerHandlerIdentifier = ContainerHandlerIdentifier;\n//# sourceMappingURL=ContainerHandlerIdentifier.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIdentifier.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIndex.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIndex.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ContainerHandlerIndex = void 0;\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\nconst EntryHandlerPredicate_1 = __webpack_require__(/*! ../entryhandler/EntryHandlerPredicate */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerPredicate.js\");\nconst Util_1 = __webpack_require__(/*! ../Util */ \"./node_modules/jsonld-streaming-parser/lib/Util.js\");\n/**\n * Container handler for @index.\n *\n * This will ignore the current key and add this entry to the parent node.\n */\nclass ContainerHandlerIndex {\n    canCombineWithGraph() {\n        return true;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        if (!Array.isArray(value)) {\n            const graphContainer = '@graph' in containers;\n            // Check if the container is a property-based container by checking if there is a valid @index.\n            const context = await parsingContext.getContext(keys);\n            const indexKey = keys[depth - 1];\n            const indexPropertyRaw = Util_1.Util.getContextValueIndex(context, indexKey);\n            if (indexPropertyRaw) {\n                // Validate the @index value\n                if (jsonld_context_parser_1.Util.isPotentialKeyword(indexPropertyRaw)) {\n                    throw new jsonld_context_parser_1.ErrorCoded(`Keywords can not be used as @index value, got: ${indexPropertyRaw}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                if (typeof indexPropertyRaw !== 'string') {\n                    throw new jsonld_context_parser_1.ErrorCoded(`@index values must be strings, got: ${indexPropertyRaw}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                // When @index is used, values must be node values, unless @type: @id is defined in the context\n                if (typeof value !== 'object') {\n                    // Error if we don't have @type: @id\n                    if (Util_1.Util.getContextValueType(context, indexKey) !== '@id') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Property-based index containers require nodes as values or strings with @type: @id, but got: ${value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                    }\n                    // Add an @id to the stack, so our expanded @index value can make use of it\n                    const id = util.resourceToTerm(context, value);\n                    if (id) {\n                        parsingContext.idStack[depth + 1] = [id];\n                    }\n                }\n                // Expand the @index value\n                const indexProperty = util.createVocabOrBaseTerm(context, indexPropertyRaw);\n                if (indexProperty) {\n                    const indexValues = await util.valueToTerm(context, indexPropertyRaw, await util.getContainerKey(keys[depth], keys, depth), depth, keys);\n                    if (graphContainer) {\n                        // When we're in a graph container, attach the index to the graph identifier\n                        const graphId = await util.getGraphContainerValue(keys, depth + 1);\n                        for (const indexValue of indexValues) {\n                            parsingContext.emitQuad(depth, util.dataFactory.quad(graphId, indexProperty, indexValue, util.getDefaultGraph()));\n                        }\n                    }\n                    else {\n                        // Otherwise, attach the index to the node identifier\n                        for (const indexValue of indexValues) {\n                            await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth + 1, indexProperty, indexValue, false, false, false);\n                        }\n                    }\n                }\n            }\n            const depthOffset = graphContainer ? 2 : 1;\n            await parsingContext.newOnValueJob(keys.slice(0, keys.length - depthOffset), value, depth - depthOffset, true);\n            // Flush any pending flush buffers\n            await parsingContext.handlePendingContainerFlushBuffers();\n        }\n        parsingContext.emittedStack[depth] = false; // We have emitted a level higher\n    }\n}\nexports.ContainerHandlerIndex = ContainerHandlerIndex;\n//# sourceMappingURL=ContainerHandlerIndex.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIndex.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerLanguage.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerLanguage.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ContainerHandlerLanguage = void 0;\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\n/**\n * Container handler for @language.\n *\n * It assumes that the current key is the language of the current value.\n * This will add this value to the parent node.\n */\nclass ContainerHandlerLanguage {\n    canCombineWithGraph() {\n        return false;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        const language = await util.getContainerKey(keys[depth], keys, depth);\n        if (Array.isArray(value)) {\n            // No type-checking needed, will be handled on each value when this handler is called recursively.\n            value = value.map((subValue) => ({ '@value': subValue, '@language': language }));\n        }\n        else {\n            if (typeof value !== 'string') {\n                throw new jsonld_context_parser_1.ErrorCoded(`Got invalid language map value, got '${JSON.stringify(value)}', but expected string`, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_MAP_VALUE);\n            }\n            value = { '@value': value, '@language': language };\n        }\n        await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), value, depth - 1, true);\n        parsingContext.emittedStack[depth] = false; // We have emitted a level higher\n    }\n}\nexports.ContainerHandlerLanguage = ContainerHandlerLanguage;\n//# sourceMappingURL=ContainerHandlerLanguage.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerLanguage.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerType.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerType.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ContainerHandlerType = void 0;\nconst EntryHandlerPredicate_1 = __webpack_require__(/*! ../entryhandler/EntryHandlerPredicate */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerPredicate.js\");\nconst Util_1 = __webpack_require__(/*! ../Util */ \"./node_modules/jsonld-streaming-parser/lib/Util.js\");\n/**\n * Container handler for @type.\n *\n * This will add this entry to the parent node, and use the current key as an rdf:type value.\n */\nclass ContainerHandlerType {\n    canCombineWithGraph() {\n        return false;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        if (!Array.isArray(value)) {\n            if (typeof value === 'string') {\n                // Determine the @type of the container\n                const context = await parsingContext.getContext(keys);\n                const containerTypeType = Util_1.Util.getContextValueType(context, keys[depth - 1]);\n                // String values refer to node references\n                const id = containerTypeType === '@vocab'\n                    ? await util.createVocabOrBaseTerm(context, value)\n                    : await util.resourceToTerm(context, value);\n                if (id) {\n                    // Handle the value of this node as @id, which will also cause the predicate from above to be emitted.\n                    const subValue = { '@id': id.termType === 'NamedNode' ? id.value : value };\n                    await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), subValue, depth - 1, true);\n                    // Set the id in the stack so it can be used for the rdf:type handling later on\n                    parsingContext.idStack[depth + 1] = [id];\n                }\n            }\n            else {\n                // Other values are handled by handling them as a proper job\n                // Check needed for cases where entries don't have an explicit @id\n                const entryHasIdentifier = !!parsingContext.idStack[depth + 1];\n                // Handle the value of this node, which will also cause the predicate from above to be emitted.\n                if (!entryHasIdentifier) {\n                    delete parsingContext.idStack[depth]; // Force new (blank node) identifier\n                }\n                await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), value, depth - 1, true);\n                if (!entryHasIdentifier) {\n                    parsingContext.idStack[depth + 1] = parsingContext.idStack[depth]; // Copy the id to the child node, for @type\n                }\n            }\n            // Identify the type to emit.\n            const keyOriginal = await util.getContainerKey(keys[depth], keys, depth);\n            const type = keyOriginal !== null\n                ? util.createVocabOrBaseTerm(await parsingContext.getContext(keys), keyOriginal)\n                : null;\n            if (type) {\n                // Push the type to the stack using the rdf:type predicate\n                await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth + 1, util.rdfType, type, false, false, false);\n            }\n            // Flush any pending flush buffers\n            await parsingContext.handlePendingContainerFlushBuffers();\n        }\n        parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n    }\n}\nexports.ContainerHandlerType = ContainerHandlerType;\n//# sourceMappingURL=ContainerHandlerType.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerType.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerArrayValue.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerArrayValue.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerArrayValue = void 0;\nconst Util_1 = __webpack_require__(/*! ../Util */ \"./node_modules/jsonld-streaming-parser/lib/Util.js\");\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\n/**\n * Handles values that are part of an array.\n */\nclass EntryHandlerArrayValue {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return this.test(parsingContext, util, null, keys, depth);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return typeof keys[depth] === 'number';\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        let parentKey = await util.unaliasKeywordParent(keys, depth);\n        // Check if we have an anonymous list\n        if (parentKey === '@list') {\n            // Our value is part of an array\n            // Determine the list root key\n            let listRootKey = null;\n            let listRootDepth = 0;\n            for (let i = depth - 2; i > 0; i--) {\n                const keyOption = keys[i];\n                if (typeof keyOption === 'string' || typeof keyOption === 'number') {\n                    listRootDepth = i;\n                    listRootKey = keyOption;\n                    break;\n                }\n            }\n            if (listRootKey !== null) {\n                // Emit the given objects as list elements\n                const values = await util.valueToTerm(await parsingContext.getContext(keys), listRootKey, value, depth, keys);\n                for (const object of values) {\n                    await this.handleListElement(parsingContext, util, object, value, depth, keys.slice(0, listRootDepth), listRootDepth);\n                }\n                // If no values were found, emit a falsy list element to force an empty RDF list to be emitted.\n                if (values.length === 0) {\n                    await this.handleListElement(parsingContext, util, null, value, depth, keys.slice(0, listRootDepth), listRootDepth);\n                }\n            }\n        }\n        else if (parentKey === '@set') {\n            // Our value is part of a set, so we just add it to the parent-parent\n            await parsingContext.newOnValueJob(keys.slice(0, -2), value, depth - 2, false);\n        }\n        else if (parentKey !== undefined && parentKey !== '@type') {\n            // Buffer our value using the parent key as predicate\n            // Determine the first parent key that is *not* an array key\n            // This is needed in case we have an @list container with nested arrays,\n            // where each of them should produce nested RDF lists.\n            for (let i = depth - 1; i > 0; i--) {\n                if (typeof keys[i] !== 'number') {\n                    parentKey = await util.unaliasKeyword(keys[i], keys, i);\n                    break;\n                }\n            }\n            // Check if the predicate is marked as an @list in the context\n            const parentContext = await parsingContext.getContext(keys.slice(0, -1));\n            if ('@list' in Util_1.Util.getContextValueContainer(parentContext, parentKey)) {\n                // Our value is part of an array\n                // Emit the given objects as list elements\n                parsingContext.emittedStack[depth + 1] = true; // Ensure the creation of bnodes for empty nodes\n                const values = await util.valueToTerm(await parsingContext.getContext(keys), parentKey, value, depth, keys);\n                for (const object of values) {\n                    await this.handleListElement(parsingContext, util, object, value, depth, keys.slice(0, -1), depth - 1);\n                }\n                // If no values were found, emit a falsy list element to force an empty RDF list to be emitted.\n                if (values.length === 0) {\n                    await this.handleListElement(parsingContext, util, null, value, depth, keys.slice(0, -1), depth - 1);\n                }\n            }\n            else {\n                // Copy the stack values up one level so that the next job can access them.\n                parsingContext.shiftStack(depth, 1);\n                // Execute the job one level higher\n                await parsingContext.newOnValueJob(keys.slice(0, -1), value, depth - 1, false);\n                // Remove any defined contexts at this level to avoid it to propagate to the next array element.\n                parsingContext.contextTree.removeContext(keys.slice(0, -1));\n            }\n        }\n    }\n    async handleListElement(parsingContext, util, value, valueOriginal, depth, listRootKeys, listRootDepth) {\n        // Buffer our value as an RDF list using the listRootKey as predicate\n        let listPointer = parsingContext.listPointerStack[depth];\n        if (valueOriginal !== null && (await util.unaliasKeywords(valueOriginal, listRootKeys, depth))['@value'] !== null) {\n            if (!listPointer || !listPointer.value) {\n                const linkTerm = util.dataFactory.blankNode();\n                listPointer = { value: linkTerm, listRootDepth, listId: linkTerm };\n            }\n            else {\n                // rdf:rest links are always emitted before the next element,\n                // as the blank node identifier is only created at that point.\n                // Because of this reason, the final rdf:nil is emitted when the stack depth is decreased.\n                const newLinkTerm = util.dataFactory.blankNode();\n                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer.value, util.rdfRest, newLinkTerm, util.getDefaultGraph()));\n                // Update the list pointer for the next element\n                listPointer.value = newLinkTerm;\n            }\n            // Emit a list element for the current value\n            // Omit rdf:first if the value is invalid\n            if (value) {\n                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer.value, util.rdfFirst, value, util.getDefaultGraph()));\n            }\n        }\n        else {\n            // A falsy list element if found.\n            // Mark it as an rdf:nil list until another valid list element comes in\n            if (!listPointer) {\n                listPointer = { listRootDepth, listId: util.rdfNil };\n            }\n        }\n        parsingContext.listPointerStack[depth] = listPointer;\n        // Error if an annotation was defined\n        if (parsingContext.rdfstar && parsingContext.annotationsBuffer[depth]) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal annotation inside a list`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n        }\n    }\n}\nexports.EntryHandlerArrayValue = EntryHandlerArrayValue;\n//# sourceMappingURL=EntryHandlerArrayValue.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerArrayValue.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerContainer.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerContainer.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerContainer = void 0;\nconst ContainerHandlerIdentifier_1 = __webpack_require__(/*! ../containerhandler/ContainerHandlerIdentifier */ \"./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIdentifier.js\");\nconst ContainerHandlerIndex_1 = __webpack_require__(/*! ../containerhandler/ContainerHandlerIndex */ \"./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIndex.js\");\nconst ContainerHandlerLanguage_1 = __webpack_require__(/*! ../containerhandler/ContainerHandlerLanguage */ \"./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerLanguage.js\");\nconst ContainerHandlerType_1 = __webpack_require__(/*! ../containerhandler/ContainerHandlerType */ \"./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerType.js\");\nconst Util_1 = __webpack_require__(/*! ../Util */ \"./node_modules/jsonld-streaming-parser/lib/Util.js\");\n/**\n * Handles values that are part of a container type (like @index),\n * as specified by {@link IContainerHandler}.\n */\nclass EntryHandlerContainer {\n    /**\n     * Check fit the given container is a simple @graph container.\n     * Concretely, it will check if no @index or @id is active as well.\n     * @param containers A container hash.\n     */\n    static isSimpleGraphContainer(containers) {\n        return '@graph' in containers\n            && (('@set' in containers && Object.keys(containers).length === 2) || Object.keys(containers).length === 1);\n    }\n    /**\n     * Check fit the given container is a complex @graph container.\n     * Concretely, it will check if @index or @id is active as well next to @graph.\n     * @param containers A container hash.\n     */\n    static isComplexGraphContainer(containers) {\n        return '@graph' in containers\n            && (('@set' in containers && Object.keys(containers).length > 2)\n                || (!('@set' in containers) && Object.keys(containers).length > 1));\n    }\n    /**\n     * Create an graph container index that can be used for identifying a graph term inside the graphContainerTermStack.\n     * @param containers The applicable containers.\n     * @param depth The container depth.\n     * @param keys The array of keys.\n     * @return The graph index.\n     */\n    static getContainerGraphIndex(containers, depth, keys) {\n        let isSimpleGraphContainer = EntryHandlerContainer.isSimpleGraphContainer(containers);\n        let index = '';\n        for (let i = depth; i < keys.length; i++) {\n            if (!isSimpleGraphContainer || typeof keys[i] === 'number') {\n                index += ':' + keys[i];\n            }\n            // Only allow a second 'real' key if in a non-simple graph container.\n            if (!isSimpleGraphContainer && typeof keys[i] !== 'number') {\n                isSimpleGraphContainer = true;\n            }\n        }\n        return index;\n    }\n    /**\n     * Return the applicable container type at the given depth.\n     *\n     * This will ignore any arrays in the key chain.\n     *\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {any[]} keys The array of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<{ containers: {[typeName: string]: boolean}, depth: number, fallback: boolean }>}\n     *          All applicable containers for the given depth,\n     *          the `depth` of the container root (can change when arrays are in the key chain),\n     *          and the `fallback` flag that indicates if the default container type was returned\n     *            (i.e., no dedicated container type is defined).\n     */\n    static async getContainerHandler(parsingContext, keys, depth) {\n        const fallback = {\n            containers: { '@set': true },\n            depth,\n            fallback: true,\n        };\n        // A flag that is enabled when @graph container should be tested in next iteration\n        let checkGraphContainer = false;\n        // Iterate from deeper to higher\n        const context = await parsingContext.getContext(keys, 2);\n        for (let i = depth - 1; i >= 0; i--) {\n            if (typeof keys[i] !== 'number') { // Skip array keys\n                // @graph containers without any other types are one level less deep, and require special handling\n                const containersSelf = Util_1.Util.getContextValue(context, '@container', keys[i], false);\n                if (containersSelf && EntryHandlerContainer.isSimpleGraphContainer(containersSelf)) {\n                    return {\n                        containers: containersSelf,\n                        depth: i + 1,\n                        fallback: false,\n                    };\n                }\n                const containersParent = Util_1.Util.getContextValue(context, '@container', keys[i - 1], false);\n                if (!containersParent) { // If we have the fallback container value\n                    if (checkGraphContainer) {\n                        // Return false if we were already expecting a @graph-@id of @graph-@index container\n                        return fallback;\n                    }\n                    // Check parent-parent, we may be in a @graph-@id of @graph-@index container, which have two levels\n                    checkGraphContainer = true;\n                }\n                else {\n                    // We had an invalid container next iteration, so we now have to check if we were in an @graph container\n                    const graphContainer = '@graph' in containersParent;\n                    // We're in a regular container\n                    for (const containerHandleName in EntryHandlerContainer.CONTAINER_HANDLERS) {\n                        if (containersParent[containerHandleName]) {\n                            if (graphContainer) {\n                                // Only accept graph containers if their combined handlers can handle them.\n                                if (EntryHandlerContainer.CONTAINER_HANDLERS[containerHandleName].canCombineWithGraph()) {\n                                    return {\n                                        containers: containersParent,\n                                        depth: i,\n                                        fallback: false,\n                                    };\n                                }\n                                else {\n                                    return fallback;\n                                }\n                            }\n                            else {\n                                // Only accept if we were not expecting a @graph-@id of @graph-@index container\n                                if (checkGraphContainer) {\n                                    return fallback;\n                                }\n                                else {\n                                    return {\n                                        containers: containersParent,\n                                        depth: i,\n                                        fallback: false,\n                                    };\n                                }\n                            }\n                        }\n                    }\n                    // Fail if no valid container handlers were found\n                    return fallback;\n                }\n            }\n        }\n        return fallback;\n    }\n    /**\n     * Check if we are handling a value at the given depth\n     * that is part of something that should be handled as a container,\n     * AND if this container should be buffered, so that it can be handled by a dedicated container handler.\n     *\n     * For instance, any container with @graph will NOT be buffered.\n     *\n     * This will ignore any arrays in the key chain.\n     *\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {any[]} keys The array of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<boolean>} If we are in the scope of a container handler.\n     */\n    static async isBufferableContainerHandler(parsingContext, keys, depth) {\n        const handler = await EntryHandlerContainer.getContainerHandler(parsingContext, keys, depth);\n        return !handler.fallback && !('@graph' in handler.containers);\n    }\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return !!await this.test(parsingContext, util, null, keys, depth);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        const containers = Util_1.Util.getContextValueContainer(await parsingContext.getContext(keys, 2), keys[depth - 1]);\n        for (const containerName in EntryHandlerContainer.CONTAINER_HANDLERS) {\n            if (containers[containerName]) {\n                return {\n                    containers,\n                    handler: EntryHandlerContainer.CONTAINER_HANDLERS[containerName],\n                };\n            }\n        }\n        return null;\n    }\n    async handle(parsingContext, util, key, keys, value, depth, testResult) {\n        return testResult.handler.handle(testResult.containers, parsingContext, util, keys, value, depth);\n    }\n}\nEntryHandlerContainer.CONTAINER_HANDLERS = {\n    '@id': new ContainerHandlerIdentifier_1.ContainerHandlerIdentifier(),\n    '@index': new ContainerHandlerIndex_1.ContainerHandlerIndex(),\n    '@language': new ContainerHandlerLanguage_1.ContainerHandlerLanguage(),\n    '@type': new ContainerHandlerType_1.ContainerHandlerType(),\n};\nexports.EntryHandlerContainer = EntryHandlerContainer;\n//# sourceMappingURL=EntryHandlerContainer.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerContainer.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerInvalidFallback.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerInvalidFallback.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerInvalidFallback = void 0;\n/**\n * A catch-all for properties, that will either emit an error or ignore,\n * depending on whether or not the `strictValues` property is set.\n */\nclass EntryHandlerInvalidFallback {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return true;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerInvalidFallback = EntryHandlerInvalidFallback;\n//# sourceMappingURL=EntryHandlerInvalidFallback.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerInvalidFallback.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerPredicate.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerPredicate.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerPredicate = void 0;\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\nconst Util_1 = __webpack_require__(/*! ../Util */ \"./node_modules/jsonld-streaming-parser/lib/Util.js\");\n/**\n * Interprets keys as predicates.\n * The most common case in JSON-LD processing.\n */\nclass EntryHandlerPredicate {\n    /**\n     * Handle the given predicate-object by either emitting it,\n     * or by placing it in the appropriate stack for later emission when no @graph and/or @id has been defined.\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {Util} util A utility instance.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth The current depth.\n     * @param {Term} predicate The predicate.\n     * @param {Term} object The object.\n     * @param {boolean} reverse If the property is reversed.\n     * @param {boolean} isEmbedded If the property exists in an embedded node as direct child.\n     * @param {boolean} isAnnotation If the property exists in an annotation object.\n     * @return {Promise<void>} A promise resolving when handling is done.\n     */\n    static async handlePredicateObject(parsingContext, util, keys, depth, predicate, object, reverse, isEmbedded, isAnnotation) {\n        const depthProperties = await util.getPropertiesDepth(keys, depth);\n        const depthOffsetGraph = await util.getDepthOffsetGraph(depth, keys);\n        const depthPropertiesGraph = depth - depthOffsetGraph;\n        const subjects = parsingContext.idStack[depthProperties];\n        if (subjects && !isAnnotation) {\n            // Emit directly if the @id was already defined\n            for (const subject of subjects) {\n                // Check if we're in a @graph context\n                const atGraph = depthOffsetGraph >= 0;\n                if (atGraph) {\n                    const graphs = parsingContext.idStack[depthPropertiesGraph - 1];\n                    if (graphs) {\n                        for (const graph of graphs) {\n                            // Emit our quad if graph @id is known\n                            util.emitQuadChecked(depth, subject, predicate, object, graph, reverse, isEmbedded);\n                        }\n                    }\n                    else {\n                        // Buffer our triple if graph @id is not known yet.\n                        if (reverse) {\n                            util.validateReverseSubject(object);\n                            parsingContext.getUnidentifiedGraphBufferSafe(depthPropertiesGraph - 1).push({ subject: object, predicate, object: subject, isEmbedded });\n                        }\n                        else {\n                            parsingContext.getUnidentifiedGraphBufferSafe(depthPropertiesGraph - 1)\n                                .push({ subject, predicate, object, isEmbedded });\n                        }\n                    }\n                }\n                else {\n                    // Emit if no @graph was applicable\n                    const graph = await util.getGraphContainerValue(keys, depthProperties);\n                    util.emitQuadChecked(depth, subject, predicate, object, graph, reverse, isEmbedded);\n                }\n            }\n        }\n        else {\n            // Buffer until our @id becomes known, or we go up the stack\n            if (reverse) {\n                util.validateReverseSubject(object);\n            }\n            // Either push to the annotations or the actual value buffer\n            if (isAnnotation) {\n                // Only add to buffer if rdfstar is enabled\n                if (parsingContext.rdfstar) {\n                    // Error if an @id was defined\n                    if (parsingContext.idStack[depth]) {\n                        parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @id inside an annotation: ${parsingContext.idStack[depth][0].value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n                    }\n                    // Error if we're in an embedded node\n                    for (let i = 0; i < depth; i++) {\n                        if (await util.unaliasKeyword(keys[i], keys, i) === '@id') {\n                            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal annotation inside an embedded node`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n                        }\n                    }\n                    // Store new annotation in the buffer\n                    const annotationsBuffer = parsingContext.getAnnotationsBufferSafe(depthProperties);\n                    const newAnnotation = { predicate, object, reverse, nestedAnnotations: [], depth: depthProperties };\n                    annotationsBuffer.push(newAnnotation);\n                    // Check in the buffer if any annotations were defined at a deeper depth,\n                    // if so, they are considered nested annotations.\n                    for (let i = annotationsBuffer.length - 2; i >= 0; i--) {\n                        // We iterate in reverse order, to enable easy item removal from the back.\n                        const existingAnnotation = annotationsBuffer[i];\n                        if (existingAnnotation.depth > depthProperties) {\n                            newAnnotation.nestedAnnotations.push(existingAnnotation);\n                            annotationsBuffer.splice(i, 1);\n                        }\n                    }\n                }\n            }\n            else {\n                parsingContext.getUnidentifiedValueBufferSafe(depthProperties).push({ predicate, object, reverse, isEmbedded });\n            }\n        }\n    }\n    isPropertyHandler() {\n        return true;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        const key = keys[depth];\n        if (key) {\n            const context = await parsingContext.getContext(keys);\n            if (!parsingContext.jsonLiteralStack[depth] && await util.predicateToTerm(context, keys[depth])) {\n                // If this valid predicate is of type @json, mark it so in the stack so that no deeper handling of nodes occurs.\n                if (Util_1.Util.getContextValueType(context, key) === '@json') {\n                    parsingContext.jsonLiteralStack[depth + 1] = true;\n                }\n                return true;\n            }\n        }\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return keys[depth];\n    }\n    async handle(parsingContext, util, key, keys, value, depth, testResult) {\n        const keyOriginal = keys[depth];\n        const context = await parsingContext.getContext(keys);\n        const predicate = await util.predicateToTerm(context, key);\n        if (predicate) {\n            const objects = await util.valueToTerm(context, key, value, depth, keys);\n            if (objects.length) {\n                for (let object of objects) {\n                    // Based on parent key, check if reverse, embedded, and annotation.\n                    let parentKey = await util.unaliasKeywordParent(keys, depth);\n                    const reverse = Util_1.Util.isPropertyReverse(context, keyOriginal, parentKey);\n                    let parentDepthOffset = 0;\n                    while (parentKey === '@reverse' || typeof parentKey === 'number') {\n                        // Check parent of parent when checking while we're in an array or in @reverse\n                        if (typeof parentKey === 'number') {\n                            parentDepthOffset++;\n                        }\n                        else {\n                            depth--;\n                        }\n                        parentKey = await util.unaliasKeywordParent(keys, depth - parentDepthOffset);\n                    }\n                    const isEmbedded = Util_1.Util.isPropertyInEmbeddedNode(parentKey);\n                    util.validateReverseInEmbeddedNode(key, reverse, isEmbedded);\n                    const isAnnotation = Util_1.Util.isPropertyInAnnotationObject(parentKey);\n                    if (value) {\n                        // Special case if our term was defined as an @list, but does not occur in an array,\n                        // In that case we just emit it as an RDF list with a single element.\n                        const listValueContainer = '@list' in Util_1.Util.getContextValueContainer(context, key);\n                        if (listValueContainer || value['@list']) {\n                            if (((listValueContainer && !Array.isArray(value) && !value['@list'])\n                                || (value['@list'] && !Array.isArray(value['@list'])))\n                                && object !== util.rdfNil) {\n                                const listPointer = util.dataFactory.blankNode();\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer, util.rdfRest, util.rdfNil, util.getDefaultGraph()));\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer, util.rdfFirst, object, util.getDefaultGraph()));\n                                object = listPointer;\n                            }\n                            // Lists are not allowed in @reverse'd properties\n                            if (reverse && !parsingContext.allowSubjectList) {\n                                throw new jsonld_context_parser_1.ErrorCoded(`Found illegal list value in subject position at ${key}`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_VALUE);\n                            }\n                        }\n                    }\n                    await EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth, predicate, object, reverse, isEmbedded, isAnnotation);\n                }\n            }\n        }\n    }\n}\nexports.EntryHandlerPredicate = EntryHandlerPredicate;\n//# sourceMappingURL=EntryHandlerPredicate.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerPredicate.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerKeyword = void 0;\n/**\n * An abstract keyword entry handler.\n */\nclass EntryHandlerKeyword {\n    constructor(keyword) {\n        this.keyword = keyword;\n    }\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return key === this.keyword;\n    }\n}\nexports.EntryHandlerKeyword = EntryHandlerKeyword;\n//# sourceMappingURL=EntryHandlerKeyword.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordAnnotation.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordAnnotation.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerKeywordAnnotation = void 0;\nconst EntryHandlerKeyword_1 = __webpack_require__(/*! ./EntryHandlerKeyword */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js\");\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\n/**\n * Handles @annotation entries.\n */\nclass EntryHandlerKeywordAnnotation extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@annotation');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // Validate value\n        if (typeof value === 'string' || (typeof value === 'object' && value['@value'])) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal annotation value: ${JSON.stringify(value)}`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n        }\n        // Rest of the processing is done as regular nodes\n    }\n}\nexports.EntryHandlerKeywordAnnotation = EntryHandlerKeywordAnnotation;\n//# sourceMappingURL=EntryHandlerKeywordAnnotation.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordAnnotation.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordContext.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordContext.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerKeywordContext = void 0;\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\nconst EntryHandlerKeyword_1 = __webpack_require__(/*! ./EntryHandlerKeyword */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js\");\n/**\n * Handles @context entries.\n */\nclass EntryHandlerKeywordContext extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@context');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // Error if an out-of-order context was found when support is not enabled.\n        if (parsingContext.streamingProfile\n            && (parsingContext.processingStack[depth]\n                || parsingContext.processingType[depth]\n                || parsingContext.idStack[depth] !== undefined)) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded('Found an out-of-order context, while streaming is enabled.' +\n                '(disable `streamingProfile`)', jsonld_context_parser_1.ERROR_CODES.INVALID_STREAMING_KEY_ORDER));\n        }\n        // Find the parent context to inherit from.\n        // We actually request a context for the current depth (with fallback to parent)\n        // because we want to take into account any property-scoped contexts that are defined for this depth.\n        const parentContext = parsingContext.getContext(keys);\n        // Set the context for this scope\n        const context = parsingContext.parseContext(value, (await parentContext).getContextRaw());\n        parsingContext.contextTree.setContext(keys.slice(0, -1), context);\n        parsingContext.emitContext(value);\n        await parsingContext.validateContext(await context);\n    }\n}\nexports.EntryHandlerKeywordContext = EntryHandlerKeywordContext;\n//# sourceMappingURL=EntryHandlerKeywordContext.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordContext.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordGraph.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordGraph.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerKeywordGraph = void 0;\nconst EntryHandlerKeyword_1 = __webpack_require__(/*! ./EntryHandlerKeyword */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js\");\n/**\n * Handles @graph entries.\n */\nclass EntryHandlerKeywordGraph extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@graph');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // The current identifier identifies a graph for the deeper level.\n        parsingContext.graphStack[depth + 1] = true;\n    }\n}\nexports.EntryHandlerKeywordGraph = EntryHandlerKeywordGraph;\n//# sourceMappingURL=EntryHandlerKeywordGraph.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordGraph.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordId.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordId.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerKeywordId = void 0;\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\nconst EntryHandlerKeyword_1 = __webpack_require__(/*! ./EntryHandlerKeyword */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js\");\n/**\n * Handles @id entries.\n */\nclass EntryHandlerKeywordId extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@id');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'string') {\n            // JSON-LD-star allows @id object values\n            if (parsingContext.rdfstar && typeof value === 'object') {\n                const valueKeys = Object.keys(value);\n                if (valueKeys.length === 1 && valueKeys[0] === '@id') {\n                    parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid embedded node without property with @id ${value['@id']}`, jsonld_context_parser_1.ERROR_CODES.INVALID_EMBEDDED_NODE));\n                }\n            }\n            else {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @id '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_ID_VALUE));\n            }\n            return;\n        }\n        // Determine the canonical place for this id.\n        // For example, @nest parents should be ignored.\n        const depthProperties = await util.getPropertiesDepth(keys, depth);\n        // Error if an @id for this node already existed.\n        if (parsingContext.idStack[depthProperties] !== undefined) {\n            if (parsingContext.idStack[depthProperties][0].listHead) {\n                // Error if an @list was already defined for this node\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @list for key: '${keys[depth - 1]}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT));\n            }\n            else {\n                // Otherwise, the previous id was just because of an @id entry.\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found duplicate @ids '${parsingContext\n                    .idStack[depthProperties][0].value}' and '${value}'`, jsonld_context_parser_1.ERROR_CODES.COLLIDING_KEYWORDS));\n            }\n        }\n        // Error if an annotation was defined\n        if (parsingContext.rdfstar && parsingContext.annotationsBuffer[depth]) {\n            for (const annotation of parsingContext.annotationsBuffer[depth]) {\n                if (annotation.depth === depth) {\n                    parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @id inside an annotation: ${value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_ANNOTATION));\n                }\n            }\n        }\n        // Save our @id on the stack\n        parsingContext.idStack[depthProperties] = util.nullableTermToArray(await util.resourceToTerm(await parsingContext.getContext(keys), value));\n    }\n}\nexports.EntryHandlerKeywordId = EntryHandlerKeywordId;\n//# sourceMappingURL=EntryHandlerKeywordId.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordId.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordIncluded.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordIncluded.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerKeywordIncluded = void 0;\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\nconst EntryHandlerKeyword_1 = __webpack_require__(/*! ./EntryHandlerKeyword */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js\");\n/**\n * Handles @included entries.\n */\nclass EntryHandlerKeywordIncluded extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@included');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'object') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @included '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        const valueUnliased = await util.unaliasKeywords(value, keys, depth, await parsingContext.getContext(keys));\n        if ('@value' in valueUnliased) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @included @value node '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        if ('@list' in valueUnliased) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @included @list node '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordIncluded = EntryHandlerKeywordIncluded;\n//# sourceMappingURL=EntryHandlerKeywordIncluded.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordIncluded.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordNest.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordNest.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerKeywordNest = void 0;\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\nconst EntryHandlerKeyword_1 = __webpack_require__(/*! ./EntryHandlerKeyword */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js\");\n/**\n * Handles @nest entries.\n */\nclass EntryHandlerKeywordNest extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@nest');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'object') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found invalid @nest entry for '${key}': '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_NEST_VALUE));\n        }\n        if ('@value' in await util.unaliasKeywords(value, keys, depth, await parsingContext.getContext(keys))) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an invalid @value node for '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_NEST_VALUE));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordNest = EntryHandlerKeywordNest;\n//# sourceMappingURL=EntryHandlerKeywordNest.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordNest.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordType.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordType.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerKeywordType = void 0;\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\nconst Util_1 = __webpack_require__(/*! ../../Util */ \"./node_modules/jsonld-streaming-parser/lib/Util.js\");\nconst EntryHandlerPredicate_1 = __webpack_require__(/*! ../EntryHandlerPredicate */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerPredicate.js\");\nconst EntryHandlerKeyword_1 = __webpack_require__(/*! ./EntryHandlerKeyword */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js\");\n/**\n * Handles @graph entries.\n */\nclass EntryHandlerKeywordType extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@type');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        const keyOriginal = keys[depth];\n        // The current identifier identifies an rdf:type predicate.\n        // But we only emit it once the node closes,\n        // as it's possible that the @type is used to identify the datatype of a literal, which we ignore here.\n        const context = await parsingContext.getContext(keys);\n        const predicate = util.rdfType;\n        const parentKey = await util.unaliasKeywordParent(keys, depth);\n        const reverse = Util_1.Util.isPropertyReverse(context, keyOriginal, parentKey);\n        const isEmbedded = Util_1.Util.isPropertyInEmbeddedNode(parentKey);\n        util.validateReverseInEmbeddedNode(key, reverse, isEmbedded);\n        const isAnnotation = Util_1.Util.isPropertyInAnnotationObject(parentKey);\n        // Handle multiple values if the value is an array\n        const elements = Array.isArray(value) ? value : [value];\n        for (const element of elements) {\n            if (typeof element !== 'string') {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @type '${element}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPE_VALUE));\n            }\n            const type = util.createVocabOrBaseTerm(context, element);\n            if (type) {\n                await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth, predicate, type, reverse, isEmbedded, isAnnotation);\n            }\n        }\n        // Collect type-scoped contexts if they exist\n        let scopedContext = Promise.resolve(context);\n        let hasTypedScopedContext = false;\n        for (const element of elements.sort()) { // Spec requires lexicographical ordering\n            const typeContext = Util_1.Util.getContextValue(context, '@context', element, null);\n            if (typeContext) {\n                hasTypedScopedContext = true;\n                scopedContext = scopedContext.then((c) => parsingContext.parseContext(typeContext, c.getContextRaw()));\n            }\n        }\n        // Error if an out-of-order type-scoped context was found when support is not enabled.\n        if (parsingContext.streamingProfile\n            && (hasTypedScopedContext || !parsingContext.streamingProfileAllowOutOfOrderPlainType)\n            && (parsingContext.processingStack[depth] || parsingContext.idStack[depth])) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded('Found an out-of-order type-scoped context, while streaming is enabled.' +\n                '(disable `streamingProfile`)', jsonld_context_parser_1.ERROR_CODES.INVALID_STREAMING_KEY_ORDER));\n        }\n        // If at least least one type-scoped context applies, set them in the tree.\n        if (hasTypedScopedContext) {\n            // Do not propagate by default\n            scopedContext = scopedContext.then((c) => {\n                // Set the original context at this depth as a fallback\n                // This is needed when a context was already defined at the given depth,\n                // and this context needs to remain accessible from child nodes when propagation is disabled.\n                if (c.getContextRaw()['@propagate'] !== true) {\n                    return new jsonld_context_parser_1.JsonLdContextNormalized(Object.assign(Object.assign({}, c.getContextRaw()), { '@propagate': false, '@__propagateFallback': context.getContextRaw() }));\n                }\n                return c;\n            });\n            // Set the new context in the context tree\n            parsingContext.contextTree.setContext(keys.slice(0, keys.length - 1), scopedContext);\n        }\n        // Flag that type has been processed at this depth\n        parsingContext.processingType[depth] = true;\n    }\n}\nexports.EntryHandlerKeywordType = EntryHandlerKeywordType;\n//# sourceMappingURL=EntryHandlerKeywordType.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordType.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordUnknownFallback.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordUnknownFallback.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerKeywordUnknownFallback = void 0;\nconst jsonld_context_parser_1 = __webpack_require__(/*! jsonld-context-parser */ \"./node_modules/jsonld-context-parser/index.js\");\n/**\n * A catch-all for keywords, that will either emit an error or ignore,\n * depending on whether or not the `strictValues` property is set.\n */\nclass EntryHandlerKeywordUnknownFallback {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        const key = await util.unaliasKeyword(keys[depth], keys, depth);\n        if (jsonld_context_parser_1.Util.isPotentialKeyword(key)) {\n            // Don't emit anything inside free-floating lists\n            if (!inProperty) {\n                if (key === '@list') {\n                    return false;\n                }\n            }\n            return true;\n        }\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return jsonld_context_parser_1.Util.isPotentialKeyword(key);\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        const keywordType = EntryHandlerKeywordUnknownFallback.VALID_KEYWORDS_TYPES[key];\n        if (keywordType !== undefined) {\n            if (keywordType && typeof value !== keywordType.type) {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid value type for '${key}' with value '${value}'`, keywordType.errorCode));\n            }\n        }\n        else if (parsingContext.strictValues) {\n            parsingContext.emitError(new Error(`Unknown keyword '${key}' with value '${value}'`));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nEntryHandlerKeywordUnknownFallback.VALID_KEYWORDS_TYPES = {\n    '@index': { type: 'string', errorCode: jsonld_context_parser_1.ERROR_CODES.INVALID_INDEX_VALUE },\n    '@list': null,\n    '@reverse': { type: 'object', errorCode: jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_VALUE },\n    '@set': null,\n    '@value': null,\n};\nexports.EntryHandlerKeywordUnknownFallback = EntryHandlerKeywordUnknownFallback;\n//# sourceMappingURL=EntryHandlerKeywordUnknownFallback.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordUnknownFallback.js?");

/***/ }),

/***/ "./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordValue.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordValue.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EntryHandlerKeywordValue = void 0;\nconst EntryHandlerKeyword_1 = __webpack_require__(/*! ./EntryHandlerKeyword */ \"./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js\");\n/**\n * Handles @value entries.\n */\nclass EntryHandlerKeywordValue extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@value');\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        // If this is @value, mark it so in the stack so that no deeper handling of nodes occurs.\n        const key = keys[depth];\n        if (key && !parsingContext.literalStack[depth] && await this.test(parsingContext, util, key, keys, depth)) {\n            parsingContext.literalStack[depth] = true;\n        }\n        return super.validate(parsingContext, util, keys, depth, inProperty);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return await util.unaliasKeyword(keys[depth], keys.slice(0, keys.length - 1), depth - 1, true) === '@value';\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // If the value is valid, indicate that we are processing a literal.\n        // The actual value will be determined at the parent level when the @value is part of an object,\n        // because we may want to take into account additional entries such as @language.\n        // See {@link Util.valueToTerm}\n        // Indicate that we are processing a literal, and that no later predicates should be parsed at this depth.\n        parsingContext.literalStack[depth] = true;\n        // Void any buffers that we may have accumulated up until now\n        delete parsingContext.unidentifiedValuesBuffer[depth];\n        delete parsingContext.unidentifiedGraphsBuffer[depth];\n        // Indicate that we have not emitted at this depth\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordValue = EntryHandlerKeywordValue;\n//# sourceMappingURL=EntryHandlerKeywordValue.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordValue.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/ContextResolver.js":
/*!****************************************************!*\
  !*** ./node_modules/jsonld/lib/ContextResolver.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2019 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isString: _isString,\n} = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\nconst {\n  asArray: _asArray\n} = __webpack_require__(/*! ./util */ \"./node_modules/jsonld/lib/util.js\");\nconst {prependBase} = __webpack_require__(/*! ./url */ \"./node_modules/jsonld/lib/url.js\");\nconst JsonLdError = __webpack_require__(/*! ./JsonLdError */ \"./node_modules/jsonld/lib/JsonLdError.js\");\nconst ResolvedContext = __webpack_require__(/*! ./ResolvedContext */ \"./node_modules/jsonld/lib/ResolvedContext.js\");\n\nconst MAX_CONTEXT_URLS = 10;\n\nmodule.exports = class ContextResolver {\n  /**\n   * Creates a ContextResolver.\n   *\n   * @param sharedCache a shared LRU cache with `get` and `set` APIs.\n   */\n  constructor({sharedCache}) {\n    this.perOpCache = new Map();\n    this.sharedCache = sharedCache;\n  }\n\n  async resolve({\n    activeCtx, context, documentLoader, base, cycles = new Set()\n  }) {\n    // process `@context`\n    if(context && _isObject(context) && context['@context']) {\n      context = context['@context'];\n    }\n\n    // context is one or more contexts\n    context = _asArray(context);\n\n    // resolve each context in the array\n    const allResolved = [];\n    for(const ctx of context) {\n      if(_isString(ctx)) {\n        // see if `ctx` has been resolved before...\n        let resolved = this._get(ctx);\n        if(!resolved) {\n          // not resolved yet, resolve\n          resolved = await this._resolveRemoteContext(\n            {activeCtx, url: ctx, documentLoader, base, cycles});\n        }\n\n        // add to output and continue\n        if(_isArray(resolved)) {\n          allResolved.push(...resolved);\n        } else {\n          allResolved.push(resolved);\n        }\n        continue;\n      }\n      if(ctx === null) {\n        // handle `null` context, nothing to cache\n        allResolved.push(new ResolvedContext({document: null}));\n        continue;\n      }\n      if(!_isObject(ctx)) {\n        _throwInvalidLocalContext(context);\n      }\n      // context is an object, get/create `ResolvedContext` for it\n      const key = JSON.stringify(ctx);\n      let resolved = this._get(key);\n      if(!resolved) {\n        // create a new static `ResolvedContext` and cache it\n        resolved = new ResolvedContext({document: ctx});\n        this._cacheResolvedContext({key, resolved, tag: 'static'});\n      }\n      allResolved.push(resolved);\n    }\n\n    return allResolved;\n  }\n\n  _get(key) {\n    // get key from per operation cache; no `tag` is used with this cache so\n    // any retrieved context will always be the same during a single operation\n    let resolved = this.perOpCache.get(key);\n    if(!resolved) {\n      // see if the shared cache has a `static` entry for this URL\n      const tagMap = this.sharedCache.get(key);\n      if(tagMap) {\n        resolved = tagMap.get('static');\n        if(resolved) {\n          this.perOpCache.set(key, resolved);\n        }\n      }\n    }\n    return resolved;\n  }\n\n  _cacheResolvedContext({key, resolved, tag}) {\n    this.perOpCache.set(key, resolved);\n    if(tag !== undefined) {\n      let tagMap = this.sharedCache.get(key);\n      if(!tagMap) {\n        tagMap = new Map();\n        this.sharedCache.set(key, tagMap);\n      }\n      tagMap.set(tag, resolved);\n    }\n    return resolved;\n  }\n\n  async _resolveRemoteContext({activeCtx, url, documentLoader, base, cycles}) {\n    // resolve relative URL and fetch context\n    url = prependBase(base, url);\n    const {context, remoteDoc} = await this._fetchContext(\n      {activeCtx, url, documentLoader, cycles});\n\n    // update base according to remote document and resolve any relative URLs\n    base = remoteDoc.documentUrl || url;\n    _resolveContextUrls({context, base});\n\n    // resolve, cache, and return context\n    const resolved = await this.resolve(\n      {activeCtx, context, documentLoader, base, cycles});\n    this._cacheResolvedContext({key: url, resolved, tag: remoteDoc.tag});\n    return resolved;\n  }\n\n  async _fetchContext({activeCtx, url, documentLoader, cycles}) {\n    // check for max context URLs fetched during a resolve operation\n    if(cycles.size > MAX_CONTEXT_URLS) {\n      throw new JsonLdError(\n        'Maximum number of @context URLs exceeded.',\n        'jsonld.ContextUrlError',\n        {\n          code: activeCtx.processingMode === 'json-ld-1.0' ?\n            'loading remote context failed' :\n            'context overflow',\n          max: MAX_CONTEXT_URLS\n        });\n    }\n\n    // check for context URL cycle\n    // shortcut to avoid extra work that would eventually hit the max above\n    if(cycles.has(url)) {\n      throw new JsonLdError(\n        'Cyclical @context URLs detected.',\n        'jsonld.ContextUrlError',\n        {\n          code: activeCtx.processingMode === 'json-ld-1.0' ?\n            'recursive context inclusion' :\n            'context overflow',\n          url\n        });\n    }\n\n    // track cycles\n    cycles.add(url);\n\n    let context;\n    let remoteDoc;\n\n    try {\n      remoteDoc = await documentLoader(url);\n      context = remoteDoc.document || null;\n      // parse string context as JSON\n      if(_isString(context)) {\n        context = JSON.parse(context);\n      }\n    } catch(e) {\n      throw new JsonLdError(\n        'Dereferencing a URL did not result in a valid JSON-LD object. ' +\n        'Possible causes are an inaccessible URL perhaps due to ' +\n        'a same-origin policy (ensure the server uses CORS if you are ' +\n        'using client-side JavaScript), too many redirects, a ' +\n        'non-JSON response, or more than one HTTP Link Header was ' +\n        'provided for a remote context.',\n        'jsonld.InvalidUrl',\n        {code: 'loading remote context failed', url, cause: e});\n    }\n\n    // ensure ctx is an object\n    if(!_isObject(context)) {\n      throw new JsonLdError(\n        'Dereferencing a URL did not result in a JSON object. The ' +\n        'response was valid JSON, but it was not a JSON object.',\n        'jsonld.InvalidUrl', {code: 'invalid remote context', url});\n    }\n\n    // use empty context if no @context key is present\n    if(!('@context' in context)) {\n      context = {'@context': {}};\n    } else {\n      context = {'@context': context['@context']};\n    }\n\n    // append @context URL to context if given\n    if(remoteDoc.contextUrl) {\n      if(!_isArray(context['@context'])) {\n        context['@context'] = [context['@context']];\n      }\n      context['@context'].push(remoteDoc.contextUrl);\n    }\n\n    return {context, remoteDoc};\n  }\n};\n\nfunction _throwInvalidLocalContext(ctx) {\n  throw new JsonLdError(\n    'Invalid JSON-LD syntax; @context must be an object.',\n    'jsonld.SyntaxError', {\n      code: 'invalid local context', context: ctx\n    });\n}\n\n/**\n * Resolve all relative `@context` URLs in the given context by inline\n * replacing them with absolute URLs.\n *\n * @param context the context.\n * @param base the base IRI to use to resolve relative IRIs.\n */\nfunction _resolveContextUrls({context, base}) {\n  if(!context) {\n    return;\n  }\n\n  const ctx = context['@context'];\n\n  if(_isString(ctx)) {\n    context['@context'] = prependBase(base, ctx);\n    return;\n  }\n\n  if(_isArray(ctx)) {\n    for(let i = 0; i < ctx.length; ++i) {\n      const element = ctx[i];\n      if(_isString(element)) {\n        ctx[i] = prependBase(base, element);\n        continue;\n      }\n      if(_isObject(element)) {\n        _resolveContextUrls({context: {'@context': element}, base});\n      }\n    }\n    return;\n  }\n\n  if(!_isObject(ctx)) {\n    // no @context URLs can be found in non-object\n    return;\n  }\n\n  // ctx is an object, resolve any context URLs in terms\n  for(const term in ctx) {\n    _resolveContextUrls({context: ctx[term], base});\n  }\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/ContextResolver.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/JsonLdError.js":
/*!************************************************!*\
  !*** ./node_modules/jsonld/lib/JsonLdError.js ***!
  \************************************************/
/***/ ((module) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nmodule.exports = class JsonLdError extends Error {\n  /**\n   * Creates a JSON-LD Error.\n   *\n   * @param msg the error message.\n   * @param type the error type.\n   * @param details the error details.\n   */\n  constructor(\n    message = 'An unspecified JSON-LD error occurred.',\n    name = 'jsonld.Error',\n    details = {}) {\n    super(message);\n    this.name = name;\n    this.message = message;\n    this.details = details;\n  }\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/JsonLdError.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/JsonLdProcessor.js":
/*!****************************************************!*\
  !*** ./node_modules/jsonld/lib/JsonLdProcessor.js ***!
  \****************************************************/
/***/ ((module) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nmodule.exports = jsonld => {\n  class JsonLdProcessor {\n    toString() {\n      return '[object JsonLdProcessor]';\n    }\n  }\n  Object.defineProperty(JsonLdProcessor, 'prototype', {\n    writable: false,\n    enumerable: false\n  });\n  Object.defineProperty(JsonLdProcessor.prototype, 'constructor', {\n    writable: true,\n    enumerable: false,\n    configurable: true,\n    value: JsonLdProcessor\n  });\n\n  // The Web IDL test harness will check the number of parameters defined in\n  // the functions below. The number of parameters must exactly match the\n  // required (non-optional) parameters of the JsonLdProcessor interface as\n  // defined here:\n  // https://www.w3.org/TR/json-ld-api/#the-jsonldprocessor-interface\n\n  JsonLdProcessor.compact = function(input, ctx) {\n    if(arguments.length < 2) {\n      return Promise.reject(\n        new TypeError('Could not compact, too few arguments.'));\n    }\n    return jsonld.compact(input, ctx);\n  };\n  JsonLdProcessor.expand = function(input) {\n    if(arguments.length < 1) {\n      return Promise.reject(\n        new TypeError('Could not expand, too few arguments.'));\n    }\n    return jsonld.expand(input);\n  };\n  JsonLdProcessor.flatten = function(input) {\n    if(arguments.length < 1) {\n      return Promise.reject(\n        new TypeError('Could not flatten, too few arguments.'));\n    }\n    return jsonld.flatten(input);\n  };\n\n  return JsonLdProcessor;\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/JsonLdProcessor.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/NQuads.js":
/*!*******************************************!*\
  !*** ./node_modules/jsonld/lib/NQuads.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\n// TODO: move `NQuads` to its own package\nmodule.exports = __webpack_require__(/*! rdf-canonize */ \"./node_modules/jsonld/node_modules/rdf-canonize/index.js\").NQuads;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/NQuads.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/RequestQueue.js":
/*!*************************************************!*\
  !*** ./node_modules/jsonld/lib/RequestQueue.js ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("/*\n * Copyright (c) 2017-2019 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nmodule.exports = class RequestQueue {\n  /**\n   * Creates a simple queue for requesting documents.\n   */\n  constructor() {\n    this._requests = {};\n  }\n\n  wrapLoader(loader) {\n    const self = this;\n    self._loader = loader;\n    return function(/* url */) {\n      return self.add.apply(self, arguments);\n    };\n  }\n\n  async add(url) {\n    let promise = this._requests[url];\n    if(promise) {\n      // URL already queued, wait for it to load\n      return Promise.resolve(promise);\n    }\n\n    // queue URL and load it\n    promise = this._requests[url] = this._loader(url);\n\n    try {\n      return await promise;\n    } finally {\n      delete this._requests[url];\n    }\n  }\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/RequestQueue.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/ResolvedContext.js":
/*!****************************************************!*\
  !*** ./node_modules/jsonld/lib/ResolvedContext.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2019 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst LRU = __webpack_require__(/*! lru-cache */ \"./node_modules/lru-cache/index.js\");\n\nconst MAX_ACTIVE_CONTEXTS = 10;\n\nmodule.exports = class ResolvedContext {\n  /**\n   * Creates a ResolvedContext.\n   *\n   * @param document the context document.\n   */\n  constructor({document}) {\n    this.document = document;\n    // TODO: enable customization of processed context cache\n    // TODO: limit based on size of processed contexts vs. number of them\n    this.cache = new LRU({max: MAX_ACTIVE_CONTEXTS});\n  }\n\n  getProcessed(activeCtx) {\n    return this.cache.get(activeCtx);\n  }\n\n  setProcessed(activeCtx, processedCtx) {\n    this.cache.set(activeCtx, processedCtx);\n  }\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/ResolvedContext.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/compact.js":
/*!********************************************!*\
  !*** ./node_modules/jsonld/lib/compact.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst JsonLdError = __webpack_require__(/*! ./JsonLdError */ \"./node_modules/jsonld/lib/JsonLdError.js\");\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isString: _isString,\n  isUndefined: _isUndefined\n} = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\n\nconst {\n  isList: _isList,\n  isValue: _isValue,\n  isGraph: _isGraph,\n  isSimpleGraph: _isSimpleGraph,\n  isSubjectReference: _isSubjectReference\n} = __webpack_require__(/*! ./graphTypes */ \"./node_modules/jsonld/lib/graphTypes.js\");\n\nconst {\n  expandIri: _expandIri,\n  getContextValue: _getContextValue,\n  isKeyword: _isKeyword,\n  process: _processContext,\n  processingMode: _processingMode\n} = __webpack_require__(/*! ./context */ \"./node_modules/jsonld/lib/context.js\");\n\nconst {\n  removeBase: _removeBase,\n  prependBase: _prependBase\n} = __webpack_require__(/*! ./url */ \"./node_modules/jsonld/lib/url.js\");\n\nconst {\n  REGEX_KEYWORD,\n  addValue: _addValue,\n  asArray: _asArray,\n  compareShortestLeast: _compareShortestLeast\n} = __webpack_require__(/*! ./util */ \"./node_modules/jsonld/lib/util.js\");\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Recursively compacts an element using the given active context. All values\n * must be in expanded form before this method is called.\n *\n * @param activeCtx the active context to use.\n * @param activeProperty the compacted property associated with the element\n *          to compact, null for none.\n * @param element the element to compact.\n * @param options the compaction options.\n *\n * @return a promise that resolves to the compacted value.\n */\napi.compact = async ({\n  activeCtx,\n  activeProperty = null,\n  element,\n  options = {}\n}) => {\n  // recursively compact array\n  if(_isArray(element)) {\n    let rval = [];\n    for(let i = 0; i < element.length; ++i) {\n      const compacted = await api.compact({\n        activeCtx,\n        activeProperty,\n        element: element[i],\n        options\n      });\n      if(compacted === null) {\n        // FIXME: need event?\n        continue;\n      }\n      rval.push(compacted);\n    }\n    if(options.compactArrays && rval.length === 1) {\n      // use single element if no container is specified\n      const container = _getContextValue(\n        activeCtx, activeProperty, '@container') || [];\n      if(container.length === 0) {\n        rval = rval[0];\n      }\n    }\n    return rval;\n  }\n\n  // use any scoped context on activeProperty\n  const ctx = _getContextValue(activeCtx, activeProperty, '@context');\n  if(!_isUndefined(ctx)) {\n    activeCtx = await _processContext({\n      activeCtx,\n      localCtx: ctx,\n      propagate: true,\n      overrideProtected: true,\n      options\n    });\n  }\n\n  // recursively compact object\n  if(_isObject(element)) {\n    if(options.link && '@id' in element &&\n      options.link.hasOwnProperty(element['@id'])) {\n      // check for a linked element to reuse\n      const linked = options.link[element['@id']];\n      for(let i = 0; i < linked.length; ++i) {\n        if(linked[i].expanded === element) {\n          return linked[i].compacted;\n        }\n      }\n    }\n\n    // do value compaction on @values and subject references\n    if(_isValue(element) || _isSubjectReference(element)) {\n      const rval =\n        api.compactValue({activeCtx, activeProperty, value: element, options});\n      if(options.link && _isSubjectReference(element)) {\n        // store linked element\n        if(!(options.link.hasOwnProperty(element['@id']))) {\n          options.link[element['@id']] = [];\n        }\n        options.link[element['@id']].push({expanded: element, compacted: rval});\n      }\n      return rval;\n    }\n\n    // if expanded property is @list and we're contained within a list\n    // container, recursively compact this item to an array\n    if(_isList(element)) {\n      const container = _getContextValue(\n        activeCtx, activeProperty, '@container') || [];\n      if(container.includes('@list')) {\n        return api.compact({\n          activeCtx,\n          activeProperty,\n          element: element['@list'],\n          options\n        });\n      }\n    }\n\n    // FIXME: avoid misuse of active property as an expanded property?\n    const insideReverse = (activeProperty === '@reverse');\n\n    const rval = {};\n\n    // original context before applying property-scoped and local contexts\n    const inputCtx = activeCtx;\n\n    // revert to previous context, if there is one,\n    // and element is not a value object or a node reference\n    if(!_isValue(element) && !_isSubjectReference(element)) {\n      activeCtx = activeCtx.revertToPreviousContext();\n    }\n\n    // apply property-scoped context after reverting term-scoped context\n    const propertyScopedCtx =\n      _getContextValue(inputCtx, activeProperty, '@context');\n    if(!_isUndefined(propertyScopedCtx)) {\n      activeCtx = await _processContext({\n        activeCtx,\n        localCtx: propertyScopedCtx,\n        propagate: true,\n        overrideProtected: true,\n        options\n      });\n    }\n\n    if(options.link && '@id' in element) {\n      // store linked element\n      if(!options.link.hasOwnProperty(element['@id'])) {\n        options.link[element['@id']] = [];\n      }\n      options.link[element['@id']].push({expanded: element, compacted: rval});\n    }\n\n    // apply any context defined on an alias of @type\n    // if key is @type and any compacted value is a term having a local\n    // context, overlay that context\n    let types = element['@type'] || [];\n    if(types.length > 1) {\n      types = Array.from(types).sort();\n    }\n    // find all type-scoped contexts based on current context, prior to\n    // updating it\n    const typeContext = activeCtx;\n    for(const type of types) {\n      const compactedType = api.compactIri(\n        {activeCtx: typeContext, iri: type, relativeTo: {vocab: true}});\n\n      // Use any type-scoped context defined on this value\n      const ctx = _getContextValue(inputCtx, compactedType, '@context');\n      if(!_isUndefined(ctx)) {\n        activeCtx = await _processContext({\n          activeCtx,\n          localCtx: ctx,\n          options,\n          propagate: false\n        });\n      }\n    }\n\n    // process element keys in order\n    const keys = Object.keys(element).sort();\n    for(const expandedProperty of keys) {\n      const expandedValue = element[expandedProperty];\n\n      // compact @id\n      if(expandedProperty === '@id') {\n        let compactedValue = _asArray(expandedValue).map(\n          expandedIri => api.compactIri({\n            activeCtx,\n            iri: expandedIri,\n            relativeTo: {vocab: false},\n            base: options.base\n          }));\n        if(compactedValue.length === 1) {\n          compactedValue = compactedValue[0];\n        }\n\n        // use keyword alias and add value\n        const alias = api.compactIri(\n          {activeCtx, iri: '@id', relativeTo: {vocab: true}});\n\n        rval[alias] = compactedValue;\n        continue;\n      }\n\n      // compact @type(s)\n      if(expandedProperty === '@type') {\n        // resolve type values against previous context\n        let compactedValue = _asArray(expandedValue).map(\n          expandedIri => api.compactIri({\n            activeCtx: inputCtx,\n            iri: expandedIri,\n            relativeTo: {vocab: true}\n          }));\n        if(compactedValue.length === 1) {\n          compactedValue = compactedValue[0];\n        }\n\n        // use keyword alias and add value\n        const alias = api.compactIri(\n          {activeCtx, iri: '@type', relativeTo: {vocab: true}});\n        const container = _getContextValue(\n          activeCtx, alias, '@container') || [];\n\n        // treat as array for @type if @container includes @set\n        const typeAsSet =\n          container.includes('@set') &&\n          _processingMode(activeCtx, 1.1);\n        const isArray =\n          typeAsSet || (_isArray(compactedValue) && expandedValue.length === 0);\n        _addValue(rval, alias, compactedValue, {propertyIsArray: isArray});\n        continue;\n      }\n\n      // handle @reverse\n      if(expandedProperty === '@reverse') {\n        // recursively compact expanded value\n        const compactedValue = await api.compact({\n          activeCtx,\n          activeProperty: '@reverse',\n          element: expandedValue,\n          options\n        });\n\n        // handle double-reversed properties\n        for(const compactedProperty in compactedValue) {\n          if(activeCtx.mappings.has(compactedProperty) &&\n            activeCtx.mappings.get(compactedProperty).reverse) {\n            const value = compactedValue[compactedProperty];\n            const container = _getContextValue(\n              activeCtx, compactedProperty, '@container') || [];\n            const useArray = (\n              container.includes('@set') || !options.compactArrays);\n            _addValue(\n              rval, compactedProperty, value, {propertyIsArray: useArray});\n            delete compactedValue[compactedProperty];\n          }\n        }\n\n        if(Object.keys(compactedValue).length > 0) {\n          // use keyword alias and add value\n          const alias = api.compactIri({\n            activeCtx,\n            iri: expandedProperty,\n            relativeTo: {vocab: true}\n          });\n          _addValue(rval, alias, compactedValue);\n        }\n\n        continue;\n      }\n\n      if(expandedProperty === '@preserve') {\n        // compact using activeProperty\n        const compactedValue = await api.compact({\n          activeCtx,\n          activeProperty,\n          element: expandedValue,\n          options\n        });\n\n        if(!(_isArray(compactedValue) && compactedValue.length === 0)) {\n          _addValue(rval, expandedProperty, compactedValue);\n        }\n        continue;\n      }\n\n      // handle @index property\n      if(expandedProperty === '@index') {\n        // drop @index if inside an @index container\n        const container = _getContextValue(\n          activeCtx, activeProperty, '@container') || [];\n        if(container.includes('@index')) {\n          continue;\n        }\n\n        // use keyword alias and add value\n        const alias = api.compactIri({\n          activeCtx,\n          iri: expandedProperty,\n          relativeTo: {vocab: true}\n        });\n        _addValue(rval, alias, expandedValue);\n        continue;\n      }\n\n      // skip array processing for keywords that aren't\n      // @graph, @list, or @included\n      if(expandedProperty !== '@graph' && expandedProperty !== '@list' &&\n        expandedProperty !== '@included' &&\n        _isKeyword(expandedProperty)) {\n        // use keyword alias and add value as is\n        const alias = api.compactIri({\n          activeCtx,\n          iri: expandedProperty,\n          relativeTo: {vocab: true}\n        });\n        _addValue(rval, alias, expandedValue);\n        continue;\n      }\n\n      // Note: expanded value must be an array due to expansion algorithm.\n      if(!_isArray(expandedValue)) {\n        throw new JsonLdError(\n          'JSON-LD expansion error; expanded value must be an array.',\n          'jsonld.SyntaxError');\n      }\n\n      // preserve empty arrays\n      if(expandedValue.length === 0) {\n        const itemActiveProperty = api.compactIri({\n          activeCtx,\n          iri: expandedProperty,\n          value: expandedValue,\n          relativeTo: {vocab: true},\n          reverse: insideReverse\n        });\n        const nestProperty = activeCtx.mappings.has(itemActiveProperty) ?\n          activeCtx.mappings.get(itemActiveProperty)['@nest'] : null;\n        let nestResult = rval;\n        if(nestProperty) {\n          _checkNestProperty(activeCtx, nestProperty, options);\n          if(!_isObject(rval[nestProperty])) {\n            rval[nestProperty] = {};\n          }\n          nestResult = rval[nestProperty];\n        }\n        _addValue(\n          nestResult, itemActiveProperty, expandedValue, {\n            propertyIsArray: true\n          });\n      }\n\n      // recusively process array values\n      for(const expandedItem of expandedValue) {\n        // compact property and get container type\n        const itemActiveProperty = api.compactIri({\n          activeCtx,\n          iri: expandedProperty,\n          value: expandedItem,\n          relativeTo: {vocab: true},\n          reverse: insideReverse\n        });\n\n        // if itemActiveProperty is a @nest property, add values to nestResult,\n        // otherwise rval\n        const nestProperty = activeCtx.mappings.has(itemActiveProperty) ?\n          activeCtx.mappings.get(itemActiveProperty)['@nest'] : null;\n        let nestResult = rval;\n        if(nestProperty) {\n          _checkNestProperty(activeCtx, nestProperty, options);\n          if(!_isObject(rval[nestProperty])) {\n            rval[nestProperty] = {};\n          }\n          nestResult = rval[nestProperty];\n        }\n\n        const container = _getContextValue(\n          activeCtx, itemActiveProperty, '@container') || [];\n\n        // get simple @graph or @list value if appropriate\n        const isGraph = _isGraph(expandedItem);\n        const isList = _isList(expandedItem);\n        let inner;\n        if(isList) {\n          inner = expandedItem['@list'];\n        } else if(isGraph) {\n          inner = expandedItem['@graph'];\n        }\n\n        // recursively compact expanded item\n        let compactedItem = await api.compact({\n          activeCtx,\n          activeProperty: itemActiveProperty,\n          element: (isList || isGraph) ? inner : expandedItem,\n          options\n        });\n\n        // handle @list\n        if(isList) {\n          // ensure @list value is an array\n          if(!_isArray(compactedItem)) {\n            compactedItem = [compactedItem];\n          }\n\n          if(!container.includes('@list')) {\n            // wrap using @list alias\n            compactedItem = {\n              [api.compactIri({\n                activeCtx,\n                iri: '@list',\n                relativeTo: {vocab: true}\n              })]: compactedItem\n            };\n\n            // include @index from expanded @list, if any\n            if('@index' in expandedItem) {\n              compactedItem[api.compactIri({\n                activeCtx,\n                iri: '@index',\n                relativeTo: {vocab: true}\n              })] = expandedItem['@index'];\n            }\n          } else {\n            _addValue(nestResult, itemActiveProperty, compactedItem, {\n              valueIsArray: true,\n              allowDuplicate: true\n            });\n            continue;\n          }\n        }\n\n        // Graph object compaction cases\n        if(isGraph) {\n          if(container.includes('@graph') && (container.includes('@id') ||\n            container.includes('@index') && _isSimpleGraph(expandedItem))) {\n            // get or create the map object\n            let mapObject;\n            if(nestResult.hasOwnProperty(itemActiveProperty)) {\n              mapObject = nestResult[itemActiveProperty];\n            } else {\n              nestResult[itemActiveProperty] = mapObject = {};\n            }\n\n            // index on @id or @index or alias of @none\n            const key = (container.includes('@id') ?\n              expandedItem['@id'] : expandedItem['@index']) ||\n              api.compactIri({activeCtx, iri: '@none',\n                relativeTo: {vocab: true}});\n            // add compactedItem to map, using value of `@id` or a new blank\n            // node identifier\n\n            _addValue(\n              mapObject, key, compactedItem, {\n                propertyIsArray:\n                  (!options.compactArrays || container.includes('@set'))\n              });\n          } else if(container.includes('@graph') &&\n            _isSimpleGraph(expandedItem)) {\n            // container includes @graph but not @id or @index and value is a\n            // simple graph object add compact value\n            // if compactedItem contains multiple values, it is wrapped in\n            // `@included`\n            if(_isArray(compactedItem) && compactedItem.length > 1) {\n              compactedItem = {'@included': compactedItem};\n            }\n            _addValue(\n              nestResult, itemActiveProperty, compactedItem, {\n                propertyIsArray:\n                  (!options.compactArrays || container.includes('@set'))\n              });\n          } else {\n            // wrap using @graph alias, remove array if only one item and\n            // compactArrays not set\n            if(_isArray(compactedItem) && compactedItem.length === 1 &&\n              options.compactArrays) {\n              compactedItem = compactedItem[0];\n            }\n            compactedItem = {\n              [api.compactIri({\n                activeCtx,\n                iri: '@graph',\n                relativeTo: {vocab: true}\n              })]: compactedItem\n            };\n\n            // include @id from expanded graph, if any\n            if('@id' in expandedItem) {\n              compactedItem[api.compactIri({\n                activeCtx,\n                iri: '@id',\n                relativeTo: {vocab: true}\n              })] = expandedItem['@id'];\n            }\n\n            // include @index from expanded graph, if any\n            if('@index' in expandedItem) {\n              compactedItem[api.compactIri({\n                activeCtx,\n                iri: '@index',\n                relativeTo: {vocab: true}\n              })] = expandedItem['@index'];\n            }\n            _addValue(\n              nestResult, itemActiveProperty, compactedItem, {\n                propertyIsArray:\n                  (!options.compactArrays || container.includes('@set'))\n              });\n          }\n        } else if(container.includes('@language') ||\n          container.includes('@index') || container.includes('@id') ||\n          container.includes('@type')) {\n          // handle language and index maps\n          // get or create the map object\n          let mapObject;\n          if(nestResult.hasOwnProperty(itemActiveProperty)) {\n            mapObject = nestResult[itemActiveProperty];\n          } else {\n            nestResult[itemActiveProperty] = mapObject = {};\n          }\n\n          let key;\n          if(container.includes('@language')) {\n            // if container is a language map, simplify compacted value to\n            // a simple string\n            if(_isValue(compactedItem)) {\n              compactedItem = compactedItem['@value'];\n            }\n            key = expandedItem['@language'];\n          } else if(container.includes('@index')) {\n            const indexKey = _getContextValue(\n              activeCtx, itemActiveProperty, '@index') || '@index';\n            const containerKey = api.compactIri(\n              {activeCtx, iri: indexKey, relativeTo: {vocab: true}});\n            if(indexKey === '@index') {\n              key = expandedItem['@index'];\n              delete compactedItem[containerKey];\n            } else {\n              let others;\n              [key, ...others] = _asArray(compactedItem[indexKey] || []);\n              if(!_isString(key)) {\n                // Will use @none if it isn't a string.\n                key = null;\n              } else {\n                switch(others.length) {\n                  case 0:\n                    delete compactedItem[indexKey];\n                    break;\n                  case 1:\n                    compactedItem[indexKey] = others[0];\n                    break;\n                  default:\n                    compactedItem[indexKey] = others;\n                    break;\n                }\n              }\n            }\n          } else if(container.includes('@id')) {\n            const idKey = api.compactIri({activeCtx, iri: '@id',\n              relativeTo: {vocab: true}});\n            key = compactedItem[idKey];\n            delete compactedItem[idKey];\n          } else if(container.includes('@type')) {\n            const typeKey = api.compactIri({\n              activeCtx,\n              iri: '@type',\n              relativeTo: {vocab: true}\n            });\n            let types;\n            [key, ...types] = _asArray(compactedItem[typeKey] || []);\n            switch(types.length) {\n              case 0:\n                delete compactedItem[typeKey];\n                break;\n              case 1:\n                compactedItem[typeKey] = types[0];\n                break;\n              default:\n                compactedItem[typeKey] = types;\n                break;\n            }\n\n            // If compactedItem contains a single entry\n            // whose key maps to @id, recompact without @type\n            if(Object.keys(compactedItem).length === 1 &&\n              '@id' in expandedItem) {\n              compactedItem = await api.compact({\n                activeCtx,\n                activeProperty: itemActiveProperty,\n                element: {'@id': expandedItem['@id']},\n                options\n              });\n            }\n          }\n\n          // if compacting this value which has no key, index on @none\n          if(!key) {\n            key = api.compactIri({activeCtx, iri: '@none',\n              relativeTo: {vocab: true}});\n          }\n          // add compact value to map object using key from expanded value\n          // based on the container type\n          _addValue(\n            mapObject, key, compactedItem, {\n              propertyIsArray: container.includes('@set')\n            });\n        } else {\n          // use an array if: compactArrays flag is false,\n          // @container is @set or @list , value is an empty\n          // array, or key is @graph\n          const isArray = (!options.compactArrays ||\n            container.includes('@set') || container.includes('@list') ||\n            (_isArray(compactedItem) && compactedItem.length === 0) ||\n            expandedProperty === '@list' || expandedProperty === '@graph');\n\n          // add compact value\n          _addValue(\n            nestResult, itemActiveProperty, compactedItem,\n            {propertyIsArray: isArray});\n        }\n      }\n    }\n\n    return rval;\n  }\n\n  // only primitives remain which are already compact\n  return element;\n};\n\n/**\n * Compacts an IRI or keyword into a term or prefix if it can be. If the\n * IRI has an associated value it may be passed.\n *\n * @param activeCtx the active context to use.\n * @param iri the IRI to compact.\n * @param value the value to check or null.\n * @param relativeTo options for how to compact IRIs:\n *          vocab: true to split after @vocab, false not to.\n * @param reverse true if a reverse property is being compacted, false if not.\n * @param base the absolute URL to use for compacting document-relative IRIs.\n *\n * @return the compacted term, prefix, keyword alias, or the original IRI.\n */\napi.compactIri = ({\n  activeCtx,\n  iri,\n  value = null,\n  relativeTo = {vocab: false},\n  reverse = false,\n  base = null\n}) => {\n  // can't compact null\n  if(iri === null) {\n    return iri;\n  }\n\n  // if context is from a property term scoped context composed with a\n  // type-scoped context, then use the previous context instead\n  if(activeCtx.isPropertyTermScoped && activeCtx.previousContext) {\n    activeCtx = activeCtx.previousContext;\n  }\n\n  const inverseCtx = activeCtx.getInverse();\n\n  // if term is a keyword, it may be compacted to a simple alias\n  if(_isKeyword(iri) &&\n    iri in inverseCtx &&\n    '@none' in inverseCtx[iri] &&\n    '@type' in inverseCtx[iri]['@none'] &&\n    '@none' in inverseCtx[iri]['@none']['@type']) {\n    return inverseCtx[iri]['@none']['@type']['@none'];\n  }\n\n  // use inverse context to pick a term if iri is relative to vocab\n  if(relativeTo.vocab && iri in inverseCtx) {\n    const defaultLanguage = activeCtx['@language'] || '@none';\n\n    // prefer @index if available in value\n    const containers = [];\n    if(_isObject(value) && '@index' in value && !('@graph' in value)) {\n      containers.push('@index', '@index@set');\n    }\n\n    // if value is a preserve object, use its value\n    if(_isObject(value) && '@preserve' in value) {\n      value = value['@preserve'][0];\n    }\n\n    // prefer most specific container including @graph, prefering @set\n    // variations\n    if(_isGraph(value)) {\n      // favor indexmap if the graph is indexed\n      if('@index' in value) {\n        containers.push(\n          '@graph@index', '@graph@index@set', '@index', '@index@set');\n      }\n      // favor idmap if the graph is has an @id\n      if('@id' in value) {\n        containers.push(\n          '@graph@id', '@graph@id@set');\n      }\n      containers.push('@graph', '@graph@set', '@set');\n      // allow indexmap if the graph is not indexed\n      if(!('@index' in value)) {\n        containers.push(\n          '@graph@index', '@graph@index@set', '@index', '@index@set');\n      }\n      // allow idmap if the graph does not have an @id\n      if(!('@id' in value)) {\n        containers.push('@graph@id', '@graph@id@set');\n      }\n    } else if(_isObject(value) && !_isValue(value)) {\n      containers.push('@id', '@id@set', '@type', '@set@type');\n    }\n\n    // defaults for term selection based on type/language\n    let typeOrLanguage = '@language';\n    let typeOrLanguageValue = '@null';\n\n    if(reverse) {\n      typeOrLanguage = '@type';\n      typeOrLanguageValue = '@reverse';\n      containers.push('@set');\n    } else if(_isList(value)) {\n      // choose the most specific term that works for all elements in @list\n      // only select @list containers if @index is NOT in value\n      if(!('@index' in value)) {\n        containers.push('@list');\n      }\n      const list = value['@list'];\n      if(list.length === 0) {\n        // any empty list can be matched against any term that uses the\n        // @list container regardless of @type or @language\n        typeOrLanguage = '@any';\n        typeOrLanguageValue = '@none';\n      } else {\n        let commonLanguage = (list.length === 0) ? defaultLanguage : null;\n        let commonType = null;\n        for(let i = 0; i < list.length; ++i) {\n          const item = list[i];\n          let itemLanguage = '@none';\n          let itemType = '@none';\n          if(_isValue(item)) {\n            if('@direction' in item) {\n              const lang = (item['@language'] || '').toLowerCase();\n              const dir = item['@direction'];\n              itemLanguage = `${lang}_${dir}`;\n            } else if('@language' in item) {\n              itemLanguage = item['@language'].toLowerCase();\n            } else if('@type' in item) {\n              itemType = item['@type'];\n            } else {\n              // plain literal\n              itemLanguage = '@null';\n            }\n          } else {\n            itemType = '@id';\n          }\n          if(commonLanguage === null) {\n            commonLanguage = itemLanguage;\n          } else if(itemLanguage !== commonLanguage && _isValue(item)) {\n            commonLanguage = '@none';\n          }\n          if(commonType === null) {\n            commonType = itemType;\n          } else if(itemType !== commonType) {\n            commonType = '@none';\n          }\n          // there are different languages and types in the list, so choose\n          // the most generic term, no need to keep iterating the list\n          if(commonLanguage === '@none' && commonType === '@none') {\n            break;\n          }\n        }\n        commonLanguage = commonLanguage || '@none';\n        commonType = commonType || '@none';\n        if(commonType !== '@none') {\n          typeOrLanguage = '@type';\n          typeOrLanguageValue = commonType;\n        } else {\n          typeOrLanguageValue = commonLanguage;\n        }\n      }\n    } else {\n      if(_isValue(value)) {\n        if('@language' in value && !('@index' in value)) {\n          containers.push('@language', '@language@set');\n          typeOrLanguageValue = value['@language'];\n          const dir = value['@direction'];\n          if(dir) {\n            typeOrLanguageValue = `${typeOrLanguageValue}_${dir}`;\n          }\n        } else if('@direction' in value && !('@index' in value)) {\n          typeOrLanguageValue = `_${value['@direction']}`;\n        } else if('@type' in value) {\n          typeOrLanguage = '@type';\n          typeOrLanguageValue = value['@type'];\n        }\n      } else {\n        typeOrLanguage = '@type';\n        typeOrLanguageValue = '@id';\n      }\n      containers.push('@set');\n    }\n\n    // do term selection\n    containers.push('@none');\n\n    // an index map can be used to index values using @none, so add as a low\n    // priority\n    if(_isObject(value) && !('@index' in value)) {\n      // allow indexing even if no @index present\n      containers.push('@index', '@index@set');\n    }\n\n    // values without type or language can use @language map\n    if(_isValue(value) && Object.keys(value).length === 1) {\n      // allow indexing even if no @index present\n      containers.push('@language', '@language@set');\n    }\n\n    const term = _selectTerm(\n      activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue);\n    if(term !== null) {\n      return term;\n    }\n  }\n\n  // no term match, use @vocab if available\n  if(relativeTo.vocab) {\n    if('@vocab' in activeCtx) {\n      // determine if vocab is a prefix of the iri\n      const vocab = activeCtx['@vocab'];\n      if(iri.indexOf(vocab) === 0 && iri !== vocab) {\n        // use suffix as relative iri if it is not a term in the active context\n        const suffix = iri.substr(vocab.length);\n        if(!activeCtx.mappings.has(suffix)) {\n          return suffix;\n        }\n      }\n    }\n  }\n\n  // no term or @vocab match, check for possible CURIEs\n  let choice = null;\n  // TODO: make FastCurieMap a class with a method to do this lookup\n  const partialMatches = [];\n  let iriMap = activeCtx.fastCurieMap;\n  // check for partial matches of against `iri`, which means look until\n  // iri.length - 1, not full length\n  const maxPartialLength = iri.length - 1;\n  for(let i = 0; i < maxPartialLength && iri[i] in iriMap; ++i) {\n    iriMap = iriMap[iri[i]];\n    if('' in iriMap) {\n      partialMatches.push(iriMap[''][0]);\n    }\n  }\n  // check partial matches in reverse order to prefer longest ones first\n  for(let i = partialMatches.length - 1; i >= 0; --i) {\n    const entry = partialMatches[i];\n    const terms = entry.terms;\n    for(const term of terms) {\n      // a CURIE is usable if:\n      // 1. it has no mapping, OR\n      // 2. value is null, which means we're not compacting an @value, AND\n      //   the mapping matches the IRI\n      const curie = term + ':' + iri.substr(entry.iri.length);\n      const isUsableCurie = (activeCtx.mappings.get(term)._prefix &&\n        (!activeCtx.mappings.has(curie) ||\n        (value === null && activeCtx.mappings.get(curie)['@id'] === iri)));\n\n      // select curie if it is shorter or the same length but lexicographically\n      // less than the current choice\n      if(isUsableCurie && (choice === null ||\n        _compareShortestLeast(curie, choice) < 0)) {\n        choice = curie;\n      }\n    }\n  }\n\n  // return chosen curie\n  if(choice !== null) {\n    return choice;\n  }\n\n  // If iri could be confused with a compact IRI using a term in this context,\n  // signal an error\n  for(const [term, td] of activeCtx.mappings) {\n    if(td && td._prefix && iri.startsWith(term + ':')) {\n      throw new JsonLdError(\n        `Absolute IRI \"${iri}\" confused with prefix \"${term}\".`,\n        'jsonld.SyntaxError',\n        {code: 'IRI confused with prefix', context: activeCtx});\n    }\n  }\n\n  // compact IRI relative to base\n  if(!relativeTo.vocab) {\n    if('@base' in activeCtx) {\n      if(!activeCtx['@base']) {\n        // The None case preserves rval as potentially relative\n        return iri;\n      } else {\n        const _iri = _removeBase(_prependBase(base, activeCtx['@base']), iri);\n        return REGEX_KEYWORD.test(_iri) ? `./${_iri}` : _iri;\n      }\n    } else {\n      return _removeBase(base, iri);\n    }\n  }\n\n  // return IRI as is\n  return iri;\n};\n\n/**\n * Performs value compaction on an object with '@value' or '@id' as the only\n * property.\n *\n * @param activeCtx the active context.\n * @param activeProperty the active property that points to the value.\n * @param value the value to compact.\n * @param {Object} [options] - processing options.\n *\n * @return the compaction result.\n */\napi.compactValue = ({activeCtx, activeProperty, value, options}) => {\n  // value is a @value\n  if(_isValue(value)) {\n    // get context rules\n    const type = _getContextValue(activeCtx, activeProperty, '@type');\n    const language = _getContextValue(activeCtx, activeProperty, '@language');\n    const direction = _getContextValue(activeCtx, activeProperty, '@direction');\n    const container =\n      _getContextValue(activeCtx, activeProperty, '@container') || [];\n\n    // whether or not the value has an @index that must be preserved\n    const preserveIndex = '@index' in value && !container.includes('@index');\n\n    // if there's no @index to preserve ...\n    if(!preserveIndex && type !== '@none') {\n      // matching @type or @language specified in context, compact value\n      if(value['@type'] === type) {\n        return value['@value'];\n      }\n      if('@language' in value && value['@language'] === language &&\n         '@direction' in value && value['@direction'] === direction) {\n        return value['@value'];\n      }\n      if('@language' in value && value['@language'] === language) {\n        return value['@value'];\n      }\n      if('@direction' in value && value['@direction'] === direction) {\n        return value['@value'];\n      }\n    }\n\n    // return just the value of @value if all are true:\n    // 1. @value is the only key or @index isn't being preserved\n    // 2. there is no default language or @value is not a string or\n    //   the key has a mapping with a null @language\n    const keyCount = Object.keys(value).length;\n    const isValueOnlyKey = (keyCount === 1 ||\n      (keyCount === 2 && '@index' in value && !preserveIndex));\n    const hasDefaultLanguage = ('@language' in activeCtx);\n    const isValueString = _isString(value['@value']);\n    const hasNullMapping = (activeCtx.mappings.has(activeProperty) &&\n      activeCtx.mappings.get(activeProperty)['@language'] === null);\n    if(isValueOnlyKey &&\n      type !== '@none' &&\n      (!hasDefaultLanguage || !isValueString || hasNullMapping)) {\n      return value['@value'];\n    }\n\n    const rval = {};\n\n    // preserve @index\n    if(preserveIndex) {\n      rval[api.compactIri({\n        activeCtx,\n        iri: '@index',\n        relativeTo: {vocab: true}\n      })] = value['@index'];\n    }\n\n    if('@type' in value) {\n      // compact @type IRI\n      rval[api.compactIri({\n        activeCtx,\n        iri: '@type',\n        relativeTo: {vocab: true}\n      })] = api.compactIri(\n        {activeCtx, iri: value['@type'], relativeTo: {vocab: true}});\n    } else if('@language' in value) {\n      // alias @language\n      rval[api.compactIri({\n        activeCtx,\n        iri: '@language',\n        relativeTo: {vocab: true}\n      })] = value['@language'];\n    }\n\n    if('@direction' in value) {\n      // alias @direction\n      rval[api.compactIri({\n        activeCtx,\n        iri: '@direction',\n        relativeTo: {vocab: true}\n      })] = value['@direction'];\n    }\n\n    // alias @value\n    rval[api.compactIri({\n      activeCtx,\n      iri: '@value',\n      relativeTo: {vocab: true}\n    })] = value['@value'];\n\n    return rval;\n  }\n\n  // value is a subject reference\n  const expandedProperty = _expandIri(activeCtx, activeProperty, {vocab: true},\n    options);\n  const type = _getContextValue(activeCtx, activeProperty, '@type');\n  const compacted = api.compactIri({\n    activeCtx,\n    iri: value['@id'],\n    relativeTo: {vocab: type === '@vocab'},\n    base: options.base});\n\n  // compact to scalar\n  if(type === '@id' || type === '@vocab' || expandedProperty === '@graph') {\n    return compacted;\n  }\n\n  return {\n    [api.compactIri({\n      activeCtx,\n      iri: '@id',\n      relativeTo: {vocab: true}\n    })]: compacted\n  };\n};\n\n/**\n * Picks the preferred compaction term from the given inverse context entry.\n *\n * @param activeCtx the active context.\n * @param iri the IRI to pick the term for.\n * @param value the value to pick the term for.\n * @param containers the preferred containers.\n * @param typeOrLanguage either '@type' or '@language'.\n * @param typeOrLanguageValue the preferred value for '@type' or '@language'.\n *\n * @return the preferred term.\n */\nfunction _selectTerm(\n  activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue) {\n  if(typeOrLanguageValue === null) {\n    typeOrLanguageValue = '@null';\n  }\n\n  // preferences for the value of @type or @language\n  const prefs = [];\n\n  // determine prefs for @id based on whether or not value compacts to a term\n  if((typeOrLanguageValue === '@id' || typeOrLanguageValue === '@reverse') &&\n    _isObject(value) && '@id' in value) {\n    // prefer @reverse first\n    if(typeOrLanguageValue === '@reverse') {\n      prefs.push('@reverse');\n    }\n    // try to compact value to a term\n    const term = api.compactIri(\n      {activeCtx, iri: value['@id'], relativeTo: {vocab: true}});\n    if(activeCtx.mappings.has(term) &&\n      activeCtx.mappings.get(term) &&\n      activeCtx.mappings.get(term)['@id'] === value['@id']) {\n      // prefer @vocab\n      prefs.push.apply(prefs, ['@vocab', '@id']);\n    } else {\n      // prefer @id\n      prefs.push.apply(prefs, ['@id', '@vocab']);\n    }\n  } else {\n    prefs.push(typeOrLanguageValue);\n\n    // consider direction only\n    const langDir = prefs.find(el => el.includes('_'));\n    if(langDir) {\n      // consider _dir portion\n      prefs.push(langDir.replace(/^[^_]+_/, '_'));\n    }\n  }\n  prefs.push('@none');\n\n  const containerMap = activeCtx.inverse[iri];\n  for(const container of containers) {\n    // if container not available in the map, continue\n    if(!(container in containerMap)) {\n      continue;\n    }\n\n    const typeOrLanguageValueMap = containerMap[container][typeOrLanguage];\n    for(const pref of prefs) {\n      // if type/language option not available in the map, continue\n      if(!(pref in typeOrLanguageValueMap)) {\n        continue;\n      }\n\n      // select term\n      return typeOrLanguageValueMap[pref];\n    }\n  }\n\n  return null;\n}\n\n/**\n * The value of `@nest` in the term definition must either be `@nest`, or a term\n * which resolves to `@nest`.\n *\n * @param activeCtx the active context.\n * @param nestProperty a term in the active context or `@nest`.\n * @param {Object} [options] - processing options.\n */\nfunction _checkNestProperty(activeCtx, nestProperty, options) {\n  if(_expandIri(activeCtx, nestProperty, {vocab: true}, options) !== '@nest') {\n    throw new JsonLdError(\n      'JSON-LD compact error; nested property must have an @nest value ' +\n      'resolving to @nest.',\n      'jsonld.SyntaxError', {code: 'invalid @nest value'});\n  }\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/compact.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/constants.js":
/*!**********************************************!*\
  !*** ./node_modules/jsonld/lib/constants.js ***!
  \**********************************************/
/***/ ((module) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\nconst XSD = 'http://www.w3.org/2001/XMLSchema#';\n\nmodule.exports = {\n  // TODO: Deprecated and will be removed later. Use LINK_HEADER_CONTEXT.\n  LINK_HEADER_REL: 'http://www.w3.org/ns/json-ld#context',\n\n  LINK_HEADER_CONTEXT: 'http://www.w3.org/ns/json-ld#context',\n\n  RDF,\n  RDF_LIST: RDF + 'List',\n  RDF_FIRST: RDF + 'first',\n  RDF_REST: RDF + 'rest',\n  RDF_NIL: RDF + 'nil',\n  RDF_TYPE: RDF + 'type',\n  RDF_PLAIN_LITERAL: RDF + 'PlainLiteral',\n  RDF_XML_LITERAL: RDF + 'XMLLiteral',\n  RDF_JSON_LITERAL: RDF + 'JSON',\n  RDF_OBJECT: RDF + 'object',\n  RDF_LANGSTRING: RDF + 'langString',\n\n  XSD,\n  XSD_BOOLEAN: XSD + 'boolean',\n  XSD_DOUBLE: XSD + 'double',\n  XSD_INTEGER: XSD + 'integer',\n  XSD_STRING: XSD + 'string',\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/constants.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/context.js":
/*!********************************************!*\
  !*** ./node_modules/jsonld/lib/context.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017-2019 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst util = __webpack_require__(/*! ./util */ \"./node_modules/jsonld/lib/util.js\");\nconst JsonLdError = __webpack_require__(/*! ./JsonLdError */ \"./node_modules/jsonld/lib/JsonLdError.js\");\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isString: _isString,\n  isUndefined: _isUndefined\n} = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\n\nconst {\n  isAbsolute: _isAbsoluteIri,\n  isRelative: _isRelativeIri,\n  prependBase\n} = __webpack_require__(/*! ./url */ \"./node_modules/jsonld/lib/url.js\");\n\nconst {\n  handleEvent: _handleEvent\n} = __webpack_require__(/*! ./events */ \"./node_modules/jsonld/lib/events.js\");\n\nconst {\n  REGEX_BCP47,\n  REGEX_KEYWORD,\n  asArray: _asArray,\n  compareShortestLeast: _compareShortestLeast\n} = __webpack_require__(/*! ./util */ \"./node_modules/jsonld/lib/util.js\");\n\nconst INITIAL_CONTEXT_CACHE = new Map();\nconst INITIAL_CONTEXT_CACHE_MAX_SIZE = 10000;\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Processes a local context and returns a new active context.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context to process.\n * @param options the context processing options.\n * @param propagate `true` if `false`, retains any previously defined term,\n *   which can be rolled back when the descending into a new node object.\n * @param overrideProtected `false` allows protected terms to be modified.\n *\n * @return a Promise that resolves to the new active context.\n */\napi.process = async ({\n  activeCtx, localCtx, options,\n  propagate = true,\n  overrideProtected = false,\n  cycles = new Set()\n}) => {\n  // normalize local context to an array of @context objects\n  if(_isObject(localCtx) && '@context' in localCtx &&\n    _isArray(localCtx['@context'])) {\n    localCtx = localCtx['@context'];\n  }\n  const ctxs = _asArray(localCtx);\n\n  // no contexts in array, return current active context w/o changes\n  if(ctxs.length === 0) {\n    return activeCtx;\n  }\n\n  // event handler for capturing events to replay when using a cached context\n  const events = [];\n  const eventCaptureHandler = [\n    ({event, next}) => {\n      events.push(event);\n      next();\n    }\n  ];\n  // chain to original handler\n  if(options.eventHandler) {\n    eventCaptureHandler.push(options.eventHandler);\n  }\n  // store original options to use when replaying events\n  const originalOptions = options;\n  // shallow clone options with event capture handler\n  options = {...options, eventHandler: eventCaptureHandler};\n\n  // resolve contexts\n  const resolved = await options.contextResolver.resolve({\n    activeCtx,\n    context: localCtx,\n    documentLoader: options.documentLoader,\n    base: options.base\n  });\n\n  // override propagate if first resolved context has `@propagate`\n  if(_isObject(resolved[0].document) &&\n    typeof resolved[0].document['@propagate'] === 'boolean') {\n    // retrieve early, error checking done later\n    propagate = resolved[0].document['@propagate'];\n  }\n\n  // process each context in order, update active context\n  // on each iteration to ensure proper caching\n  let rval = activeCtx;\n\n  // track the previous context\n  // if not propagating, make sure rval has a previous context\n  if(!propagate && !rval.previousContext) {\n    // clone `rval` context before updating\n    rval = rval.clone();\n    rval.previousContext = activeCtx;\n  }\n\n  for(const resolvedContext of resolved) {\n    let {document: ctx} = resolvedContext;\n\n    // update active context to one computed from last iteration\n    activeCtx = rval;\n\n    // reset to initial context\n    if(ctx === null) {\n      // We can't nullify if there are protected terms and we're\n      // not allowing overrides (e.g. processing a property term scoped context)\n      if(!overrideProtected && Object.keys(activeCtx.protected).length !== 0) {\n        throw new JsonLdError(\n          'Tried to nullify a context with protected terms outside of ' +\n          'a term definition.',\n          'jsonld.SyntaxError',\n          {code: 'invalid context nullification'});\n      }\n      rval = activeCtx = api.getInitialContext(options).clone();\n      continue;\n    }\n\n    // get processed context from cache if available\n    const processed = resolvedContext.getProcessed(activeCtx);\n    if(processed) {\n      if(originalOptions.eventHandler) {\n        // replay events with original non-capturing options\n        for(const event of processed.events) {\n          _handleEvent({event, options: originalOptions});\n        }\n      }\n\n      rval = activeCtx = processed.context;\n      continue;\n    }\n\n    // dereference @context key if present\n    if(_isObject(ctx) && '@context' in ctx) {\n      ctx = ctx['@context'];\n    }\n\n    // context must be an object by now, all URLs retrieved before this call\n    if(!_isObject(ctx)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context must be an object.',\n        'jsonld.SyntaxError', {code: 'invalid local context', context: ctx});\n    }\n\n    // TODO: there is likely a `previousContext` cloning optimization that\n    // could be applied here (no need to copy it under certain conditions)\n\n    // clone context before updating it\n    rval = rval.clone();\n\n    // define context mappings for keys in local context\n    const defined = new Map();\n\n    // handle @version\n    if('@version' in ctx) {\n      if(ctx['@version'] !== 1.1) {\n        throw new JsonLdError(\n          'Unsupported JSON-LD version: ' + ctx['@version'],\n          'jsonld.UnsupportedVersion',\n          {code: 'invalid @version value', context: ctx});\n      }\n      if(activeCtx.processingMode &&\n        activeCtx.processingMode === 'json-ld-1.0') {\n        throw new JsonLdError(\n          '@version: ' + ctx['@version'] + ' not compatible with ' +\n          activeCtx.processingMode,\n          'jsonld.ProcessingModeConflict',\n          {code: 'processing mode conflict', context: ctx});\n      }\n      rval.processingMode = 'json-ld-1.1';\n      rval['@version'] = ctx['@version'];\n      defined.set('@version', true);\n    }\n\n    // if not set explicitly, set processingMode to \"json-ld-1.1\"\n    rval.processingMode =\n      rval.processingMode || activeCtx.processingMode;\n\n    // handle @base\n    if('@base' in ctx) {\n      let base = ctx['@base'];\n\n      if(base === null || _isAbsoluteIri(base)) {\n        // no action\n      } else if(_isRelativeIri(base)) {\n        base = prependBase(rval['@base'], base);\n      } else {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@base\" in a ' +\n          '@context must be an absolute IRI, a relative IRI, or null.',\n          'jsonld.SyntaxError', {code: 'invalid base IRI', context: ctx});\n      }\n\n      rval['@base'] = base;\n      defined.set('@base', true);\n    }\n\n    // handle @vocab\n    if('@vocab' in ctx) {\n      const value = ctx['@vocab'];\n      if(value === null) {\n        delete rval['@vocab'];\n      } else if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@vocab\" in a ' +\n          '@context must be a string or null.',\n          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});\n      } else if(!_isAbsoluteIri(value) && api.processingMode(rval, 1.0)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@vocab\" in a ' +\n          '@context must be an absolute IRI.',\n          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});\n      } else {\n        const vocab = _expandIri(rval, value, {vocab: true, base: true},\n          undefined, undefined, options);\n        if(!_isAbsoluteIri(vocab)) {\n          if(options.eventHandler) {\n            _handleEvent({\n              event: {\n                type: ['JsonLdEvent'],\n                code: 'relative @vocab reference',\n                level: 'warning',\n                message: 'Relative @vocab reference found.',\n                details: {\n                  vocab\n                }\n              },\n              options\n            });\n          }\n        }\n        rval['@vocab'] = vocab;\n      }\n      defined.set('@vocab', true);\n    }\n\n    // handle @language\n    if('@language' in ctx) {\n      const value = ctx['@language'];\n      if(value === null) {\n        delete rval['@language'];\n      } else if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@language\" in a ' +\n          '@context must be a string or null.',\n          'jsonld.SyntaxError',\n          {code: 'invalid default language', context: ctx});\n      } else {\n        if(!value.match(REGEX_BCP47)) {\n          if(options.eventHandler) {\n            _handleEvent({\n              event: {\n                type: ['JsonLdEvent'],\n                code: 'invalid @language value',\n                level: 'warning',\n                message: '@language value must be valid BCP47.',\n                details: {\n                  language: value\n                }\n              },\n              options\n            });\n          }\n        }\n        rval['@language'] = value.toLowerCase();\n      }\n      defined.set('@language', true);\n    }\n\n    // handle @direction\n    if('@direction' in ctx) {\n      const value = ctx['@direction'];\n      if(activeCtx.processingMode === 'json-ld-1.0') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @direction not compatible with ' +\n          activeCtx.processingMode,\n          'jsonld.SyntaxError',\n          {code: 'invalid context member', context: ctx});\n      }\n      if(value === null) {\n        delete rval['@direction'];\n      } else if(value !== 'ltr' && value !== 'rtl') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@direction\" in a ' +\n          '@context must be null, \"ltr\", or \"rtl\".',\n          'jsonld.SyntaxError',\n          {code: 'invalid base direction', context: ctx});\n      } else {\n        rval['@direction'] = value;\n      }\n      defined.set('@direction', true);\n    }\n\n    // handle @propagate\n    // note: we've already extracted it, here we just do error checking\n    if('@propagate' in ctx) {\n      const value = ctx['@propagate'];\n      if(activeCtx.processingMode === 'json-ld-1.0') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @propagate not compatible with ' +\n          activeCtx.processingMode,\n          'jsonld.SyntaxError',\n          {code: 'invalid context entry', context: ctx});\n      }\n      if(typeof value !== 'boolean') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @propagate value must be a boolean.',\n          'jsonld.SyntaxError',\n          {code: 'invalid @propagate value', context: localCtx});\n      }\n      defined.set('@propagate', true);\n    }\n\n    // handle @import\n    if('@import' in ctx) {\n      const value = ctx['@import'];\n      if(activeCtx.processingMode === 'json-ld-1.0') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @import not compatible with ' +\n          activeCtx.processingMode,\n          'jsonld.SyntaxError',\n          {code: 'invalid context entry', context: ctx});\n      }\n      if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @import must be a string.',\n          'jsonld.SyntaxError',\n          {code: 'invalid @import value', context: localCtx});\n      }\n\n      // resolve contexts\n      const resolvedImport = await options.contextResolver.resolve({\n        activeCtx,\n        context: value,\n        documentLoader: options.documentLoader,\n        base: options.base\n      });\n      if(resolvedImport.length !== 1) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @import must reference a single context.',\n          'jsonld.SyntaxError',\n          {code: 'invalid remote context', context: localCtx});\n      }\n      const processedImport = resolvedImport[0].getProcessed(activeCtx);\n      if(processedImport) {\n        // Note: if the same context were used in this active context\n        // as a reference context, then processed_input might not\n        // be a dict.\n        ctx = processedImport;\n      } else {\n        const importCtx = resolvedImport[0].document;\n        if('@import' in importCtx) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax: ' +\n            'imported context must not include @import.',\n            'jsonld.SyntaxError',\n            {code: 'invalid context entry', context: localCtx});\n        }\n\n        // merge ctx into importCtx and replace rval with the result\n        for(const key in importCtx) {\n          if(!ctx.hasOwnProperty(key)) {\n            ctx[key] = importCtx[key];\n          }\n        }\n\n        // Note: this could potenially conflict if the import\n        // were used in the same active context as a referenced\n        // context and an import. In this case, we\n        // could override the cached result, but seems unlikely.\n        resolvedImport[0].setProcessed(activeCtx, ctx);\n      }\n\n      defined.set('@import', true);\n    }\n\n    // handle @protected; determine whether this sub-context is declaring\n    // all its terms to be \"protected\" (exceptions can be made on a\n    // per-definition basis)\n    defined.set('@protected', ctx['@protected'] || false);\n\n    // process all other keys\n    for(const key in ctx) {\n      api.createTermDefinition({\n        activeCtx: rval,\n        localCtx: ctx,\n        term: key,\n        defined,\n        options,\n        overrideProtected\n      });\n\n      if(_isObject(ctx[key]) && '@context' in ctx[key]) {\n        const keyCtx = ctx[key]['@context'];\n        let process = true;\n        if(_isString(keyCtx)) {\n          const url = prependBase(options.base, keyCtx);\n          // track processed contexts to avoid scoped context recursion\n          if(cycles.has(url)) {\n            process = false;\n          } else {\n            cycles.add(url);\n          }\n        }\n        // parse context to validate\n        if(process) {\n          try {\n            await api.process({\n              activeCtx: rval.clone(),\n              localCtx: ctx[key]['@context'],\n              overrideProtected: true,\n              options,\n              cycles\n            });\n          } catch(e) {\n            throw new JsonLdError(\n              'Invalid JSON-LD syntax; invalid scoped context.',\n              'jsonld.SyntaxError',\n              {\n                code: 'invalid scoped context',\n                context: ctx[key]['@context'],\n                term: key\n              });\n          }\n        }\n      }\n    }\n\n    // cache processed result\n    resolvedContext.setProcessed(activeCtx, {\n      context: rval,\n      events\n    });\n  }\n\n  return rval;\n};\n\n/**\n * Creates a term definition during context processing.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context being processed.\n * @param term the term in the local context to define the mapping for.\n * @param defined a map of defining/defined keys to detect cycles and prevent\n *          double definitions.\n * @param {Object} [options] - creation options.\n * @param overrideProtected `false` allows protected terms to be modified.\n */\napi.createTermDefinition = ({\n  activeCtx,\n  localCtx,\n  term,\n  defined,\n  options,\n  overrideProtected = false,\n}) => {\n  if(defined.has(term)) {\n    // term already defined\n    if(defined.get(term)) {\n      return;\n    }\n    // cycle detected\n    throw new JsonLdError(\n      'Cyclical context definition detected.',\n      'jsonld.CyclicalContext',\n      {code: 'cyclic IRI mapping', context: localCtx, term});\n  }\n\n  // now defining term\n  defined.set(term, false);\n\n  // get context term value\n  let value;\n  if(localCtx.hasOwnProperty(term)) {\n    value = localCtx[term];\n  }\n\n  if(term === '@type' &&\n     _isObject(value) &&\n     (value['@container'] || '@set') === '@set' &&\n     api.processingMode(activeCtx, 1.1)) {\n\n    const validKeys = ['@container', '@id', '@protected'];\n    const keys = Object.keys(value);\n    if(keys.length === 0 || keys.some(k => !validKeys.includes(k))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; keywords cannot be overridden.',\n        'jsonld.SyntaxError',\n        {code: 'keyword redefinition', context: localCtx, term});\n    }\n  } else if(api.isKeyword(term)) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; keywords cannot be overridden.',\n      'jsonld.SyntaxError',\n      {code: 'keyword redefinition', context: localCtx, term});\n  } else if(term.match(REGEX_KEYWORD)) {\n    if(options.eventHandler) {\n      _handleEvent({\n        event: {\n          type: ['JsonLdEvent'],\n          code: 'reserved term',\n          level: 'warning',\n          message:\n            'Terms beginning with \"@\" are ' +\n            'reserved for future use and dropped.',\n          details: {\n            term\n          }\n        },\n        options\n      });\n    }\n    return;\n  } else if(term === '') {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; a term cannot be an empty string.',\n      'jsonld.SyntaxError',\n      {code: 'invalid term definition', context: localCtx});\n  }\n\n  // keep reference to previous mapping for potential `@protected` check\n  const previousMapping = activeCtx.mappings.get(term);\n\n  // remove old mapping\n  if(activeCtx.mappings.has(term)) {\n    activeCtx.mappings.delete(term);\n  }\n\n  // convert short-hand value to object w/@id\n  let simpleTerm = false;\n  if(_isString(value) || value === null) {\n    simpleTerm = true;\n    value = {'@id': value};\n  }\n\n  if(!_isObject(value)) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; @context term values must be ' +\n      'strings or objects.',\n      'jsonld.SyntaxError',\n      {code: 'invalid term definition', context: localCtx});\n  }\n\n  // create new mapping\n  const mapping = {};\n  activeCtx.mappings.set(term, mapping);\n  mapping.reverse = false;\n\n  // make sure term definition only has expected keywords\n  const validKeys = ['@container', '@id', '@language', '@reverse', '@type'];\n\n  // JSON-LD 1.1 support\n  if(api.processingMode(activeCtx, 1.1)) {\n    validKeys.push(\n      '@context', '@direction', '@index', '@nest', '@prefix', '@protected');\n  }\n\n  for(const kw in value) {\n    if(!validKeys.includes(kw)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a term definition must not contain ' + kw,\n        'jsonld.SyntaxError',\n        {code: 'invalid term definition', context: localCtx});\n    }\n  }\n\n  // always compute whether term has a colon as an optimization for\n  // _compactIri\n  const colon = term.indexOf(':');\n  mapping._termHasColon = (colon > 0);\n\n  if('@reverse' in value) {\n    if('@id' in value) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @reverse term definition must not ' +\n        'contain @id.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n    if('@nest' in value) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @reverse term definition must not ' +\n        'contain @nest.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n    const reverse = value['@reverse'];\n    if(!_isString(reverse)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @reverse value must be a string.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n\n    if(reverse.match(REGEX_KEYWORD)) {\n      if(options.eventHandler) {\n        _handleEvent({\n          event: {\n            type: ['JsonLdEvent'],\n            code: 'reserved @reverse value',\n            level: 'warning',\n            message:\n              '@reverse values beginning with \"@\" are ' +\n              'reserved for future use and dropped.',\n            details: {\n              reverse\n            }\n          },\n          options\n        });\n      }\n      if(previousMapping) {\n        activeCtx.mappings.set(term, previousMapping);\n      } else {\n        activeCtx.mappings.delete(term);\n      }\n      return;\n    }\n\n    // expand and add @id mapping\n    const id = _expandIri(\n      activeCtx, reverse, {vocab: true, base: false}, localCtx, defined,\n      options);\n    if(!_isAbsoluteIri(id)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @reverse value must be an ' +\n        'absolute IRI or a blank node identifier.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n\n    mapping['@id'] = id;\n    mapping.reverse = true;\n  } else if('@id' in value) {\n    let id = value['@id'];\n    if(id && !_isString(id)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @id value must be an array ' +\n        'of strings or a string.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n    if(id === null) {\n      // reserve a null term, which may be protected\n      mapping['@id'] = null;\n    } else if(!api.isKeyword(id) && id.match(REGEX_KEYWORD)) {\n      if(options.eventHandler) {\n        _handleEvent({\n          event: {\n            type: ['JsonLdEvent'],\n            code: 'reserved @id value',\n            level: 'warning',\n            message:\n              '@id values beginning with \"@\" are ' +\n              'reserved for future use and dropped.',\n            details: {\n              id\n            }\n          },\n          options\n        });\n      }\n      if(previousMapping) {\n        activeCtx.mappings.set(term, previousMapping);\n      } else {\n        activeCtx.mappings.delete(term);\n      }\n      return;\n    } else if(id !== term) {\n      // expand and add @id mapping\n      id = _expandIri(\n        activeCtx, id, {vocab: true, base: false}, localCtx, defined, options);\n      if(!_isAbsoluteIri(id) && !api.isKeyword(id)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; a @context @id value must be an ' +\n          'absolute IRI, a blank node identifier, or a keyword.',\n          'jsonld.SyntaxError',\n          {code: 'invalid IRI mapping', context: localCtx});\n      }\n\n      // if term has the form of an IRI it must map the same\n      if(term.match(/(?::[^:])|\\//)) {\n        const termDefined = new Map(defined).set(term, true);\n        const termIri = _expandIri(\n          activeCtx, term, {vocab: true, base: false},\n          localCtx, termDefined, options);\n        if(termIri !== id) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; term in form of IRI must ' +\n            'expand to definition.',\n            'jsonld.SyntaxError',\n            {code: 'invalid IRI mapping', context: localCtx});\n        }\n      }\n\n      mapping['@id'] = id;\n      // indicate if this term may be used as a compact IRI prefix\n      mapping._prefix = (simpleTerm &&\n        !mapping._termHasColon &&\n        id.match(/[:\\/\\?#\\[\\]@]$/) !== null);\n    }\n  }\n\n  if(!('@id' in mapping)) {\n    // see if the term has a prefix\n    if(mapping._termHasColon) {\n      const prefix = term.substr(0, colon);\n      if(localCtx.hasOwnProperty(prefix)) {\n        // define parent prefix\n        api.createTermDefinition({\n          activeCtx, localCtx, term: prefix, defined, options\n        });\n      }\n\n      if(activeCtx.mappings.has(prefix)) {\n        // set @id based on prefix parent\n        const suffix = term.substr(colon + 1);\n        mapping['@id'] = activeCtx.mappings.get(prefix)['@id'] + suffix;\n      } else {\n        // term is an absolute IRI\n        mapping['@id'] = term;\n      }\n    } else if(term === '@type') {\n      // Special case, were we've previously determined that container is @set\n      mapping['@id'] = term;\n    } else {\n      // non-IRIs *must* define @ids if @vocab is not available\n      if(!('@vocab' in activeCtx)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @context terms must define an @id.',\n          'jsonld.SyntaxError',\n          {code: 'invalid IRI mapping', context: localCtx, term});\n      }\n      // prepend vocab to term\n      mapping['@id'] = activeCtx['@vocab'] + term;\n    }\n  }\n\n  // Handle term protection\n  if(value['@protected'] === true ||\n    (defined.get('@protected') === true && value['@protected'] !== false)) {\n    activeCtx.protected[term] = true;\n    mapping.protected = true;\n  }\n\n  // IRI mapping now defined\n  defined.set(term, true);\n\n  if('@type' in value) {\n    let type = value['@type'];\n    if(!_isString(type)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an @context @type value must be a string.',\n        'jsonld.SyntaxError',\n        {code: 'invalid type mapping', context: localCtx});\n    }\n\n    if((type === '@json' || type === '@none')) {\n      if(api.processingMode(activeCtx, 1.0)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; an @context @type value must not be ' +\n          `\"${type}\" in JSON-LD 1.0 mode.`,\n          'jsonld.SyntaxError',\n          {code: 'invalid type mapping', context: localCtx});\n      }\n    } else if(type !== '@id' && type !== '@vocab') {\n      // expand @type to full IRI\n      type = _expandIri(\n        activeCtx, type, {vocab: true, base: false}, localCtx, defined,\n        options);\n      if(!_isAbsoluteIri(type)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; an @context @type value must be an ' +\n          'absolute IRI.',\n          'jsonld.SyntaxError',\n          {code: 'invalid type mapping', context: localCtx});\n      }\n      if(type.indexOf('_:') === 0) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; an @context @type value must be an IRI, ' +\n          'not a blank node identifier.',\n          'jsonld.SyntaxError',\n          {code: 'invalid type mapping', context: localCtx});\n      }\n    }\n\n    // add @type to mapping\n    mapping['@type'] = type;\n  }\n\n  if('@container' in value) {\n    // normalize container to an array form\n    const container = _isString(value['@container']) ?\n      [value['@container']] : (value['@container'] || []);\n    const validContainers = ['@list', '@set', '@index', '@language'];\n    let isValid = true;\n    const hasSet = container.includes('@set');\n\n    // JSON-LD 1.1 support\n    if(api.processingMode(activeCtx, 1.1)) {\n      validContainers.push('@graph', '@id', '@type');\n\n      // check container length\n      if(container.includes('@list')) {\n        if(container.length !== 1) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; @context @container with @list must ' +\n            'have no other values',\n            'jsonld.SyntaxError',\n            {code: 'invalid container mapping', context: localCtx});\n        }\n      } else if(container.includes('@graph')) {\n        if(container.some(key =>\n          key !== '@graph' && key !== '@id' && key !== '@index' &&\n          key !== '@set')) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; @context @container with @graph must ' +\n            'have no other values other than @id, @index, and @set',\n            'jsonld.SyntaxError',\n            {code: 'invalid container mapping', context: localCtx});\n        }\n      } else {\n        // otherwise, container may also include @set\n        isValid &= container.length <= (hasSet ? 2 : 1);\n      }\n\n      if(container.includes('@type')) {\n        // If mapping does not have an @type,\n        // set it to @id\n        mapping['@type'] = mapping['@type'] || '@id';\n\n        // type mapping must be either @id or @vocab\n        if(!['@id', '@vocab'].includes(mapping['@type'])) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; container: @type requires @type to be ' +\n            '@id or @vocab.',\n            'jsonld.SyntaxError',\n            {code: 'invalid type mapping', context: localCtx});\n        }\n      }\n    } else {\n      // in JSON-LD 1.0, container must not be an array (it must be a string,\n      // which is one of the validContainers)\n      isValid &= !_isArray(value['@container']);\n\n      // check container length\n      isValid &= container.length <= 1;\n    }\n\n    // check against valid containers\n    isValid &= container.every(c => validContainers.includes(c));\n\n    // @set not allowed with @list\n    isValid &= !(hasSet && container.includes('@list'));\n\n    if(!isValid) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @container value must be ' +\n        'one of the following: ' + validContainers.join(', '),\n        'jsonld.SyntaxError',\n        {code: 'invalid container mapping', context: localCtx});\n    }\n\n    if(mapping.reverse &&\n      !container.every(c => ['@index', '@set'].includes(c))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @container value for a @reverse ' +\n        'type definition must be @index or @set.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n\n    // add @container to mapping\n    mapping['@container'] = container;\n  }\n\n  // property indexing\n  if('@index' in value) {\n    if(!('@container' in value) || !mapping['@container'].includes('@index')) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @index without @index in @container: ' +\n        `\"${value['@index']}\" on term \"${term}\".`, 'jsonld.SyntaxError',\n        {code: 'invalid term definition', context: localCtx});\n    }\n    if(!_isString(value['@index']) || value['@index'].indexOf('@') === 0) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @index must expand to an IRI: ' +\n        `\"${value['@index']}\" on term \"${term}\".`, 'jsonld.SyntaxError',\n        {code: 'invalid term definition', context: localCtx});\n    }\n    mapping['@index'] = value['@index'];\n  }\n\n  // scoped contexts\n  if('@context' in value) {\n    mapping['@context'] = value['@context'];\n  }\n\n  if('@language' in value && !('@type' in value)) {\n    let language = value['@language'];\n    if(language !== null && !_isString(language)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @language value must be ' +\n        'a string or null.', 'jsonld.SyntaxError',\n        {code: 'invalid language mapping', context: localCtx});\n    }\n\n    // add @language to mapping\n    if(language !== null) {\n      language = language.toLowerCase();\n    }\n    mapping['@language'] = language;\n  }\n\n  // term may be used as a prefix\n  if('@prefix' in value) {\n    if(term.match(/:|\\//)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @prefix used on a compact IRI term',\n        'jsonld.SyntaxError',\n        {code: 'invalid term definition', context: localCtx});\n    }\n    if(api.isKeyword(mapping['@id'])) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; keywords may not be used as prefixes',\n        'jsonld.SyntaxError',\n        {code: 'invalid term definition', context: localCtx});\n    }\n    if(typeof value['@prefix'] === 'boolean') {\n      mapping._prefix = value['@prefix'] === true;\n    } else {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context value for @prefix must be boolean',\n        'jsonld.SyntaxError',\n        {code: 'invalid @prefix value', context: localCtx});\n    }\n  }\n\n  if('@direction' in value) {\n    const direction = value['@direction'];\n    if(direction !== null && direction !== 'ltr' && direction !== 'rtl') {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @direction value must be ' +\n        'null, \"ltr\", or \"rtl\".',\n        'jsonld.SyntaxError',\n        {code: 'invalid base direction', context: localCtx});\n    }\n    mapping['@direction'] = direction;\n  }\n\n  if('@nest' in value) {\n    const nest = value['@nest'];\n    if(!_isString(nest) || (nest !== '@nest' && nest.indexOf('@') === 0)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @nest value must be ' +\n        'a string which is not a keyword other than @nest.',\n        'jsonld.SyntaxError',\n        {code: 'invalid @nest value', context: localCtx});\n    }\n    mapping['@nest'] = nest;\n  }\n\n  // disallow aliasing @context and @preserve\n  const id = mapping['@id'];\n  if(id === '@context' || id === '@preserve') {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; @context and @preserve cannot be aliased.',\n      'jsonld.SyntaxError', {code: 'invalid keyword alias', context: localCtx});\n  }\n\n  // Check for overriding protected terms\n  if(previousMapping && previousMapping.protected && !overrideProtected) {\n    // force new term to continue to be protected and see if the mappings would\n    // be equal\n    activeCtx.protected[term] = true;\n    mapping.protected = true;\n    if(!_deepCompare(previousMapping, mapping)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; tried to redefine a protected term.',\n        'jsonld.SyntaxError',\n        {code: 'protected term redefinition', context: localCtx, term});\n    }\n  }\n};\n\n/**\n * Expands a string to a full IRI. The string may be a term, a prefix, a\n * relative IRI, or an absolute IRI. The associated absolute IRI will be\n * returned.\n *\n * @param activeCtx the current active context.\n * @param value the string to expand.\n * @param relativeTo options for how to resolve relative IRIs:\n *          base: true to resolve against the base IRI, false not to.\n *          vocab: true to concatenate after @vocab, false not to.\n * @param {Object} [options] - processing options.\n *\n * @return the expanded value.\n */\napi.expandIri = (activeCtx, value, relativeTo, options) => {\n  return _expandIri(activeCtx, value, relativeTo, undefined, undefined,\n    options);\n};\n\n/**\n * Expands a string to a full IRI. The string may be a term, a prefix, a\n * relative IRI, or an absolute IRI. The associated absolute IRI will be\n * returned.\n *\n * @param activeCtx the current active context.\n * @param value the string to expand.\n * @param relativeTo options for how to resolve relative IRIs:\n *          base: true to resolve against the base IRI, false not to.\n *          vocab: true to concatenate after @vocab, false not to.\n * @param localCtx the local context being processed (only given if called\n *          during context processing).\n * @param defined a map for tracking cycles in context definitions (only given\n *          if called during context processing).\n * @param {Object} [options] - processing options.\n *\n * @return the expanded value.\n */\nfunction _expandIri(activeCtx, value, relativeTo, localCtx, defined, options) {\n  // already expanded\n  if(value === null || !_isString(value) || api.isKeyword(value)) {\n    return value;\n  }\n\n  // ignore non-keyword things that look like a keyword\n  if(value.match(REGEX_KEYWORD)) {\n    return null;\n  }\n\n  // define term dependency if not defined\n  if(localCtx && localCtx.hasOwnProperty(value) &&\n    defined.get(value) !== true) {\n    api.createTermDefinition({\n      activeCtx, localCtx, term: value, defined, options\n    });\n  }\n\n  relativeTo = relativeTo || {};\n  if(relativeTo.vocab) {\n    const mapping = activeCtx.mappings.get(value);\n\n    // value is explicitly ignored with a null mapping\n    if(mapping === null) {\n      return null;\n    }\n\n    if(_isObject(mapping) && '@id' in mapping) {\n      // value is a term\n      return mapping['@id'];\n    }\n  }\n\n  // split value into prefix:suffix\n  const colon = value.indexOf(':');\n  if(colon > 0) {\n    const prefix = value.substr(0, colon);\n    const suffix = value.substr(colon + 1);\n\n    // do not expand blank nodes (prefix of '_') or already-absolute\n    // IRIs (suffix of '//')\n    if(prefix === '_' || suffix.indexOf('//') === 0) {\n      return value;\n    }\n\n    // prefix dependency not defined, define it\n    if(localCtx && localCtx.hasOwnProperty(prefix)) {\n      api.createTermDefinition({\n        activeCtx, localCtx, term: prefix, defined, options\n      });\n    }\n\n    // use mapping if prefix is defined\n    const mapping = activeCtx.mappings.get(prefix);\n    if(mapping && mapping._prefix) {\n      return mapping['@id'] + suffix;\n    }\n\n    // already absolute IRI\n    if(_isAbsoluteIri(value)) {\n      return value;\n    }\n  }\n\n  // A flag that captures whether the iri being expanded is\n  // the value for an @type\n  //let typeExpansion = false;\n\n  //if(options !== undefined && options.typeExpansion !== undefined) {\n  //  typeExpansion = options.typeExpansion;\n  //}\n\n  if(relativeTo.vocab && '@vocab' in activeCtx) {\n    // prepend vocab\n    const prependedResult = activeCtx['@vocab'] + value;\n    // FIXME: needed? may be better as debug event.\n    /*\n    if(options && options.eventHandler) {\n      _handleEvent({\n        event: {\n          type: ['JsonLdEvent'],\n          code: 'prepending @vocab during expansion',\n          level: 'info',\n          message: 'Prepending @vocab during expansion.',\n          details: {\n            type: '@vocab',\n            vocab: activeCtx['@vocab'],\n            value,\n            result: prependedResult,\n            typeExpansion\n          }\n        },\n        options\n      });\n    }\n    */\n    // the null case preserves value as potentially relative\n    value = prependedResult;\n  } else if(relativeTo.base) {\n    // prepend base\n    let prependedResult;\n    let base;\n    if('@base' in activeCtx) {\n      if(activeCtx['@base']) {\n        base = prependBase(options.base, activeCtx['@base']);\n        prependedResult = prependBase(base, value);\n      } else {\n        base = activeCtx['@base'];\n        prependedResult = value;\n      }\n    } else {\n      base = options.base;\n      prependedResult = prependBase(options.base, value);\n    }\n    // FIXME: needed? may be better as debug event.\n    /*\n    if(options && options.eventHandler) {\n      _handleEvent({\n        event: {\n          type: ['JsonLdEvent'],\n          code: 'prepending @base during expansion',\n          level: 'info',\n          message: 'Prepending @base during expansion.',\n          details: {\n            type: '@base',\n            base,\n            value,\n            result: prependedResult,\n            typeExpansion\n          }\n        },\n        options\n      });\n    }\n    */\n    // the null case preserves value as potentially relative\n    value = prependedResult;\n  }\n\n  // FIXME: duplicate? needed? maybe just enable in a verbose debug mode\n  /*\n  if(!_isAbsoluteIri(value) && options && options.eventHandler) {\n    // emit event indicating a relative IRI was found, which can result in it\n    // being dropped when converting to other RDF representations\n    _handleEvent({\n      event: {\n        type: ['JsonLdEvent'],\n        code: 'relative IRI after expansion',\n        // FIXME: what level?\n        level: 'warning',\n        message: 'Relative IRI after expansion.',\n        details: {\n          relativeIri: value,\n          typeExpansion\n        }\n      },\n      options\n    });\n    // NOTE: relative reference events emitted at calling sites as needed\n  }\n  */\n\n  return value;\n}\n\n/**\n * Gets the initial context.\n *\n * @param options the options to use:\n *          [base] the document base IRI.\n *\n * @return the initial context.\n */\napi.getInitialContext = options => {\n  const key = JSON.stringify({processingMode: options.processingMode});\n  const cached = INITIAL_CONTEXT_CACHE.get(key);\n  if(cached) {\n    return cached;\n  }\n\n  const initialContext = {\n    processingMode: options.processingMode,\n    mappings: new Map(),\n    inverse: null,\n    getInverse: _createInverseContext,\n    clone: _cloneActiveContext,\n    revertToPreviousContext: _revertToPreviousContext,\n    protected: {}\n  };\n  // TODO: consider using LRU cache instead\n  if(INITIAL_CONTEXT_CACHE.size === INITIAL_CONTEXT_CACHE_MAX_SIZE) {\n    // clear whole cache -- assumes scenario where the cache fills means\n    // the cache isn't being used very efficiently anyway\n    INITIAL_CONTEXT_CACHE.clear();\n  }\n  INITIAL_CONTEXT_CACHE.set(key, initialContext);\n  return initialContext;\n\n  /**\n   * Generates an inverse context for use in the compaction algorithm, if\n   * not already generated for the given active context.\n   *\n   * @return the inverse context.\n   */\n  function _createInverseContext() {\n    const activeCtx = this;\n\n    // lazily create inverse\n    if(activeCtx.inverse) {\n      return activeCtx.inverse;\n    }\n    const inverse = activeCtx.inverse = {};\n\n    // variables for building fast CURIE map\n    const fastCurieMap = activeCtx.fastCurieMap = {};\n    const irisToTerms = {};\n\n    // handle default language\n    const defaultLanguage = (activeCtx['@language'] || '@none').toLowerCase();\n\n    // handle default direction\n    const defaultDirection = activeCtx['@direction'];\n\n    // create term selections for each mapping in the context, ordered by\n    // shortest and then lexicographically least\n    const mappings = activeCtx.mappings;\n    const terms = [...mappings.keys()].sort(_compareShortestLeast);\n    for(const term of terms) {\n      const mapping = mappings.get(term);\n      if(mapping === null) {\n        continue;\n      }\n\n      let container = mapping['@container'] || '@none';\n      container = [].concat(container).sort().join('');\n\n      if(mapping['@id'] === null) {\n        continue;\n      }\n      // iterate over every IRI in the mapping\n      const ids = _asArray(mapping['@id']);\n      for(const iri of ids) {\n        let entry = inverse[iri];\n        const isKeyword = api.isKeyword(iri);\n\n        if(!entry) {\n          // initialize entry\n          inverse[iri] = entry = {};\n\n          if(!isKeyword && !mapping._termHasColon) {\n            // init IRI to term map and fast CURIE prefixes\n            irisToTerms[iri] = [term];\n            const fastCurieEntry = {iri, terms: irisToTerms[iri]};\n            if(iri[0] in fastCurieMap) {\n              fastCurieMap[iri[0]].push(fastCurieEntry);\n            } else {\n              fastCurieMap[iri[0]] = [fastCurieEntry];\n            }\n          }\n        } else if(!isKeyword && !mapping._termHasColon) {\n          // add IRI to term match\n          irisToTerms[iri].push(term);\n        }\n\n        // add new entry\n        if(!entry[container]) {\n          entry[container] = {\n            '@language': {},\n            '@type': {},\n            '@any': {}\n          };\n        }\n        entry = entry[container];\n        _addPreferredTerm(term, entry['@any'], '@none');\n\n        if(mapping.reverse) {\n          // term is preferred for values using @reverse\n          _addPreferredTerm(term, entry['@type'], '@reverse');\n        } else if(mapping['@type'] === '@none') {\n          _addPreferredTerm(term, entry['@any'], '@none');\n          _addPreferredTerm(term, entry['@language'], '@none');\n          _addPreferredTerm(term, entry['@type'], '@none');\n        } else if('@type' in mapping) {\n          // term is preferred for values using specific type\n          _addPreferredTerm(term, entry['@type'], mapping['@type']);\n        } else if('@language' in mapping && '@direction' in mapping) {\n          // term is preferred for values using specific language and direction\n          const language = mapping['@language'];\n          const direction = mapping['@direction'];\n          if(language && direction) {\n            _addPreferredTerm(term, entry['@language'],\n              `${language}_${direction}`.toLowerCase());\n          } else if(language) {\n            _addPreferredTerm(term, entry['@language'], language.toLowerCase());\n          } else if(direction) {\n            _addPreferredTerm(term, entry['@language'], `_${direction}`);\n          } else {\n            _addPreferredTerm(term, entry['@language'], '@null');\n          }\n        } else if('@language' in mapping) {\n          _addPreferredTerm(term, entry['@language'],\n            (mapping['@language'] || '@null').toLowerCase());\n        } else if('@direction' in mapping) {\n          if(mapping['@direction']) {\n            _addPreferredTerm(term, entry['@language'],\n              `_${mapping['@direction']}`);\n          } else {\n            _addPreferredTerm(term, entry['@language'], '@none');\n          }\n        } else if(defaultDirection) {\n          _addPreferredTerm(term, entry['@language'], `_${defaultDirection}`);\n          _addPreferredTerm(term, entry['@language'], '@none');\n          _addPreferredTerm(term, entry['@type'], '@none');\n        } else {\n          // add entries for no type and no language\n          _addPreferredTerm(term, entry['@language'], defaultLanguage);\n          _addPreferredTerm(term, entry['@language'], '@none');\n          _addPreferredTerm(term, entry['@type'], '@none');\n        }\n      }\n    }\n\n    // build fast CURIE map\n    for(const key in fastCurieMap) {\n      _buildIriMap(fastCurieMap, key, 1);\n    }\n\n    return inverse;\n  }\n\n  /**\n   * Runs a recursive algorithm to build a lookup map for quickly finding\n   * potential CURIEs.\n   *\n   * @param iriMap the map to build.\n   * @param key the current key in the map to work on.\n   * @param idx the index into the IRI to compare.\n   */\n  function _buildIriMap(iriMap, key, idx) {\n    const entries = iriMap[key];\n    const next = iriMap[key] = {};\n\n    let iri;\n    let letter;\n    for(const entry of entries) {\n      iri = entry.iri;\n      if(idx >= iri.length) {\n        letter = '';\n      } else {\n        letter = iri[idx];\n      }\n      if(letter in next) {\n        next[letter].push(entry);\n      } else {\n        next[letter] = [entry];\n      }\n    }\n\n    for(const key in next) {\n      if(key === '') {\n        continue;\n      }\n      _buildIriMap(next, key, idx + 1);\n    }\n  }\n\n  /**\n   * Adds the term for the given entry if not already added.\n   *\n   * @param term the term to add.\n   * @param entry the inverse context typeOrLanguage entry to add to.\n   * @param typeOrLanguageValue the key in the entry to add to.\n   */\n  function _addPreferredTerm(term, entry, typeOrLanguageValue) {\n    if(!entry.hasOwnProperty(typeOrLanguageValue)) {\n      entry[typeOrLanguageValue] = term;\n    }\n  }\n\n  /**\n   * Clones an active context, creating a child active context.\n   *\n   * @return a clone (child) of the active context.\n   */\n  function _cloneActiveContext() {\n    const child = {};\n    child.mappings = util.clone(this.mappings);\n    child.clone = this.clone;\n    child.inverse = null;\n    child.getInverse = this.getInverse;\n    child.protected = util.clone(this.protected);\n    if(this.previousContext) {\n      child.previousContext = this.previousContext.clone();\n    }\n    child.revertToPreviousContext = this.revertToPreviousContext;\n    if('@base' in this) {\n      child['@base'] = this['@base'];\n    }\n    if('@language' in this) {\n      child['@language'] = this['@language'];\n    }\n    if('@vocab' in this) {\n      child['@vocab'] = this['@vocab'];\n    }\n    return child;\n  }\n\n  /**\n   * Reverts any type-scoped context in this active context to the previous\n   * context.\n   */\n  function _revertToPreviousContext() {\n    if(!this.previousContext) {\n      return this;\n    }\n    return this.previousContext.clone();\n  }\n};\n\n/**\n * Gets the value for the given active context key and type, null if none is\n * set or undefined if none is set and type is '@context'.\n *\n * @param ctx the active context.\n * @param key the context key.\n * @param [type] the type of value to get (eg: '@id', '@type'), if not\n *          specified gets the entire entry for a key, null if not found.\n *\n * @return the value, null, or undefined.\n */\napi.getContextValue = (ctx, key, type) => {\n  // invalid key\n  if(key === null) {\n    if(type === '@context') {\n      return undefined;\n    }\n    return null;\n  }\n\n  // get specific entry information\n  if(ctx.mappings.has(key)) {\n    const entry = ctx.mappings.get(key);\n\n    if(_isUndefined(type)) {\n      // return whole entry\n      return entry;\n    }\n    if(entry.hasOwnProperty(type)) {\n      // return entry value for type\n      return entry[type];\n    }\n  }\n\n  // get default language\n  if(type === '@language' && type in ctx) {\n    return ctx[type];\n  }\n\n  // get default direction\n  if(type === '@direction' && type in ctx) {\n    return ctx[type];\n  }\n\n  if(type === '@context') {\n    return undefined;\n  }\n  return null;\n};\n\n/**\n * Processing Mode check.\n *\n * @param activeCtx the current active context.\n * @param version the string or numeric version to check.\n *\n * @return boolean.\n */\napi.processingMode = (activeCtx, version) => {\n  if(version.toString() >= '1.1') {\n    return !activeCtx.processingMode ||\n      activeCtx.processingMode >= 'json-ld-' + version.toString();\n  } else {\n    return activeCtx.processingMode === 'json-ld-1.0';\n  }\n};\n\n/**\n * Returns whether or not the given value is a keyword.\n *\n * @param v the value to check.\n *\n * @return true if the value is a keyword, false if not.\n */\napi.isKeyword = v => {\n  if(!_isString(v) || v[0] !== '@') {\n    return false;\n  }\n  switch(v) {\n    case '@base':\n    case '@container':\n    case '@context':\n    case '@default':\n    case '@direction':\n    case '@embed':\n    case '@explicit':\n    case '@graph':\n    case '@id':\n    case '@included':\n    case '@index':\n    case '@json':\n    case '@language':\n    case '@list':\n    case '@nest':\n    case '@none':\n    case '@omitDefault':\n    case '@prefix':\n    case '@preserve':\n    case '@protected':\n    case '@requireAll':\n    case '@reverse':\n    case '@set':\n    case '@type':\n    case '@value':\n    case '@version':\n    case '@vocab':\n      return true;\n  }\n  return false;\n};\n\nfunction _deepCompare(x1, x2) {\n  // compare `null` or primitive types directly\n  if((!(x1 && typeof x1 === 'object')) ||\n     (!(x2 && typeof x2 === 'object'))) {\n    return x1 === x2;\n  }\n  // x1 and x2 are objects (also potentially arrays)\n  const x1Array = Array.isArray(x1);\n  if(x1Array !== Array.isArray(x2)) {\n    return false;\n  }\n  if(x1Array) {\n    if(x1.length !== x2.length) {\n      return false;\n    }\n    for(let i = 0; i < x1.length; ++i) {\n      if(!_deepCompare(x1[i], x2[i])) {\n        return false;\n      }\n    }\n    return true;\n  }\n  // x1 and x2 are non-array objects\n  const k1s = Object.keys(x1);\n  const k2s = Object.keys(x2);\n  if(k1s.length !== k2s.length) {\n    return false;\n  }\n  for(const k1 in x1) {\n    let v1 = x1[k1];\n    let v2 = x2[k1];\n    // special case: `@container` can be in any order\n    if(k1 === '@container') {\n      if(Array.isArray(v1) && Array.isArray(v2)) {\n        v1 = v1.slice().sort();\n        v2 = v2.slice().sort();\n      }\n    }\n    if(!_deepCompare(v1, v2)) {\n      return false;\n    }\n  }\n  return true;\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/context.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/documentLoaders/xhr.js":
/*!********************************************************!*\
  !*** ./node_modules/jsonld/lib/documentLoaders/xhr.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst {parseLinkHeader, buildHeaders} = __webpack_require__(/*! ../util */ \"./node_modules/jsonld/lib/util.js\");\nconst {LINK_HEADER_CONTEXT} = __webpack_require__(/*! ../constants */ \"./node_modules/jsonld/lib/constants.js\");\nconst JsonLdError = __webpack_require__(/*! ../JsonLdError */ \"./node_modules/jsonld/lib/JsonLdError.js\");\nconst RequestQueue = __webpack_require__(/*! ../RequestQueue */ \"./node_modules/jsonld/lib/RequestQueue.js\");\nconst {prependBase} = __webpack_require__(/*! ../url */ \"./node_modules/jsonld/lib/url.js\");\n\nconst REGEX_LINK_HEADER = /(^|(\\r\\n))link:/i;\n\n/**\n * Creates a built-in XMLHttpRequest document loader.\n *\n * @param options the options to use:\n *          secure: require all URLs to use HTTPS.\n *          headers: an object (map) of headers which will be passed as request\n *            headers for the requested document. Accept is not allowed.\n *          [xhr]: the XMLHttpRequest API to use.\n *\n * @return the XMLHttpRequest document loader.\n */\nmodule.exports = ({\n  secure,\n  headers = {},\n  xhr\n} = {headers: {}}) => {\n  headers = buildHeaders(headers);\n  const queue = new RequestQueue();\n  return queue.wrapLoader(loader);\n\n  async function loader(url) {\n    if(url.indexOf('http:') !== 0 && url.indexOf('https:') !== 0) {\n      throw new JsonLdError(\n        'URL could not be dereferenced; only \"http\" and \"https\" URLs are ' +\n        'supported.',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url});\n    }\n    if(secure && url.indexOf('https') !== 0) {\n      throw new JsonLdError(\n        'URL could not be dereferenced; secure mode is enabled and ' +\n        'the URL\\'s scheme is not \"https\".',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url});\n    }\n\n    let req;\n    try {\n      req = await _get(xhr, url, headers);\n    } catch(e) {\n      throw new JsonLdError(\n        'URL could not be dereferenced, an error occurred.',\n        'jsonld.LoadDocumentError',\n        {code: 'loading document failed', url, cause: e});\n    }\n\n    if(req.status >= 400) {\n      throw new JsonLdError(\n        'URL could not be dereferenced: ' + req.statusText,\n        'jsonld.LoadDocumentError', {\n          code: 'loading document failed',\n          url,\n          httpStatusCode: req.status\n        });\n    }\n\n    let doc = {contextUrl: null, documentUrl: url, document: req.response};\n    let alternate = null;\n\n    // handle Link Header (avoid unsafe header warning by existence testing)\n    const contentType = req.getResponseHeader('Content-Type');\n    let linkHeader;\n    if(REGEX_LINK_HEADER.test(req.getAllResponseHeaders())) {\n      linkHeader = req.getResponseHeader('Link');\n    }\n    if(linkHeader && contentType !== 'application/ld+json') {\n      // only 1 related link header permitted\n      const linkHeaders = parseLinkHeader(linkHeader);\n      const linkedContext = linkHeaders[LINK_HEADER_CONTEXT];\n      if(Array.isArray(linkedContext)) {\n        throw new JsonLdError(\n          'URL could not be dereferenced, it has more than one ' +\n          'associated HTTP Link Header.',\n          'jsonld.InvalidUrl',\n          {code: 'multiple context link headers', url});\n      }\n      if(linkedContext) {\n        doc.contextUrl = linkedContext.target;\n      }\n\n      // \"alternate\" link header is a redirect\n      alternate = linkHeaders.alternate;\n      if(alternate &&\n        alternate.type == 'application/ld+json' &&\n        !(contentType || '').match(/^application\\/(\\w*\\+)?json$/)) {\n        doc = await loader(prependBase(url, alternate.target));\n      }\n    }\n\n    return doc;\n  }\n};\n\nfunction _get(xhr, url, headers) {\n  xhr = xhr || XMLHttpRequest;\n  const req = new xhr();\n  return new Promise((resolve, reject) => {\n    req.onload = () => resolve(req);\n    req.onerror = err => reject(err);\n    req.open('GET', url, true);\n    for(const k in headers) {\n      req.setRequestHeader(k, headers[k]);\n    }\n    req.send();\n  });\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/documentLoaders/xhr.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/events.js":
/*!*******************************************!*\
  !*** ./node_modules/jsonld/lib/events.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2020 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst JsonLdError = __webpack_require__(/*! ./JsonLdError */ \"./node_modules/jsonld/lib/JsonLdError.js\");\n\nconst {\n  isArray: _isArray\n} = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\n\nconst {\n  asArray: _asArray\n} = __webpack_require__(/*! ./util */ \"./node_modules/jsonld/lib/util.js\");\n\nconst api = {};\nmodule.exports = api;\n\n// default handler, store as null or an array\n// exposed to allow fast external pre-handleEvent() checks\napi.defaultEventHandler = null;\n\n/**\n * Setup event handler.\n *\n * Return an array event handler constructed from an optional safe mode\n * handler, an optional options event handler, and an optional default handler.\n *\n * @param {object} options - processing options\n *   {function|object|array} [eventHandler] - an event handler.\n *\n * @return an array event handler.\n */\napi.setupEventHandler = ({options = {}}) => {\n  // build in priority order\n  const eventHandler = [].concat(\n    options.safe ? api.safeEventHandler : [],\n    options.eventHandler ? _asArray(options.eventHandler) : [],\n    api.defaultEventHandler ? api.defaultEventHandler : []\n  );\n  // null if no handlers\n  return eventHandler.length === 0 ? null : eventHandler;\n};\n\n/**\n * Handle an event.\n *\n * Top level APIs have a common 'eventHandler' option. This option can be a\n * function, array of functions, object mapping event.code to functions (with a\n * default to call next()), or any combination of such handlers. Handlers will\n * be called with an object with an 'event' entry and a 'next' function. Custom\n * handlers should process the event as appropriate. The 'next()' function\n * should be called to let the next handler process the event.\n *\n * NOTE: Only call this function if options.eventHandler is set and is an\n * array of hanlers. This is an optimization. Callers are expected to check\n * for an event handler before constructing events and calling this function.\n *\n * @param {object} event - event structure:\n *   {string} code - event code\n *   {string} level - severity level, one of: ['warning']\n *   {string} message - human readable message\n *   {object} details - event specific details\n * @param {object} options - processing options\n *   {array} eventHandler - an event handler array.\n */\napi.handleEvent = ({\n  event,\n  options\n}) => {\n  _handle({event, handlers: options.eventHandler});\n};\n\nfunction _handle({event, handlers}) {\n  let doNext = true;\n  for(let i = 0; doNext && i < handlers.length; ++i) {\n    doNext = false;\n    const handler = handlers[i];\n    if(_isArray(handler)) {\n      doNext = _handle({event, handlers: handler});\n    } else if(typeof handler === 'function') {\n      handler({event, next: () => {\n        doNext = true;\n      }});\n    } else if(typeof handler === 'object') {\n      if(event.code in handler) {\n        handler[event.code]({event, next: () => {\n          doNext = true;\n        }});\n      } else {\n        doNext = true;\n      }\n    } else {\n      throw new JsonLdError(\n        'Invalid event handler.',\n        'jsonld.InvalidEventHandler',\n        {event});\n    }\n  }\n  return doNext;\n}\n\nconst _notSafeEventCodes = new Set([\n  'empty object',\n  'free-floating scalar',\n  'invalid @language value',\n  'invalid property',\n  // NOTE: spec edge case\n  'null @id value',\n  'null @value value',\n  'object with only @id',\n  'object with only @language',\n  'object with only @list',\n  'object with only @value',\n  'relative @id reference',\n  'relative @type reference',\n  'relative @vocab reference',\n  'reserved @id value',\n  'reserved @reverse value',\n  'reserved term',\n  // toRDF\n  'blank node predicate',\n  'relative graph reference',\n  'relative object reference',\n  'relative predicate reference',\n  'relative subject reference',\n  // toRDF / fromRDF\n  'rdfDirection not set'\n]);\n\n// safe handler that rejects unsafe warning conditions\napi.safeEventHandler = function safeEventHandler({event, next}) {\n  // fail on all unsafe warnings\n  if(event.level === 'warning' && _notSafeEventCodes.has(event.code)) {\n    throw new JsonLdError(\n      'Safe mode validation error.',\n      'jsonld.ValidationError',\n      {event}\n    );\n  }\n  next();\n};\n\n// logs all events and continues\napi.logEventHandler = function logEventHandler({event, next}) {\n  console.log(`EVENT: ${event.message}`, {event});\n  next();\n};\n\n// log 'warning' level events\napi.logWarningEventHandler = function logWarningEventHandler({event, next}) {\n  if(event.level === 'warning') {\n    console.warn(`WARNING: ${event.message}`, {event});\n  }\n  next();\n};\n\n// fallback to throw errors for any unhandled events\napi.unhandledEventHandler = function unhandledEventHandler({event}) {\n  throw new JsonLdError(\n    'No handler for event.',\n    'jsonld.UnhandledEvent',\n    {event}\n  );\n};\n\n/**\n * Set default event handler.\n *\n * By default, all event are unhandled. It is recommended to pass in an\n * eventHandler into each call. However, this call allows using a default\n * eventHandler when one is not otherwise provided.\n *\n * @param {object} options - default handler options:\n *   {function|object|array} eventHandler - a default event handler.\n *     falsey to unset.\n */\napi.setDefaultEventHandler = function({eventHandler} = {}) {\n  api.defaultEventHandler = eventHandler ? _asArray(eventHandler) : null;\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/events.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/expand.js":
/*!*******************************************!*\
  !*** ./node_modules/jsonld/lib/expand.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst JsonLdError = __webpack_require__(/*! ./JsonLdError */ \"./node_modules/jsonld/lib/JsonLdError.js\");\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isEmptyObject: _isEmptyObject,\n  isString: _isString,\n  isUndefined: _isUndefined\n} = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\n\nconst {\n  isList: _isList,\n  isValue: _isValue,\n  isGraph: _isGraph,\n  isSubject: _isSubject\n} = __webpack_require__(/*! ./graphTypes */ \"./node_modules/jsonld/lib/graphTypes.js\");\n\nconst {\n  expandIri: _expandIri,\n  getContextValue: _getContextValue,\n  isKeyword: _isKeyword,\n  process: _processContext,\n  processingMode: _processingMode\n} = __webpack_require__(/*! ./context */ \"./node_modules/jsonld/lib/context.js\");\n\nconst {\n  isAbsolute: _isAbsoluteIri\n} = __webpack_require__(/*! ./url */ \"./node_modules/jsonld/lib/url.js\");\n\nconst {\n  REGEX_BCP47,\n  REGEX_KEYWORD,\n  addValue: _addValue,\n  asArray: _asArray,\n  getValues: _getValues,\n  validateTypeValue: _validateTypeValue\n} = __webpack_require__(/*! ./util */ \"./node_modules/jsonld/lib/util.js\");\n\nconst {\n  handleEvent: _handleEvent\n} = __webpack_require__(/*! ./events */ \"./node_modules/jsonld/lib/events.js\");\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Recursively expands an element using the given context. Any context in\n * the element will be removed. All context URLs must have been retrieved\n * before calling this method.\n *\n * @param activeCtx the context to use.\n * @param activeProperty the property for the element, null for none.\n * @param element the element to expand.\n * @param options the expansion options.\n * @param insideList true if the element is a list, false if not.\n * @param insideIndex true if the element is inside an index container,\n *          false if not.\n * @param typeScopedContext an optional type-scoped active context for\n *          expanding values of nodes that were expressed according to\n *          a type-scoped context.\n *\n * @return a Promise that resolves to the expanded value.\n */\napi.expand = async ({\n  activeCtx,\n  activeProperty = null,\n  element,\n  options = {},\n  insideList = false,\n  insideIndex = false,\n  typeScopedContext = null\n}) => {\n  // nothing to expand\n  if(element === null || element === undefined) {\n    return null;\n  }\n\n  // disable framing if activeProperty is @default\n  if(activeProperty === '@default') {\n    options = Object.assign({}, options, {isFrame: false});\n  }\n\n  if(!_isArray(element) && !_isObject(element)) {\n    // drop free-floating scalars that are not in lists\n    if(!insideList && (activeProperty === null ||\n      _expandIri(activeCtx, activeProperty, {vocab: true},\n        options) === '@graph')) {\n      // FIXME\n      if(options.eventHandler) {\n        _handleEvent({\n          event: {\n            type: ['JsonLdEvent'],\n            code: 'free-floating scalar',\n            level: 'warning',\n            message: 'Dropping free-floating scalar not in a list.',\n            details: {\n              value: element\n              //activeProperty\n              //insideList\n            }\n          },\n          options\n        });\n      }\n      return null;\n    }\n\n    // expand element according to value expansion rules\n    return _expandValue({activeCtx, activeProperty, value: element, options});\n  }\n\n  // recursively expand array\n  if(_isArray(element)) {\n    let rval = [];\n    const container = _getContextValue(\n      activeCtx, activeProperty, '@container') || [];\n    insideList = insideList || container.includes('@list');\n    for(let i = 0; i < element.length; ++i) {\n      // expand element\n      let e = await api.expand({\n        activeCtx,\n        activeProperty,\n        element: element[i],\n        options,\n        insideIndex,\n        typeScopedContext\n      });\n      if(insideList && _isArray(e)) {\n        e = {'@list': e};\n      }\n\n      if(e === null) {\n        // FIXME: add debug event?\n        //unmappedValue: element[i],\n        //activeProperty,\n        //parent: element,\n        //index: i,\n        //expandedParent: rval,\n        //insideList\n\n        // NOTE: no-value events emitted at calling sites as needed\n        continue;\n      }\n\n      if(_isArray(e)) {\n        rval = rval.concat(e);\n      } else {\n        rval.push(e);\n      }\n    }\n    return rval;\n  }\n\n  // recursively expand object:\n\n  // first, expand the active property\n  const expandedActiveProperty = _expandIri(\n    activeCtx, activeProperty, {vocab: true}, options);\n\n  // Get any property-scoped context for activeProperty\n  const propertyScopedCtx =\n    _getContextValue(activeCtx, activeProperty, '@context');\n\n  // second, determine if any type-scoped context should be reverted; it\n  // should only be reverted when the following are all true:\n  // 1. `element` is not a value or subject reference\n  // 2. `insideIndex` is false\n  typeScopedContext = typeScopedContext ||\n    (activeCtx.previousContext ? activeCtx : null);\n  let keys = Object.keys(element).sort();\n  let mustRevert = !insideIndex;\n  if(mustRevert && typeScopedContext && keys.length <= 2 &&\n    !keys.includes('@context')) {\n    for(const key of keys) {\n      const expandedProperty = _expandIri(\n        typeScopedContext, key, {vocab: true}, options);\n      if(expandedProperty === '@value') {\n        // value found, ensure type-scoped context is used to expand it\n        mustRevert = false;\n        activeCtx = typeScopedContext;\n        break;\n      }\n      if(expandedProperty === '@id' && keys.length === 1) {\n        // subject reference found, do not revert\n        mustRevert = false;\n        break;\n      }\n    }\n  }\n\n  if(mustRevert) {\n    // revert type scoped context\n    activeCtx = activeCtx.revertToPreviousContext();\n  }\n\n  // apply property-scoped context after reverting term-scoped context\n  if(!_isUndefined(propertyScopedCtx)) {\n    activeCtx = await _processContext({\n      activeCtx,\n      localCtx: propertyScopedCtx,\n      propagate: true,\n      overrideProtected: true,\n      options\n    });\n  }\n\n  // if element has a context, process it\n  if('@context' in element) {\n    activeCtx = await _processContext(\n      {activeCtx, localCtx: element['@context'], options});\n  }\n\n  // set the type-scoped context to the context on input, for use later\n  typeScopedContext = activeCtx;\n\n  // Remember the first key found expanding to @type\n  let typeKey = null;\n\n  // look for scoped contexts on `@type`\n  for(const key of keys) {\n    const expandedProperty = _expandIri(activeCtx, key, {vocab: true}, options);\n    if(expandedProperty === '@type') {\n      // set scoped contexts from @type\n      // avoid sorting if possible\n      typeKey = typeKey || key;\n      const value = element[key];\n      const types =\n        Array.isArray(value) ?\n          (value.length > 1 ? value.slice().sort() : value) : [value];\n      for(const type of types) {\n        const ctx = _getContextValue(typeScopedContext, type, '@context');\n        if(!_isUndefined(ctx)) {\n          activeCtx = await _processContext({\n            activeCtx,\n            localCtx: ctx,\n            options,\n            propagate: false\n          });\n        }\n      }\n    }\n  }\n\n  // process each key and value in element, ignoring @nest content\n  let rval = {};\n  await _expandObject({\n    activeCtx,\n    activeProperty,\n    expandedActiveProperty,\n    element,\n    expandedParent: rval,\n    options,\n    insideList,\n    typeKey,\n    typeScopedContext\n  });\n\n  // get property count on expanded output\n  keys = Object.keys(rval);\n  let count = keys.length;\n\n  if('@value' in rval) {\n    // @value must only have @language or @type\n    if('@type' in rval && ('@language' in rval || '@direction' in rval)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an element containing \"@value\" may not ' +\n        'contain both \"@type\" and either \"@language\" or \"@direction\".',\n        'jsonld.SyntaxError', {code: 'invalid value object', element: rval});\n    }\n    let validCount = count - 1;\n    if('@type' in rval) {\n      validCount -= 1;\n    }\n    if('@index' in rval) {\n      validCount -= 1;\n    }\n    if('@language' in rval) {\n      validCount -= 1;\n    }\n    if('@direction' in rval) {\n      validCount -= 1;\n    }\n    if(validCount !== 0) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an element containing \"@value\" may only ' +\n        'have an \"@index\" property and either \"@type\" ' +\n        'or either or both \"@language\" or \"@direction\".',\n        'jsonld.SyntaxError', {code: 'invalid value object', element: rval});\n    }\n    const values = rval['@value'] === null ? [] : _asArray(rval['@value']);\n    const types = _getValues(rval, '@type');\n\n    // drop null @values\n    if(_processingMode(activeCtx, 1.1) && types.includes('@json') &&\n      types.length === 1) {\n      // Any value of @value is okay if @type: @json\n    } else if(values.length === 0) {\n      // FIXME\n      if(options.eventHandler) {\n        _handleEvent({\n          event: {\n            type: ['JsonLdEvent'],\n            code: 'null @value value',\n            level: 'warning',\n            message: 'Dropping null @value value.',\n            details: {\n              value: rval\n            }\n          },\n          options\n        });\n      }\n      rval = null;\n    } else if(!values.every(v => (_isString(v) || _isEmptyObject(v))) &&\n      '@language' in rval) {\n      // if @language is present, @value must be a string\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; only strings may be language-tagged.',\n        'jsonld.SyntaxError',\n        {code: 'invalid language-tagged value', element: rval});\n    } else if(!types.every(t =>\n      (_isAbsoluteIri(t) && !(_isString(t) && t.indexOf('_:') === 0) ||\n      _isEmptyObject(t)))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an element containing \"@value\" and \"@type\" ' +\n        'must have an absolute IRI for the value of \"@type\".',\n        'jsonld.SyntaxError', {code: 'invalid typed value', element: rval});\n    }\n  } else if('@type' in rval && !_isArray(rval['@type'])) {\n    // convert @type to an array\n    rval['@type'] = [rval['@type']];\n  } else if('@set' in rval || '@list' in rval) {\n    // handle @set and @list\n    if(count > 1 && !(count === 2 && '@index' in rval)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; if an element has the property \"@set\" ' +\n        'or \"@list\", then it can have at most one other property that is ' +\n        '\"@index\".', 'jsonld.SyntaxError',\n        {code: 'invalid set or list object', element: rval});\n    }\n    // optimize away @set\n    if('@set' in rval) {\n      rval = rval['@set'];\n      keys = Object.keys(rval);\n      count = keys.length;\n    }\n  } else if(count === 1 && '@language' in rval) {\n    // drop objects with only @language\n    // FIXME\n    if(options.eventHandler) {\n      _handleEvent({\n        event: {\n          type: ['JsonLdEvent'],\n          code: 'object with only @language',\n          level: 'warning',\n          message: 'Dropping object with only @language.',\n          details: {\n            value: rval\n          }\n        },\n        options\n      });\n    }\n    rval = null;\n  }\n\n  // drop certain top-level objects that do not occur in lists\n  if(_isObject(rval) &&\n    !options.keepFreeFloatingNodes && !insideList &&\n    (activeProperty === null ||\n      expandedActiveProperty === '@graph' ||\n      (_getContextValue(activeCtx, activeProperty, '@container') || [])\n        .includes('@graph')\n    )) {\n    // drop empty object, top-level @value/@list, or object with only @id\n    rval = _dropUnsafeObject({value: rval, count, options});\n  }\n\n  return rval;\n};\n\n/**\n * Drop empty object, top-level @value/@list, or object with only @id\n *\n * @param value Value to check.\n * @param count Number of properties in object.\n * @param options The expansion options.\n *\n * @return null if dropped, value otherwise.\n */\nfunction _dropUnsafeObject({\n  value,\n  count,\n  options\n}) {\n  if(count === 0 || '@value' in value || '@list' in value ||\n    (count === 1 && '@id' in value)) {\n    // FIXME\n    if(options.eventHandler) {\n      // FIXME: one event or diff event for empty, @v/@l, {@id}?\n      let code;\n      let message;\n      if(count === 0) {\n        code = 'empty object';\n        message = 'Dropping empty object.';\n      } else if('@value' in value) {\n        code = 'object with only @value';\n        message = 'Dropping object with only @value.';\n      } else if('@list' in value) {\n        code = 'object with only @list';\n        message = 'Dropping object with only @list.';\n      } else if(count === 1 && '@id' in value) {\n        code = 'object with only @id';\n        message = 'Dropping object with only @id.';\n      }\n      _handleEvent({\n        event: {\n          type: ['JsonLdEvent'],\n          code,\n          level: 'warning',\n          message,\n          details: {\n            value\n          }\n        },\n        options\n      });\n    }\n    return null;\n  }\n  return value;\n}\n\n/**\n * Expand each key and value of element adding to result\n *\n * @param activeCtx the context to use.\n * @param activeProperty the property for the element.\n * @param expandedActiveProperty the expansion of activeProperty\n * @param element the element to expand.\n * @param expandedParent the expanded result into which to add values.\n * @param options the expansion options.\n * @param insideList true if the element is a list, false if not.\n * @param typeKey first key found expanding to @type.\n * @param typeScopedContext the context before reverting.\n */\nasync function _expandObject({\n  activeCtx,\n  activeProperty,\n  expandedActiveProperty,\n  element,\n  expandedParent,\n  options = {},\n  insideList,\n  typeKey,\n  typeScopedContext\n}) {\n  const keys = Object.keys(element).sort();\n  const nests = [];\n  let unexpandedValue;\n\n  // Figure out if this is the type for a JSON literal\n  const isJsonType = element[typeKey] &&\n    _expandIri(activeCtx,\n      (_isArray(element[typeKey]) ? element[typeKey][0] : element[typeKey]),\n      {vocab: true}, {\n        ...options,\n        typeExpansion: true\n      }) === '@json';\n\n  for(const key of keys) {\n    let value = element[key];\n    let expandedValue;\n\n    // skip @context\n    if(key === '@context') {\n      continue;\n    }\n\n    // expand property\n    const expandedProperty = _expandIri(activeCtx, key, {vocab: true}, options);\n\n    // drop non-absolute IRI keys that aren't keywords\n    if(expandedProperty === null ||\n      !(_isAbsoluteIri(expandedProperty) || _isKeyword(expandedProperty))) {\n      if(options.eventHandler) {\n        _handleEvent({\n          event: {\n            type: ['JsonLdEvent'],\n            code: 'invalid property',\n            level: 'warning',\n            message: 'Dropping property that did not expand into an ' +\n              'absolute IRI or keyword.',\n            details: {\n              property: key,\n              expandedProperty\n            }\n          },\n          options\n        });\n      }\n      continue;\n    }\n\n    if(_isKeyword(expandedProperty)) {\n      if(expandedActiveProperty === '@reverse') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; a keyword cannot be used as a @reverse ' +\n          'property.', 'jsonld.SyntaxError',\n          {code: 'invalid reverse property map', value});\n      }\n      if(expandedProperty in expandedParent &&\n         expandedProperty !== '@included' &&\n         expandedProperty !== '@type') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; colliding keywords detected.',\n          'jsonld.SyntaxError',\n          {code: 'colliding keywords', keyword: expandedProperty});\n      }\n    }\n\n    // syntax error if @id is not a string\n    if(expandedProperty === '@id') {\n      if(!_isString(value)) {\n        if(!options.isFrame) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; \"@id\" value must a string.',\n            'jsonld.SyntaxError', {code: 'invalid @id value', value});\n        }\n        if(_isObject(value)) {\n          // empty object is a wildcard\n          if(!_isEmptyObject(value)) {\n            throw new JsonLdError(\n              'Invalid JSON-LD syntax; \"@id\" value an empty object or array ' +\n              'of strings, if framing',\n              'jsonld.SyntaxError', {code: 'invalid @id value', value});\n          }\n        } else if(_isArray(value)) {\n          if(!value.every(v => _isString(v))) {\n            throw new JsonLdError(\n              'Invalid JSON-LD syntax; \"@id\" value an empty object or array ' +\n              'of strings, if framing',\n              'jsonld.SyntaxError', {code: 'invalid @id value', value});\n          }\n        } else {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; \"@id\" value an empty object or array ' +\n            'of strings, if framing',\n            'jsonld.SyntaxError', {code: 'invalid @id value', value});\n        }\n      }\n\n      _addValue(\n        expandedParent, '@id',\n        _asArray(value).map(v => {\n          if(_isString(v)) {\n            const ve = _expandIri(activeCtx, v, {base: true}, options);\n            if(options.eventHandler) {\n              if(ve === null) {\n                // NOTE: spec edge case\n                // See https://github.com/w3c/json-ld-api/issues/480\n                if(v === null) {\n                  _handleEvent({\n                    event: {\n                      type: ['JsonLdEvent'],\n                      code: 'null @id value',\n                      level: 'warning',\n                      message: 'Null @id found.',\n                      details: {\n                        id: v\n                      }\n                    },\n                    options\n                  });\n                } else {\n                  // matched KEYWORD regex\n                  _handleEvent({\n                    event: {\n                      type: ['JsonLdEvent'],\n                      code: 'reserved @id value',\n                      level: 'warning',\n                      message: 'Reserved @id found.',\n                      details: {\n                        id: v\n                      }\n                    },\n                    options\n                  });\n                }\n              } else if(!_isAbsoluteIri(ve)) {\n                _handleEvent({\n                  event: {\n                    type: ['JsonLdEvent'],\n                    code: 'relative @id reference',\n                    level: 'warning',\n                    message: 'Relative @id reference found.',\n                    details: {\n                      id: v,\n                      expandedId: ve\n                    }\n                  },\n                  options\n                });\n              }\n            }\n            return ve;\n          }\n          return v;\n        }),\n        {propertyIsArray: options.isFrame});\n      continue;\n    }\n\n    if(expandedProperty === '@type') {\n      // if framing, can be a default object, but need to expand\n      // key to determine that\n      if(_isObject(value)) {\n        value = Object.fromEntries(Object.entries(value).map(([k, v]) => [\n          _expandIri(typeScopedContext, k, {vocab: true}),\n          _asArray(v).map(vv =>\n            _expandIri(typeScopedContext, vv, {base: true, vocab: true},\n              {...options, typeExpansion: true})\n          )\n        ]));\n      }\n      _validateTypeValue(value, options.isFrame);\n      _addValue(\n        expandedParent, '@type',\n        _asArray(value).map(v => {\n          if(_isString(v)) {\n            const ve = _expandIri(typeScopedContext, v,\n              {base: true, vocab: true},\n              {...options, typeExpansion: true});\n            if(ve !== '@json' && !_isAbsoluteIri(ve)) {\n              if(options.eventHandler) {\n                _handleEvent({\n                  event: {\n                    type: ['JsonLdEvent'],\n                    code: 'relative @type reference',\n                    level: 'warning',\n                    message: 'Relative @type reference found.',\n                    details: {\n                      type: v\n                    }\n                  },\n                  options\n                });\n              }\n            }\n            return ve;\n          }\n          return v;\n        }),\n        {propertyIsArray: !!options.isFrame});\n      continue;\n    }\n\n    // Included blocks are treated as an array of separate object nodes sharing\n    // the same referencing active_property.\n    // For 1.0, it is skipped as are other unknown keywords\n    if(expandedProperty === '@included' && _processingMode(activeCtx, 1.1)) {\n      const includedResult = _asArray(await api.expand({\n        activeCtx,\n        activeProperty,\n        element: value,\n        options\n      }));\n\n      // Expanded values must be node objects\n      if(!includedResult.every(v => _isSubject(v))) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; ' +\n          'values of @included must expand to node objects.',\n          'jsonld.SyntaxError', {code: 'invalid @included value', value});\n      }\n\n      _addValue(\n        expandedParent, '@included', includedResult, {propertyIsArray: true});\n      continue;\n    }\n\n    // @graph must be an array or an object\n    if(expandedProperty === '@graph' &&\n      !(_isObject(value) || _isArray(value))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; \"@graph\" value must not be an ' +\n        'object or an array.',\n        'jsonld.SyntaxError', {code: 'invalid @graph value', value});\n    }\n\n    if(expandedProperty === '@value') {\n      // capture value for later\n      // \"colliding keywords\" check prevents this from being set twice\n      unexpandedValue = value;\n      if(isJsonType && _processingMode(activeCtx, 1.1)) {\n        // no coercion to array, and retain all values\n        expandedParent['@value'] = value;\n      } else {\n        _addValue(\n          expandedParent, '@value', value, {propertyIsArray: options.isFrame});\n      }\n      continue;\n    }\n\n    // @language must be a string\n    // it should match BCP47\n    if(expandedProperty === '@language') {\n      if(value === null) {\n        // drop null @language values, they expand as if they didn't exist\n        continue;\n      }\n      if(!_isString(value) && !options.isFrame) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@language\" value must be a string.',\n          'jsonld.SyntaxError',\n          {code: 'invalid language-tagged string', value});\n      }\n      // ensure language value is lowercase\n      value = _asArray(value).map(v => _isString(v) ? v.toLowerCase() : v);\n\n      // ensure language tag matches BCP47\n      for(const language of value) {\n        if(_isString(language) && !language.match(REGEX_BCP47)) {\n          if(options.eventHandler) {\n            _handleEvent({\n              event: {\n                type: ['JsonLdEvent'],\n                code: 'invalid @language value',\n                level: 'warning',\n                message: '@language value must be valid BCP47.',\n                details: {\n                  language\n                }\n              },\n              options\n            });\n          }\n        }\n      }\n\n      _addValue(\n        expandedParent, '@language', value, {propertyIsArray: options.isFrame});\n      continue;\n    }\n\n    // @direction must be \"ltr\" or \"rtl\"\n    if(expandedProperty === '@direction') {\n      if(!_isString(value) && !options.isFrame) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@direction\" value must be a string.',\n          'jsonld.SyntaxError',\n          {code: 'invalid base direction', value});\n      }\n\n      value = _asArray(value);\n\n      // ensure direction is \"ltr\" or \"rtl\"\n      for(const dir of value) {\n        if(_isString(dir) && dir !== 'ltr' && dir !== 'rtl') {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; \"@direction\" must be \"ltr\" or \"rtl\".',\n            'jsonld.SyntaxError',\n            {code: 'invalid base direction', value});\n        }\n      }\n\n      _addValue(\n        expandedParent, '@direction', value,\n        {propertyIsArray: options.isFrame});\n      continue;\n    }\n\n    // @index must be a string\n    if(expandedProperty === '@index') {\n      if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@index\" value must be a string.',\n          'jsonld.SyntaxError',\n          {code: 'invalid @index value', value});\n      }\n      _addValue(expandedParent, '@index', value);\n      continue;\n    }\n\n    // @reverse must be an object\n    if(expandedProperty === '@reverse') {\n      if(!_isObject(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@reverse\" value must be an object.',\n          'jsonld.SyntaxError', {code: 'invalid @reverse value', value});\n      }\n\n      expandedValue = await api.expand({\n        activeCtx,\n        activeProperty: '@reverse',\n        element: value,\n        options\n      });\n      // properties double-reversed\n      if('@reverse' in expandedValue) {\n        for(const property in expandedValue['@reverse']) {\n          _addValue(\n            expandedParent, property, expandedValue['@reverse'][property],\n            {propertyIsArray: true});\n        }\n      }\n\n      // FIXME: can this be merged with code below to simplify?\n      // merge in all reversed properties\n      let reverseMap = expandedParent['@reverse'] || null;\n      for(const property in expandedValue) {\n        if(property === '@reverse') {\n          continue;\n        }\n        if(reverseMap === null) {\n          reverseMap = expandedParent['@reverse'] = {};\n        }\n        _addValue(reverseMap, property, [], {propertyIsArray: true});\n        const items = expandedValue[property];\n        for(let ii = 0; ii < items.length; ++ii) {\n          const item = items[ii];\n          if(_isValue(item) || _isList(item)) {\n            throw new JsonLdError(\n              'Invalid JSON-LD syntax; \"@reverse\" value must not be a ' +\n              '@value or an @list.', 'jsonld.SyntaxError',\n              {code: 'invalid reverse property value', value: expandedValue});\n          }\n          _addValue(reverseMap, property, item, {propertyIsArray: true});\n        }\n      }\n\n      continue;\n    }\n\n    // nested keys\n    if(expandedProperty === '@nest') {\n      nests.push(key);\n      continue;\n    }\n\n    // use potential scoped context for key\n    let termCtx = activeCtx;\n    const ctx = _getContextValue(activeCtx, key, '@context');\n    if(!_isUndefined(ctx)) {\n      termCtx = await _processContext({\n        activeCtx,\n        localCtx: ctx,\n        propagate: true,\n        overrideProtected: true,\n        options\n      });\n    }\n\n    const container = _getContextValue(activeCtx, key, '@container') || [];\n\n    if(container.includes('@language') && _isObject(value)) {\n      const direction = _getContextValue(termCtx, key, '@direction');\n      // handle language map container (skip if value is not an object)\n      expandedValue = _expandLanguageMap(termCtx, value, direction, options);\n    } else if(container.includes('@index') && _isObject(value)) {\n      // handle index container (skip if value is not an object)\n      const asGraph = container.includes('@graph');\n      const indexKey = _getContextValue(termCtx, key, '@index') || '@index';\n      const propertyIndex = indexKey !== '@index' &&\n        _expandIri(activeCtx, indexKey, {vocab: true}, options);\n\n      expandedValue = await _expandIndexMap({\n        activeCtx: termCtx,\n        options,\n        activeProperty: key,\n        value,\n        asGraph,\n        indexKey,\n        propertyIndex\n      });\n    } else if(container.includes('@id') && _isObject(value)) {\n      // handle id container (skip if value is not an object)\n      const asGraph = container.includes('@graph');\n      expandedValue = await _expandIndexMap({\n        activeCtx: termCtx,\n        options,\n        activeProperty: key,\n        value,\n        asGraph,\n        indexKey: '@id'\n      });\n    } else if(container.includes('@type') && _isObject(value)) {\n      // handle type container (skip if value is not an object)\n      expandedValue = await _expandIndexMap({\n        // since container is `@type`, revert type scoped context when expanding\n        activeCtx: termCtx.revertToPreviousContext(),\n        options,\n        activeProperty: key,\n        value,\n        asGraph: false,\n        indexKey: '@type'\n      });\n    } else {\n      // recurse into @list or @set\n      const isList = expandedProperty === '@list';\n      if(isList || expandedProperty === '@set') {\n        let nextActiveProperty = activeProperty;\n        if(isList && expandedActiveProperty === '@graph') {\n          nextActiveProperty = null;\n        }\n        expandedValue = await api.expand({\n          activeCtx: termCtx,\n          activeProperty: nextActiveProperty,\n          element: value,\n          options,\n          insideList: isList\n        });\n      } else if(\n        _getContextValue(activeCtx, key, '@type') === '@json') {\n        expandedValue = {\n          '@type': '@json',\n          '@value': value\n        };\n      } else {\n        // recursively expand value with key as new active property\n        expandedValue = await api.expand({\n          activeCtx: termCtx,\n          activeProperty: key,\n          element: value,\n          options,\n          insideList: false\n        });\n      }\n    }\n\n    // drop null values if property is not @value\n    if(expandedValue === null && expandedProperty !== '@value') {\n      // FIXME: event?\n      //unmappedValue: value,\n      //expandedProperty,\n      //key,\n      continue;\n    }\n\n    // convert expanded value to @list if container specifies it\n    if(expandedProperty !== '@list' && !_isList(expandedValue) &&\n      container.includes('@list')) {\n      // ensure expanded value in @list is an array\n      expandedValue = {'@list': _asArray(expandedValue)};\n    }\n\n    // convert expanded value to @graph if container specifies it\n    // and value is not, itself, a graph\n    // index cases handled above\n    if(container.includes('@graph') &&\n      !container.some(key => key === '@id' || key === '@index')) {\n      // ensure expanded values are in an array\n      expandedValue = _asArray(expandedValue);\n      if(!options.isFrame) {\n        // drop items if needed\n        expandedValue = expandedValue.filter(v => {\n          const count = Object.keys(v).length;\n          return _dropUnsafeObject({value: v, count, options}) !== null;\n        });\n      }\n      if(expandedValue.length === 0) {\n        // all items dropped, skip adding and continue\n        continue;\n      }\n      // convert to graph\n      expandedValue = expandedValue.map(v => ({'@graph': _asArray(v)}));\n    }\n\n    // FIXME: can this be merged with code above to simplify?\n    // merge in reverse properties\n    if(termCtx.mappings.has(key) && termCtx.mappings.get(key).reverse) {\n      const reverseMap =\n        expandedParent['@reverse'] = expandedParent['@reverse'] || {};\n      expandedValue = _asArray(expandedValue);\n      for(let ii = 0; ii < expandedValue.length; ++ii) {\n        const item = expandedValue[ii];\n        if(_isValue(item) || _isList(item)) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; \"@reverse\" value must not be a ' +\n            '@value or an @list.', 'jsonld.SyntaxError',\n            {code: 'invalid reverse property value', value: expandedValue});\n        }\n        _addValue(reverseMap, expandedProperty, item, {propertyIsArray: true});\n      }\n      continue;\n    }\n\n    // add value for property\n    // special keywords handled above\n    _addValue(expandedParent, expandedProperty, expandedValue, {\n      propertyIsArray: true\n    });\n  }\n\n  // @value must not be an object or an array (unless framing) or if @type is\n  // @json\n  if('@value' in expandedParent) {\n    if(expandedParent['@type'] === '@json' && _processingMode(activeCtx, 1.1)) {\n      // allow any value, to be verified when the object is fully expanded and\n      // the @type is @json.\n    } else if((_isObject(unexpandedValue) || _isArray(unexpandedValue)) &&\n      !options.isFrame) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; \"@value\" value must not be an ' +\n        'object or an array.',\n        'jsonld.SyntaxError',\n        {code: 'invalid value object value', value: unexpandedValue});\n    }\n  }\n\n  // expand each nested key\n  for(const key of nests) {\n    const nestedValues = _isArray(element[key]) ? element[key] : [element[key]];\n    for(const nv of nestedValues) {\n      if(!_isObject(nv) || Object.keys(nv).some(k =>\n        _expandIri(activeCtx, k, {vocab: true}, options) === '@value')) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; nested value must be a node object.',\n          'jsonld.SyntaxError',\n          {code: 'invalid @nest value', value: nv});\n      }\n      await _expandObject({\n        activeCtx,\n        activeProperty,\n        expandedActiveProperty,\n        element: nv,\n        expandedParent,\n        options,\n        insideList,\n        typeScopedContext,\n        typeKey\n      });\n    }\n  }\n}\n\n/**\n * Expands the given value by using the coercion and keyword rules in the\n * given context.\n *\n * @param activeCtx the active context to use.\n * @param activeProperty the active property the value is associated with.\n * @param value the value to expand.\n * @param {Object} [options] - processing options.\n *\n * @return the expanded value.\n */\nfunction _expandValue({activeCtx, activeProperty, value, options}) {\n  // nothing to expand\n  if(value === null || value === undefined) {\n    return null;\n  }\n\n  // special-case expand @id and @type (skips '@id' expansion)\n  const expandedProperty = _expandIri(\n    activeCtx, activeProperty, {vocab: true}, options);\n  if(expandedProperty === '@id') {\n    return _expandIri(activeCtx, value, {base: true}, options);\n  } else if(expandedProperty === '@type') {\n    return _expandIri(activeCtx, value, {vocab: true, base: true},\n      {...options, typeExpansion: true});\n  }\n\n  // get type definition from context\n  const type = _getContextValue(activeCtx, activeProperty, '@type');\n\n  // do @id expansion (automatic for @graph)\n  if((type === '@id' || expandedProperty === '@graph') && _isString(value)) {\n    const expandedValue = _expandIri(activeCtx, value, {base: true}, options);\n    // NOTE: handle spec edge case and avoid invalid {\"@id\": null}\n    if(expandedValue === null && value.match(REGEX_KEYWORD)) {\n      if(options.eventHandler) {\n        _handleEvent({\n          event: {\n            type: ['JsonLdEvent'],\n            code: 'reserved @id value',\n            level: 'warning',\n            message: 'Reserved @id found.',\n            details: {\n              id: activeProperty\n            }\n          },\n          options\n        });\n      }\n    }\n    return {'@id': expandedValue};\n  }\n  // do @id expansion w/vocab\n  if(type === '@vocab' && _isString(value)) {\n    return {\n      '@id': _expandIri(activeCtx, value, {vocab: true, base: true}, options)\n    };\n  }\n\n  // do not expand keyword values\n  if(_isKeyword(expandedProperty)) {\n    return value;\n  }\n\n  const rval = {};\n\n  if(type && !['@id', '@vocab', '@none'].includes(type)) {\n    // other type\n    rval['@type'] = type;\n  } else if(_isString(value)) {\n    // check for language tagging for strings\n    const language = _getContextValue(activeCtx, activeProperty, '@language');\n    if(language !== null) {\n      rval['@language'] = language;\n    }\n    const direction = _getContextValue(activeCtx, activeProperty, '@direction');\n    if(direction !== null) {\n      rval['@direction'] = direction;\n    }\n  }\n  // do conversion of values that aren't basic JSON types to strings\n  if(!['boolean', 'number', 'string'].includes(typeof value)) {\n    value = value.toString();\n  }\n  rval['@value'] = value;\n\n  return rval;\n}\n\n/**\n * Expands a language map.\n *\n * @param activeCtx the active context to use.\n * @param languageMap the language map to expand.\n * @param direction the direction to apply to values.\n * @param {Object} [options] - processing options.\n *\n * @return the expanded language map.\n */\nfunction _expandLanguageMap(activeCtx, languageMap, direction, options) {\n  const rval = [];\n  const keys = Object.keys(languageMap).sort();\n  for(const key of keys) {\n    const expandedKey = _expandIri(activeCtx, key, {vocab: true}, options);\n    let val = languageMap[key];\n    if(!_isArray(val)) {\n      val = [val];\n    }\n    for(const item of val) {\n      if(item === null) {\n        // null values are allowed (8.5) but ignored (3.1)\n        continue;\n      }\n      if(!_isString(item)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; language map values must be strings.',\n          'jsonld.SyntaxError',\n          {code: 'invalid language map value', languageMap});\n      }\n      const val = {'@value': item};\n      if(expandedKey !== '@none') {\n        if(!key.match(REGEX_BCP47)) {\n          if(options.eventHandler) {\n            _handleEvent({\n              event: {\n                type: ['JsonLdEvent'],\n                code: 'invalid @language value',\n                level: 'warning',\n                message: '@language value must be valid BCP47.',\n                details: {\n                  language: key\n                }\n              },\n              options\n            });\n          }\n        }\n        val['@language'] = key.toLowerCase();\n      }\n      if(direction) {\n        val['@direction'] = direction;\n      }\n      rval.push(val);\n    }\n  }\n  return rval;\n}\n\nasync function _expandIndexMap({\n  activeCtx, options, activeProperty, value, asGraph, indexKey, propertyIndex\n}) {\n  const rval = [];\n  const keys = Object.keys(value).sort();\n  const isTypeIndex = indexKey === '@type';\n  for(let key of keys) {\n    // if indexKey is @type, there may be a context defined for it\n    if(isTypeIndex) {\n      const ctx = _getContextValue(activeCtx, key, '@context');\n      if(!_isUndefined(ctx)) {\n        activeCtx = await _processContext({\n          activeCtx,\n          localCtx: ctx,\n          propagate: false,\n          options\n        });\n      }\n    }\n\n    let val = value[key];\n    if(!_isArray(val)) {\n      val = [val];\n    }\n\n    val = await api.expand({\n      activeCtx,\n      activeProperty,\n      element: val,\n      options,\n      insideList: false,\n      insideIndex: true\n    });\n\n    // expand for @type, but also for @none\n    let expandedKey;\n    if(propertyIndex) {\n      if(key === '@none') {\n        expandedKey = '@none';\n      } else {\n        expandedKey = _expandValue(\n          {activeCtx, activeProperty: indexKey, value: key, options});\n      }\n    } else {\n      expandedKey = _expandIri(activeCtx, key, {vocab: true}, options);\n    }\n\n    if(indexKey === '@id') {\n      // expand document relative\n      key = _expandIri(activeCtx, key, {base: true}, options);\n    } else if(isTypeIndex) {\n      key = expandedKey;\n    }\n\n    for(let item of val) {\n      // If this is also a @graph container, turn items into graphs\n      if(asGraph && !_isGraph(item)) {\n        item = {'@graph': [item]};\n      }\n      if(indexKey === '@type') {\n        if(expandedKey === '@none') {\n          // ignore @none\n        } else if(item['@type']) {\n          item['@type'] = [key].concat(item['@type']);\n        } else {\n          item['@type'] = [key];\n        }\n      } else if(_isValue(item) &&\n        !['@language', '@type', '@index'].includes(indexKey)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; Attempt to add illegal key to value ' +\n          `object: \"${indexKey}\".`,\n          'jsonld.SyntaxError',\n          {code: 'invalid value object', value: item});\n      } else if(propertyIndex) {\n        // index is a property to be expanded, and values interpreted for that\n        // property\n        if(expandedKey !== '@none') {\n          // expand key as a value\n          _addValue(item, propertyIndex, expandedKey, {\n            propertyIsArray: true,\n            prependValue: true\n          });\n        }\n      } else if(expandedKey !== '@none' && !(indexKey in item)) {\n        item[indexKey] = key;\n      }\n      rval.push(item);\n    }\n  }\n  return rval;\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/expand.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/flatten.js":
/*!********************************************!*\
  !*** ./node_modules/jsonld/lib/flatten.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst {\n  isSubjectReference: _isSubjectReference\n} = __webpack_require__(/*! ./graphTypes */ \"./node_modules/jsonld/lib/graphTypes.js\");\n\nconst {\n  createMergedNodeMap: _createMergedNodeMap\n} = __webpack_require__(/*! ./nodeMap */ \"./node_modules/jsonld/lib/nodeMap.js\");\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Performs JSON-LD flattening.\n *\n * @param input the expanded JSON-LD to flatten.\n *\n * @return the flattened output.\n */\napi.flatten = input => {\n  const defaultGraph = _createMergedNodeMap(input);\n\n  // produce flattened output\n  const flattened = [];\n  const keys = Object.keys(defaultGraph).sort();\n  for(let ki = 0; ki < keys.length; ++ki) {\n    const node = defaultGraph[keys[ki]];\n    // only add full subjects to top-level\n    if(!_isSubjectReference(node)) {\n      flattened.push(node);\n    }\n  }\n  return flattened;\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/flatten.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/frame.js":
/*!******************************************!*\
  !*** ./node_modules/jsonld/lib/frame.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst {isKeyword} = __webpack_require__(/*! ./context */ \"./node_modules/jsonld/lib/context.js\");\nconst graphTypes = __webpack_require__(/*! ./graphTypes */ \"./node_modules/jsonld/lib/graphTypes.js\");\nconst types = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\nconst util = __webpack_require__(/*! ./util */ \"./node_modules/jsonld/lib/util.js\");\nconst url = __webpack_require__(/*! ./url */ \"./node_modules/jsonld/lib/url.js\");\nconst JsonLdError = __webpack_require__(/*! ./JsonLdError */ \"./node_modules/jsonld/lib/JsonLdError.js\");\nconst {\n  createNodeMap: _createNodeMap,\n  mergeNodeMapGraphs: _mergeNodeMapGraphs\n} = __webpack_require__(/*! ./nodeMap */ \"./node_modules/jsonld/lib/nodeMap.js\");\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Performs JSON-LD `merged` framing.\n *\n * @param input the expanded JSON-LD to frame.\n * @param frame the expanded JSON-LD frame to use.\n * @param options the framing options.\n *\n * @return the framed output.\n */\napi.frameMergedOrDefault = (input, frame, options) => {\n  // create framing state\n  const state = {\n    options,\n    embedded: false,\n    graph: '@default',\n    graphMap: {'@default': {}},\n    subjectStack: [],\n    link: {},\n    bnodeMap: {}\n  };\n\n  // produce a map of all graphs and name each bnode\n  // FIXME: currently uses subjects from @merged graph only\n  const issuer = new util.IdentifierIssuer('_:b');\n  _createNodeMap(input, state.graphMap, '@default', issuer);\n  if(options.merged) {\n    state.graphMap['@merged'] = _mergeNodeMapGraphs(state.graphMap);\n    state.graph = '@merged';\n  }\n  state.subjects = state.graphMap[state.graph];\n\n  // frame the subjects\n  const framed = [];\n  api.frame(state, Object.keys(state.subjects).sort(), frame, framed);\n\n  // If pruning blank nodes, find those to prune\n  if(options.pruneBlankNodeIdentifiers) {\n    // remove all blank nodes appearing only once, done in compaction\n    options.bnodesToClear =\n      Object.keys(state.bnodeMap).filter(id => state.bnodeMap[id].length === 1);\n  }\n\n  // remove @preserve from results\n  options.link = {};\n  return _cleanupPreserve(framed, options);\n};\n\n/**\n * Frames subjects according to the given frame.\n *\n * @param state the current framing state.\n * @param subjects the subjects to filter.\n * @param frame the frame.\n * @param parent the parent subject or top-level array.\n * @param property the parent property, initialized to null.\n */\napi.frame = (state, subjects, frame, parent, property = null) => {\n  // validate the frame\n  _validateFrame(frame);\n  frame = frame[0];\n\n  // get flags for current frame\n  const options = state.options;\n  const flags = {\n    embed: _getFrameFlag(frame, options, 'embed'),\n    explicit: _getFrameFlag(frame, options, 'explicit'),\n    requireAll: _getFrameFlag(frame, options, 'requireAll')\n  };\n\n  // get link for current graph\n  if(!state.link.hasOwnProperty(state.graph)) {\n    state.link[state.graph] = {};\n  }\n  const link = state.link[state.graph];\n\n  // filter out subjects that match the frame\n  const matches = _filterSubjects(state, subjects, frame, flags);\n\n  // add matches to output\n  const ids = Object.keys(matches).sort();\n  for(const id of ids) {\n    const subject = matches[id];\n\n    /* Note: In order to treat each top-level match as a compartmentalized\n    result, clear the unique embedded subjects map when the property is null,\n    which only occurs at the top-level. */\n    if(property === null) {\n      state.uniqueEmbeds = {[state.graph]: {}};\n    } else {\n      state.uniqueEmbeds[state.graph] = state.uniqueEmbeds[state.graph] || {};\n    }\n\n    if(flags.embed === '@link' && id in link) {\n      // TODO: may want to also match an existing linked subject against\n      // the current frame ... so different frames could produce different\n      // subjects that are only shared in-memory when the frames are the same\n\n      // add existing linked subject\n      _addFrameOutput(parent, property, link[id]);\n      continue;\n    }\n\n    // start output for subject\n    const output = {'@id': id};\n    if(id.indexOf('_:') === 0) {\n      util.addValue(state.bnodeMap, id, output, {propertyIsArray: true});\n    }\n    link[id] = output;\n\n    // validate @embed\n    if((flags.embed === '@first' || flags.embed === '@last') && state.is11) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; invalid value of @embed.',\n        'jsonld.SyntaxError', {code: 'invalid @embed value', frame});\n    }\n\n    if(!state.embedded && state.uniqueEmbeds[state.graph].hasOwnProperty(id)) {\n      // skip adding this node object to the top level, as it was\n      // already included in another node object\n      continue;\n    }\n\n    // if embed is @never or if a circular reference would be created by an\n    // embed, the subject cannot be embedded, just add the reference;\n    // note that a circular reference won't occur when the embed flag is\n    // `@link` as the above check will short-circuit before reaching this point\n    if(state.embedded &&\n      (flags.embed === '@never' ||\n      _createsCircularReference(subject, state.graph, state.subjectStack))) {\n      _addFrameOutput(parent, property, output);\n      continue;\n    }\n\n    // if only the first (or once) should be embedded\n    if(state.embedded &&\n       (flags.embed == '@first' || flags.embed == '@once') &&\n       state.uniqueEmbeds[state.graph].hasOwnProperty(id)) {\n      _addFrameOutput(parent, property, output);\n      continue;\n    }\n\n    // if only the last match should be embedded\n    if(flags.embed === '@last') {\n      // remove any existing embed\n      if(id in state.uniqueEmbeds[state.graph]) {\n        _removeEmbed(state, id);\n      }\n    }\n\n    state.uniqueEmbeds[state.graph][id] = {parent, property};\n\n    // push matching subject onto stack to enable circular embed checks\n    state.subjectStack.push({subject, graph: state.graph});\n\n    // subject is also the name of a graph\n    if(id in state.graphMap) {\n      let recurse = false;\n      let subframe = null;\n      if(!('@graph' in frame)) {\n        recurse = state.graph !== '@merged';\n        subframe = {};\n      } else {\n        subframe = frame['@graph'][0];\n        recurse = !(id === '@merged' || id === '@default');\n        if(!types.isObject(subframe)) {\n          subframe = {};\n        }\n      }\n\n      if(recurse) {\n        // recurse into graph\n        api.frame(\n          {...state, graph: id, embedded: false},\n          Object.keys(state.graphMap[id]).sort(), [subframe], output, '@graph');\n      }\n    }\n\n    // if frame has @included, recurse over its sub-frame\n    if('@included' in frame) {\n      api.frame(\n        {...state, embedded: false},\n        subjects, frame['@included'], output, '@included');\n    }\n\n    // iterate over subject properties\n    for(const prop of Object.keys(subject).sort()) {\n      // copy keywords to output\n      if(isKeyword(prop)) {\n        output[prop] = util.clone(subject[prop]);\n\n        if(prop === '@type') {\n          // count bnode values of @type\n          for(const type of subject['@type']) {\n            if(type.indexOf('_:') === 0) {\n              util.addValue(\n                state.bnodeMap, type, output, {propertyIsArray: true});\n            }\n          }\n        }\n        continue;\n      }\n\n      // explicit is on and property isn't in the frame, skip processing\n      if(flags.explicit && !(prop in frame)) {\n        continue;\n      }\n\n      // add objects\n      for(const o of subject[prop]) {\n        const subframe = (prop in frame ?\n          frame[prop] : _createImplicitFrame(flags));\n\n        // recurse into list\n        if(graphTypes.isList(o)) {\n          const subframe =\n            (frame[prop] && frame[prop][0] && frame[prop][0]['@list']) ?\n              frame[prop][0]['@list'] :\n              _createImplicitFrame(flags);\n\n          // add empty list\n          const list = {'@list': []};\n          _addFrameOutput(output, prop, list);\n\n          // add list objects\n          const src = o['@list'];\n          for(const oo of src) {\n            if(graphTypes.isSubjectReference(oo)) {\n              // recurse into subject reference\n              api.frame(\n                {...state, embedded: true},\n                [oo['@id']], subframe, list, '@list');\n            } else {\n              // include other values automatically\n              _addFrameOutput(list, '@list', util.clone(oo));\n            }\n          }\n        } else if(graphTypes.isSubjectReference(o)) {\n          // recurse into subject reference\n          api.frame(\n            {...state, embedded: true},\n            [o['@id']], subframe, output, prop);\n        } else if(_valueMatch(subframe[0], o)) {\n          // include other values, if they match\n          _addFrameOutput(output, prop, util.clone(o));\n        }\n      }\n    }\n\n    // handle defaults\n    for(const prop of Object.keys(frame).sort()) {\n      // skip keywords\n      if(prop === '@type') {\n        if(!types.isObject(frame[prop][0]) ||\n           !('@default' in frame[prop][0])) {\n          continue;\n        }\n        // allow through default types\n      } else if(isKeyword(prop)) {\n        continue;\n      }\n\n      // if omit default is off, then include default values for properties\n      // that appear in the next frame but are not in the matching subject\n      const next = frame[prop][0] || {};\n      const omitDefaultOn = _getFrameFlag(next, options, 'omitDefault');\n      if(!omitDefaultOn && !(prop in output)) {\n        let preserve = '@null';\n        if('@default' in next) {\n          preserve = util.clone(next['@default']);\n        }\n        if(!types.isArray(preserve)) {\n          preserve = [preserve];\n        }\n        output[prop] = [{'@preserve': preserve}];\n      }\n    }\n\n    // if embed reverse values by finding nodes having this subject as a value\n    // of the associated property\n    for(const reverseProp of Object.keys(frame['@reverse'] || {}).sort()) {\n      const subframe = frame['@reverse'][reverseProp];\n      for(const subject of Object.keys(state.subjects)) {\n        const nodeValues =\n          util.getValues(state.subjects[subject], reverseProp);\n        if(nodeValues.some(v => v['@id'] === id)) {\n          // node has property referencing this subject, recurse\n          output['@reverse'] = output['@reverse'] || {};\n          util.addValue(\n            output['@reverse'], reverseProp, [], {propertyIsArray: true});\n          api.frame(\n            {...state, embedded: true},\n            [subject], subframe, output['@reverse'][reverseProp],\n            property);\n        }\n      }\n    }\n\n    // add output to parent\n    _addFrameOutput(parent, property, output);\n\n    // pop matching subject from circular ref-checking stack\n    state.subjectStack.pop();\n  }\n};\n\n/**\n * Replace `@null` with `null`, removing it from arrays.\n *\n * @param input the framed, compacted output.\n * @param options the framing options used.\n *\n * @return the resulting output.\n */\napi.cleanupNull = (input, options) => {\n  // recurse through arrays\n  if(types.isArray(input)) {\n    const noNulls = input.map(v => api.cleanupNull(v, options));\n    return noNulls.filter(v => v); // removes nulls from array\n  }\n\n  if(input === '@null') {\n    return null;\n  }\n\n  if(types.isObject(input)) {\n    // handle in-memory linked nodes\n    if('@id' in input) {\n      const id = input['@id'];\n      if(options.link.hasOwnProperty(id)) {\n        const idx = options.link[id].indexOf(input);\n        if(idx !== -1) {\n          // already visited\n          return options.link[id][idx];\n        }\n        // prevent circular visitation\n        options.link[id].push(input);\n      } else {\n        // prevent circular visitation\n        options.link[id] = [input];\n      }\n    }\n\n    for(const key in input) {\n      input[key] = api.cleanupNull(input[key], options);\n    }\n  }\n  return input;\n};\n\n/**\n * Creates an implicit frame when recursing through subject matches. If\n * a frame doesn't have an explicit frame for a particular property, then\n * a wildcard child frame will be created that uses the same flags that the\n * parent frame used.\n *\n * @param flags the current framing flags.\n *\n * @return the implicit frame.\n */\nfunction _createImplicitFrame(flags) {\n  const frame = {};\n  for(const key in flags) {\n    if(flags[key] !== undefined) {\n      frame['@' + key] = [flags[key]];\n    }\n  }\n  return [frame];\n}\n\n/**\n * Checks the current subject stack to see if embedding the given subject\n * would cause a circular reference.\n *\n * @param subjectToEmbed the subject to embed.\n * @param graph the graph the subject to embed is in.\n * @param subjectStack the current stack of subjects.\n *\n * @return true if a circular reference would be created, false if not.\n */\nfunction _createsCircularReference(subjectToEmbed, graph, subjectStack) {\n  for(let i = subjectStack.length - 1; i >= 0; --i) {\n    const subject = subjectStack[i];\n    if(subject.graph === graph &&\n      subject.subject['@id'] === subjectToEmbed['@id']) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Gets the frame flag value for the given flag name.\n *\n * @param frame the frame.\n * @param options the framing options.\n * @param name the flag name.\n *\n * @return the flag value.\n */\nfunction _getFrameFlag(frame, options, name) {\n  const flag = '@' + name;\n  let rval = (flag in frame ? frame[flag][0] : options[name]);\n  if(name === 'embed') {\n    // default is \"@last\"\n    // backwards-compatibility support for \"embed\" maps:\n    // true => \"@last\"\n    // false => \"@never\"\n    if(rval === true) {\n      rval = '@once';\n    } else if(rval === false) {\n      rval = '@never';\n    } else if(rval !== '@always' && rval !== '@never' && rval !== '@link' &&\n      rval !== '@first' && rval !== '@last' && rval !== '@once') {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; invalid value of @embed.',\n        'jsonld.SyntaxError', {code: 'invalid @embed value', frame});\n    }\n  }\n  return rval;\n}\n\n/**\n * Validates a JSON-LD frame, throwing an exception if the frame is invalid.\n *\n * @param frame the frame to validate.\n */\nfunction _validateFrame(frame) {\n  if(!types.isArray(frame) || frame.length !== 1 || !types.isObject(frame[0])) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; a JSON-LD frame must be a single object.',\n      'jsonld.SyntaxError', {frame});\n  }\n\n  if('@id' in frame[0]) {\n    for(const id of util.asArray(frame[0]['@id'])) {\n      // @id must be wildcard or an IRI\n      if(!(types.isObject(id) || url.isAbsolute(id)) ||\n        (types.isString(id) && id.indexOf('_:') === 0)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; invalid @id in frame.',\n          'jsonld.SyntaxError', {code: 'invalid frame', frame});\n      }\n    }\n  }\n\n  if('@type' in frame[0]) {\n    for(const type of util.asArray(frame[0]['@type'])) {\n      // @type must be wildcard, IRI, or @json\n      if(!(types.isObject(type) || url.isAbsolute(type) ||\n          (type === '@json')) ||\n        (types.isString(type) && type.indexOf('_:') === 0)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; invalid @type in frame.',\n          'jsonld.SyntaxError', {code: 'invalid frame', frame});\n      }\n    }\n  }\n}\n\n/**\n * Returns a map of all of the subjects that match a parsed frame.\n *\n * @param state the current framing state.\n * @param subjects the set of subjects to filter.\n * @param frame the parsed frame.\n * @param flags the frame flags.\n *\n * @return all of the matched subjects.\n */\nfunction _filterSubjects(state, subjects, frame, flags) {\n  // filter subjects in @id order\n  const rval = {};\n  for(const id of subjects) {\n    const subject = state.graphMap[state.graph][id];\n    if(_filterSubject(state, subject, frame, flags)) {\n      rval[id] = subject;\n    }\n  }\n  return rval;\n}\n\n/**\n * Returns true if the given subject matches the given frame.\n *\n * Matches either based on explicit type inclusion where the node has any\n * type listed in the frame. If the frame has empty types defined matches\n * nodes not having a @type. If the frame has a type of {} defined matches\n * nodes having any type defined.\n *\n * Otherwise, does duck typing, where the node must have all of the\n * properties defined in the frame.\n *\n * @param state the current framing state.\n * @param subject the subject to check.\n * @param frame the frame to check.\n * @param flags the frame flags.\n *\n * @return true if the subject matches, false if not.\n */\nfunction _filterSubject(state, subject, frame, flags) {\n  // check ducktype\n  let wildcard = true;\n  let matchesSome = false;\n\n  for(const key in frame) {\n    let matchThis = false;\n    const nodeValues = util.getValues(subject, key);\n    const isEmpty = util.getValues(frame, key).length === 0;\n\n    if(key === '@id') {\n      // match on no @id or any matching @id, including wildcard\n      if(types.isEmptyObject(frame['@id'][0] || {})) {\n        matchThis = true;\n      } else if(frame['@id'].length >= 0) {\n        matchThis = frame['@id'].includes(nodeValues[0]);\n      }\n      if(!flags.requireAll) {\n        return matchThis;\n      }\n    } else if(key === '@type') {\n      // check @type (object value means 'any' type,\n      // fall through to ducktyping)\n      wildcard = false;\n      if(isEmpty) {\n        if(nodeValues.length > 0) {\n          // don't match on no @type\n          return false;\n        }\n        matchThis = true;\n      } else if(frame['@type'].length === 1 &&\n        types.isEmptyObject(frame['@type'][0])) {\n        // match on wildcard @type if there is a type\n        matchThis = nodeValues.length > 0;\n      } else {\n        // match on a specific @type\n        for(const type of frame['@type']) {\n          if(types.isObject(type) && '@default' in type) {\n            // match on default object\n            matchThis = true;\n          } else {\n            matchThis = matchThis || nodeValues.some(tt => tt === type);\n          }\n        }\n      }\n      if(!flags.requireAll) {\n        return matchThis;\n      }\n    } else if(isKeyword(key)) {\n      continue;\n    } else {\n      // Force a copy of this frame entry so it can be manipulated\n      const thisFrame = util.getValues(frame, key)[0];\n      let hasDefault = false;\n      if(thisFrame) {\n        _validateFrame([thisFrame]);\n        hasDefault = '@default' in thisFrame;\n      }\n\n      // no longer a wildcard pattern if frame has any non-keyword properties\n      wildcard = false;\n\n      // skip, but allow match if node has no value for property, and frame has\n      // a default value\n      if(nodeValues.length === 0 && hasDefault) {\n        continue;\n      }\n\n      // if frame value is empty, don't match if subject has any value\n      if(nodeValues.length > 0 && isEmpty) {\n        return false;\n      }\n\n      if(thisFrame === undefined) {\n        // node does not match if values is not empty and the value of property\n        // in frame is match none.\n        if(nodeValues.length > 0) {\n          return false;\n        }\n        matchThis = true;\n      } else {\n        if(graphTypes.isList(thisFrame)) {\n          const listValue = thisFrame['@list'][0];\n          if(graphTypes.isList(nodeValues[0])) {\n            const nodeListValues = nodeValues[0]['@list'];\n\n            if(graphTypes.isValue(listValue)) {\n              // match on any matching value\n              matchThis = nodeListValues.some(lv => _valueMatch(listValue, lv));\n            } else if(graphTypes.isSubject(listValue) ||\n              graphTypes.isSubjectReference(listValue)) {\n              matchThis = nodeListValues.some(lv => _nodeMatch(\n                state, listValue, lv, flags));\n            }\n          }\n        } else if(graphTypes.isValue(thisFrame)) {\n          matchThis = nodeValues.some(nv => _valueMatch(thisFrame, nv));\n        } else if(graphTypes.isSubjectReference(thisFrame)) {\n          matchThis =\n            nodeValues.some(nv => _nodeMatch(state, thisFrame, nv, flags));\n        } else if(types.isObject(thisFrame)) {\n          matchThis = nodeValues.length > 0;\n        } else {\n          matchThis = false;\n        }\n      }\n    }\n\n    // all non-defaulted values must match if requireAll is set\n    if(!matchThis && flags.requireAll) {\n      return false;\n    }\n\n    matchesSome = matchesSome || matchThis;\n  }\n\n  // return true if wildcard or subject matches some properties\n  return wildcard || matchesSome;\n}\n\n/**\n * Removes an existing embed.\n *\n * @param state the current framing state.\n * @param id the @id of the embed to remove.\n */\nfunction _removeEmbed(state, id) {\n  // get existing embed\n  const embeds = state.uniqueEmbeds[state.graph];\n  const embed = embeds[id];\n  const parent = embed.parent;\n  const property = embed.property;\n\n  // create reference to replace embed\n  const subject = {'@id': id};\n\n  // remove existing embed\n  if(types.isArray(parent)) {\n    // replace subject with reference\n    for(let i = 0; i < parent.length; ++i) {\n      if(util.compareValues(parent[i], subject)) {\n        parent[i] = subject;\n        break;\n      }\n    }\n  } else {\n    // replace subject with reference\n    const useArray = types.isArray(parent[property]);\n    util.removeValue(parent, property, subject, {propertyIsArray: useArray});\n    util.addValue(parent, property, subject, {propertyIsArray: useArray});\n  }\n\n  // recursively remove dependent dangling embeds\n  const removeDependents = id => {\n    // get embed keys as a separate array to enable deleting keys in map\n    const ids = Object.keys(embeds);\n    for(const next of ids) {\n      if(next in embeds && types.isObject(embeds[next].parent) &&\n        embeds[next].parent['@id'] === id) {\n        delete embeds[next];\n        removeDependents(next);\n      }\n    }\n  };\n  removeDependents(id);\n}\n\n/**\n * Removes the @preserve keywords from expanded result of framing.\n *\n * @param input the framed, framed output.\n * @param options the framing options used.\n *\n * @return the resulting output.\n */\nfunction _cleanupPreserve(input, options) {\n  // recurse through arrays\n  if(types.isArray(input)) {\n    return input.map(value => _cleanupPreserve(value, options));\n  }\n\n  if(types.isObject(input)) {\n    // remove @preserve\n    if('@preserve' in input) {\n      return input['@preserve'][0];\n    }\n\n    // skip @values\n    if(graphTypes.isValue(input)) {\n      return input;\n    }\n\n    // recurse through @lists\n    if(graphTypes.isList(input)) {\n      input['@list'] = _cleanupPreserve(input['@list'], options);\n      return input;\n    }\n\n    // handle in-memory linked nodes\n    if('@id' in input) {\n      const id = input['@id'];\n      if(options.link.hasOwnProperty(id)) {\n        const idx = options.link[id].indexOf(input);\n        if(idx !== -1) {\n          // already visited\n          return options.link[id][idx];\n        }\n        // prevent circular visitation\n        options.link[id].push(input);\n      } else {\n        // prevent circular visitation\n        options.link[id] = [input];\n      }\n    }\n\n    // recurse through properties\n    for(const prop in input) {\n      // potentially remove the id, if it is an unreference bnode\n      if(prop === '@id' && options.bnodesToClear.includes(input[prop])) {\n        delete input['@id'];\n        continue;\n      }\n\n      input[prop] = _cleanupPreserve(input[prop], options);\n    }\n  }\n  return input;\n}\n\n/**\n * Adds framing output to the given parent.\n *\n * @param parent the parent to add to.\n * @param property the parent property.\n * @param output the output to add.\n */\nfunction _addFrameOutput(parent, property, output) {\n  if(types.isObject(parent)) {\n    util.addValue(parent, property, output, {propertyIsArray: true});\n  } else {\n    parent.push(output);\n  }\n}\n\n/**\n * Node matches if it is a node, and matches the pattern as a frame.\n *\n * @param state the current framing state.\n * @param pattern used to match value\n * @param value to check\n * @param flags the frame flags.\n */\nfunction _nodeMatch(state, pattern, value, flags) {\n  if(!('@id' in value)) {\n    return false;\n  }\n  const nodeObject = state.subjects[value['@id']];\n  return nodeObject && _filterSubject(state, nodeObject, pattern, flags);\n}\n\n/**\n * Value matches if it is a value and matches the value pattern\n *\n * * `pattern` is empty\n * * @values are the same, or `pattern[@value]` is a wildcard, and\n * * @types are the same or `value[@type]` is not null\n *   and `pattern[@type]` is `{}`, or `value[@type]` is null\n *   and `pattern[@type]` is null or `[]`, and\n * * @languages are the same or `value[@language]` is not null\n *   and `pattern[@language]` is `{}`, or `value[@language]` is null\n *   and `pattern[@language]` is null or `[]`.\n *\n * @param pattern used to match value\n * @param value to check\n */\nfunction _valueMatch(pattern, value) {\n  const v1 = value['@value'];\n  const t1 = value['@type'];\n  const l1 = value['@language'];\n  const v2 = pattern['@value'] ?\n    (types.isArray(pattern['@value']) ?\n      pattern['@value'] : [pattern['@value']]) :\n    [];\n  const t2 = pattern['@type'] ?\n    (types.isArray(pattern['@type']) ?\n      pattern['@type'] : [pattern['@type']]) :\n    [];\n  const l2 = pattern['@language'] ?\n    (types.isArray(pattern['@language']) ?\n      pattern['@language'] : [pattern['@language']]) :\n    [];\n\n  if(v2.length === 0 && t2.length === 0 && l2.length === 0) {\n    return true;\n  }\n  if(!(v2.includes(v1) || types.isEmptyObject(v2[0]))) {\n    return false;\n  }\n  if(!(!t1 && t2.length === 0 || t2.includes(t1) || t1 &&\n    types.isEmptyObject(t2[0]))) {\n    return false;\n  }\n  if(!(!l1 && l2.length === 0 || l2.includes(l1) || l1 &&\n    types.isEmptyObject(l2[0]))) {\n    return false;\n  }\n  return true;\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/frame.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/fromRdf.js":
/*!********************************************!*\
  !*** ./node_modules/jsonld/lib/fromRdf.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017-2023 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst JsonLdError = __webpack_require__(/*! ./JsonLdError */ \"./node_modules/jsonld/lib/JsonLdError.js\");\nconst graphTypes = __webpack_require__(/*! ./graphTypes */ \"./node_modules/jsonld/lib/graphTypes.js\");\nconst types = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\n\nconst {\n  REGEX_BCP47,\n  addValue: _addValue\n} = __webpack_require__(/*! ./util */ \"./node_modules/jsonld/lib/util.js\");\n\nconst {\n  handleEvent: _handleEvent\n} = __webpack_require__(/*! ./events */ \"./node_modules/jsonld/lib/events.js\");\n\n// constants\nconst {\n  // RDF,\n  RDF_LIST,\n  RDF_FIRST,\n  RDF_REST,\n  RDF_NIL,\n  RDF_TYPE,\n  // RDF_PLAIN_LITERAL,\n  // RDF_XML_LITERAL,\n  RDF_JSON_LITERAL,\n  // RDF_OBJECT,\n  // RDF_LANGSTRING,\n\n  // XSD,\n  XSD_BOOLEAN,\n  XSD_DOUBLE,\n  XSD_INTEGER,\n  XSD_STRING,\n} = __webpack_require__(/*! ./constants */ \"./node_modules/jsonld/lib/constants.js\");\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Converts an RDF dataset to JSON-LD.\n *\n * @param dataset the RDF dataset.\n * @param options the RDF serialization options.\n *\n * @return a Promise that resolves to the JSON-LD output.\n */\napi.fromRDF = async (\n  dataset,\n  options\n) => {\n  const {\n    useRdfType = false,\n    useNativeTypes = false,\n    rdfDirection = null\n  } = options;\n  // FIXME: use Maps?\n  const defaultGraph = {};\n  const graphMap = {'@default': defaultGraph};\n  const referencedOnce = {};\n  if(rdfDirection) {\n    if(rdfDirection === 'compound-literal') {\n      throw new JsonLdError(\n        'Unsupported rdfDirection value.',\n        'jsonld.InvalidRdfDirection',\n        {value: rdfDirection});\n    } else if(rdfDirection !== 'i18n-datatype') {\n      throw new JsonLdError(\n        'Unknown rdfDirection value.',\n        'jsonld.InvalidRdfDirection',\n        {value: rdfDirection});\n    }\n  }\n\n  for(const quad of dataset) {\n    // TODO: change 'name' to 'graph'\n    const name = (quad.graph.termType === 'DefaultGraph') ?\n      '@default' : quad.graph.value;\n    if(!(name in graphMap)) {\n      graphMap[name] = {};\n    }\n    if(name !== '@default' && !(name in defaultGraph)) {\n      defaultGraph[name] = {'@id': name};\n    }\n\n    const nodeMap = graphMap[name];\n\n    // get subject, predicate, object\n    const s = quad.subject.value;\n    const p = quad.predicate.value;\n    const o = quad.object;\n\n    if(!(s in nodeMap)) {\n      nodeMap[s] = {'@id': s};\n    }\n    const node = nodeMap[s];\n\n    const objectIsNode = o.termType.endsWith('Node');\n    if(objectIsNode && !(o.value in nodeMap)) {\n      nodeMap[o.value] = {'@id': o.value};\n    }\n\n    if(p === RDF_TYPE && !useRdfType && objectIsNode) {\n      _addValue(node, '@type', o.value, {propertyIsArray: true});\n      continue;\n    }\n\n    const value = _RDFToObject(o, useNativeTypes, rdfDirection, options);\n    _addValue(node, p, value, {propertyIsArray: true});\n\n    // object may be an RDF list/partial list node but we can't know easily\n    // until all triples are read\n    if(objectIsNode) {\n      if(o.value === RDF_NIL) {\n        // track rdf:nil uniquely per graph\n        const object = nodeMap[o.value];\n        if(!('usages' in object)) {\n          object.usages = [];\n        }\n        object.usages.push({\n          node,\n          property: p,\n          value\n        });\n      } else if(o.value in referencedOnce) {\n        // object referenced more than once\n        referencedOnce[o.value] = false;\n      } else {\n        // keep track of single reference\n        referencedOnce[o.value] = {\n          node,\n          property: p,\n          value\n        };\n      }\n    }\n  }\n\n  /*\n  for(let name in dataset) {\n    const graph = dataset[name];\n    if(!(name in graphMap)) {\n      graphMap[name] = {};\n    }\n    if(name !== '@default' && !(name in defaultGraph)) {\n      defaultGraph[name] = {'@id': name};\n    }\n    const nodeMap = graphMap[name];\n    for(let ti = 0; ti < graph.length; ++ti) {\n      const triple = graph[ti];\n\n      // get subject, predicate, object\n      const s = triple.subject.value;\n      const p = triple.predicate.value;\n      const o = triple.object;\n\n      if(!(s in nodeMap)) {\n        nodeMap[s] = {'@id': s};\n      }\n      const node = nodeMap[s];\n\n      const objectIsId = (o.type === 'IRI' || o.type === 'blank node');\n      if(objectIsId && !(o.value in nodeMap)) {\n        nodeMap[o.value] = {'@id': o.value};\n      }\n\n      if(p === RDF_TYPE && !useRdfType && objectIsId) {\n        _addValue(node, '@type', o.value, {propertyIsArray: true});\n        continue;\n      }\n\n      const value = _RDFToObject(o, useNativeTypes);\n      _addValue(node, p, value, {propertyIsArray: true});\n\n      // object may be an RDF list/partial list node but we can't know easily\n      // until all triples are read\n      if(objectIsId) {\n        if(o.value === RDF_NIL) {\n          // track rdf:nil uniquely per graph\n          const object = nodeMap[o.value];\n          if(!('usages' in object)) {\n            object.usages = [];\n          }\n          object.usages.push({\n            node: node,\n            property: p,\n            value: value\n          });\n        } else if(o.value in referencedOnce) {\n          // object referenced more than once\n          referencedOnce[o.value] = false;\n        } else {\n          // keep track of single reference\n          referencedOnce[o.value] = {\n            node: node,\n            property: p,\n            value: value\n          };\n        }\n      }\n    }\n  }*/\n\n  // convert linked lists to @list arrays\n  for(const name in graphMap) {\n    const graphObject = graphMap[name];\n\n    // no @lists to be converted, continue\n    if(!(RDF_NIL in graphObject)) {\n      continue;\n    }\n\n    // iterate backwards through each RDF list\n    const nil = graphObject[RDF_NIL];\n    if(!nil.usages) {\n      continue;\n    }\n    for(let usage of nil.usages) {\n      let node = usage.node;\n      let property = usage.property;\n      let head = usage.value;\n      const list = [];\n      const listNodes = [];\n\n      // ensure node is a well-formed list node; it must:\n      // 1. Be referenced only once.\n      // 2. Have an array for rdf:first that has 1 item.\n      // 3. Have an array for rdf:rest that has 1 item.\n      // 4. Have no keys other than: @id, rdf:first, rdf:rest, and,\n      //   optionally, @type where the value is rdf:List.\n      let nodeKeyCount = Object.keys(node).length;\n      while(property === RDF_REST &&\n        types.isObject(referencedOnce[node['@id']]) &&\n        types.isArray(node[RDF_FIRST]) && node[RDF_FIRST].length === 1 &&\n        types.isArray(node[RDF_REST]) && node[RDF_REST].length === 1 &&\n        (nodeKeyCount === 3 ||\n          (nodeKeyCount === 4 && types.isArray(node['@type']) &&\n          node['@type'].length === 1 && node['@type'][0] === RDF_LIST))) {\n        list.push(node[RDF_FIRST][0]);\n        listNodes.push(node['@id']);\n\n        // get next node, moving backwards through list\n        usage = referencedOnce[node['@id']];\n        node = usage.node;\n        property = usage.property;\n        head = usage.value;\n        nodeKeyCount = Object.keys(node).length;\n\n        // if node is not a blank node, then list head found\n        if(!graphTypes.isBlankNode(node)) {\n          break;\n        }\n      }\n\n      // transform list into @list object\n      delete head['@id'];\n      head['@list'] = list.reverse();\n      for(const listNode of listNodes) {\n        delete graphObject[listNode];\n      }\n    }\n\n    delete nil.usages;\n  }\n\n  const result = [];\n  const subjects = Object.keys(defaultGraph).sort();\n  for(const subject of subjects) {\n    const node = defaultGraph[subject];\n    if(subject in graphMap) {\n      const graph = node['@graph'] = [];\n      const graphObject = graphMap[subject];\n      const graphSubjects = Object.keys(graphObject).sort();\n      for(const graphSubject of graphSubjects) {\n        const node = graphObject[graphSubject];\n        // only add full subjects to top-level\n        if(!graphTypes.isSubjectReference(node)) {\n          graph.push(node);\n        }\n      }\n    }\n    // only add full subjects to top-level\n    if(!graphTypes.isSubjectReference(node)) {\n      result.push(node);\n    }\n  }\n\n  return result;\n};\n\n/**\n * Converts an RDF triple object to a JSON-LD object.\n *\n * @param o the RDF triple object to convert.\n * @param useNativeTypes true to output native types, false not to.\n * @param rdfDirection text direction mode [null, i18n-datatype]\n * @param options top level API options\n *\n * @return the JSON-LD object.\n */\nfunction _RDFToObject(o, useNativeTypes, rdfDirection, options) {\n  // convert NamedNode/BlankNode object to JSON-LD\n  if(o.termType.endsWith('Node')) {\n    return {'@id': o.value};\n  }\n\n  // convert literal to JSON-LD\n  const rval = {'@value': o.value};\n\n  // add language\n  if(o.language) {\n    if(!o.language.match(REGEX_BCP47)) {\n      if(options.eventHandler) {\n        _handleEvent({\n          event: {\n            type: ['JsonLdEvent'],\n            code: 'invalid @language value',\n            level: 'warning',\n            message: '@language value must be valid BCP47.',\n            details: {\n              language: o.language\n            }\n          },\n          options\n        });\n      }\n    }\n    rval['@language'] = o.language;\n  } else {\n    let type = o.datatype.value;\n    if(!type) {\n      type = XSD_STRING;\n    }\n    if(type === RDF_JSON_LITERAL) {\n      type = '@json';\n      try {\n        rval['@value'] = JSON.parse(rval['@value']);\n      } catch(e) {\n        throw new JsonLdError(\n          'JSON literal could not be parsed.',\n          'jsonld.InvalidJsonLiteral',\n          {code: 'invalid JSON literal', value: rval['@value'], cause: e});\n      }\n    }\n    // use native types for certain xsd types\n    if(useNativeTypes) {\n      if(type === XSD_BOOLEAN) {\n        if(rval['@value'] === 'true') {\n          rval['@value'] = true;\n        } else if(rval['@value'] === 'false') {\n          rval['@value'] = false;\n        }\n      } else if(types.isNumeric(rval['@value'])) {\n        if(type === XSD_INTEGER) {\n          const i = parseInt(rval['@value'], 10);\n          if(i.toFixed(0) === rval['@value']) {\n            rval['@value'] = i;\n          }\n        } else if(type === XSD_DOUBLE) {\n          rval['@value'] = parseFloat(rval['@value']);\n        }\n      }\n      // do not add native type\n      if(![XSD_BOOLEAN, XSD_INTEGER, XSD_DOUBLE, XSD_STRING].includes(type)) {\n        rval['@type'] = type;\n      }\n    } else if(rdfDirection === 'i18n-datatype' &&\n      type.startsWith('https://www.w3.org/ns/i18n#')) {\n      const [, language, direction] = type.split(/[#_]/);\n      if(language.length > 0) {\n        rval['@language'] = language;\n        if(!language.match(REGEX_BCP47)) {\n          if(options.eventHandler) {\n            _handleEvent({\n              event: {\n                type: ['JsonLdEvent'],\n                code: 'invalid @language value',\n                level: 'warning',\n                message: '@language value must be valid BCP47.',\n                details: {\n                  language\n                }\n              },\n              options\n            });\n          }\n        }\n      }\n      rval['@direction'] = direction;\n    } else if(type !== XSD_STRING) {\n      rval['@type'] = type;\n    }\n  }\n\n  return rval;\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/fromRdf.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/graphTypes.js":
/*!***********************************************!*\
  !*** ./node_modules/jsonld/lib/graphTypes.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst types = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Returns true if the given value is a subject with properties.\n *\n * @param v the value to check.\n *\n * @return true if the value is a subject with properties, false if not.\n */\napi.isSubject = v => {\n  // Note: A value is a subject if all of these hold true:\n  // 1. It is an Object.\n  // 2. It is not a @value, @set, or @list.\n  // 3. It has more than 1 key OR any existing key is not @id.\n  if(types.isObject(v) &&\n    !(('@value' in v) || ('@set' in v) || ('@list' in v))) {\n    const keyCount = Object.keys(v).length;\n    return (keyCount > 1 || !('@id' in v));\n  }\n  return false;\n};\n\n/**\n * Returns true if the given value is a subject reference.\n *\n * @param v the value to check.\n *\n * @return true if the value is a subject reference, false if not.\n */\napi.isSubjectReference = v =>\n  // Note: A value is a subject reference if all of these hold true:\n  // 1. It is an Object.\n  // 2. It has a single key: @id.\n  (types.isObject(v) && Object.keys(v).length === 1 && ('@id' in v));\n\n/**\n * Returns true if the given value is a @value.\n *\n * @param v the value to check.\n *\n * @return true if the value is a @value, false if not.\n */\napi.isValue = v =>\n  // Note: A value is a @value if all of these hold true:\n  // 1. It is an Object.\n  // 2. It has the @value property.\n  types.isObject(v) && ('@value' in v);\n\n/**\n * Returns true if the given value is a @list.\n *\n * @param v the value to check.\n *\n * @return true if the value is a @list, false if not.\n */\napi.isList = v =>\n  // Note: A value is a @list if all of these hold true:\n  // 1. It is an Object.\n  // 2. It has the @list property.\n  types.isObject(v) && ('@list' in v);\n\n/**\n * Returns true if the given value is a @graph.\n *\n * @return true if the value is a @graph, false if not.\n */\napi.isGraph = v => {\n  // Note: A value is a graph if all of these hold true:\n  // 1. It is an object.\n  // 2. It has an `@graph` key.\n  // 3. It may have '@id' or '@index'\n  return types.isObject(v) &&\n    '@graph' in v &&\n    Object.keys(v)\n      .filter(key => key !== '@id' && key !== '@index').length === 1;\n};\n\n/**\n * Returns true if the given value is a simple @graph.\n *\n * @return true if the value is a simple @graph, false if not.\n */\napi.isSimpleGraph = v => {\n  // Note: A value is a simple graph if all of these hold true:\n  // 1. It is an object.\n  // 2. It has an `@graph` key.\n  // 3. It has only 1 key or 2 keys where one of them is `@index`.\n  return api.isGraph(v) && !('@id' in v);\n};\n\n/**\n * Returns true if the given value is a blank node.\n *\n * @param v the value to check.\n *\n * @return true if the value is a blank node, false if not.\n */\napi.isBlankNode = v => {\n  // Note: A value is a blank node if all of these hold true:\n  // 1. It is an Object.\n  // 2. If it has an @id key that is not a string OR begins with '_:'.\n  // 3. It has no keys OR is not a @value, @set, or @list.\n  if(types.isObject(v)) {\n    if('@id' in v) {\n      const id = v['@id'];\n      return !types.isString(id) || id.indexOf('_:') === 0;\n    }\n    return (Object.keys(v).length === 0 ||\n      !(('@value' in v) || ('@set' in v) || ('@list' in v)));\n  }\n  return false;\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/graphTypes.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/jsonld.js":
/*!*******************************************!*\
  !*** ./node_modules/jsonld/lib/jsonld.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/**\n * A JavaScript implementation of the JSON-LD API.\n *\n * @author Dave Longley\n *\n * @license BSD 3-Clause License\n * Copyright (c) 2011-2022 Digital Bazaar, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * Redistributions of source code must retain the above copyright notice,\n * this list of conditions and the following disclaimer.\n *\n * Redistributions in binary form must reproduce the above copyright\n * notice, this list of conditions and the following disclaimer in the\n * documentation and/or other materials provided with the distribution.\n *\n * Neither the name of the Digital Bazaar, Inc. nor the names of its\n * contributors may be used to endorse or promote products derived from\n * this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\n * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\nconst canonize = __webpack_require__(/*! rdf-canonize */ \"./node_modules/jsonld/node_modules/rdf-canonize/index.js\");\nconst platform = __webpack_require__(/*! ./platform */ \"./node_modules/jsonld/lib/platform-browser.js\");\nconst util = __webpack_require__(/*! ./util */ \"./node_modules/jsonld/lib/util.js\");\nconst ContextResolver = __webpack_require__(/*! ./ContextResolver */ \"./node_modules/jsonld/lib/ContextResolver.js\");\nconst IdentifierIssuer = util.IdentifierIssuer;\nconst JsonLdError = __webpack_require__(/*! ./JsonLdError */ \"./node_modules/jsonld/lib/JsonLdError.js\");\nconst LRU = __webpack_require__(/*! lru-cache */ \"./node_modules/lru-cache/index.js\");\nconst NQuads = __webpack_require__(/*! ./NQuads */ \"./node_modules/jsonld/lib/NQuads.js\");\n\nconst {expand: _expand} = __webpack_require__(/*! ./expand */ \"./node_modules/jsonld/lib/expand.js\");\nconst {flatten: _flatten} = __webpack_require__(/*! ./flatten */ \"./node_modules/jsonld/lib/flatten.js\");\nconst {fromRDF: _fromRDF} = __webpack_require__(/*! ./fromRdf */ \"./node_modules/jsonld/lib/fromRdf.js\");\nconst {toRDF: _toRDF} = __webpack_require__(/*! ./toRdf */ \"./node_modules/jsonld/lib/toRdf.js\");\n\nconst {\n  frameMergedOrDefault: _frameMergedOrDefault,\n  cleanupNull: _cleanupNull\n} = __webpack_require__(/*! ./frame */ \"./node_modules/jsonld/lib/frame.js\");\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isString: _isString\n} = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\n\nconst {\n  isSubjectReference: _isSubjectReference,\n} = __webpack_require__(/*! ./graphTypes */ \"./node_modules/jsonld/lib/graphTypes.js\");\n\nconst {\n  expandIri: _expandIri,\n  getInitialContext: _getInitialContext,\n  process: _processContext,\n  processingMode: _processingMode\n} = __webpack_require__(/*! ./context */ \"./node_modules/jsonld/lib/context.js\");\n\nconst {\n  compact: _compact,\n  compactIri: _compactIri\n} = __webpack_require__(/*! ./compact */ \"./node_modules/jsonld/lib/compact.js\");\n\nconst {\n  createNodeMap: _createNodeMap,\n  createMergedNodeMap: _createMergedNodeMap,\n  mergeNodeMaps: _mergeNodeMaps\n} = __webpack_require__(/*! ./nodeMap */ \"./node_modules/jsonld/lib/nodeMap.js\");\n\nconst {\n  logEventHandler: _logEventHandler,\n  logWarningEventHandler: _logWarningEventHandler,\n  safeEventHandler: _safeEventHandler,\n  setDefaultEventHandler: _setDefaultEventHandler,\n  setupEventHandler: _setupEventHandler,\n  strictEventHandler: _strictEventHandler,\n  unhandledEventHandler: _unhandledEventHandler\n} = __webpack_require__(/*! ./events */ \"./node_modules/jsonld/lib/events.js\");\n\n/* eslint-disable indent */\n// attaches jsonld API to the given object\nconst wrapper = function(jsonld) {\n\n/** Registered RDF dataset parsers hashed by content-type. */\nconst _rdfParsers = {};\n\n// resolved context cache\n// TODO: consider basing max on context size rather than number\nconst RESOLVED_CONTEXT_CACHE_MAX_SIZE = 100;\nconst _resolvedContextCache = new LRU({max: RESOLVED_CONTEXT_CACHE_MAX_SIZE});\n\n/* Core API */\n\n/**\n * Performs JSON-LD compaction.\n *\n * @param input the JSON-LD input to compact.\n * @param ctx the context to compact with.\n * @param [options] options to use:\n *          [base] the base IRI to use.\n *          [compactArrays] true to compact arrays to single values when\n *            appropriate, false not to (default: true).\n *          [compactToRelative] true to compact IRIs to be relative to document\n *            base, false to keep absolute (default: true)\n *          [graph] true to always output a top-level graph (default: false).\n *          [expandContext] a context to expand with.\n *          [skipExpansion] true to assume the input is expanded and skip\n *            expansion, false not to, defaults to false. Some well-formed\n *            and safe-mode checks may be omitted.\n *          [documentLoader(url, options)] the document loader.\n *          [framing] true if compaction is occuring during a framing operation.\n *          [safe] true to use safe mode. (default: false)\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the compacted output.\n */\njsonld.compact = async function(input, ctx, options) {\n  if(arguments.length < 2) {\n    throw new TypeError('Could not compact, too few arguments.');\n  }\n\n  if(ctx === null) {\n    throw new JsonLdError(\n      'The compaction context must not be null.',\n      'jsonld.CompactError', {code: 'invalid local context'});\n  }\n\n  // nothing to compact\n  if(input === null) {\n    return null;\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    compactArrays: true,\n    compactToRelative: true,\n    graph: false,\n    skipExpansion: false,\n    link: false,\n    issuer: new IdentifierIssuer('_:b'),\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n  if(options.link) {\n    // force skip expansion when linking, \"link\" is not part of the public\n    // API, it should only be called from framing\n    options.skipExpansion = true;\n  }\n  if(!options.compactToRelative) {\n    delete options.base;\n  }\n\n  // expand input\n  let expanded;\n  if(options.skipExpansion) {\n    expanded = input;\n  } else {\n    expanded = await jsonld.expand(input, options);\n  }\n\n  // process context\n  const activeCtx = await jsonld.processContext(\n    _getInitialContext(options), ctx, options);\n\n  // do compaction\n  let compacted = await _compact({\n    activeCtx,\n    element: expanded,\n    options\n  });\n\n  // perform clean up\n  if(options.compactArrays && !options.graph && _isArray(compacted)) {\n    if(compacted.length === 1) {\n      // simplify to a single item\n      compacted = compacted[0];\n    } else if(compacted.length === 0) {\n      // simplify to an empty object\n      compacted = {};\n    }\n  } else if(options.graph && _isObject(compacted)) {\n    // always use array if graph option is on\n    compacted = [compacted];\n  }\n\n  // follow @context key\n  if(_isObject(ctx) && '@context' in ctx) {\n    ctx = ctx['@context'];\n  }\n\n  // build output context\n  ctx = util.clone(ctx);\n  if(!_isArray(ctx)) {\n    ctx = [ctx];\n  }\n  // remove empty contexts\n  const tmp = ctx;\n  ctx = [];\n  for(let i = 0; i < tmp.length; ++i) {\n    if(!_isObject(tmp[i]) || Object.keys(tmp[i]).length > 0) {\n      ctx.push(tmp[i]);\n    }\n  }\n\n  // remove array if only one context\n  const hasContext = (ctx.length > 0);\n  if(ctx.length === 1) {\n    ctx = ctx[0];\n  }\n\n  // add context and/or @graph\n  if(_isArray(compacted)) {\n    // use '@graph' keyword\n    const graphAlias = _compactIri({\n      activeCtx, iri: '@graph', relativeTo: {vocab: true}\n    });\n    const graph = compacted;\n    compacted = {};\n    if(hasContext) {\n      compacted['@context'] = ctx;\n    }\n    compacted[graphAlias] = graph;\n  } else if(_isObject(compacted) && hasContext) {\n    // reorder keys so @context is first\n    const graph = compacted;\n    compacted = {'@context': ctx};\n    for(const key in graph) {\n      compacted[key] = graph[key];\n    }\n  }\n\n  return compacted;\n};\n\n/**\n * Performs JSON-LD expansion.\n *\n * @param input the JSON-LD input to expand.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [keepFreeFloatingNodes] true to keep free-floating nodes,\n *            false not to, defaults to false.\n *          [documentLoader(url, options)] the document loader.\n *          [safe] true to use safe mode. (default: false)\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the expanded output.\n */\njsonld.expand = async function(input, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not expand, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    keepFreeFloatingNodes: false,\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // build set of objects that may have @contexts to resolve\n  const toResolve = {};\n\n  // build set of contexts to process prior to expansion\n  const contextsToProcess = [];\n\n  // if an `expandContext` has been given ensure it gets resolved\n  if('expandContext' in options) {\n    const expandContext = util.clone(options.expandContext);\n    if(_isObject(expandContext) && '@context' in expandContext) {\n      toResolve.expandContext = expandContext;\n    } else {\n      toResolve.expandContext = {'@context': expandContext};\n    }\n    contextsToProcess.push(toResolve.expandContext);\n  }\n\n  // if input is a string, attempt to dereference remote document\n  let defaultBase;\n  if(!_isString(input)) {\n    // input is not a URL, do not need to retrieve it first\n    toResolve.input = util.clone(input);\n  } else {\n    // load remote doc\n    const remoteDoc = await jsonld.get(input, options);\n    defaultBase = remoteDoc.documentUrl;\n    toResolve.input = remoteDoc.document;\n    if(remoteDoc.contextUrl) {\n      // context included in HTTP link header and must be resolved\n      toResolve.remoteContext = {'@context': remoteDoc.contextUrl};\n      contextsToProcess.push(toResolve.remoteContext);\n    }\n  }\n\n  // set default base\n  if(!('base' in options)) {\n    options.base = defaultBase || '';\n  }\n\n  // process any additional contexts\n  let activeCtx = _getInitialContext(options);\n  for(const localCtx of contextsToProcess) {\n    activeCtx = await _processContext({activeCtx, localCtx, options});\n  }\n\n  // expand resolved input\n  let expanded = await _expand({\n    activeCtx,\n    element: toResolve.input,\n    options\n  });\n\n  // optimize away @graph with no other properties\n  if(_isObject(expanded) && ('@graph' in expanded) &&\n    Object.keys(expanded).length === 1) {\n    expanded = expanded['@graph'];\n  } else if(expanded === null) {\n    expanded = [];\n  }\n\n  // normalize to an array\n  if(!_isArray(expanded)) {\n    expanded = [expanded];\n  }\n\n  return expanded;\n};\n\n/**\n * Performs JSON-LD flattening.\n *\n * @param input the JSON-LD to flatten.\n * @param ctx the context to use to compact the flattened output, or null.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [documentLoader(url, options)] the document loader.\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the flattened output.\n */\njsonld.flatten = async function(input, ctx, options) {\n  if(arguments.length < 1) {\n    return new TypeError('Could not flatten, too few arguments.');\n  }\n\n  if(typeof ctx === 'function') {\n    ctx = null;\n  } else {\n    ctx = ctx || null;\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // expand input\n  const expanded = await jsonld.expand(input, options);\n\n  // do flattening\n  const flattened = _flatten(expanded);\n\n  if(ctx === null) {\n    // no compaction required\n    return flattened;\n  }\n\n  // compact result (force @graph option to true, skip expansion)\n  options.graph = true;\n  options.skipExpansion = true;\n  const compacted = await jsonld.compact(flattened, ctx, options);\n\n  return compacted;\n};\n\n/**\n * Performs JSON-LD framing.\n *\n * @param input the JSON-LD input to frame.\n * @param frame the JSON-LD frame to use.\n * @param [options] the framing options.\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [embed] default @embed flag: '@last', '@always', '@never', '@link'\n *            (default: '@last').\n *          [explicit] default @explicit flag (default: false).\n *          [requireAll] default @requireAll flag (default: true).\n *          [omitDefault] default @omitDefault flag (default: false).\n *          [documentLoader(url, options)] the document loader.\n *          [safe] true to use safe mode. (default: false)\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the framed output.\n */\njsonld.frame = async function(input, frame, options) {\n  if(arguments.length < 2) {\n    throw new TypeError('Could not frame, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    embed: '@once',\n    explicit: false,\n    requireAll: false,\n    omitDefault: false,\n    bnodesToClear: [],\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // if frame is a string, attempt to dereference remote document\n  if(_isString(frame)) {\n    // load remote doc\n    const remoteDoc = await jsonld.get(frame, options);\n    frame = remoteDoc.document;\n\n    if(remoteDoc.contextUrl) {\n      // inject link header @context into frame\n      let ctx = frame['@context'];\n      if(!ctx) {\n        ctx = remoteDoc.contextUrl;\n      } else if(_isArray(ctx)) {\n        ctx.push(remoteDoc.contextUrl);\n      } else {\n        ctx = [ctx, remoteDoc.contextUrl];\n      }\n      frame['@context'] = ctx;\n    }\n  }\n\n  const frameContext = frame ? frame['@context'] || {} : {};\n\n  // process context\n  const activeCtx = await jsonld.processContext(\n    _getInitialContext(options), frameContext, options);\n\n  // mode specific defaults\n  if(!options.hasOwnProperty('omitGraph')) {\n    options.omitGraph = _processingMode(activeCtx, 1.1);\n  }\n  if(!options.hasOwnProperty('pruneBlankNodeIdentifiers')) {\n    options.pruneBlankNodeIdentifiers = _processingMode(activeCtx, 1.1);\n  }\n\n  // expand input\n  const expanded = await jsonld.expand(input, options);\n\n  // expand frame\n  const opts = {...options};\n  opts.isFrame = true;\n  opts.keepFreeFloatingNodes = true;\n  const expandedFrame = await jsonld.expand(frame, opts);\n\n  // if the unexpanded frame includes a key expanding to @graph, frame the\n  // default graph, otherwise, the merged graph\n  const frameKeys = Object.keys(frame)\n    .map(key => _expandIri(activeCtx, key, {vocab: true}));\n  opts.merged = !frameKeys.includes('@graph');\n  opts.is11 = _processingMode(activeCtx, 1.1);\n\n  // do framing\n  const framed = _frameMergedOrDefault(expanded, expandedFrame, opts);\n\n  opts.graph = !options.omitGraph;\n  opts.skipExpansion = true;\n  opts.link = {};\n  opts.framing = true;\n  let compacted = await jsonld.compact(framed, frameContext, opts);\n\n  // replace @null with null, compacting arrays\n  opts.link = {};\n  compacted = _cleanupNull(compacted, opts);\n\n  return compacted;\n};\n\n/**\n * **Experimental**\n *\n * Links a JSON-LD document's nodes in memory.\n *\n * @param input the JSON-LD document to link.\n * @param [ctx] the JSON-LD context to apply.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [documentLoader(url, options)] the document loader.\n *          [safe] true to use safe mode. (default: false)\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the linked output.\n */\njsonld.link = async function(input, ctx, options) {\n  // API matches running frame with a wildcard frame and embed: '@link'\n  // get arguments\n  const frame = {};\n  if(ctx) {\n    frame['@context'] = ctx;\n  }\n  frame['@embed'] = '@link';\n  return jsonld.frame(input, frame, options);\n};\n\n/**\n * Performs RDF dataset normalization on the given input. The input is JSON-LD\n * unless the 'inputFormat' option is used. The output is an RDF dataset\n * unless the 'format' option is used.\n *\n * Note: Canonicalization sets `safe` to `true` and `base` to `null` by\n * default in order to produce safe outputs and \"fail closed\" by default. This\n * is different from the other API transformations in this version which\n * allow unsafe defaults (for cryptographic usage) in order to comply with the\n * JSON-LD 1.1 specification.\n *\n * @param input the input to normalize as JSON-LD or as a format specified by\n *          the 'inputFormat' option.\n * @param [options] the options to use:\n *          [algorithm] the normalization algorithm to use, `URDNA2015` or\n *            `URGNA2012` (default: `URDNA2015`).\n *          [base] the base IRI to use (default: `null`).\n *          [expandContext] a context to expand with.\n *          [skipExpansion] true to assume the input is expanded and skip\n *            expansion, false not to, defaults to false. Some well-formed\n *            and safe-mode checks may be omitted.\n *          [inputFormat] the format if input is not JSON-LD:\n *            'application/n-quads' for N-Quads.\n *          [format] the format if output is a string:\n *            'application/n-quads' for N-Quads.\n *          [documentLoader(url, options)] the document loader.\n *          [useNative] true to use a native canonize algorithm\n *          [rdfDirection] null or 'i18n-datatype' to support RDF\n *             transformation of @direction (default: null).\n *          [safe] true to use safe mode. (default: true).\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the normalized output.\n */\njsonld.normalize = jsonld.canonize = async function(input, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not canonize, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : null,\n    algorithm: 'URDNA2015',\n    skipExpansion: false,\n    safe: true,\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n  if('inputFormat' in options) {\n    if(options.inputFormat !== 'application/n-quads' &&\n      options.inputFormat !== 'application/nquads') {\n      throw new JsonLdError(\n        'Unknown canonicalization input format.',\n        'jsonld.CanonizeError');\n    }\n    // TODO: `await` for async parsers\n    const parsedInput = NQuads.parse(input);\n\n    // do canonicalization\n    return canonize.canonize(parsedInput, options);\n  }\n\n  // convert to RDF dataset then do normalization\n  const opts = {...options};\n  delete opts.format;\n  opts.produceGeneralizedRdf = false;\n  const dataset = await jsonld.toRDF(input, opts);\n\n  // do canonicalization\n  return canonize.canonize(dataset, options);\n};\n\n/**\n * Converts an RDF dataset to JSON-LD.\n *\n * @param dataset a serialized string of RDF in a format specified by the\n *          format option or an RDF dataset to convert.\n * @param [options] the options to use:\n *          [format] the format if dataset param must first be parsed:\n *            'application/n-quads' for N-Quads (default).\n *          [rdfParser] a custom RDF-parser to use to parse the dataset.\n *          [useRdfType] true to use rdf:type, false to use @type\n *            (default: false).\n *          [useNativeTypes] true to convert XSD types into native types\n *            (boolean, integer, double), false not to (default: false).\n *          [rdfDirection] null or 'i18n-datatype' to support RDF\n *             transformation of @direction (default: null).\n *          [safe] true to use safe mode. (default: false)\n *\n * @return a Promise that resolves to the JSON-LD document.\n */\njsonld.fromRDF = async function(dataset, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not convert from RDF, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    format: _isString(dataset) ? 'application/n-quads' : undefined\n  });\n\n  const {format} = options;\n  let {rdfParser} = options;\n\n  // handle special format\n  if(format) {\n    // check supported formats\n    rdfParser = rdfParser || _rdfParsers[format];\n    if(!rdfParser) {\n      throw new JsonLdError(\n        'Unknown input format.',\n        'jsonld.UnknownFormat', {format});\n    }\n  } else {\n    // no-op parser, assume dataset already parsed\n    rdfParser = () => dataset;\n  }\n\n  // rdfParser must be synchronous or return a promise, no callback support\n  const parsedDataset = await rdfParser(dataset);\n  return _fromRDF(parsedDataset, options);\n};\n\n/**\n * Outputs the RDF dataset found in the given JSON-LD object.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [skipExpansion] true to assume the input is expanded and skip\n *            expansion, false not to, defaults to false. Some well-formed\n *            and safe-mode checks may be omitted.\n *          [format] the format to use to output a string:\n *            'application/n-quads' for N-Quads.\n *          [produceGeneralizedRdf] true to output generalized RDF, false\n *            to produce only standard RDF (default: false).\n *          [documentLoader(url, options)] the document loader.\n *          [safe] true to use safe mode. (default: false)\n *          [rdfDirection] null or 'i18n-datatype' to support RDF\n *             transformation of @direction (default: null).\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the RDF dataset.\n */\njsonld.toRDF = async function(input, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not convert to RDF, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    skipExpansion: false,\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // TODO: support toRDF custom map?\n  let expanded;\n  if(options.skipExpansion) {\n    expanded = input;\n  } else {\n    // expand input\n    expanded = await jsonld.expand(input, options);\n  }\n\n  // output RDF dataset\n  const dataset = _toRDF(expanded, options);\n  if(options.format) {\n    if(options.format === 'application/n-quads' ||\n      options.format === 'application/nquads') {\n      return NQuads.serialize(dataset);\n    }\n    throw new JsonLdError(\n      'Unknown output format.',\n      'jsonld.UnknownFormat', {format: options.format});\n  }\n\n  return dataset;\n};\n\n/**\n * **Experimental**\n *\n * Recursively flattens the nodes in the given JSON-LD input into a merged\n * map of node ID => node. All graphs will be merged into the default graph.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [documentLoader(url, options)] the document loader.\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the merged node map.\n */\njsonld.createNodeMap = async function(input, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not create node map, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // expand input\n  const expanded = await jsonld.expand(input, options);\n\n  return _createMergedNodeMap(expanded, options);\n};\n\n/**\n * **Experimental**\n *\n * Merges two or more JSON-LD documents into a single flattened document.\n *\n * @param docs the JSON-LD documents to merge together.\n * @param ctx the context to use to compact the merged result, or null.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [mergeNodes] true to merge properties for nodes with the same ID,\n *            false to ignore new properties for nodes with the same ID once\n *            the ID has been defined; note that this may not prevent merging\n *            new properties where a node is in the `object` position\n *            (default: true).\n *          [documentLoader(url, options)] the document loader.\n *          [safe] true to use safe mode. (default: false)\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the merged output.\n */\njsonld.merge = async function(docs, ctx, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not merge, too few arguments.');\n  }\n  if(!_isArray(docs)) {\n    throw new TypeError('Could not merge, \"docs\" must be an array.');\n  }\n\n  if(typeof ctx === 'function') {\n    ctx = null;\n  } else {\n    ctx = ctx || null;\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // expand all documents\n  const expanded = await Promise.all(docs.map(doc => {\n    const opts = {...options};\n    return jsonld.expand(doc, opts);\n  }));\n\n  let mergeNodes = true;\n  if('mergeNodes' in options) {\n    mergeNodes = options.mergeNodes;\n  }\n\n  const issuer = options.issuer || new IdentifierIssuer('_:b');\n  const graphs = {'@default': {}};\n\n  for(let i = 0; i < expanded.length; ++i) {\n    // uniquely relabel blank nodes\n    const doc = util.relabelBlankNodes(expanded[i], {\n      issuer: new IdentifierIssuer('_:b' + i + '-')\n    });\n\n    // add nodes to the shared node map graphs if merging nodes, to a\n    // separate graph set if not\n    const _graphs = (mergeNodes || i === 0) ? graphs : {'@default': {}};\n    _createNodeMap(doc, _graphs, '@default', issuer);\n\n    if(_graphs !== graphs) {\n      // merge document graphs but don't merge existing nodes\n      for(const graphName in _graphs) {\n        const _nodeMap = _graphs[graphName];\n        if(!(graphName in graphs)) {\n          graphs[graphName] = _nodeMap;\n          continue;\n        }\n        const nodeMap = graphs[graphName];\n        for(const key in _nodeMap) {\n          if(!(key in nodeMap)) {\n            nodeMap[key] = _nodeMap[key];\n          }\n        }\n      }\n    }\n  }\n\n  // add all non-default graphs to default graph\n  const defaultGraph = _mergeNodeMaps(graphs);\n\n  // produce flattened output\n  const flattened = [];\n  const keys = Object.keys(defaultGraph).sort();\n  for(let ki = 0; ki < keys.length; ++ki) {\n    const node = defaultGraph[keys[ki]];\n    // only add full subjects to top-level\n    if(!_isSubjectReference(node)) {\n      flattened.push(node);\n    }\n  }\n\n  if(ctx === null) {\n    return flattened;\n  }\n\n  // compact result (force @graph option to true, skip expansion)\n  options.graph = true;\n  options.skipExpansion = true;\n  const compacted = await jsonld.compact(flattened, ctx, options);\n\n  return compacted;\n};\n\n/**\n * The default document loader for external documents.\n *\n * @param url the URL to load.\n *\n * @return a promise that resolves to the remote document.\n */\nObject.defineProperty(jsonld, 'documentLoader', {\n  get: () => jsonld._documentLoader,\n  set: v => jsonld._documentLoader = v\n});\n// default document loader not implemented\njsonld.documentLoader = async url => {\n  throw new JsonLdError(\n    'Could not retrieve a JSON-LD document from the URL. URL ' +\n    'dereferencing not implemented.', 'jsonld.LoadDocumentError',\n    {code: 'loading document failed', url});\n};\n\n/**\n * Gets a remote JSON-LD document using the default document loader or\n * one given in the passed options.\n *\n * @param url the URL to fetch.\n * @param [options] the options to use:\n *          [documentLoader] the document loader to use.\n *\n * @return a Promise that resolves to the retrieved remote document.\n */\njsonld.get = async function(url, options) {\n  let load;\n  if(typeof options.documentLoader === 'function') {\n    load = options.documentLoader;\n  } else {\n    load = jsonld.documentLoader;\n  }\n\n  const remoteDoc = await load(url);\n\n  try {\n    if(!remoteDoc.document) {\n      throw new JsonLdError(\n        'No remote document found at the given URL.',\n        'jsonld.NullRemoteDocument');\n    }\n    if(_isString(remoteDoc.document)) {\n      remoteDoc.document = JSON.parse(remoteDoc.document);\n    }\n  } catch(e) {\n    throw new JsonLdError(\n      'Could not retrieve a JSON-LD document from the URL.',\n      'jsonld.LoadDocumentError', {\n        code: 'loading document failed',\n        cause: e,\n        remoteDoc\n      });\n  }\n\n  return remoteDoc;\n};\n\n/**\n * Processes a local context, resolving any URLs as necessary, and returns a\n * new active context.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context to process.\n * @param [options] the options to use:\n *          [documentLoader(url, options)] the document loader.\n *          [safe] true to use safe mode. (default: false)\n *          [contextResolver] internal use only.\n *\n * @return a Promise that resolves to the new active context.\n */\njsonld.processContext = async function(\n  activeCtx, localCtx, options) {\n  // set default options\n  options = _setDefaults(options, {\n    base: '',\n    contextResolver: new ContextResolver(\n      {sharedCache: _resolvedContextCache})\n  });\n\n  // return initial context early for null context\n  if(localCtx === null) {\n    return _getInitialContext(options);\n  }\n\n  // get URLs in localCtx\n  localCtx = util.clone(localCtx);\n  if(!(_isObject(localCtx) && '@context' in localCtx)) {\n    localCtx = {'@context': localCtx};\n  }\n\n  return _processContext({activeCtx, localCtx, options});\n};\n\n// backwards compatibility\njsonld.getContextValue = (__webpack_require__(/*! ./context */ \"./node_modules/jsonld/lib/context.js\").getContextValue);\n\n/**\n * Document loaders.\n */\njsonld.documentLoaders = {};\n\n/**\n * Assigns the default document loader for external document URLs to a built-in\n * default. Supported types currently include: 'xhr' and 'node'.\n *\n * @param type the type to set.\n * @param [params] the parameters required to use the document loader.\n */\njsonld.useDocumentLoader = function(type) {\n  if(!(type in jsonld.documentLoaders)) {\n    throw new JsonLdError(\n      'Unknown document loader type: \"' + type + '\"',\n      'jsonld.UnknownDocumentLoader',\n      {type});\n  }\n\n  // set document loader\n  jsonld.documentLoader = jsonld.documentLoaders[type].apply(\n    jsonld, Array.prototype.slice.call(arguments, 1));\n};\n\n/**\n * Registers an RDF dataset parser by content-type, for use with\n * jsonld.fromRDF. An RDF dataset parser will always be given one parameter,\n * a string of input. An RDF dataset parser can be synchronous or\n * asynchronous (by returning a promise).\n *\n * @param contentType the content-type for the parser.\n * @param parser(input) the parser function (takes a string as a parameter\n *          and either returns an RDF dataset or a Promise that resolves to one.\n */\njsonld.registerRDFParser = function(contentType, parser) {\n  _rdfParsers[contentType] = parser;\n};\n\n/**\n * Unregisters an RDF dataset parser by content-type.\n *\n * @param contentType the content-type for the parser.\n */\njsonld.unregisterRDFParser = function(contentType) {\n  delete _rdfParsers[contentType];\n};\n\n// register the N-Quads RDF parser\njsonld.registerRDFParser('application/n-quads', NQuads.parse);\njsonld.registerRDFParser('application/nquads', NQuads.parse);\n\n/* URL API */\njsonld.url = __webpack_require__(/*! ./url */ \"./node_modules/jsonld/lib/url.js\");\n\n/* Events API and handlers */\njsonld.logEventHandler = _logEventHandler;\njsonld.logWarningEventHandler = _logWarningEventHandler;\njsonld.safeEventHandler = _safeEventHandler;\njsonld.setDefaultEventHandler = _setDefaultEventHandler;\njsonld.strictEventHandler = _strictEventHandler;\njsonld.unhandledEventHandler = _unhandledEventHandler;\n\n/* Utility API */\njsonld.util = util;\n// backwards compatibility\nObject.assign(jsonld, util);\n\n// reexpose API as jsonld.promises for backwards compatability\njsonld.promises = jsonld;\n\n// backwards compatibility\njsonld.RequestQueue = __webpack_require__(/*! ./RequestQueue */ \"./node_modules/jsonld/lib/RequestQueue.js\");\n\n/* WebIDL API */\njsonld.JsonLdProcessor = __webpack_require__(/*! ./JsonLdProcessor */ \"./node_modules/jsonld/lib/JsonLdProcessor.js\")(jsonld);\n\nplatform.setupGlobals(jsonld);\nplatform.setupDocumentLoaders(jsonld);\n\nfunction _setDefaults(options, {\n  documentLoader = jsonld.documentLoader,\n  ...defaults\n}) {\n  // fail if obsolete options present\n  if(options && 'compactionMap' in options) {\n    throw new JsonLdError(\n      '\"compactionMap\" not supported.',\n      'jsonld.OptionsError');\n  }\n  if(options && 'expansionMap' in options) {\n    throw new JsonLdError(\n      '\"expansionMap\" not supported.',\n      'jsonld.OptionsError');\n  }\n  return Object.assign(\n    {},\n    {documentLoader},\n    defaults,\n    options,\n    {eventHandler: _setupEventHandler({options})}\n  );\n}\n\n// end of jsonld API `wrapper` factory\nreturn jsonld;\n};\n\n// external APIs:\n\n// used to generate a new jsonld API instance\nconst factory = function() {\n  return wrapper(function() {\n    return factory();\n  });\n};\n\n// wrap the main jsonld API instance\nwrapper(factory);\n// export API\nmodule.exports = factory;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/jsonld.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/nodeMap.js":
/*!********************************************!*\
  !*** ./node_modules/jsonld/lib/nodeMap.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst {isKeyword} = __webpack_require__(/*! ./context */ \"./node_modules/jsonld/lib/context.js\");\nconst graphTypes = __webpack_require__(/*! ./graphTypes */ \"./node_modules/jsonld/lib/graphTypes.js\");\nconst types = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\nconst util = __webpack_require__(/*! ./util */ \"./node_modules/jsonld/lib/util.js\");\nconst JsonLdError = __webpack_require__(/*! ./JsonLdError */ \"./node_modules/jsonld/lib/JsonLdError.js\");\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Creates a merged JSON-LD node map (node ID => node).\n *\n * @param input the expanded JSON-LD to create a node map of.\n * @param [options] the options to use:\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *\n * @return the node map.\n */\napi.createMergedNodeMap = (input, options) => {\n  options = options || {};\n\n  // produce a map of all subjects and name each bnode\n  const issuer = options.issuer || new util.IdentifierIssuer('_:b');\n  const graphs = {'@default': {}};\n  api.createNodeMap(input, graphs, '@default', issuer);\n\n  // add all non-default graphs to default graph\n  return api.mergeNodeMaps(graphs);\n};\n\n/**\n * Recursively flattens the subjects in the given JSON-LD expanded input\n * into a node map.\n *\n * @param input the JSON-LD expanded input.\n * @param graphs a map of graph name to subject map.\n * @param graph the name of the current graph.\n * @param issuer the blank node identifier issuer.\n * @param name the name assigned to the current input if it is a bnode.\n * @param list the list to append to, null for none.\n */\napi.createNodeMap = (input, graphs, graph, issuer, name, list) => {\n  // recurse through array\n  if(types.isArray(input)) {\n    for(const node of input) {\n      api.createNodeMap(node, graphs, graph, issuer, undefined, list);\n    }\n    return;\n  }\n\n  // add non-object to list\n  if(!types.isObject(input)) {\n    if(list) {\n      list.push(input);\n    }\n    return;\n  }\n\n  // add values to list\n  if(graphTypes.isValue(input)) {\n    if('@type' in input) {\n      let type = input['@type'];\n      // rename @type blank node\n      if(type.indexOf('_:') === 0) {\n        input['@type'] = type = issuer.getId(type);\n      }\n    }\n    if(list) {\n      list.push(input);\n    }\n    return;\n  } else if(list && graphTypes.isList(input)) {\n    const _list = [];\n    api.createNodeMap(input['@list'], graphs, graph, issuer, name, _list);\n    list.push({'@list': _list});\n    return;\n  }\n\n  // Note: At this point, input must be a subject.\n\n  // spec requires @type to be named first, so assign names early\n  if('@type' in input) {\n    const types = input['@type'];\n    for(const type of types) {\n      if(type.indexOf('_:') === 0) {\n        issuer.getId(type);\n      }\n    }\n  }\n\n  // get name for subject\n  if(types.isUndefined(name)) {\n    name = graphTypes.isBlankNode(input) ?\n      issuer.getId(input['@id']) : input['@id'];\n  }\n\n  // add subject reference to list\n  if(list) {\n    list.push({'@id': name});\n  }\n\n  // create new subject or merge into existing one\n  const subjects = graphs[graph];\n  const subject = subjects[name] = subjects[name] || {};\n  subject['@id'] = name;\n  const properties = Object.keys(input).sort();\n  for(let property of properties) {\n    // skip @id\n    if(property === '@id') {\n      continue;\n    }\n\n    // handle reverse properties\n    if(property === '@reverse') {\n      const referencedNode = {'@id': name};\n      const reverseMap = input['@reverse'];\n      for(const reverseProperty in reverseMap) {\n        const items = reverseMap[reverseProperty];\n        for(const item of items) {\n          let itemName = item['@id'];\n          if(graphTypes.isBlankNode(item)) {\n            itemName = issuer.getId(itemName);\n          }\n          api.createNodeMap(item, graphs, graph, issuer, itemName);\n          util.addValue(\n            subjects[itemName], reverseProperty, referencedNode,\n            {propertyIsArray: true, allowDuplicate: false});\n        }\n      }\n      continue;\n    }\n\n    // recurse into graph\n    if(property === '@graph') {\n      // add graph subjects map entry\n      if(!(name in graphs)) {\n        graphs[name] = {};\n      }\n      api.createNodeMap(input[property], graphs, name, issuer);\n      continue;\n    }\n\n    // recurse into included\n    if(property === '@included') {\n      api.createNodeMap(input[property], graphs, graph, issuer);\n      continue;\n    }\n\n    // copy non-@type keywords\n    if(property !== '@type' && isKeyword(property)) {\n      if(property === '@index' && property in subject &&\n        (input[property] !== subject[property] ||\n        input[property]['@id'] !== subject[property]['@id'])) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; conflicting @index property detected.',\n          'jsonld.SyntaxError',\n          {code: 'conflicting indexes', subject});\n      }\n      subject[property] = input[property];\n      continue;\n    }\n\n    // iterate over objects\n    const objects = input[property];\n\n    // if property is a bnode, assign it a new id\n    if(property.indexOf('_:') === 0) {\n      property = issuer.getId(property);\n    }\n\n    // ensure property is added for empty arrays\n    if(objects.length === 0) {\n      util.addValue(subject, property, [], {propertyIsArray: true});\n      continue;\n    }\n    for(let o of objects) {\n      if(property === '@type') {\n        // rename @type blank nodes\n        o = (o.indexOf('_:') === 0) ? issuer.getId(o) : o;\n      }\n\n      // handle embedded subject or subject reference\n      if(graphTypes.isSubject(o) || graphTypes.isSubjectReference(o)) {\n        // skip null @id\n        if('@id' in o && !o['@id']) {\n          continue;\n        }\n\n        // relabel blank node @id\n        const id = graphTypes.isBlankNode(o) ?\n          issuer.getId(o['@id']) : o['@id'];\n\n        // add reference and recurse\n        util.addValue(\n          subject, property, {'@id': id},\n          {propertyIsArray: true, allowDuplicate: false});\n        api.createNodeMap(o, graphs, graph, issuer, id);\n      } else if(graphTypes.isValue(o)) {\n        util.addValue(\n          subject, property, o,\n          {propertyIsArray: true, allowDuplicate: false});\n      } else if(graphTypes.isList(o)) {\n        // handle @list\n        const _list = [];\n        api.createNodeMap(o['@list'], graphs, graph, issuer, name, _list);\n        o = {'@list': _list};\n        util.addValue(\n          subject, property, o,\n          {propertyIsArray: true, allowDuplicate: false});\n      } else {\n        // handle @value\n        api.createNodeMap(o, graphs, graph, issuer, name);\n        util.addValue(\n          subject, property, o, {propertyIsArray: true, allowDuplicate: false});\n      }\n    }\n  }\n};\n\n/**\n * Merge separate named graphs into a single merged graph including\n * all nodes from the default graph and named graphs.\n *\n * @param graphs a map of graph name to subject map.\n *\n * @return the merged graph map.\n */\napi.mergeNodeMapGraphs = graphs => {\n  const merged = {};\n  for(const name of Object.keys(graphs).sort()) {\n    for(const id of Object.keys(graphs[name]).sort()) {\n      const node = graphs[name][id];\n      if(!(id in merged)) {\n        merged[id] = {'@id': id};\n      }\n      const mergedNode = merged[id];\n\n      for(const property of Object.keys(node).sort()) {\n        if(isKeyword(property) && property !== '@type') {\n          // copy keywords\n          mergedNode[property] = util.clone(node[property]);\n        } else {\n          // merge objects\n          for(const value of node[property]) {\n            util.addValue(\n              mergedNode, property, util.clone(value),\n              {propertyIsArray: true, allowDuplicate: false});\n          }\n        }\n      }\n    }\n  }\n\n  return merged;\n};\n\napi.mergeNodeMaps = graphs => {\n  // add all non-default graphs to default graph\n  const defaultGraph = graphs['@default'];\n  const graphNames = Object.keys(graphs).sort();\n  for(const graphName of graphNames) {\n    if(graphName === '@default') {\n      continue;\n    }\n    const nodeMap = graphs[graphName];\n    let subject = defaultGraph[graphName];\n    if(!subject) {\n      defaultGraph[graphName] = subject = {\n        '@id': graphName,\n        '@graph': []\n      };\n    } else if(!('@graph' in subject)) {\n      subject['@graph'] = [];\n    }\n    const graph = subject['@graph'];\n    for(const id of Object.keys(nodeMap).sort()) {\n      const node = nodeMap[id];\n      // only add full subjects\n      if(!graphTypes.isSubjectReference(node)) {\n        graph.push(node);\n      }\n    }\n  }\n  return defaultGraph;\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/nodeMap.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/platform-browser.js":
/*!*****************************************************!*\
  !*** ./node_modules/jsonld/lib/platform-browser.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2021 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst xhrLoader = __webpack_require__(/*! ./documentLoaders/xhr */ \"./node_modules/jsonld/lib/documentLoaders/xhr.js\");\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Setup browser document loaders.\n *\n * @param jsonld the jsonld api.\n */\napi.setupDocumentLoaders = function(jsonld) {\n  if(typeof XMLHttpRequest !== 'undefined') {\n    jsonld.documentLoaders.xhr = xhrLoader;\n    // use xhr document loader by default\n    jsonld.useDocumentLoader('xhr');\n  }\n};\n\n/**\n * Setup browser globals.\n *\n * @param jsonld the jsonld api.\n */\napi.setupGlobals = function(jsonld) {\n  // setup browser global JsonLdProcessor\n  if(typeof globalThis.JsonLdProcessor === 'undefined') {\n    Object.defineProperty(globalThis, 'JsonLdProcessor', {\n      writable: true,\n      enumerable: false,\n      configurable: true,\n      value: jsonld.JsonLdProcessor\n    });\n  }\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/platform-browser.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/toRdf.js":
/*!******************************************!*\
  !*** ./node_modules/jsonld/lib/toRdf.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017-2023 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst {createNodeMap} = __webpack_require__(/*! ./nodeMap */ \"./node_modules/jsonld/lib/nodeMap.js\");\nconst {isKeyword} = __webpack_require__(/*! ./context */ \"./node_modules/jsonld/lib/context.js\");\nconst graphTypes = __webpack_require__(/*! ./graphTypes */ \"./node_modules/jsonld/lib/graphTypes.js\");\nconst jsonCanonicalize = __webpack_require__(/*! canonicalize */ \"./node_modules/canonicalize/lib/canonicalize.js\");\nconst JsonLdError = __webpack_require__(/*! ./JsonLdError */ \"./node_modules/jsonld/lib/JsonLdError.js\");\nconst types = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\nconst util = __webpack_require__(/*! ./util */ \"./node_modules/jsonld/lib/util.js\");\n\nconst {\n  handleEvent: _handleEvent\n} = __webpack_require__(/*! ./events */ \"./node_modules/jsonld/lib/events.js\");\n\nconst {\n  // RDF,\n  // RDF_LIST,\n  RDF_FIRST,\n  RDF_REST,\n  RDF_NIL,\n  RDF_TYPE,\n  // RDF_PLAIN_LITERAL,\n  // RDF_XML_LITERAL,\n  RDF_JSON_LITERAL,\n  // RDF_OBJECT,\n  RDF_LANGSTRING,\n\n  // XSD,\n  XSD_BOOLEAN,\n  XSD_DOUBLE,\n  XSD_INTEGER,\n  XSD_STRING,\n} = __webpack_require__(/*! ./constants */ \"./node_modules/jsonld/lib/constants.js\");\n\nconst {\n  isAbsolute: _isAbsoluteIri\n} = __webpack_require__(/*! ./url */ \"./node_modules/jsonld/lib/url.js\");\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Outputs an RDF dataset for the expanded JSON-LD input.\n *\n * @param input the expanded JSON-LD input.\n * @param options the RDF serialization options.\n *\n * @return the RDF dataset.\n */\napi.toRDF = (input, options) => {\n  // create node map for default graph (and any named graphs)\n  const issuer = new util.IdentifierIssuer('_:b');\n  const nodeMap = {'@default': {}};\n  createNodeMap(input, nodeMap, '@default', issuer);\n\n  const dataset = [];\n  const graphNames = Object.keys(nodeMap).sort();\n  for(const graphName of graphNames) {\n    let graphTerm;\n    if(graphName === '@default') {\n      graphTerm = {termType: 'DefaultGraph', value: ''};\n    } else if(_isAbsoluteIri(graphName)) {\n      if(graphName.startsWith('_:')) {\n        graphTerm = {termType: 'BlankNode'};\n      } else {\n        graphTerm = {termType: 'NamedNode'};\n      }\n      graphTerm.value = graphName;\n    } else {\n      // skip relative IRIs (not valid RDF)\n      if(options.eventHandler) {\n        _handleEvent({\n          event: {\n            type: ['JsonLdEvent'],\n            code: 'relative graph reference',\n            level: 'warning',\n            message: 'Relative graph reference found.',\n            details: {\n              graph: graphName\n            }\n          },\n          options\n        });\n      }\n      continue;\n    }\n    _graphToRDF(dataset, nodeMap[graphName], graphTerm, issuer, options);\n  }\n\n  return dataset;\n};\n\n/**\n * Adds RDF quads for a particular graph to the given dataset.\n *\n * @param dataset the dataset to append RDF quads to.\n * @param graph the graph to create RDF quads for.\n * @param graphTerm the graph term for each quad.\n * @param issuer a IdentifierIssuer for assigning blank node names.\n * @param options the RDF serialization options.\n *\n * @return the array of RDF triples for the given graph.\n */\nfunction _graphToRDF(dataset, graph, graphTerm, issuer, options) {\n  const ids = Object.keys(graph).sort();\n  for(const id of ids) {\n    const node = graph[id];\n    const properties = Object.keys(node).sort();\n    for(let property of properties) {\n      const items = node[property];\n      if(property === '@type') {\n        property = RDF_TYPE;\n      } else if(isKeyword(property)) {\n        continue;\n      }\n\n      for(const item of items) {\n        // RDF subject\n        const subject = {\n          termType: id.startsWith('_:') ? 'BlankNode' : 'NamedNode',\n          value: id\n        };\n\n        // skip relative IRI subjects (not valid RDF)\n        if(!_isAbsoluteIri(id)) {\n          if(options.eventHandler) {\n            _handleEvent({\n              event: {\n                type: ['JsonLdEvent'],\n                code: 'relative subject reference',\n                level: 'warning',\n                message: 'Relative subject reference found.',\n                details: {\n                  subject: id\n                }\n              },\n              options\n            });\n          }\n          continue;\n        }\n\n        // RDF predicate\n        const predicate = {\n          termType: property.startsWith('_:') ? 'BlankNode' : 'NamedNode',\n          value: property\n        };\n\n        // skip relative IRI predicates (not valid RDF)\n        if(!_isAbsoluteIri(property)) {\n          if(options.eventHandler) {\n            _handleEvent({\n              event: {\n                type: ['JsonLdEvent'],\n                code: 'relative predicate reference',\n                level: 'warning',\n                message: 'Relative predicate reference found.',\n                details: {\n                  predicate: property\n                }\n              },\n              options\n            });\n          }\n          continue;\n        }\n\n        // skip blank node predicates unless producing generalized RDF\n        if(predicate.termType === 'BlankNode' &&\n          !options.produceGeneralizedRdf) {\n          if(options.eventHandler) {\n            _handleEvent({\n              event: {\n                type: ['JsonLdEvent'],\n                code: 'blank node predicate',\n                level: 'warning',\n                message: 'Dropping blank node predicate.',\n                details: {\n                  // FIXME: add better issuer API to get reverse mapping\n                  property: issuer.getOldIds()\n                    .find(key => issuer.getId(key) === property)\n                }\n              },\n              options\n            });\n          }\n          continue;\n        }\n\n        // convert list, value or node object to triple\n        const object = _objectToRDF(\n          item, issuer, dataset, graphTerm, options.rdfDirection, options);\n        // skip null objects (they are relative IRIs)\n        if(object) {\n          dataset.push({\n            subject,\n            predicate,\n            object,\n            graph: graphTerm\n          });\n        }\n      }\n    }\n  }\n}\n\n/**\n * Converts a @list value into linked list of blank node RDF quads\n * (an RDF collection).\n *\n * @param list the @list value.\n * @param issuer a IdentifierIssuer for assigning blank node names.\n * @param dataset the array of quads to append to.\n * @param graphTerm the graph term for each quad.\n * @param options the RDF serialization options.\n *\n * @return the head of the list.\n */\nfunction _listToRDF(list, issuer, dataset, graphTerm, rdfDirection, options) {\n  const first = {termType: 'NamedNode', value: RDF_FIRST};\n  const rest = {termType: 'NamedNode', value: RDF_REST};\n  const nil = {termType: 'NamedNode', value: RDF_NIL};\n\n  const last = list.pop();\n  // Result is the head of the list\n  const result = last ? {termType: 'BlankNode', value: issuer.getId()} : nil;\n  let subject = result;\n\n  for(const item of list) {\n    const object = _objectToRDF(\n      item, issuer, dataset, graphTerm, rdfDirection, options);\n    const next = {termType: 'BlankNode', value: issuer.getId()};\n    dataset.push({\n      subject,\n      predicate: first,\n      object,\n      graph: graphTerm\n    });\n    dataset.push({\n      subject,\n      predicate: rest,\n      object: next,\n      graph: graphTerm\n    });\n    subject = next;\n  }\n\n  // Tail of list\n  if(last) {\n    const object = _objectToRDF(\n      last, issuer, dataset, graphTerm, rdfDirection, options);\n    dataset.push({\n      subject,\n      predicate: first,\n      object,\n      graph: graphTerm\n    });\n    dataset.push({\n      subject,\n      predicate: rest,\n      object: nil,\n      graph: graphTerm\n    });\n  }\n\n  return result;\n}\n\n/**\n * Converts a JSON-LD value object to an RDF literal or a JSON-LD string,\n * node object to an RDF resource, or adds a list.\n *\n * @param item the JSON-LD value or node object.\n * @param issuer a IdentifierIssuer for assigning blank node names.\n * @param dataset the dataset to append RDF quads to.\n * @param graphTerm the graph term for each quad.\n * @param options the RDF serialization options.\n *\n * @return the RDF literal or RDF resource.\n */\nfunction _objectToRDF(\n  item, issuer, dataset, graphTerm, rdfDirection, options\n) {\n  const object = {};\n\n  // convert value object to RDF\n  if(graphTypes.isValue(item)) {\n    object.termType = 'Literal';\n    object.value = undefined;\n    object.datatype = {\n      termType: 'NamedNode'\n    };\n    let value = item['@value'];\n    const datatype = item['@type'] || null;\n\n    // convert to XSD/JSON datatypes as appropriate\n    if(datatype === '@json') {\n      object.value = jsonCanonicalize(value);\n      object.datatype.value = RDF_JSON_LITERAL;\n    } else if(types.isBoolean(value)) {\n      object.value = value.toString();\n      object.datatype.value = datatype || XSD_BOOLEAN;\n    } else if(types.isDouble(value) || datatype === XSD_DOUBLE) {\n      if(!types.isDouble(value)) {\n        value = parseFloat(value);\n      }\n      // canonical double representation\n      object.value = value.toExponential(15).replace(/(\\d)0*e\\+?/, '$1E');\n      object.datatype.value = datatype || XSD_DOUBLE;\n    } else if(types.isNumber(value)) {\n      object.value = value.toFixed(0);\n      object.datatype.value = datatype || XSD_INTEGER;\n    } else if('@direction' in item && rdfDirection === 'i18n-datatype') {\n      const language = (item['@language'] || '').toLowerCase();\n      const direction = item['@direction'];\n      const datatype = `https://www.w3.org/ns/i18n#${language}_${direction}`;\n      object.datatype.value = datatype;\n      object.value = value;\n    } else if('@direction' in item && rdfDirection === 'compound-literal') {\n      throw new JsonLdError(\n        'Unsupported rdfDirection value.',\n        'jsonld.InvalidRdfDirection',\n        {value: rdfDirection});\n    } else if('@direction' in item && rdfDirection) {\n      throw new JsonLdError(\n        'Unknown rdfDirection value.',\n        'jsonld.InvalidRdfDirection',\n        {value: rdfDirection});\n    } else if('@language' in item) {\n      if('@direction' in item && !rdfDirection) {\n        if(options.eventHandler) {\n          // FIXME: only emit once?\n          _handleEvent({\n            event: {\n              type: ['JsonLdEvent'],\n              code: 'rdfDirection not set',\n              level: 'warning',\n              message: 'rdfDirection not set for @direction.',\n              details: {\n                object: object.value\n              }\n            },\n            options\n          });\n        }\n      }\n      object.value = value;\n      object.datatype.value = datatype || RDF_LANGSTRING;\n      object.language = item['@language'];\n    } else {\n      if('@direction' in item && !rdfDirection) {\n        if(options.eventHandler) {\n          // FIXME: only emit once?\n          _handleEvent({\n            event: {\n              type: ['JsonLdEvent'],\n              code: 'rdfDirection not set',\n              level: 'warning',\n              message: 'rdfDirection not set for @direction.',\n              details: {\n                object: object.value\n              }\n            },\n            options\n          });\n        }\n      }\n      object.value = value;\n      object.datatype.value = datatype || XSD_STRING;\n    }\n  } else if(graphTypes.isList(item)) {\n    const _list = _listToRDF(\n      item['@list'], issuer, dataset, graphTerm, rdfDirection, options);\n    object.termType = _list.termType;\n    object.value = _list.value;\n  } else {\n    // convert string/node object to RDF\n    const id = types.isObject(item) ? item['@id'] : item;\n    object.termType = id.startsWith('_:') ? 'BlankNode' : 'NamedNode';\n    object.value = id;\n  }\n\n  // skip relative IRIs, not valid RDF\n  if(object.termType === 'NamedNode' && !_isAbsoluteIri(object.value)) {\n    if(options.eventHandler) {\n      _handleEvent({\n        event: {\n          type: ['JsonLdEvent'],\n          code: 'relative object reference',\n          level: 'warning',\n          message: 'Relative object reference found.',\n          details: {\n            object: object.value\n          }\n        },\n        options\n      });\n    }\n    return null;\n  }\n\n  return object;\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/toRdf.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/types.js":
/*!******************************************!*\
  !*** ./node_modules/jsonld/lib/types.js ***!
  \******************************************/
/***/ ((module) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Returns true if the given value is an Array.\n *\n * @param v the value to check.\n *\n * @return true if the value is an Array, false if not.\n */\napi.isArray = Array.isArray;\n\n/**\n * Returns true if the given value is a Boolean.\n *\n * @param v the value to check.\n *\n * @return true if the value is a Boolean, false if not.\n */\napi.isBoolean = v => (typeof v === 'boolean' ||\n  Object.prototype.toString.call(v) === '[object Boolean]');\n\n/**\n * Returns true if the given value is a double.\n *\n * @param v the value to check.\n *\n * @return true if the value is a double, false if not.\n */\napi.isDouble = v => api.isNumber(v) &&\n  (String(v).indexOf('.') !== -1 || Math.abs(v) >= 1e21);\n\n/**\n * Returns true if the given value is an empty Object.\n *\n * @param v the value to check.\n *\n * @return true if the value is an empty Object, false if not.\n */\napi.isEmptyObject = v => api.isObject(v) && Object.keys(v).length === 0;\n\n/**\n * Returns true if the given value is a Number.\n *\n * @param v the value to check.\n *\n * @return true if the value is a Number, false if not.\n */\napi.isNumber = v => (typeof v === 'number' ||\n  Object.prototype.toString.call(v) === '[object Number]');\n\n/**\n * Returns true if the given value is numeric.\n *\n * @param v the value to check.\n *\n * @return true if the value is numeric, false if not.\n */\napi.isNumeric = v => !isNaN(parseFloat(v)) && isFinite(v);\n\n/**\n * Returns true if the given value is an Object.\n *\n * @param v the value to check.\n *\n * @return true if the value is an Object, false if not.\n */\napi.isObject = v => Object.prototype.toString.call(v) === '[object Object]';\n\n/**\n * Returns true if the given value is a String.\n *\n * @param v the value to check.\n *\n * @return true if the value is a String, false if not.\n */\napi.isString = v => (typeof v === 'string' ||\n  Object.prototype.toString.call(v) === '[object String]');\n\n/**\n * Returns true if the given value is undefined.\n *\n * @param v the value to check.\n *\n * @return true if the value is undefined, false if not.\n */\napi.isUndefined = v => typeof v === 'undefined';\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/types.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/url.js":
/*!****************************************!*\
  !*** ./node_modules/jsonld/lib/url.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst types = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\n\nconst api = {};\nmodule.exports = api;\n\n// define URL parser\n// parseUri 1.2.2\n// (c) Steven Levithan <stevenlevithan.com>\n// MIT License\n// with local jsonld.js modifications\napi.parsers = {\n  simple: {\n    // RFC 3986 basic parts\n    keys: [\n      'href', 'scheme', 'authority', 'path', 'query', 'fragment'\n    ],\n    /* eslint-disable-next-line max-len */\n    regex: /^(?:([^:\\/?#]+):)?(?:\\/\\/([^\\/?#]*))?([^?#]*)(?:\\?([^#]*))?(?:#(.*))?/\n  },\n  full: {\n    keys: [\n      'href', 'protocol', 'scheme', 'authority', 'auth', 'user', 'password',\n      'hostname', 'port', 'path', 'directory', 'file', 'query', 'fragment'\n    ],\n    /* eslint-disable-next-line max-len */\n    regex: /^(([a-zA-Z][a-zA-Z0-9+-.]*):)?(?:\\/\\/((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d*))?))?(?:(((?:[^?#\\/]*\\/)*)([^?#]*))(?:\\?([^#]*))?(?:#(.*))?)/\n  }\n};\napi.parse = (str, parser) => {\n  const parsed = {};\n  const o = api.parsers[parser || 'full'];\n  const m = o.regex.exec(str);\n  let i = o.keys.length;\n  while(i--) {\n    parsed[o.keys[i]] = (m[i] === undefined) ? null : m[i];\n  }\n\n  // remove default ports in found in URLs\n  if((parsed.scheme === 'https' && parsed.port === '443') ||\n    (parsed.scheme === 'http' && parsed.port === '80')) {\n    parsed.href = parsed.href.replace(':' + parsed.port, '');\n    parsed.authority = parsed.authority.replace(':' + parsed.port, '');\n    parsed.port = null;\n  }\n\n  parsed.normalizedPath = api.removeDotSegments(parsed.path);\n  return parsed;\n};\n\n/**\n * Prepends a base IRI to the given relative IRI.\n *\n * @param base the base IRI.\n * @param iri the relative IRI.\n *\n * @return the absolute IRI.\n */\napi.prependBase = (base, iri) => {\n  // skip IRI processing\n  if(base === null) {\n    return iri;\n  }\n  // already an absolute IRI\n  if(api.isAbsolute(iri)) {\n    return iri;\n  }\n\n  // parse base if it is a string\n  if(!base || types.isString(base)) {\n    base = api.parse(base || '');\n  }\n\n  // parse given IRI\n  const rel = api.parse(iri);\n\n  // per RFC3986 5.2.2\n  const transform = {\n    protocol: base.protocol || ''\n  };\n\n  if(rel.authority !== null) {\n    transform.authority = rel.authority;\n    transform.path = rel.path;\n    transform.query = rel.query;\n  } else {\n    transform.authority = base.authority;\n\n    if(rel.path === '') {\n      transform.path = base.path;\n      if(rel.query !== null) {\n        transform.query = rel.query;\n      } else {\n        transform.query = base.query;\n      }\n    } else {\n      if(rel.path.indexOf('/') === 0) {\n        // IRI represents an absolute path\n        transform.path = rel.path;\n      } else {\n        // merge paths\n        let path = base.path;\n\n        // append relative path to the end of the last directory from base\n        path = path.substr(0, path.lastIndexOf('/') + 1);\n        if((path.length > 0 || base.authority) && path.substr(-1) !== '/') {\n          path += '/';\n        }\n        path += rel.path;\n\n        transform.path = path;\n      }\n      transform.query = rel.query;\n    }\n  }\n\n  if(rel.path !== '') {\n    // remove slashes and dots in path\n    transform.path = api.removeDotSegments(transform.path);\n  }\n\n  // construct URL\n  let rval = transform.protocol;\n  if(transform.authority !== null) {\n    rval += '//' + transform.authority;\n  }\n  rval += transform.path;\n  if(transform.query !== null) {\n    rval += '?' + transform.query;\n  }\n  if(rel.fragment !== null) {\n    rval += '#' + rel.fragment;\n  }\n\n  // handle empty base\n  if(rval === '') {\n    rval = './';\n  }\n\n  return rval;\n};\n\n/**\n * Removes a base IRI from the given absolute IRI.\n *\n * @param base the base IRI.\n * @param iri the absolute IRI.\n *\n * @return the relative IRI if relative to base, otherwise the absolute IRI.\n */\napi.removeBase = (base, iri) => {\n  // skip IRI processing\n  if(base === null) {\n    return iri;\n  }\n\n  if(!base || types.isString(base)) {\n    base = api.parse(base || '');\n  }\n\n  // establish base root\n  let root = '';\n  if(base.href !== '') {\n    root += (base.protocol || '') + '//' + (base.authority || '');\n  } else if(iri.indexOf('//')) {\n    // support network-path reference with empty base\n    root += '//';\n  }\n\n  // IRI not relative to base\n  if(iri.indexOf(root) !== 0) {\n    return iri;\n  }\n\n  // remove root from IRI and parse remainder\n  const rel = api.parse(iri.substr(root.length));\n\n  // remove path segments that match (do not remove last segment unless there\n  // is a hash or query)\n  const baseSegments = base.normalizedPath.split('/');\n  const iriSegments = rel.normalizedPath.split('/');\n  const last = (rel.fragment || rel.query) ? 0 : 1;\n  while(baseSegments.length > 0 && iriSegments.length > last) {\n    if(baseSegments[0] !== iriSegments[0]) {\n      break;\n    }\n    baseSegments.shift();\n    iriSegments.shift();\n  }\n\n  // use '../' for each non-matching base segment\n  let rval = '';\n  if(baseSegments.length > 0) {\n    // don't count the last segment (if it ends with '/' last path doesn't\n    // count and if it doesn't end with '/' it isn't a path)\n    baseSegments.pop();\n    for(let i = 0; i < baseSegments.length; ++i) {\n      rval += '../';\n    }\n  }\n\n  // prepend remaining segments\n  rval += iriSegments.join('/');\n\n  // add query and hash\n  if(rel.query !== null) {\n    rval += '?' + rel.query;\n  }\n  if(rel.fragment !== null) {\n    rval += '#' + rel.fragment;\n  }\n\n  // handle empty base\n  if(rval === '') {\n    rval = './';\n  }\n\n  return rval;\n};\n\n/**\n * Removes dot segments from a URL path.\n *\n * @param path the path to remove dot segments from.\n */\napi.removeDotSegments = path => {\n  // RFC 3986 5.2.4 (reworked)\n\n  // empty path shortcut\n  if(path.length === 0) {\n    return '';\n  }\n\n  const input = path.split('/');\n  const output = [];\n\n  while(input.length > 0) {\n    const next = input.shift();\n    const done = input.length === 0;\n\n    if(next === '.') {\n      if(done) {\n        // ensure output has trailing /\n        output.push('');\n      }\n      continue;\n    }\n\n    if(next === '..') {\n      output.pop();\n      if(done) {\n        // ensure output has trailing /\n        output.push('');\n      }\n      continue;\n    }\n\n    output.push(next);\n  }\n\n  // if path was absolute, ensure output has leading /\n  if(path[0] === '/' && output.length > 0 && output[0] !== '') {\n    output.unshift('');\n  }\n  if(output.length === 1 && output[0] === '') {\n    return '/';\n  }\n\n  return output.join('/');\n};\n\n// TODO: time better isAbsolute/isRelative checks using full regexes:\n// http://jmrware.com/articles/2009/uri_regexp/URI_regex.html\n\n// regex to check for absolute IRI (starting scheme and ':') or blank node IRI\nconst isAbsoluteRegex = /^([A-Za-z][A-Za-z0-9+-.]*|_):[^\\s]*$/;\n\n/**\n * Returns true if the given value is an absolute IRI or blank node IRI, false\n * if not.\n * Note: This weak check only checks for a correct starting scheme.\n *\n * @param v the value to check.\n *\n * @return true if the value is an absolute IRI, false if not.\n */\napi.isAbsolute = v => types.isString(v) && isAbsoluteRegex.test(v);\n\n/**\n * Returns true if the given value is a relative IRI, false if not.\n * Note: this is a weak check.\n *\n * @param v the value to check.\n *\n * @return true if the value is a relative IRI, false if not.\n */\napi.isRelative = v => types.isString(v);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/url.js?");

/***/ }),

/***/ "./node_modules/jsonld/lib/util.js":
/*!*****************************************!*\
  !*** ./node_modules/jsonld/lib/util.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright (c) 2017-2019 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst graphTypes = __webpack_require__(/*! ./graphTypes */ \"./node_modules/jsonld/lib/graphTypes.js\");\nconst types = __webpack_require__(/*! ./types */ \"./node_modules/jsonld/lib/types.js\");\n// TODO: move `IdentifierIssuer` to its own package\nconst IdentifierIssuer = (__webpack_require__(/*! rdf-canonize */ \"./node_modules/jsonld/node_modules/rdf-canonize/index.js\").IdentifierIssuer);\nconst JsonLdError = __webpack_require__(/*! ./JsonLdError */ \"./node_modules/jsonld/lib/JsonLdError.js\");\n\n// constants\nconst REGEX_BCP47 = /^[a-zA-Z]{1,8}(-[a-zA-Z0-9]{1,8})*$/;\nconst REGEX_LINK_HEADERS = /(?:<[^>]*?>|\"[^\"]*?\"|[^,])+/g;\nconst REGEX_LINK_HEADER = /\\s*<([^>]*?)>\\s*(?:;\\s*(.*))?/;\nconst REGEX_LINK_HEADER_PARAMS =\n  /(.*?)=(?:(?:\"([^\"]*?)\")|([^\"]*?))\\s*(?:(?:;\\s*)|$)/g;\nconst REGEX_KEYWORD = /^@[a-zA-Z]+$/;\n\nconst DEFAULTS = {\n  headers: {\n    accept: 'application/ld+json, application/json'\n  }\n};\n\nconst api = {};\nmodule.exports = api;\napi.IdentifierIssuer = IdentifierIssuer;\napi.REGEX_BCP47 = REGEX_BCP47;\napi.REGEX_KEYWORD = REGEX_KEYWORD;\n\n/**\n * Clones an object, array, Map, Set, or string/number. If a typed JavaScript\n * object is given, such as a Date, it will be converted to a string.\n *\n * @param value the value to clone.\n *\n * @return the cloned value.\n */\napi.clone = function(value) {\n  if(value && typeof value === 'object') {\n    let rval;\n    if(types.isArray(value)) {\n      rval = [];\n      for(let i = 0; i < value.length; ++i) {\n        rval[i] = api.clone(value[i]);\n      }\n    } else if(value instanceof Map) {\n      rval = new Map();\n      for(const [k, v] of value) {\n        rval.set(k, api.clone(v));\n      }\n    } else if(value instanceof Set) {\n      rval = new Set();\n      for(const v of value) {\n        rval.add(api.clone(v));\n      }\n    } else if(types.isObject(value)) {\n      rval = {};\n      for(const key in value) {\n        rval[key] = api.clone(value[key]);\n      }\n    } else {\n      rval = value.toString();\n    }\n    return rval;\n  }\n  return value;\n};\n\n/**\n * Ensure a value is an array. If the value is an array, it is returned.\n * Otherwise, it is wrapped in an array.\n *\n * @param value the value to return as an array.\n *\n * @return the value as an array.\n */\napi.asArray = function(value) {\n  return Array.isArray(value) ? value : [value];\n};\n\n/**\n * Builds an HTTP headers object for making a JSON-LD request from custom\n * headers and asserts the `accept` header isn't overridden.\n *\n * @param headers an object of headers with keys as header names and values\n *          as header values.\n *\n * @return an object of headers with a valid `accept` header.\n */\napi.buildHeaders = (headers = {}) => {\n  const hasAccept = Object.keys(headers).some(\n    h => h.toLowerCase() === 'accept');\n\n  if(hasAccept) {\n    throw new RangeError(\n      'Accept header may not be specified; only \"' +\n      DEFAULTS.headers.accept + '\" is supported.');\n  }\n\n  return Object.assign({Accept: DEFAULTS.headers.accept}, headers);\n};\n\n/**\n * Parses a link header. The results will be key'd by the value of \"rel\".\n *\n * Link: <http://json-ld.org/contexts/person.jsonld>;\n * rel=\"http://www.w3.org/ns/json-ld#context\"; type=\"application/ld+json\"\n *\n * Parses as: {\n *   'http://www.w3.org/ns/json-ld#context': {\n *     target: http://json-ld.org/contexts/person.jsonld,\n *     type: 'application/ld+json'\n *   }\n * }\n *\n * If there is more than one \"rel\" with the same IRI, then entries in the\n * resulting map for that \"rel\" will be arrays.\n *\n * @param header the link header to parse.\n */\napi.parseLinkHeader = header => {\n  const rval = {};\n  // split on unbracketed/unquoted commas\n  const entries = header.match(REGEX_LINK_HEADERS);\n  for(let i = 0; i < entries.length; ++i) {\n    let match = entries[i].match(REGEX_LINK_HEADER);\n    if(!match) {\n      continue;\n    }\n    const result = {target: match[1]};\n    const params = match[2];\n    while((match = REGEX_LINK_HEADER_PARAMS.exec(params))) {\n      result[match[1]] = (match[2] === undefined) ? match[3] : match[2];\n    }\n    const rel = result.rel || '';\n    if(Array.isArray(rval[rel])) {\n      rval[rel].push(result);\n    } else if(rval.hasOwnProperty(rel)) {\n      rval[rel] = [rval[rel], result];\n    } else {\n      rval[rel] = result;\n    }\n  }\n  return rval;\n};\n\n/**\n * Throws an exception if the given value is not a valid @type value.\n *\n * @param v the value to check.\n */\napi.validateTypeValue = (v, isFrame) => {\n  if(types.isString(v)) {\n    return;\n  }\n\n  if(types.isArray(v) && v.every(vv => types.isString(vv))) {\n    return;\n  }\n  if(isFrame && types.isObject(v)) {\n    switch(Object.keys(v).length) {\n      case 0:\n        // empty object is wildcard\n        return;\n      case 1:\n        // default entry is all strings\n        if('@default' in v &&\n          api.asArray(v['@default']).every(vv => types.isString(vv))) {\n          return;\n        }\n    }\n  }\n\n  throw new JsonLdError(\n    'Invalid JSON-LD syntax; \"@type\" value must a string, an array of ' +\n    'strings, an empty object, ' +\n    'or a default object.', 'jsonld.SyntaxError',\n    {code: 'invalid type value', value: v});\n};\n\n/**\n * Returns true if the given subject has the given property.\n *\n * @param subject the subject to check.\n * @param property the property to look for.\n *\n * @return true if the subject has the given property, false if not.\n */\napi.hasProperty = (subject, property) => {\n  if(subject.hasOwnProperty(property)) {\n    const value = subject[property];\n    return (!types.isArray(value) || value.length > 0);\n  }\n  return false;\n};\n\n/**\n * Determines if the given value is a property of the given subject.\n *\n * @param subject the subject to check.\n * @param property the property to check.\n * @param value the value to check.\n *\n * @return true if the value exists, false if not.\n */\napi.hasValue = (subject, property, value) => {\n  if(api.hasProperty(subject, property)) {\n    let val = subject[property];\n    const isList = graphTypes.isList(val);\n    if(types.isArray(val) || isList) {\n      if(isList) {\n        val = val['@list'];\n      }\n      for(let i = 0; i < val.length; ++i) {\n        if(api.compareValues(value, val[i])) {\n          return true;\n        }\n      }\n    } else if(!types.isArray(value)) {\n      // avoid matching the set of values with an array value parameter\n      return api.compareValues(value, val);\n    }\n  }\n  return false;\n};\n\n/**\n * Adds a value to a subject. If the value is an array, all values in the\n * array will be added.\n *\n * @param subject the subject to add the value to.\n * @param property the property that relates the value to the subject.\n * @param value the value to add.\n * @param [options] the options to use:\n *        [propertyIsArray] true if the property is always an array, false\n *          if not (default: false).\n *        [valueIsArray] true if the value to be added should be preserved as\n *          an array (lists) (default: false).\n *        [allowDuplicate] true to allow duplicates, false not to (uses a\n *          simple shallow comparison of subject ID or value) (default: true).\n *        [prependValue] false to prepend value to any existing values.\n *          (default: false)\n */\napi.addValue = (subject, property, value, options) => {\n  options = options || {};\n  if(!('propertyIsArray' in options)) {\n    options.propertyIsArray = false;\n  }\n  if(!('valueIsArray' in options)) {\n    options.valueIsArray = false;\n  }\n  if(!('allowDuplicate' in options)) {\n    options.allowDuplicate = true;\n  }\n  if(!('prependValue' in options)) {\n    options.prependValue = false;\n  }\n\n  if(options.valueIsArray) {\n    subject[property] = value;\n  } else if(types.isArray(value)) {\n    if(value.length === 0 && options.propertyIsArray &&\n      !subject.hasOwnProperty(property)) {\n      subject[property] = [];\n    }\n    if(options.prependValue) {\n      value = value.concat(subject[property]);\n      subject[property] = [];\n    }\n    for(let i = 0; i < value.length; ++i) {\n      api.addValue(subject, property, value[i], options);\n    }\n  } else if(subject.hasOwnProperty(property)) {\n    // check if subject already has value if duplicates not allowed\n    const hasValue = (!options.allowDuplicate &&\n      api.hasValue(subject, property, value));\n\n    // make property an array if value not present or always an array\n    if(!types.isArray(subject[property]) &&\n      (!hasValue || options.propertyIsArray)) {\n      subject[property] = [subject[property]];\n    }\n\n    // add new value\n    if(!hasValue) {\n      if(options.prependValue) {\n        subject[property].unshift(value);\n      } else {\n        subject[property].push(value);\n      }\n    }\n  } else {\n    // add new value as set or single value\n    subject[property] = options.propertyIsArray ? [value] : value;\n  }\n};\n\n/**\n * Gets all of the values for a subject's property as an array.\n *\n * @param subject the subject.\n * @param property the property.\n *\n * @return all of the values for a subject's property as an array.\n */\napi.getValues = (subject, property) => [].concat(subject[property] || []);\n\n/**\n * Removes a property from a subject.\n *\n * @param subject the subject.\n * @param property the property.\n */\napi.removeProperty = (subject, property) => {\n  delete subject[property];\n};\n\n/**\n * Removes a value from a subject.\n *\n * @param subject the subject.\n * @param property the property that relates the value to the subject.\n * @param value the value to remove.\n * @param [options] the options to use:\n *          [propertyIsArray] true if the property is always an array, false\n *            if not (default: false).\n */\napi.removeValue = (subject, property, value, options) => {\n  options = options || {};\n  if(!('propertyIsArray' in options)) {\n    options.propertyIsArray = false;\n  }\n\n  // filter out value\n  const values = api.getValues(subject, property).filter(\n    e => !api.compareValues(e, value));\n\n  if(values.length === 0) {\n    api.removeProperty(subject, property);\n  } else if(values.length === 1 && !options.propertyIsArray) {\n    subject[property] = values[0];\n  } else {\n    subject[property] = values;\n  }\n};\n\n/**\n * Relabels all blank nodes in the given JSON-LD input.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [issuer] an IdentifierIssuer to use to label blank nodes.\n */\napi.relabelBlankNodes = (input, options) => {\n  options = options || {};\n  const issuer = options.issuer || new IdentifierIssuer('_:b');\n  return _labelBlankNodes(issuer, input);\n};\n\n/**\n * Compares two JSON-LD values for equality. Two JSON-LD values will be\n * considered equal if:\n *\n * 1. They are both primitives of the same type and value.\n * 2. They are both @values with the same @value, @type, @language,\n *   and @index, OR\n * 3. They both have @ids they are the same.\n *\n * @param v1 the first value.\n * @param v2 the second value.\n *\n * @return true if v1 and v2 are considered equal, false if not.\n */\napi.compareValues = (v1, v2) => {\n  // 1. equal primitives\n  if(v1 === v2) {\n    return true;\n  }\n\n  // 2. equal @values\n  if(graphTypes.isValue(v1) && graphTypes.isValue(v2) &&\n    v1['@value'] === v2['@value'] &&\n    v1['@type'] === v2['@type'] &&\n    v1['@language'] === v2['@language'] &&\n    v1['@index'] === v2['@index']) {\n    return true;\n  }\n\n  // 3. equal @ids\n  if(types.isObject(v1) &&\n    ('@id' in v1) &&\n    types.isObject(v2) &&\n    ('@id' in v2)) {\n    return v1['@id'] === v2['@id'];\n  }\n\n  return false;\n};\n\n/**\n * Compares two strings first based on length and then lexicographically.\n *\n * @param a the first string.\n * @param b the second string.\n *\n * @return -1 if a < b, 1 if a > b, 0 if a === b.\n */\napi.compareShortestLeast = (a, b) => {\n  if(a.length < b.length) {\n    return -1;\n  }\n  if(b.length < a.length) {\n    return 1;\n  }\n  if(a === b) {\n    return 0;\n  }\n  return (a < b) ? -1 : 1;\n};\n\n/**\n * Labels the blank nodes in the given value using the given IdentifierIssuer.\n *\n * @param issuer the IdentifierIssuer to use.\n * @param element the element with blank nodes to rename.\n *\n * @return the element.\n */\nfunction _labelBlankNodes(issuer, element) {\n  if(types.isArray(element)) {\n    for(let i = 0; i < element.length; ++i) {\n      element[i] = _labelBlankNodes(issuer, element[i]);\n    }\n  } else if(graphTypes.isList(element)) {\n    element['@list'] = _labelBlankNodes(issuer, element['@list']);\n  } else if(types.isObject(element)) {\n    // relabel blank node\n    if(graphTypes.isBlankNode(element)) {\n      element['@id'] = issuer.getId(element['@id']);\n    }\n\n    // recursively apply to all keys\n    const keys = Object.keys(element).sort();\n    for(let ki = 0; ki < keys.length; ++ki) {\n      const key = keys[ki];\n      if(key !== '@id') {\n        element[key] = _labelBlankNodes(issuer, element[key]);\n      }\n    }\n  }\n\n  return element;\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/lib/util.js?");

/***/ }),

/***/ "./node_modules/jsonld/node_modules/rdf-canonize/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/jsonld/node_modules/rdf-canonize/index.js ***!
  \****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/**\n * An implementation of the RDF Dataset Normalization specification.\n *\n * @author Dave Longley\n *\n * Copyright 2010-2021 Digital Bazaar, Inc.\n */\nmodule.exports = __webpack_require__(/*! ./lib */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/index.js\");\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/node_modules/rdf-canonize/index.js?");

/***/ }),

/***/ "./node_modules/jsonld/node_modules/rdf-canonize/lib/IdentifierIssuer.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/jsonld/node_modules/rdf-canonize/lib/IdentifierIssuer.js ***!
  \*******************************************************************************/
/***/ ((module) => {

"use strict";
eval("/*\n * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nmodule.exports = class IdentifierIssuer {\n  /**\n   * Creates a new IdentifierIssuer. A IdentifierIssuer issues unique\n   * identifiers, keeping track of any previously issued identifiers.\n   *\n   * @param prefix the prefix to use ('<prefix><counter>').\n   * @param existing an existing Map to use.\n   * @param counter the counter to use.\n   */\n  constructor(prefix, existing = new Map(), counter = 0) {\n    this.prefix = prefix;\n    this._existing = existing;\n    this.counter = counter;\n  }\n\n  /**\n   * Copies this IdentifierIssuer.\n   *\n   * @return a copy of this IdentifierIssuer.\n   */\n  clone() {\n    const {prefix, _existing, counter} = this;\n    return new IdentifierIssuer(prefix, new Map(_existing), counter);\n  }\n\n  /**\n   * Gets the new identifier for the given old identifier, where if no old\n   * identifier is given a new identifier will be generated.\n   *\n   * @param [old] the old identifier to get the new identifier for.\n   *\n   * @return the new identifier.\n   */\n  getId(old) {\n    // return existing old identifier\n    const existing = old && this._existing.get(old);\n    if(existing) {\n      return existing;\n    }\n\n    // get next identifier\n    const identifier = this.prefix + this.counter;\n    this.counter++;\n\n    // save mapping\n    if(old) {\n      this._existing.set(old, identifier);\n    }\n\n    return identifier;\n  }\n\n  /**\n   * Returns true if the given old identifer has already been assigned a new\n   * identifier.\n   *\n   * @param old the old identifier to check.\n   *\n   * @return true if the old identifier has been assigned a new identifier,\n   *   false if not.\n   */\n  hasId(old) {\n    return this._existing.has(old);\n  }\n\n  /**\n   * Returns all of the IDs that have been issued new IDs in the order in\n   * which they were issued new IDs.\n   *\n   * @return the list of old IDs that has been issued new IDs in order.\n   */\n  getOldIds() {\n    return [...this._existing.keys()];\n  }\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/node_modules/rdf-canonize/lib/IdentifierIssuer.js?");

/***/ }),

/***/ "./node_modules/jsonld/node_modules/rdf-canonize/lib/MessageDigest-browser.js":
/*!************************************************************************************!*\
  !*** ./node_modules/jsonld/node_modules/rdf-canonize/lib/MessageDigest-browser.js ***!
  \************************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.\n */\n\n\n__webpack_require__(/*! setimmediate */ \"./node_modules/setimmediate/setImmediate.js\");\n\nconst crypto = self.crypto || self.msCrypto;\n\nmodule.exports = class MessageDigest {\n  /**\n   * Creates a new MessageDigest.\n   *\n   * @param algorithm the algorithm to use.\n   */\n  constructor(algorithm) {\n    // check if crypto.subtle is available\n    // check is here rather than top-level to only fail if class is used\n    if(!(crypto && crypto.subtle)) {\n      throw new Error('crypto.subtle not found.');\n    }\n    if(algorithm === 'sha256') {\n      this.algorithm = {name: 'SHA-256'};\n    } else if(algorithm === 'sha1') {\n      this.algorithm = {name: 'SHA-1'};\n    } else {\n      throw new Error(`Unsupported algorithm \"${algorithm}\".`);\n    }\n    this._content = '';\n  }\n\n  update(msg) {\n    this._content += msg;\n  }\n\n  async digest() {\n    const data = new TextEncoder().encode(this._content);\n    const buffer = new Uint8Array(\n      await crypto.subtle.digest(this.algorithm, data));\n    // return digest in hex\n    let hex = '';\n    for(let i = 0; i < buffer.length; ++i) {\n      hex += buffer[i].toString(16).padStart(2, '0');\n    }\n    return hex;\n  }\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/node_modules/rdf-canonize/lib/MessageDigest-browser.js?");

/***/ }),

/***/ "./node_modules/jsonld/node_modules/rdf-canonize/lib/NQuads.js":
/*!*********************************************************************!*\
  !*** ./node_modules/jsonld/node_modules/rdf-canonize/lib/NQuads.js ***!
  \*********************************************************************/
/***/ ((module) => {

"use strict";
eval("/*!\n * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.\n */\n\n\n// eslint-disable-next-line no-unused-vars\nconst TERMS = ['subject', 'predicate', 'object', 'graph'];\nconst RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\nconst RDF_LANGSTRING = RDF + 'langString';\nconst XSD_STRING = 'http://www.w3.org/2001/XMLSchema#string';\n\nconst TYPE_NAMED_NODE = 'NamedNode';\nconst TYPE_BLANK_NODE = 'BlankNode';\nconst TYPE_LITERAL = 'Literal';\nconst TYPE_DEFAULT_GRAPH = 'DefaultGraph';\n\n// build regexes\nconst REGEX = {};\n(() => {\n  const iri = '(?:<([^:]+:[^>]*)>)';\n  // https://www.w3.org/TR/turtle/#grammar-production-BLANK_NODE_LABEL\n  const PN_CHARS_BASE =\n    'A-Z' + 'a-z' +\n    '\\u00C0-\\u00D6' +\n    '\\u00D8-\\u00F6' +\n    '\\u00F8-\\u02FF' +\n    '\\u0370-\\u037D' +\n    '\\u037F-\\u1FFF' +\n    '\\u200C-\\u200D' +\n    '\\u2070-\\u218F' +\n    '\\u2C00-\\u2FEF' +\n    '\\u3001-\\uD7FF' +\n    '\\uF900-\\uFDCF' +\n    '\\uFDF0-\\uFFFD';\n    // TODO:\n    //'\\u10000-\\uEFFFF';\n  const PN_CHARS_U =\n    PN_CHARS_BASE +\n    '_';\n  const PN_CHARS =\n    PN_CHARS_U +\n    '0-9' +\n    '-' +\n    '\\u00B7' +\n    '\\u0300-\\u036F' +\n    '\\u203F-\\u2040';\n  const BLANK_NODE_LABEL =\n    '(_:' +\n      '(?:[' + PN_CHARS_U + '0-9])' +\n      '(?:(?:[' + PN_CHARS + '.])*(?:[' + PN_CHARS + ']))?' +\n    ')';\n  const bnode = BLANK_NODE_LABEL;\n  const plain = '\"([^\"\\\\\\\\]*(?:\\\\\\\\.[^\"\\\\\\\\]*)*)\"';\n  const datatype = '(?:\\\\^\\\\^' + iri + ')';\n  const language = '(?:@([a-zA-Z]+(?:-[a-zA-Z0-9]+)*))';\n  const literal = '(?:' + plain + '(?:' + datatype + '|' + language + ')?)';\n  const ws = '[ \\\\t]+';\n  const wso = '[ \\\\t]*';\n\n  // define quad part regexes\n  const subject = '(?:' + iri + '|' + bnode + ')' + ws;\n  const property = iri + ws;\n  const object = '(?:' + iri + '|' + bnode + '|' + literal + ')' + wso;\n  const graphName = '(?:\\\\.|(?:(?:' + iri + '|' + bnode + ')' + wso + '\\\\.))';\n\n  // end of line and empty regexes\n  REGEX.eoln = /(?:\\r\\n)|(?:\\n)|(?:\\r)/g;\n  REGEX.empty = new RegExp('^' + wso + '$');\n\n  // full quad regex\n  REGEX.quad = new RegExp(\n    '^' + wso + subject + property + object + graphName + wso + '$');\n})();\n\nmodule.exports = class NQuads {\n  /**\n   * Parses RDF in the form of N-Quads.\n   *\n   * @param input the N-Quads input to parse.\n   *\n   * @return an RDF dataset (an array of quads per http://rdf.js.org/).\n   */\n  static parse(input) {\n    // build RDF dataset\n    const dataset = [];\n\n    const graphs = {};\n\n    // split N-Quad input into lines\n    const lines = input.split(REGEX.eoln);\n    let lineNumber = 0;\n    for(const line of lines) {\n      lineNumber++;\n\n      // skip empty lines\n      if(REGEX.empty.test(line)) {\n        continue;\n      }\n\n      // parse quad\n      const match = line.match(REGEX.quad);\n      if(match === null) {\n        throw new Error('N-Quads parse error on line ' + lineNumber + '.');\n      }\n\n      // create RDF quad\n      const quad = {subject: null, predicate: null, object: null, graph: null};\n\n      // get subject\n      if(match[1] !== undefined) {\n        quad.subject = {termType: TYPE_NAMED_NODE, value: match[1]};\n      } else {\n        quad.subject = {termType: TYPE_BLANK_NODE, value: match[2]};\n      }\n\n      // get predicate\n      quad.predicate = {termType: TYPE_NAMED_NODE, value: match[3]};\n\n      // get object\n      if(match[4] !== undefined) {\n        quad.object = {termType: TYPE_NAMED_NODE, value: match[4]};\n      } else if(match[5] !== undefined) {\n        quad.object = {termType: TYPE_BLANK_NODE, value: match[5]};\n      } else {\n        quad.object = {\n          termType: TYPE_LITERAL,\n          value: undefined,\n          datatype: {\n            termType: TYPE_NAMED_NODE\n          }\n        };\n        if(match[7] !== undefined) {\n          quad.object.datatype.value = match[7];\n        } else if(match[8] !== undefined) {\n          quad.object.datatype.value = RDF_LANGSTRING;\n          quad.object.language = match[8];\n        } else {\n          quad.object.datatype.value = XSD_STRING;\n        }\n        quad.object.value = _unescape(match[6]);\n      }\n\n      // get graph\n      if(match[9] !== undefined) {\n        quad.graph = {\n          termType: TYPE_NAMED_NODE,\n          value: match[9]\n        };\n      } else if(match[10] !== undefined) {\n        quad.graph = {\n          termType: TYPE_BLANK_NODE,\n          value: match[10]\n        };\n      } else {\n        quad.graph = {\n          termType: TYPE_DEFAULT_GRAPH,\n          value: ''\n        };\n      }\n\n      // only add quad if it is unique in its graph\n      if(!(quad.graph.value in graphs)) {\n        graphs[quad.graph.value] = [quad];\n        dataset.push(quad);\n      } else {\n        let unique = true;\n        const quads = graphs[quad.graph.value];\n        for(const q of quads) {\n          if(_compareTriples(q, quad)) {\n            unique = false;\n            break;\n          }\n        }\n        if(unique) {\n          quads.push(quad);\n          dataset.push(quad);\n        }\n      }\n    }\n\n    return dataset;\n  }\n\n  /**\n   * Converts an RDF dataset to N-Quads.\n   *\n   * @param dataset (array of quads) the RDF dataset to convert.\n   *\n   * @return the N-Quads string.\n   */\n  static serialize(dataset) {\n    if(!Array.isArray(dataset)) {\n      dataset = NQuads.legacyDatasetToQuads(dataset);\n    }\n    const quads = [];\n    for(const quad of dataset) {\n      quads.push(NQuads.serializeQuad(quad));\n    }\n    return quads.sort().join('');\n  }\n\n  /**\n   * Converts RDF quad components to an N-Quad string (a single quad).\n   *\n   * @param {Object} s - N-Quad subject component.\n   * @param {Object} p - N-Quad predicate component.\n   * @param {Object} o - N-Quad object component.\n   * @param {Object} g - N-Quad graph component.\n   *\n   * @return {string} the N-Quad.\n   */\n  static serializeQuadComponents(s, p, o, g) {\n    let nquad = '';\n\n    // subject can only be NamedNode or BlankNode\n    if(s.termType === TYPE_NAMED_NODE) {\n      nquad += `<${s.value}>`;\n    } else {\n      nquad += `${s.value}`;\n    }\n\n    // predicate can only be NamedNode\n    nquad += ` <${p.value}> `;\n\n    // object is NamedNode, BlankNode, or Literal\n    if(o.termType === TYPE_NAMED_NODE) {\n      nquad += `<${o.value}>`;\n    } else if(o.termType === TYPE_BLANK_NODE) {\n      nquad += o.value;\n    } else {\n      nquad += `\"${_escape(o.value)}\"`;\n      if(o.datatype.value === RDF_LANGSTRING) {\n        if(o.language) {\n          nquad += `@${o.language}`;\n        }\n      } else if(o.datatype.value !== XSD_STRING) {\n        nquad += `^^<${o.datatype.value}>`;\n      }\n    }\n\n    // graph can only be NamedNode or BlankNode (or DefaultGraph, but that\n    // does not add to `nquad`)\n    if(g.termType === TYPE_NAMED_NODE) {\n      nquad += ` <${g.value}>`;\n    } else if(g.termType === TYPE_BLANK_NODE) {\n      nquad += ` ${g.value}`;\n    }\n\n    nquad += ' .\\n';\n    return nquad;\n  }\n\n  /**\n   * Converts an RDF quad to an N-Quad string (a single quad).\n   *\n   * @param quad the RDF quad convert.\n   *\n   * @return the N-Quad string.\n   */\n  static serializeQuad(quad) {\n    return NQuads.serializeQuadComponents(\n      quad.subject, quad.predicate, quad.object, quad.graph);\n  }\n\n  /**\n   * Converts a legacy-formatted dataset to an array of quads dataset per\n   * http://rdf.js.org/.\n   *\n   * @param dataset the legacy dataset to convert.\n   *\n   * @return the array of quads dataset.\n   */\n  static legacyDatasetToQuads(dataset) {\n    const quads = [];\n\n    const termTypeMap = {\n      'blank node': TYPE_BLANK_NODE,\n      IRI: TYPE_NAMED_NODE,\n      literal: TYPE_LITERAL\n    };\n\n    for(const graphName in dataset) {\n      const triples = dataset[graphName];\n      triples.forEach(triple => {\n        const quad = {};\n        for(const componentName in triple) {\n          const oldComponent = triple[componentName];\n          const newComponent = {\n            termType: termTypeMap[oldComponent.type],\n            value: oldComponent.value\n          };\n          if(newComponent.termType === TYPE_LITERAL) {\n            newComponent.datatype = {\n              termType: TYPE_NAMED_NODE\n            };\n            if('datatype' in oldComponent) {\n              newComponent.datatype.value = oldComponent.datatype;\n            }\n            if('language' in oldComponent) {\n              if(!('datatype' in oldComponent)) {\n                newComponent.datatype.value = RDF_LANGSTRING;\n              }\n              newComponent.language = oldComponent.language;\n            } else if(!('datatype' in oldComponent)) {\n              newComponent.datatype.value = XSD_STRING;\n            }\n          }\n          quad[componentName] = newComponent;\n        }\n        if(graphName === '@default') {\n          quad.graph = {\n            termType: TYPE_DEFAULT_GRAPH,\n            value: ''\n          };\n        } else {\n          quad.graph = {\n            termType: graphName.startsWith('_:') ?\n              TYPE_BLANK_NODE : TYPE_NAMED_NODE,\n            value: graphName\n          };\n        }\n        quads.push(quad);\n      });\n    }\n\n    return quads;\n  }\n};\n\n/**\n * Compares two RDF triples for equality.\n *\n * @param t1 the first triple.\n * @param t2 the second triple.\n *\n * @return true if the triples are the same, false if not.\n */\nfunction _compareTriples(t1, t2) {\n  // compare subject and object types first as it is the quickest check\n  if(!(t1.subject.termType === t2.subject.termType &&\n    t1.object.termType === t2.object.termType)) {\n    return false;\n  }\n  // compare values\n  if(!(t1.subject.value === t2.subject.value &&\n    t1.predicate.value === t2.predicate.value &&\n    t1.object.value === t2.object.value)) {\n    return false;\n  }\n  if(t1.object.termType !== TYPE_LITERAL) {\n    // no `datatype` or `language` to check\n    return true;\n  }\n  return (\n    (t1.object.datatype.termType === t2.object.datatype.termType) &&\n    (t1.object.language === t2.object.language) &&\n    (t1.object.datatype.value === t2.object.datatype.value)\n  );\n}\n\nconst _escapeRegex = /[\"\\\\\\n\\r]/g;\n/**\n * Escape string to N-Quads literal\n */\nfunction _escape(s) {\n  return s.replace(_escapeRegex, function(match) {\n    switch(match) {\n      case '\"': return '\\\\\"';\n      case '\\\\': return '\\\\\\\\';\n      case '\\n': return '\\\\n';\n      case '\\r': return '\\\\r';\n    }\n  });\n}\n\nconst _unescapeRegex =\n  /(?:\\\\([tbnrf\"'\\\\]))|(?:\\\\u([0-9A-Fa-f]{4}))|(?:\\\\U([0-9A-Fa-f]{8}))/g;\n/**\n * Unescape N-Quads literal to string\n */\nfunction _unescape(s) {\n  return s.replace(_unescapeRegex, function(match, code, u, U) {\n    if(code) {\n      switch(code) {\n        case 't': return '\\t';\n        case 'b': return '\\b';\n        case 'n': return '\\n';\n        case 'r': return '\\r';\n        case 'f': return '\\f';\n        case '\"': return '\"';\n        case '\\'': return '\\'';\n        case '\\\\': return '\\\\';\n      }\n    }\n    if(u) {\n      return String.fromCharCode(parseInt(u, 16));\n    }\n    if(U) {\n      // FIXME: support larger values\n      throw new Error('Unsupported U escape');\n    }\n  });\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/node_modules/rdf-canonize/lib/NQuads.js?");

/***/ }),

/***/ "./node_modules/jsonld/node_modules/rdf-canonize/lib/Permuter.js":
/*!***********************************************************************!*\
  !*** ./node_modules/jsonld/node_modules/rdf-canonize/lib/Permuter.js ***!
  \***********************************************************************/
/***/ ((module) => {

"use strict";
eval("/*!\n * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nmodule.exports = class Permuter {\n  /**\n   * A Permuter iterates over all possible permutations of the given array\n   * of elements.\n   *\n   * @param list the array of elements to iterate over.\n   */\n  constructor(list) {\n    // original array\n    this.current = list.sort();\n    // indicates whether there are more permutations\n    this.done = false;\n    // directional info for permutation algorithm\n    this.dir = new Map();\n    for(let i = 0; i < list.length; ++i) {\n      this.dir.set(list[i], true);\n    }\n  }\n\n  /**\n   * Returns true if there is another permutation.\n   *\n   * @return true if there is another permutation, false if not.\n   */\n  hasNext() {\n    return !this.done;\n  }\n\n  /**\n   * Gets the next permutation. Call hasNext() to ensure there is another one\n   * first.\n   *\n   * @return the next permutation.\n   */\n  next() {\n    // copy current permutation to return it\n    const {current, dir} = this;\n    const rval = current.slice();\n\n    /* Calculate the next permutation using the Steinhaus-Johnson-Trotter\n     permutation algorithm. */\n\n    // get largest mobile element k\n    // (mobile: element is greater than the one it is looking at)\n    let k = null;\n    let pos = 0;\n    const length = current.length;\n    for(let i = 0; i < length; ++i) {\n      const element = current[i];\n      const left = dir.get(element);\n      if((k === null || element > k) &&\n        ((left && i > 0 && element > current[i - 1]) ||\n        (!left && i < (length - 1) && element > current[i + 1]))) {\n        k = element;\n        pos = i;\n      }\n    }\n\n    // no more permutations\n    if(k === null) {\n      this.done = true;\n    } else {\n      // swap k and the element it is looking at\n      const swap = dir.get(k) ? pos - 1 : pos + 1;\n      current[pos] = current[swap];\n      current[swap] = k;\n\n      // reverse the direction of all elements larger than k\n      for(const element of current) {\n        if(element > k) {\n          dir.set(element, !dir.get(element));\n        }\n      }\n    }\n\n    return rval;\n  }\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/node_modules/rdf-canonize/lib/Permuter.js?");

/***/ }),

/***/ "./node_modules/jsonld/node_modules/rdf-canonize/lib/URDNA2015.js":
/*!************************************************************************!*\
  !*** ./node_modules/jsonld/node_modules/rdf-canonize/lib/URDNA2015.js ***!
  \************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst IdentifierIssuer = __webpack_require__(/*! ./IdentifierIssuer */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/IdentifierIssuer.js\");\nconst MessageDigest = __webpack_require__(/*! ./MessageDigest */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/MessageDigest-browser.js\");\nconst Permuter = __webpack_require__(/*! ./Permuter */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/Permuter.js\");\nconst NQuads = __webpack_require__(/*! ./NQuads */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/NQuads.js\");\n\nmodule.exports = class URDNA2015 {\n  constructor({\n    createMessageDigest = () => new MessageDigest('sha256'),\n    canonicalIdMap = new Map(),\n    maxDeepIterations = Infinity\n  } = {}) {\n    this.name = 'URDNA2015';\n    this.blankNodeInfo = new Map();\n    this.canonicalIssuer = new IdentifierIssuer('_:c14n', canonicalIdMap);\n    this.createMessageDigest = createMessageDigest;\n    this.maxDeepIterations = maxDeepIterations;\n    this.quads = null;\n    this.deepIterations = null;\n  }\n\n  // 4.4) Normalization Algorithm\n  async main(dataset) {\n    this.deepIterations = new Map();\n    this.quads = dataset;\n\n    // 1) Create the normalization state.\n    // 2) For every quad in input dataset:\n    for(const quad of dataset) {\n      // 2.1) For each blank node that occurs in the quad, add a reference\n      // to the quad using the blank node identifier in the blank node to\n      // quads map, creating a new entry if necessary.\n      this._addBlankNodeQuadInfo({quad, component: quad.subject});\n      this._addBlankNodeQuadInfo({quad, component: quad.object});\n      this._addBlankNodeQuadInfo({quad, component: quad.graph});\n    }\n\n    // 3) Create a list of non-normalized blank node identifiers\n    // non-normalized identifiers and populate it using the keys from the\n    // blank node to quads map.\n    // Note: We use a map here and it was generated during step 2.\n\n    // 4) `simple` flag is skipped -- loop is optimized away. This optimization\n    // is permitted because there was a typo in the hash first degree quads\n    // algorithm in the URDNA2015 spec that was implemented widely making it\n    // such that it could not be fixed; the result was that the loop only\n    // needs to be run once and the first degree quad hashes will never change.\n    // 5.1-5.2 are skipped; first degree quad hashes are generated just once\n    // for all non-normalized blank nodes.\n\n    // 5.3) For each blank node identifier identifier in non-normalized\n    // identifiers:\n    const hashToBlankNodes = new Map();\n    const nonNormalized = [...this.blankNodeInfo.keys()];\n    let i = 0;\n    for(const id of nonNormalized) {\n      // Note: batch hashing first degree quads 100 at a time\n      if(++i % 100 === 0) {\n        await this._yield();\n      }\n      // steps 5.3.1 and 5.3.2:\n      await this._hashAndTrackBlankNode({id, hashToBlankNodes});\n    }\n\n    // 5.4) For each hash to identifier list mapping in hash to blank\n    // nodes map, lexicographically-sorted by hash:\n    const hashes = [...hashToBlankNodes.keys()].sort();\n    // optimize away second sort, gather non-unique hashes in order as we go\n    const nonUnique = [];\n    for(const hash of hashes) {\n      // 5.4.1) If the length of identifier list is greater than 1,\n      // continue to the next mapping.\n      const idList = hashToBlankNodes.get(hash);\n      if(idList.length > 1) {\n        nonUnique.push(idList);\n        continue;\n      }\n\n      // 5.4.2) Use the Issue Identifier algorithm, passing canonical\n      // issuer and the single blank node identifier in identifier\n      // list, identifier, to issue a canonical replacement identifier\n      // for identifier.\n      const id = idList[0];\n      this.canonicalIssuer.getId(id);\n\n      // Note: These steps are skipped, optimized away since the loop\n      // only needs to be run once.\n      // 5.4.3) Remove identifier from non-normalized identifiers.\n      // 5.4.4) Remove hash from the hash to blank nodes map.\n      // 5.4.5) Set simple to true.\n    }\n\n    // 6) For each hash to identifier list mapping in hash to blank nodes map,\n    // lexicographically-sorted by hash:\n    // Note: sort optimized away, use `nonUnique`.\n    for(const idList of nonUnique) {\n      // 6.1) Create hash path list where each item will be a result of\n      // running the Hash N-Degree Quads algorithm.\n      const hashPathList = [];\n\n      // 6.2) For each blank node identifier identifier in identifier list:\n      for(const id of idList) {\n        // 6.2.1) If a canonical identifier has already been issued for\n        // identifier, continue to the next identifier.\n        if(this.canonicalIssuer.hasId(id)) {\n          continue;\n        }\n\n        // 6.2.2) Create temporary issuer, an identifier issuer\n        // initialized with the prefix _:b.\n        const issuer = new IdentifierIssuer('_:b');\n\n        // 6.2.3) Use the Issue Identifier algorithm, passing temporary\n        // issuer and identifier, to issue a new temporary blank node\n        // identifier for identifier.\n        issuer.getId(id);\n\n        // 6.2.4) Run the Hash N-Degree Quads algorithm, passing\n        // temporary issuer, and append the result to the hash path list.\n        const result = await this.hashNDegreeQuads(id, issuer);\n        hashPathList.push(result);\n      }\n\n      // 6.3) For each result in the hash path list,\n      // lexicographically-sorted by the hash in result:\n      hashPathList.sort(_stringHashCompare);\n      for(const result of hashPathList) {\n        // 6.3.1) For each blank node identifier, existing identifier,\n        // that was issued a temporary identifier by identifier issuer\n        // in result, issue a canonical identifier, in the same order,\n        // using the Issue Identifier algorithm, passing canonical\n        // issuer and existing identifier.\n        const oldIds = result.issuer.getOldIds();\n        for(const id of oldIds) {\n          this.canonicalIssuer.getId(id);\n        }\n      }\n    }\n\n    /* Note: At this point all blank nodes in the set of RDF quads have been\n    assigned canonical identifiers, which have been stored in the canonical\n    issuer. Here each quad is updated by assigning each of its blank nodes\n    its new identifier. */\n\n    // 7) For each quad, quad, in input dataset:\n    const normalized = [];\n    for(const quad of this.quads) {\n      // 7.1) Create a copy, quad copy, of quad and replace any existing\n      // blank node identifiers using the canonical identifiers\n      // previously issued by canonical issuer.\n      // Note: We optimize away the copy here.\n      const nQuad = NQuads.serializeQuadComponents(\n        this._componentWithCanonicalId(quad.subject),\n        quad.predicate,\n        this._componentWithCanonicalId(quad.object),\n        this._componentWithCanonicalId(quad.graph)\n      );\n      // 7.2) Add quad copy to the normalized dataset.\n      normalized.push(nQuad);\n    }\n\n    // sort normalized output\n    normalized.sort();\n\n    // 8) Return the normalized dataset.\n    return normalized.join('');\n  }\n\n  // 4.6) Hash First Degree Quads\n  async hashFirstDegreeQuads(id) {\n    // 1) Initialize nquads to an empty list. It will be used to store quads in\n    // N-Quads format.\n    const nquads = [];\n\n    // 2) Get the list of quads `quads` associated with the reference blank node\n    // identifier in the blank node to quads map.\n    const info = this.blankNodeInfo.get(id);\n    const quads = info.quads;\n\n    // 3) For each quad `quad` in `quads`:\n    for(const quad of quads) {\n      // 3.1) Serialize the quad in N-Quads format with the following special\n      // rule:\n\n      // 3.1.1) If any component in quad is an blank node, then serialize it\n      // using a special identifier as follows:\n      const copy = {\n        subject: null, predicate: quad.predicate, object: null, graph: null\n      };\n      // 3.1.2) If the blank node's existing blank node identifier matches\n      // the reference blank node identifier then use the blank node\n      // identifier _:a, otherwise, use the blank node identifier _:z.\n      copy.subject = this.modifyFirstDegreeComponent(\n        id, quad.subject, 'subject');\n      copy.object = this.modifyFirstDegreeComponent(\n        id, quad.object, 'object');\n      copy.graph = this.modifyFirstDegreeComponent(\n        id, quad.graph, 'graph');\n      nquads.push(NQuads.serializeQuad(copy));\n    }\n\n    // 4) Sort nquads in lexicographical order.\n    nquads.sort();\n\n    // 5) Return the hash that results from passing the sorted, joined nquads\n    // through the hash algorithm.\n    const md = this.createMessageDigest();\n    for(const nquad of nquads) {\n      md.update(nquad);\n    }\n    info.hash = await md.digest();\n    return info.hash;\n  }\n\n  // 4.7) Hash Related Blank Node\n  async hashRelatedBlankNode(related, quad, issuer, position) {\n    // 1) Set the identifier to use for related, preferring first the canonical\n    // identifier for related if issued, second the identifier issued by issuer\n    // if issued, and last, if necessary, the result of the Hash First Degree\n    // Quads algorithm, passing related.\n    let id;\n    if(this.canonicalIssuer.hasId(related)) {\n      id = this.canonicalIssuer.getId(related);\n    } else if(issuer.hasId(related)) {\n      id = issuer.getId(related);\n    } else {\n      id = this.blankNodeInfo.get(related).hash;\n    }\n\n    // 2) Initialize a string input to the value of position.\n    // Note: We use a hash object instead.\n    const md = this.createMessageDigest();\n    md.update(position);\n\n    // 3) If position is not g, append <, the value of the predicate in quad,\n    // and > to input.\n    if(position !== 'g') {\n      md.update(this.getRelatedPredicate(quad));\n    }\n\n    // 4) Append identifier to input.\n    md.update(id);\n\n    // 5) Return the hash that results from passing input through the hash\n    // algorithm.\n    return md.digest();\n  }\n\n  // 4.8) Hash N-Degree Quads\n  async hashNDegreeQuads(id, issuer) {\n    const deepIterations = this.deepIterations.get(id) || 0;\n    if(deepIterations > this.maxDeepIterations) {\n      throw new Error(\n        `Maximum deep iterations (${this.maxDeepIterations}) exceeded.`);\n    }\n    this.deepIterations.set(id, deepIterations + 1);\n\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    // Note: 2) and 3) handled within `createHashToRelated`\n    const md = this.createMessageDigest();\n    const hashToRelated = await this.createHashToRelated(id, issuer);\n\n    // 4) Create an empty string, data to hash.\n    // Note: We created a hash object `md` above instead.\n\n    // 5) For each related hash to blank node list mapping in hash to related\n    // blank nodes map, sorted lexicographically by related hash:\n    const hashes = [...hashToRelated.keys()].sort();\n    for(const hash of hashes) {\n      // 5.1) Append the related hash to the data to hash.\n      md.update(hash);\n\n      // 5.2) Create a string chosen path.\n      let chosenPath = '';\n\n      // 5.3) Create an unset chosen issuer variable.\n      let chosenIssuer;\n\n      // 5.4) For each permutation of blank node list:\n      const permuter = new Permuter(hashToRelated.get(hash));\n      let i = 0;\n      while(permuter.hasNext()) {\n        const permutation = permuter.next();\n        // Note: batch permutations 3 at a time\n        if(++i % 3 === 0) {\n          await this._yield();\n        }\n\n        // 5.4.1) Create a copy of issuer, issuer copy.\n        let issuerCopy = issuer.clone();\n\n        // 5.4.2) Create a string path.\n        let path = '';\n\n        // 5.4.3) Create a recursion list, to store blank node identifiers\n        // that must be recursively processed by this algorithm.\n        const recursionList = [];\n\n        // 5.4.4) For each related in permutation:\n        let nextPermutation = false;\n        for(const related of permutation) {\n          // 5.4.4.1) If a canonical identifier has been issued for\n          // related, append it to path.\n          if(this.canonicalIssuer.hasId(related)) {\n            path += this.canonicalIssuer.getId(related);\n          } else {\n            // 5.4.4.2) Otherwise:\n            // 5.4.4.2.1) If issuer copy has not issued an identifier for\n            // related, append related to recursion list.\n            if(!issuerCopy.hasId(related)) {\n              recursionList.push(related);\n            }\n            // 5.4.4.2.2) Use the Issue Identifier algorithm, passing\n            // issuer copy and related and append the result to path.\n            path += issuerCopy.getId(related);\n          }\n\n          // 5.4.4.3) If chosen path is not empty and the length of path\n          // is greater than or equal to the length of chosen path and\n          // path is lexicographically greater than chosen path, then\n          // skip to the next permutation.\n          // Note: Comparing path length to chosen path length can be optimized\n          // away; only compare lexicographically.\n          if(chosenPath.length !== 0 && path > chosenPath) {\n            nextPermutation = true;\n            break;\n          }\n        }\n\n        if(nextPermutation) {\n          continue;\n        }\n\n        // 5.4.5) For each related in recursion list:\n        for(const related of recursionList) {\n          // 5.4.5.1) Set result to the result of recursively executing\n          // the Hash N-Degree Quads algorithm, passing related for\n          // identifier and issuer copy for path identifier issuer.\n          const result = await this.hashNDegreeQuads(related, issuerCopy);\n\n          // 5.4.5.2) Use the Issue Identifier algorithm, passing issuer\n          // copy and related and append the result to path.\n          path += issuerCopy.getId(related);\n\n          // 5.4.5.3) Append <, the hash in result, and > to path.\n          path += `<${result.hash}>`;\n\n          // 5.4.5.4) Set issuer copy to the identifier issuer in\n          // result.\n          issuerCopy = result.issuer;\n\n          // 5.4.5.5) If chosen path is not empty and the length of path\n          // is greater than or equal to the length of chosen path and\n          // path is lexicographically greater than chosen path, then\n          // skip to the next permutation.\n          // Note: Comparing path length to chosen path length can be optimized\n          // away; only compare lexicographically.\n          if(chosenPath.length !== 0 && path > chosenPath) {\n            nextPermutation = true;\n            break;\n          }\n        }\n\n        if(nextPermutation) {\n          continue;\n        }\n\n        // 5.4.6) If chosen path is empty or path is lexicographically\n        // less than chosen path, set chosen path to path and chosen\n        // issuer to issuer copy.\n        if(chosenPath.length === 0 || path < chosenPath) {\n          chosenPath = path;\n          chosenIssuer = issuerCopy;\n        }\n      }\n\n      // 5.5) Append chosen path to data to hash.\n      md.update(chosenPath);\n\n      // 5.6) Replace issuer, by reference, with chosen issuer.\n      issuer = chosenIssuer;\n    }\n\n    // 6) Return issuer and the hash that results from passing data to hash\n    // through the hash algorithm.\n    return {hash: await md.digest(), issuer};\n  }\n\n  // helper for modifying component during Hash First Degree Quads\n  modifyFirstDegreeComponent(id, component) {\n    if(component.termType !== 'BlankNode') {\n      return component;\n    }\n    /* Note: A mistake in the URDNA2015 spec that made its way into\n    implementations (and therefore must stay to avoid interop breakage)\n    resulted in an assigned canonical ID, if available for\n    `component.value`, not being used in place of `_:a`/`_:z`, so\n    we don't use it here. */\n    return {\n      termType: 'BlankNode',\n      value: component.value === id ? '_:a' : '_:z'\n    };\n  }\n\n  // helper for getting a related predicate\n  getRelatedPredicate(quad) {\n    return `<${quad.predicate.value}>`;\n  }\n\n  // helper for creating hash to related blank nodes map\n  async createHashToRelated(id, issuer) {\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    const hashToRelated = new Map();\n\n    // 2) Get a reference, quads, to the list of quads in the blank node to\n    // quads map for the key identifier.\n    const quads = this.blankNodeInfo.get(id).quads;\n\n    // 3) For each quad in quads:\n    let i = 0;\n    for(const quad of quads) {\n      // Note: batch hashing related blank node quads 100 at a time\n      if(++i % 100 === 0) {\n        await this._yield();\n      }\n      // 3.1) For each component in quad, if component is the subject, object,\n      // and graph name and it is a blank node that is not identified by\n      // identifier:\n      // steps 3.1.1 and 3.1.2 occur in helpers:\n      await Promise.all([\n        this._addRelatedBlankNodeHash({\n          quad, component: quad.subject, position: 's',\n          id, issuer, hashToRelated\n        }),\n        this._addRelatedBlankNodeHash({\n          quad, component: quad.object, position: 'o',\n          id, issuer, hashToRelated\n        }),\n        this._addRelatedBlankNodeHash({\n          quad, component: quad.graph, position: 'g',\n          id, issuer, hashToRelated\n        })\n      ]);\n    }\n\n    return hashToRelated;\n  }\n\n  async _hashAndTrackBlankNode({id, hashToBlankNodes}) {\n    // 5.3.1) Create a hash, hash, according to the Hash First Degree\n    // Quads algorithm.\n    const hash = await this.hashFirstDegreeQuads(id);\n\n    // 5.3.2) Add hash and identifier to hash to blank nodes map,\n    // creating a new entry if necessary.\n    const idList = hashToBlankNodes.get(hash);\n    if(!idList) {\n      hashToBlankNodes.set(hash, [id]);\n    } else {\n      idList.push(id);\n    }\n  }\n\n  _addBlankNodeQuadInfo({quad, component}) {\n    if(component.termType !== 'BlankNode') {\n      return;\n    }\n    const id = component.value;\n    const info = this.blankNodeInfo.get(id);\n    if(info) {\n      info.quads.add(quad);\n    } else {\n      this.blankNodeInfo.set(id, {quads: new Set([quad]), hash: null});\n    }\n  }\n\n  async _addRelatedBlankNodeHash(\n    {quad, component, position, id, issuer, hashToRelated}) {\n    if(!(component.termType === 'BlankNode' && component.value !== id)) {\n      return;\n    }\n    // 3.1.1) Set hash to the result of the Hash Related Blank Node\n    // algorithm, passing the blank node identifier for component as\n    // related, quad, path identifier issuer as issuer, and position as\n    // either s, o, or g based on whether component is a subject, object,\n    // graph name, respectively.\n    const related = component.value;\n    const hash = await this.hashRelatedBlankNode(\n      related, quad, issuer, position);\n\n    // 3.1.2) Add a mapping of hash to the blank node identifier for\n    // component to hash to related blank nodes map, adding an entry as\n    // necessary.\n    const entries = hashToRelated.get(hash);\n    if(entries) {\n      entries.push(related);\n    } else {\n      hashToRelated.set(hash, [related]);\n    }\n  }\n\n  // canonical ids for 7.1\n  _componentWithCanonicalId(component) {\n    if(component.termType === 'BlankNode' &&\n      !component.value.startsWith(this.canonicalIssuer.prefix)) {\n      // create new BlankNode\n      return {\n        termType: 'BlankNode',\n        value: this.canonicalIssuer.getId(component.value)\n      };\n    }\n    return component;\n  }\n\n  async _yield() {\n    return new Promise(resolve => setImmediate(resolve));\n  }\n};\n\nfunction _stringHashCompare(a, b) {\n  return a.hash < b.hash ? -1 : a.hash > b.hash ? 1 : 0;\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/node_modules/rdf-canonize/lib/URDNA2015.js?");

/***/ }),

/***/ "./node_modules/jsonld/node_modules/rdf-canonize/lib/URDNA2015Sync.js":
/*!****************************************************************************!*\
  !*** ./node_modules/jsonld/node_modules/rdf-canonize/lib/URDNA2015Sync.js ***!
  \****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst IdentifierIssuer = __webpack_require__(/*! ./IdentifierIssuer */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/IdentifierIssuer.js\");\n// FIXME: do not import; convert to requiring a\n// hash factory\nconst MessageDigest = __webpack_require__(/*! ./MessageDigest */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/MessageDigest-browser.js\");\nconst Permuter = __webpack_require__(/*! ./Permuter */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/Permuter.js\");\nconst NQuads = __webpack_require__(/*! ./NQuads */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/NQuads.js\");\n\nmodule.exports = class URDNA2015Sync {\n  constructor({\n    createMessageDigest = () => new MessageDigest('sha256'),\n    canonicalIdMap = new Map(),\n    maxDeepIterations = Infinity\n  } = {}) {\n    this.name = 'URDNA2015';\n    this.blankNodeInfo = new Map();\n    this.canonicalIssuer = new IdentifierIssuer('_:c14n', canonicalIdMap);\n    this.createMessageDigest = createMessageDigest;\n    this.maxDeepIterations = maxDeepIterations;\n    this.quads = null;\n    this.deepIterations = null;\n  }\n\n  // 4.4) Normalization Algorithm\n  main(dataset) {\n    this.deepIterations = new Map();\n    this.quads = dataset;\n\n    // 1) Create the normalization state.\n    // 2) For every quad in input dataset:\n    for(const quad of dataset) {\n      // 2.1) For each blank node that occurs in the quad, add a reference\n      // to the quad using the blank node identifier in the blank node to\n      // quads map, creating a new entry if necessary.\n      this._addBlankNodeQuadInfo({quad, component: quad.subject});\n      this._addBlankNodeQuadInfo({quad, component: quad.object});\n      this._addBlankNodeQuadInfo({quad, component: quad.graph});\n    }\n\n    // 3) Create a list of non-normalized blank node identifiers\n    // non-normalized identifiers and populate it using the keys from the\n    // blank node to quads map.\n    // Note: We use a map here and it was generated during step 2.\n\n    // 4) `simple` flag is skipped -- loop is optimized away. This optimization\n    // is permitted because there was a typo in the hash first degree quads\n    // algorithm in the URDNA2015 spec that was implemented widely making it\n    // such that it could not be fixed; the result was that the loop only\n    // needs to be run once and the first degree quad hashes will never change.\n    // 5.1-5.2 are skipped; first degree quad hashes are generated just once\n    // for all non-normalized blank nodes.\n\n    // 5.3) For each blank node identifier identifier in non-normalized\n    // identifiers:\n    const hashToBlankNodes = new Map();\n    const nonNormalized = [...this.blankNodeInfo.keys()];\n    for(const id of nonNormalized) {\n      // steps 5.3.1 and 5.3.2:\n      this._hashAndTrackBlankNode({id, hashToBlankNodes});\n    }\n\n    // 5.4) For each hash to identifier list mapping in hash to blank\n    // nodes map, lexicographically-sorted by hash:\n    const hashes = [...hashToBlankNodes.keys()].sort();\n    // optimize away second sort, gather non-unique hashes in order as we go\n    const nonUnique = [];\n    for(const hash of hashes) {\n      // 5.4.1) If the length of identifier list is greater than 1,\n      // continue to the next mapping.\n      const idList = hashToBlankNodes.get(hash);\n      if(idList.length > 1) {\n        nonUnique.push(idList);\n        continue;\n      }\n\n      // 5.4.2) Use the Issue Identifier algorithm, passing canonical\n      // issuer and the single blank node identifier in identifier\n      // list, identifier, to issue a canonical replacement identifier\n      // for identifier.\n      const id = idList[0];\n      this.canonicalIssuer.getId(id);\n\n      // Note: These steps are skipped, optimized away since the loop\n      // only needs to be run once.\n      // 5.4.3) Remove identifier from non-normalized identifiers.\n      // 5.4.4) Remove hash from the hash to blank nodes map.\n      // 5.4.5) Set simple to true.\n    }\n\n    // 6) For each hash to identifier list mapping in hash to blank nodes map,\n    // lexicographically-sorted by hash:\n    // Note: sort optimized away, use `nonUnique`.\n    for(const idList of nonUnique) {\n      // 6.1) Create hash path list where each item will be a result of\n      // running the Hash N-Degree Quads algorithm.\n      const hashPathList = [];\n\n      // 6.2) For each blank node identifier identifier in identifier list:\n      for(const id of idList) {\n        // 6.2.1) If a canonical identifier has already been issued for\n        // identifier, continue to the next identifier.\n        if(this.canonicalIssuer.hasId(id)) {\n          continue;\n        }\n\n        // 6.2.2) Create temporary issuer, an identifier issuer\n        // initialized with the prefix _:b.\n        const issuer = new IdentifierIssuer('_:b');\n\n        // 6.2.3) Use the Issue Identifier algorithm, passing temporary\n        // issuer and identifier, to issue a new temporary blank node\n        // identifier for identifier.\n        issuer.getId(id);\n\n        // 6.2.4) Run the Hash N-Degree Quads algorithm, passing\n        // temporary issuer, and append the result to the hash path list.\n        const result = this.hashNDegreeQuads(id, issuer);\n        hashPathList.push(result);\n      }\n\n      // 6.3) For each result in the hash path list,\n      // lexicographically-sorted by the hash in result:\n      hashPathList.sort(_stringHashCompare);\n      for(const result of hashPathList) {\n        // 6.3.1) For each blank node identifier, existing identifier,\n        // that was issued a temporary identifier by identifier issuer\n        // in result, issue a canonical identifier, in the same order,\n        // using the Issue Identifier algorithm, passing canonical\n        // issuer and existing identifier.\n        const oldIds = result.issuer.getOldIds();\n        for(const id of oldIds) {\n          this.canonicalIssuer.getId(id);\n        }\n      }\n    }\n\n    /* Note: At this point all blank nodes in the set of RDF quads have been\n    assigned canonical identifiers, which have been stored in the canonical\n    issuer. Here each quad is updated by assigning each of its blank nodes\n    its new identifier. */\n\n    // 7) For each quad, quad, in input dataset:\n    const normalized = [];\n    for(const quad of this.quads) {\n      // 7.1) Create a copy, quad copy, of quad and replace any existing\n      // blank node identifiers using the canonical identifiers\n      // previously issued by canonical issuer.\n      // Note: We optimize away the copy here.\n      const nQuad = NQuads.serializeQuadComponents(\n        this._componentWithCanonicalId({component: quad.subject}),\n        quad.predicate,\n        this._componentWithCanonicalId({component: quad.object}),\n        this._componentWithCanonicalId({component: quad.graph})\n      );\n      // 7.2) Add quad copy to the normalized dataset.\n      normalized.push(nQuad);\n    }\n\n    // sort normalized output\n    normalized.sort();\n\n    // 8) Return the normalized dataset.\n    return normalized.join('');\n  }\n\n  // 4.6) Hash First Degree Quads\n  hashFirstDegreeQuads(id) {\n    // 1) Initialize nquads to an empty list. It will be used to store quads in\n    // N-Quads format.\n    const nquads = [];\n\n    // 2) Get the list of quads `quads` associated with the reference blank node\n    // identifier in the blank node to quads map.\n    const info = this.blankNodeInfo.get(id);\n    const quads = info.quads;\n\n    // 3) For each quad `quad` in `quads`:\n    for(const quad of quads) {\n      // 3.1) Serialize the quad in N-Quads format with the following special\n      // rule:\n\n      // 3.1.1) If any component in quad is an blank node, then serialize it\n      // using a special identifier as follows:\n      const copy = {\n        subject: null, predicate: quad.predicate, object: null, graph: null\n      };\n      // 3.1.2) If the blank node's existing blank node identifier matches\n      // the reference blank node identifier then use the blank node\n      // identifier _:a, otherwise, use the blank node identifier _:z.\n      copy.subject = this.modifyFirstDegreeComponent(\n        id, quad.subject, 'subject');\n      copy.object = this.modifyFirstDegreeComponent(\n        id, quad.object, 'object');\n      copy.graph = this.modifyFirstDegreeComponent(\n        id, quad.graph, 'graph');\n      nquads.push(NQuads.serializeQuad(copy));\n    }\n\n    // 4) Sort nquads in lexicographical order.\n    nquads.sort();\n\n    // 5) Return the hash that results from passing the sorted, joined nquads\n    // through the hash algorithm.\n    const md = this.createMessageDigest();\n    for(const nquad of nquads) {\n      md.update(nquad);\n    }\n    info.hash = md.digest();\n    return info.hash;\n  }\n\n  // 4.7) Hash Related Blank Node\n  hashRelatedBlankNode(related, quad, issuer, position) {\n    // 1) Set the identifier to use for related, preferring first the canonical\n    // identifier for related if issued, second the identifier issued by issuer\n    // if issued, and last, if necessary, the result of the Hash First Degree\n    // Quads algorithm, passing related.\n    let id;\n    if(this.canonicalIssuer.hasId(related)) {\n      id = this.canonicalIssuer.getId(related);\n    } else if(issuer.hasId(related)) {\n      id = issuer.getId(related);\n    } else {\n      id = this.blankNodeInfo.get(related).hash;\n    }\n\n    // 2) Initialize a string input to the value of position.\n    // Note: We use a hash object instead.\n    const md = this.createMessageDigest();\n    md.update(position);\n\n    // 3) If position is not g, append <, the value of the predicate in quad,\n    // and > to input.\n    if(position !== 'g') {\n      md.update(this.getRelatedPredicate(quad));\n    }\n\n    // 4) Append identifier to input.\n    md.update(id);\n\n    // 5) Return the hash that results from passing input through the hash\n    // algorithm.\n    return md.digest();\n  }\n\n  // 4.8) Hash N-Degree Quads\n  hashNDegreeQuads(id, issuer) {\n    const deepIterations = this.deepIterations.get(id) || 0;\n    if(deepIterations > this.maxDeepIterations) {\n      throw new Error(\n        `Maximum deep iterations (${this.maxDeepIterations}) exceeded.`);\n    }\n    this.deepIterations.set(id, deepIterations + 1);\n\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    // Note: 2) and 3) handled within `createHashToRelated`\n    const md = this.createMessageDigest();\n    const hashToRelated = this.createHashToRelated(id, issuer);\n\n    // 4) Create an empty string, data to hash.\n    // Note: We created a hash object `md` above instead.\n\n    // 5) For each related hash to blank node list mapping in hash to related\n    // blank nodes map, sorted lexicographically by related hash:\n    const hashes = [...hashToRelated.keys()].sort();\n    for(const hash of hashes) {\n      // 5.1) Append the related hash to the data to hash.\n      md.update(hash);\n\n      // 5.2) Create a string chosen path.\n      let chosenPath = '';\n\n      // 5.3) Create an unset chosen issuer variable.\n      let chosenIssuer;\n\n      // 5.4) For each permutation of blank node list:\n      const permuter = new Permuter(hashToRelated.get(hash));\n      while(permuter.hasNext()) {\n        const permutation = permuter.next();\n\n        // 5.4.1) Create a copy of issuer, issuer copy.\n        let issuerCopy = issuer.clone();\n\n        // 5.4.2) Create a string path.\n        let path = '';\n\n        // 5.4.3) Create a recursion list, to store blank node identifiers\n        // that must be recursively processed by this algorithm.\n        const recursionList = [];\n\n        // 5.4.4) For each related in permutation:\n        let nextPermutation = false;\n        for(const related of permutation) {\n          // 5.4.4.1) If a canonical identifier has been issued for\n          // related, append it to path.\n          if(this.canonicalIssuer.hasId(related)) {\n            path += this.canonicalIssuer.getId(related);\n          } else {\n            // 5.4.4.2) Otherwise:\n            // 5.4.4.2.1) If issuer copy has not issued an identifier for\n            // related, append related to recursion list.\n            if(!issuerCopy.hasId(related)) {\n              recursionList.push(related);\n            }\n            // 5.4.4.2.2) Use the Issue Identifier algorithm, passing\n            // issuer copy and related and append the result to path.\n            path += issuerCopy.getId(related);\n          }\n\n          // 5.4.4.3) If chosen path is not empty and the length of path\n          // is greater than or equal to the length of chosen path and\n          // path is lexicographically greater than chosen path, then\n          // skip to the next permutation.\n          // Note: Comparing path length to chosen path length can be optimized\n          // away; only compare lexicographically.\n          if(chosenPath.length !== 0 && path > chosenPath) {\n            nextPermutation = true;\n            break;\n          }\n        }\n\n        if(nextPermutation) {\n          continue;\n        }\n\n        // 5.4.5) For each related in recursion list:\n        for(const related of recursionList) {\n          // 5.4.5.1) Set result to the result of recursively executing\n          // the Hash N-Degree Quads algorithm, passing related for\n          // identifier and issuer copy for path identifier issuer.\n          const result = this.hashNDegreeQuads(related, issuerCopy);\n\n          // 5.4.5.2) Use the Issue Identifier algorithm, passing issuer\n          // copy and related and append the result to path.\n          path += issuerCopy.getId(related);\n\n          // 5.4.5.3) Append <, the hash in result, and > to path.\n          path += `<${result.hash}>`;\n\n          // 5.4.5.4) Set issuer copy to the identifier issuer in\n          // result.\n          issuerCopy = result.issuer;\n\n          // 5.4.5.5) If chosen path is not empty and the length of path\n          // is greater than or equal to the length of chosen path and\n          // path is lexicographically greater than chosen path, then\n          // skip to the next permutation.\n          // Note: Comparing path length to chosen path length can be optimized\n          // away; only compare lexicographically.\n          if(chosenPath.length !== 0 && path > chosenPath) {\n            nextPermutation = true;\n            break;\n          }\n        }\n\n        if(nextPermutation) {\n          continue;\n        }\n\n        // 5.4.6) If chosen path is empty or path is lexicographically\n        // less than chosen path, set chosen path to path and chosen\n        // issuer to issuer copy.\n        if(chosenPath.length === 0 || path < chosenPath) {\n          chosenPath = path;\n          chosenIssuer = issuerCopy;\n        }\n      }\n\n      // 5.5) Append chosen path to data to hash.\n      md.update(chosenPath);\n\n      // 5.6) Replace issuer, by reference, with chosen issuer.\n      issuer = chosenIssuer;\n    }\n\n    // 6) Return issuer and the hash that results from passing data to hash\n    // through the hash algorithm.\n    return {hash: md.digest(), issuer};\n  }\n\n  // helper for modifying component during Hash First Degree Quads\n  modifyFirstDegreeComponent(id, component) {\n    if(component.termType !== 'BlankNode') {\n      return component;\n    }\n    /* Note: A mistake in the URDNA2015 spec that made its way into\n    implementations (and therefore must stay to avoid interop breakage)\n    resulted in an assigned canonical ID, if available for\n    `component.value`, not being used in place of `_:a`/`_:z`, so\n    we don't use it here. */\n    return {\n      termType: 'BlankNode',\n      value: component.value === id ? '_:a' : '_:z'\n    };\n  }\n\n  // helper for getting a related predicate\n  getRelatedPredicate(quad) {\n    return `<${quad.predicate.value}>`;\n  }\n\n  // helper for creating hash to related blank nodes map\n  createHashToRelated(id, issuer) {\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    const hashToRelated = new Map();\n\n    // 2) Get a reference, quads, to the list of quads in the blank node to\n    // quads map for the key identifier.\n    const quads = this.blankNodeInfo.get(id).quads;\n\n    // 3) For each quad in quads:\n    for(const quad of quads) {\n      // 3.1) For each component in quad, if component is the subject, object,\n      // or graph name and it is a blank node that is not identified by\n      // identifier:\n      // steps 3.1.1 and 3.1.2 occur in helpers:\n      this._addRelatedBlankNodeHash({\n        quad, component: quad.subject, position: 's',\n        id, issuer, hashToRelated\n      });\n      this._addRelatedBlankNodeHash({\n        quad, component: quad.object, position: 'o',\n        id, issuer, hashToRelated\n      });\n      this._addRelatedBlankNodeHash({\n        quad, component: quad.graph, position: 'g',\n        id, issuer, hashToRelated\n      });\n    }\n\n    return hashToRelated;\n  }\n\n  _hashAndTrackBlankNode({id, hashToBlankNodes}) {\n    // 5.3.1) Create a hash, hash, according to the Hash First Degree\n    // Quads algorithm.\n    const hash = this.hashFirstDegreeQuads(id);\n\n    // 5.3.2) Add hash and identifier to hash to blank nodes map,\n    // creating a new entry if necessary.\n    const idList = hashToBlankNodes.get(hash);\n    if(!idList) {\n      hashToBlankNodes.set(hash, [id]);\n    } else {\n      idList.push(id);\n    }\n  }\n\n  _addBlankNodeQuadInfo({quad, component}) {\n    if(component.termType !== 'BlankNode') {\n      return;\n    }\n    const id = component.value;\n    const info = this.blankNodeInfo.get(id);\n    if(info) {\n      info.quads.add(quad);\n    } else {\n      this.blankNodeInfo.set(id, {quads: new Set([quad]), hash: null});\n    }\n  }\n\n  _addRelatedBlankNodeHash(\n    {quad, component, position, id, issuer, hashToRelated}) {\n    if(!(component.termType === 'BlankNode' && component.value !== id)) {\n      return;\n    }\n    // 3.1.1) Set hash to the result of the Hash Related Blank Node\n    // algorithm, passing the blank node identifier for component as\n    // related, quad, path identifier issuer as issuer, and position as\n    // either s, o, or g based on whether component is a subject, object,\n    // graph name, respectively.\n    const related = component.value;\n    const hash = this.hashRelatedBlankNode(related, quad, issuer, position);\n\n    // 3.1.2) Add a mapping of hash to the blank node identifier for\n    // component to hash to related blank nodes map, adding an entry as\n    // necessary.\n    const entries = hashToRelated.get(hash);\n    if(entries) {\n      entries.push(related);\n    } else {\n      hashToRelated.set(hash, [related]);\n    }\n  }\n\n  // canonical ids for 7.1\n  _componentWithCanonicalId({component}) {\n    if(component.termType === 'BlankNode' &&\n      !component.value.startsWith(this.canonicalIssuer.prefix)) {\n      // create new BlankNode\n      return {\n        termType: 'BlankNode',\n        value: this.canonicalIssuer.getId(component.value)\n      };\n    }\n    return component;\n  }\n};\n\nfunction _stringHashCompare(a, b) {\n  return a.hash < b.hash ? -1 : a.hash > b.hash ? 1 : 0;\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/node_modules/rdf-canonize/lib/URDNA2015Sync.js?");

/***/ }),

/***/ "./node_modules/jsonld/node_modules/rdf-canonize/lib/URGNA2012.js":
/*!************************************************************************!*\
  !*** ./node_modules/jsonld/node_modules/rdf-canonize/lib/URGNA2012.js ***!
  \************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst MessageDigest = __webpack_require__(/*! ./MessageDigest */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/MessageDigest-browser.js\");\nconst URDNA2015 = __webpack_require__(/*! ./URDNA2015 */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/URDNA2015.js\");\n\nmodule.exports = class URDNA2012 extends URDNA2015 {\n  constructor() {\n    super();\n    this.name = 'URGNA2012';\n    this.createMessageDigest = () => new MessageDigest('sha1');\n  }\n\n  // helper for modifying component during Hash First Degree Quads\n  modifyFirstDegreeComponent(id, component, key) {\n    if(component.termType !== 'BlankNode') {\n      return component;\n    }\n    if(key === 'graph') {\n      return {\n        termType: 'BlankNode',\n        value: '_:g'\n      };\n    }\n    return {\n      termType: 'BlankNode',\n      value: (component.value === id ? '_:a' : '_:z')\n    };\n  }\n\n  // helper for getting a related predicate\n  getRelatedPredicate(quad) {\n    return quad.predicate.value;\n  }\n\n  // helper for creating hash to related blank nodes map\n  async createHashToRelated(id, issuer) {\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    const hashToRelated = new Map();\n\n    // 2) Get a reference, quads, to the list of quads in the blank node to\n    // quads map for the key identifier.\n    const quads = this.blankNodeInfo.get(id).quads;\n\n    // 3) For each quad in quads:\n    let i = 0;\n    for(const quad of quads) {\n      // 3.1) If the quad's subject is a blank node that does not match\n      // identifier, set hash to the result of the Hash Related Blank Node\n      // algorithm, passing the blank node identifier for subject as related,\n      // quad, path identifier issuer as issuer, and p as position.\n      let position;\n      let related;\n      if(quad.subject.termType === 'BlankNode' && quad.subject.value !== id) {\n        related = quad.subject.value;\n        position = 'p';\n      } else if(\n        quad.object.termType === 'BlankNode' && quad.object.value !== id) {\n        // 3.2) Otherwise, if quad's object is a blank node that does not match\n        // identifier, to the result of the Hash Related Blank Node algorithm,\n        // passing the blank node identifier for object as related, quad, path\n        // identifier issuer as issuer, and r as position.\n        related = quad.object.value;\n        position = 'r';\n      } else {\n        // 3.3) Otherwise, continue to the next quad.\n        continue;\n      }\n      // Note: batch hashing related blank nodes 100 at a time\n      if(++i % 100 === 0) {\n        await this._yield();\n      }\n      // 3.4) Add a mapping of hash to the blank node identifier for the\n      // component that matched (subject or object) to hash to related blank\n      // nodes map, adding an entry as necessary.\n      const hash = await this.hashRelatedBlankNode(\n        related, quad, issuer, position);\n      const entries = hashToRelated.get(hash);\n      if(entries) {\n        entries.push(related);\n      } else {\n        hashToRelated.set(hash, [related]);\n      }\n    }\n\n    return hashToRelated;\n  }\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/node_modules/rdf-canonize/lib/URGNA2012.js?");

/***/ }),

/***/ "./node_modules/jsonld/node_modules/rdf-canonize/lib/URGNA2012Sync.js":
/*!****************************************************************************!*\
  !*** ./node_modules/jsonld/node_modules/rdf-canonize/lib/URGNA2012Sync.js ***!
  \****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst MessageDigest = __webpack_require__(/*! ./MessageDigest */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/MessageDigest-browser.js\");\nconst URDNA2015Sync = __webpack_require__(/*! ./URDNA2015Sync */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/URDNA2015Sync.js\");\n\nmodule.exports = class URDNA2012Sync extends URDNA2015Sync {\n  constructor() {\n    super();\n    this.name = 'URGNA2012';\n    this.createMessageDigest = () => new MessageDigest('sha1');\n  }\n\n  // helper for modifying component during Hash First Degree Quads\n  modifyFirstDegreeComponent(id, component, key) {\n    if(component.termType !== 'BlankNode') {\n      return component;\n    }\n    if(key === 'graph') {\n      return {\n        termType: 'BlankNode',\n        value: '_:g'\n      };\n    }\n    return {\n      termType: 'BlankNode',\n      value: (component.value === id ? '_:a' : '_:z')\n    };\n  }\n\n  // helper for getting a related predicate\n  getRelatedPredicate(quad) {\n    return quad.predicate.value;\n  }\n\n  // helper for creating hash to related blank nodes map\n  createHashToRelated(id, issuer) {\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    const hashToRelated = new Map();\n\n    // 2) Get a reference, quads, to the list of quads in the blank node to\n    // quads map for the key identifier.\n    const quads = this.blankNodeInfo.get(id).quads;\n\n    // 3) For each quad in quads:\n    for(const quad of quads) {\n      // 3.1) If the quad's subject is a blank node that does not match\n      // identifier, set hash to the result of the Hash Related Blank Node\n      // algorithm, passing the blank node identifier for subject as related,\n      // quad, path identifier issuer as issuer, and p as position.\n      let position;\n      let related;\n      if(quad.subject.termType === 'BlankNode' && quad.subject.value !== id) {\n        related = quad.subject.value;\n        position = 'p';\n      } else if(\n        quad.object.termType === 'BlankNode' && quad.object.value !== id) {\n        // 3.2) Otherwise, if quad's object is a blank node that does not match\n        // identifier, to the result of the Hash Related Blank Node algorithm,\n        // passing the blank node identifier for object as related, quad, path\n        // identifier issuer as issuer, and r as position.\n        related = quad.object.value;\n        position = 'r';\n      } else {\n        // 3.3) Otherwise, continue to the next quad.\n        continue;\n      }\n      // 3.4) Add a mapping of hash to the blank node identifier for the\n      // component that matched (subject or object) to hash to related blank\n      // nodes map, adding an entry as necessary.\n      const hash = this.hashRelatedBlankNode(related, quad, issuer, position);\n      const entries = hashToRelated.get(hash);\n      if(entries) {\n        entries.push(related);\n      } else {\n        hashToRelated.set(hash, [related]);\n      }\n    }\n\n    return hashToRelated;\n  }\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/node_modules/rdf-canonize/lib/URGNA2012Sync.js?");

/***/ }),

/***/ "./node_modules/jsonld/node_modules/rdf-canonize/lib/index.js":
/*!********************************************************************!*\
  !*** ./node_modules/jsonld/node_modules/rdf-canonize/lib/index.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("/**\n * An implementation of the RDF Dataset Normalization specification.\n * This library works in the browser and node.js.\n *\n * BSD 3-Clause License\n * Copyright (c) 2016-2023 Digital Bazaar, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * Redistributions of source code must retain the above copyright notice,\n * this list of conditions and the following disclaimer.\n *\n * Redistributions in binary form must reproduce the above copyright\n * notice, this list of conditions and the following disclaimer in the\n * documentation and/or other materials provided with the distribution.\n *\n * Neither the name of the Digital Bazaar, Inc. nor the names of its\n * contributors may be used to endorse or promote products derived from\n * this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\n * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n\nconst URDNA2015 = __webpack_require__(/*! ./URDNA2015 */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/URDNA2015.js\");\nconst URGNA2012 = __webpack_require__(/*! ./URGNA2012 */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/URGNA2012.js\");\nconst URDNA2015Sync = __webpack_require__(/*! ./URDNA2015Sync */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/URDNA2015Sync.js\");\nconst URGNA2012Sync = __webpack_require__(/*! ./URGNA2012Sync */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/URGNA2012Sync.js\");\n\n// optional native support\nlet rdfCanonizeNative;\ntry {\n  rdfCanonizeNative = __webpack_require__(/*! rdf-canonize-native */ \"?f4a3\");\n} catch(e) {}\n\n// return a dataset from input dataset or legacy dataset\nfunction _inputToDataset(input/*, options*/) {\n  // back-compat with legacy dataset\n  if(!Array.isArray(input)) {\n    return exports.NQuads.legacyDatasetToQuads(input);\n  }\n  return input;\n}\n\n// expose helpers\nexports.NQuads = __webpack_require__(/*! ./NQuads */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/NQuads.js\");\nexports.IdentifierIssuer = __webpack_require__(/*! ./IdentifierIssuer */ \"./node_modules/jsonld/node_modules/rdf-canonize/lib/IdentifierIssuer.js\");\n\n/**\n * Get or set native API.\n *\n * @param api the native API.\n *\n * @return the currently set native API.\n */\nexports._rdfCanonizeNative = function(api) {\n  if(api) {\n    rdfCanonizeNative = api;\n  }\n  return rdfCanonizeNative;\n};\n\n/**\n * Asynchronously canonizes an RDF dataset.\n *\n * @param {Array|object|string} input - The input to canonize given as a\n *   dataset or legacy dataset.\n * @param {object} options - The options to use:\n *   {string} algorithm - The canonicalization algorithm to use, `URDNA2015` or\n *     `URGNA2012`.\n *   {Function} [createMessageDigest] - A factory function for creating a\n *     `MessageDigest` interface that overrides the built-in message digest\n *     implementation used by the canonize algorithm; note that using a hash\n *     algorithm (or HMAC algorithm) that differs from the one specified by\n *     the canonize algorithm will result in different output.\n *   {Map} [canonicalIdMap] - An optional Map to be populated by the canonical\n *     identifier issuer with the bnode identifier mapping generated by the\n *     canonicalization algorithm.\n *   {boolean} [useNative=false] - Use native implementation.\n *   {number} [maxDeepIterations=Infinity] - The maximum number of times to run\n *     deep comparison algorithms (such as the N-Degree Hash Quads algorithm\n *     used in URDNA2015) before bailing out and throwing an error; this is a\n *     useful setting for preventing wasted CPU cycles or DoS when canonizing\n *     meaningless or potentially malicious datasets, a recommended value is\n *     `1`.\n *\n * @return a Promise that resolves to the canonicalized RDF Dataset.\n */\nexports.canonize = async function(input, options) {\n  const dataset = _inputToDataset(input, options);\n\n  if(options.useNative) {\n    if(!rdfCanonizeNative) {\n      throw new Error('rdf-canonize-native not available');\n    }\n    if(options.createMessageDigest) {\n      throw new Error(\n        '\"createMessageDigest\" cannot be used with \"useNative\".');\n    }\n    return new Promise((resolve, reject) =>\n      rdfCanonizeNative.canonize(dataset, options, (err, canonical) =>\n        err ? reject(err) : resolve(canonical)));\n  }\n\n  if(options.algorithm === 'URDNA2015') {\n    return new URDNA2015(options).main(dataset);\n  }\n  if(options.algorithm === 'URGNA2012') {\n    if(options.createMessageDigest) {\n      throw new Error(\n        '\"createMessageDigest\" cannot be used with \"URGNA2012\".');\n    }\n    return new URGNA2012(options).main(dataset);\n  }\n  if(!('algorithm' in options)) {\n    throw new Error('No RDF Dataset Canonicalization algorithm specified.');\n  }\n  throw new Error(\n    'Invalid RDF Dataset Canonicalization algorithm: ' + options.algorithm);\n};\n\n/**\n * This method is no longer available in the public API, it is for testing\n * only. It synchronously canonizes an RDF dataset and does not work in the\n * browser.\n *\n * @param {Array|object|string} input - The input to canonize given as a\n *   dataset or legacy dataset.\n * @param {object} options - The options to use:\n *   {string} algorithm - The canonicalization algorithm to use, `URDNA2015` or\n *     `URGNA2012`.\n *   {Function} [createMessageDigest] - A factory function for creating a\n *     `MessageDigest` interface that overrides the built-in message digest\n *     implementation used by the canonize algorithm; note that using a hash\n *     algorithm (or HMAC algorithm) that differs from the one specified by\n *     the canonize algorithm will result in different output.\n *   {boolean} [useNative=false] - Use native implementation.\n *   {number} [maxDeepIterations=Infinity] - The maximum number of times to run\n *     deep comparison algorithms (such as the N-Degree Hash Quads algorithm\n *     used in URDNA2015) before bailing out and throwing an error; this is a\n *     useful setting for preventing wasted CPU cycles or DoS when canonizing\n *     meaningless or potentially malicious datasets, a recommended value is\n *     `1`.\n *\n * @return the RDF dataset in canonical form.\n */\nexports._canonizeSync = function(input, options) {\n  const dataset = _inputToDataset(input, options);\n\n  if(options.useNative) {\n    if(!rdfCanonizeNative) {\n      throw new Error('rdf-canonize-native not available');\n    }\n    if(options.createMessageDigest) {\n      throw new Error(\n        '\"createMessageDigest\" cannot be used with \"useNative\".');\n    }\n    return rdfCanonizeNative.canonizeSync(dataset, options);\n  }\n  if(options.algorithm === 'URDNA2015') {\n    return new URDNA2015Sync(options).main(dataset);\n  }\n  if(options.algorithm === 'URGNA2012') {\n    if(options.createMessageDigest) {\n      throw new Error(\n        '\"createMessageDigest\" cannot be used with \"URGNA2012\".');\n    }\n    return new URGNA2012Sync(options).main(dataset);\n  }\n  if(!('algorithm' in options)) {\n    throw new Error('No RDF Dataset Canonicalization algorithm specified.');\n  }\n  throw new Error(\n    'Invalid RDF Dataset Canonicalization algorithm: ' + options.algorithm);\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/jsonld/node_modules/rdf-canonize/lib/index.js?");

/***/ }),

/***/ "./node_modules/lodash/_Symbol.js":
/*!****************************************!*\
  !*** ./node_modules/lodash/_Symbol.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var root = __webpack_require__(/*! ./_root */ \"./node_modules/lodash/_root.js\");\n\n/** Built-in value references. */\nvar Symbol = root.Symbol;\n\nmodule.exports = Symbol;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/_Symbol.js?");

/***/ }),

/***/ "./node_modules/lodash/_baseGetTag.js":
/*!********************************************!*\
  !*** ./node_modules/lodash/_baseGetTag.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var Symbol = __webpack_require__(/*! ./_Symbol */ \"./node_modules/lodash/_Symbol.js\"),\n    getRawTag = __webpack_require__(/*! ./_getRawTag */ \"./node_modules/lodash/_getRawTag.js\"),\n    objectToString = __webpack_require__(/*! ./_objectToString */ \"./node_modules/lodash/_objectToString.js\");\n\n/** `Object#toString` result references. */\nvar nullTag = '[object Null]',\n    undefinedTag = '[object Undefined]';\n\n/** Built-in value references. */\nvar symToStringTag = Symbol ? Symbol.toStringTag : undefined;\n\n/**\n * The base implementation of `getTag` without fallbacks for buggy environments.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nfunction baseGetTag(value) {\n  if (value == null) {\n    return value === undefined ? undefinedTag : nullTag;\n  }\n  return (symToStringTag && symToStringTag in Object(value))\n    ? getRawTag(value)\n    : objectToString(value);\n}\n\nmodule.exports = baseGetTag;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/_baseGetTag.js?");

/***/ }),

/***/ "./node_modules/lodash/_baseTrim.js":
/*!******************************************!*\
  !*** ./node_modules/lodash/_baseTrim.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var trimmedEndIndex = __webpack_require__(/*! ./_trimmedEndIndex */ \"./node_modules/lodash/_trimmedEndIndex.js\");\n\n/** Used to match leading whitespace. */\nvar reTrimStart = /^\\s+/;\n\n/**\n * The base implementation of `_.trim`.\n *\n * @private\n * @param {string} string The string to trim.\n * @returns {string} Returns the trimmed string.\n */\nfunction baseTrim(string) {\n  return string\n    ? string.slice(0, trimmedEndIndex(string) + 1).replace(reTrimStart, '')\n    : string;\n}\n\nmodule.exports = baseTrim;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/_baseTrim.js?");

/***/ }),

/***/ "./node_modules/lodash/_freeGlobal.js":
/*!********************************************!*\
  !*** ./node_modules/lodash/_freeGlobal.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof __webpack_require__.g == 'object' && __webpack_require__.g && __webpack_require__.g.Object === Object && __webpack_require__.g;\n\nmodule.exports = freeGlobal;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/_freeGlobal.js?");

/***/ }),

/***/ "./node_modules/lodash/_getRawTag.js":
/*!*******************************************!*\
  !*** ./node_modules/lodash/_getRawTag.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var Symbol = __webpack_require__(/*! ./_Symbol */ \"./node_modules/lodash/_Symbol.js\");\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/** Built-in value references. */\nvar symToStringTag = Symbol ? Symbol.toStringTag : undefined;\n\n/**\n * A specialized version of `baseGetTag` which ignores `Symbol.toStringTag` values.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the raw `toStringTag`.\n */\nfunction getRawTag(value) {\n  var isOwn = hasOwnProperty.call(value, symToStringTag),\n      tag = value[symToStringTag];\n\n  try {\n    value[symToStringTag] = undefined;\n    var unmasked = true;\n  } catch (e) {}\n\n  var result = nativeObjectToString.call(value);\n  if (unmasked) {\n    if (isOwn) {\n      value[symToStringTag] = tag;\n    } else {\n      delete value[symToStringTag];\n    }\n  }\n  return result;\n}\n\nmodule.exports = getRawTag;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/_getRawTag.js?");

/***/ }),

/***/ "./node_modules/lodash/_objectToString.js":
/*!************************************************!*\
  !*** ./node_modules/lodash/_objectToString.js ***!
  \************************************************/
/***/ ((module) => {

eval("/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/**\n * Converts `value` to a string using `Object.prototype.toString`.\n *\n * @private\n * @param {*} value The value to convert.\n * @returns {string} Returns the converted string.\n */\nfunction objectToString(value) {\n  return nativeObjectToString.call(value);\n}\n\nmodule.exports = objectToString;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/_objectToString.js?");

/***/ }),

/***/ "./node_modules/lodash/_root.js":
/*!**************************************!*\
  !*** ./node_modules/lodash/_root.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var freeGlobal = __webpack_require__(/*! ./_freeGlobal */ \"./node_modules/lodash/_freeGlobal.js\");\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\nmodule.exports = root;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/_root.js?");

/***/ }),

/***/ "./node_modules/lodash/_trimmedEndIndex.js":
/*!*************************************************!*\
  !*** ./node_modules/lodash/_trimmedEndIndex.js ***!
  \*************************************************/
/***/ ((module) => {

eval("/** Used to match a single whitespace character. */\nvar reWhitespace = /\\s/;\n\n/**\n * Used by `_.trim` and `_.trimEnd` to get the index of the last non-whitespace\n * character of `string`.\n *\n * @private\n * @param {string} string The string to inspect.\n * @returns {number} Returns the index of the last non-whitespace character.\n */\nfunction trimmedEndIndex(string) {\n  var index = string.length;\n\n  while (index-- && reWhitespace.test(string.charAt(index))) {}\n  return index;\n}\n\nmodule.exports = trimmedEndIndex;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/_trimmedEndIndex.js?");

/***/ }),

/***/ "./node_modules/lodash/before.js":
/*!***************************************!*\
  !*** ./node_modules/lodash/before.js ***!
  \***************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var toInteger = __webpack_require__(/*! ./toInteger */ \"./node_modules/lodash/toInteger.js\");\n\n/** Error message constants. */\nvar FUNC_ERROR_TEXT = 'Expected a function';\n\n/**\n * Creates a function that invokes `func`, with the `this` binding and arguments\n * of the created function, while it's called less than `n` times. Subsequent\n * calls to the created function return the result of the last `func` invocation.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Function\n * @param {number} n The number of calls at which `func` is no longer invoked.\n * @param {Function} func The function to restrict.\n * @returns {Function} Returns the new restricted function.\n * @example\n *\n * jQuery(element).on('click', _.before(5, addContactToList));\n * // => Allows adding up to 4 contacts to the list.\n */\nfunction before(n, func) {\n  var result;\n  if (typeof func != 'function') {\n    throw new TypeError(FUNC_ERROR_TEXT);\n  }\n  n = toInteger(n);\n  return function() {\n    if (--n > 0) {\n      result = func.apply(this, arguments);\n    }\n    if (n <= 1) {\n      func = undefined;\n    }\n    return result;\n  };\n}\n\nmodule.exports = before;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/before.js?");

/***/ }),

/***/ "./node_modules/lodash/isObject.js":
/*!*****************************************!*\
  !*** ./node_modules/lodash/isObject.js ***!
  \*****************************************/
/***/ ((module) => {

eval("/**\n * Checks if `value` is the\n * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)\n * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an object, else `false`.\n * @example\n *\n * _.isObject({});\n * // => true\n *\n * _.isObject([1, 2, 3]);\n * // => true\n *\n * _.isObject(_.noop);\n * // => true\n *\n * _.isObject(null);\n * // => false\n */\nfunction isObject(value) {\n  var type = typeof value;\n  return value != null && (type == 'object' || type == 'function');\n}\n\nmodule.exports = isObject;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/isObject.js?");

/***/ }),

/***/ "./node_modules/lodash/isObjectLike.js":
/*!*********************************************!*\
  !*** ./node_modules/lodash/isObjectLike.js ***!
  \*********************************************/
/***/ ((module) => {

eval("/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return value != null && typeof value == 'object';\n}\n\nmodule.exports = isObjectLike;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/isObjectLike.js?");

/***/ }),

/***/ "./node_modules/lodash/isSymbol.js":
/*!*****************************************!*\
  !*** ./node_modules/lodash/isSymbol.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var baseGetTag = __webpack_require__(/*! ./_baseGetTag */ \"./node_modules/lodash/_baseGetTag.js\"),\n    isObjectLike = __webpack_require__(/*! ./isObjectLike */ \"./node_modules/lodash/isObjectLike.js\");\n\n/** `Object#toString` result references. */\nvar symbolTag = '[object Symbol]';\n\n/**\n * Checks if `value` is classified as a `Symbol` primitive or object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a symbol, else `false`.\n * @example\n *\n * _.isSymbol(Symbol.iterator);\n * // => true\n *\n * _.isSymbol('abc');\n * // => false\n */\nfunction isSymbol(value) {\n  return typeof value == 'symbol' ||\n    (isObjectLike(value) && baseGetTag(value) == symbolTag);\n}\n\nmodule.exports = isSymbol;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/isSymbol.js?");

/***/ }),

/***/ "./node_modules/lodash/once.js":
/*!*************************************!*\
  !*** ./node_modules/lodash/once.js ***!
  \*************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var before = __webpack_require__(/*! ./before */ \"./node_modules/lodash/before.js\");\n\n/**\n * Creates a function that is restricted to invoking `func` once. Repeat calls\n * to the function return the value of the first invocation. The `func` is\n * invoked with the `this` binding and arguments of the created function.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Function\n * @param {Function} func The function to restrict.\n * @returns {Function} Returns the new restricted function.\n * @example\n *\n * var initialize = _.once(createApplication);\n * initialize();\n * initialize();\n * // => `createApplication` is invoked once\n */\nfunction once(func) {\n  return before(2, func);\n}\n\nmodule.exports = once;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/once.js?");

/***/ }),

/***/ "./node_modules/lodash/toFinite.js":
/*!*****************************************!*\
  !*** ./node_modules/lodash/toFinite.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var toNumber = __webpack_require__(/*! ./toNumber */ \"./node_modules/lodash/toNumber.js\");\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0,\n    MAX_INTEGER = 1.7976931348623157e+308;\n\n/**\n * Converts `value` to a finite number.\n *\n * @static\n * @memberOf _\n * @since 4.12.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted number.\n * @example\n *\n * _.toFinite(3.2);\n * // => 3.2\n *\n * _.toFinite(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toFinite(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toFinite('3.2');\n * // => 3.2\n */\nfunction toFinite(value) {\n  if (!value) {\n    return value === 0 ? value : 0;\n  }\n  value = toNumber(value);\n  if (value === INFINITY || value === -INFINITY) {\n    var sign = (value < 0 ? -1 : 1);\n    return sign * MAX_INTEGER;\n  }\n  return value === value ? value : 0;\n}\n\nmodule.exports = toFinite;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/toFinite.js?");

/***/ }),

/***/ "./node_modules/lodash/toInteger.js":
/*!******************************************!*\
  !*** ./node_modules/lodash/toInteger.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var toFinite = __webpack_require__(/*! ./toFinite */ \"./node_modules/lodash/toFinite.js\");\n\n/**\n * Converts `value` to an integer.\n *\n * **Note:** This method is loosely based on\n * [`ToInteger`](http://www.ecma-international.org/ecma-262/7.0/#sec-tointeger).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {number} Returns the converted integer.\n * @example\n *\n * _.toInteger(3.2);\n * // => 3\n *\n * _.toInteger(Number.MIN_VALUE);\n * // => 0\n *\n * _.toInteger(Infinity);\n * // => 1.7976931348623157e+308\n *\n * _.toInteger('3.2');\n * // => 3\n */\nfunction toInteger(value) {\n  var result = toFinite(value),\n      remainder = result % 1;\n\n  return result === result ? (remainder ? result - remainder : result) : 0;\n}\n\nmodule.exports = toInteger;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/toInteger.js?");

/***/ }),

/***/ "./node_modules/lodash/toNumber.js":
/*!*****************************************!*\
  !*** ./node_modules/lodash/toNumber.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var baseTrim = __webpack_require__(/*! ./_baseTrim */ \"./node_modules/lodash/_baseTrim.js\"),\n    isObject = __webpack_require__(/*! ./isObject */ \"./node_modules/lodash/isObject.js\"),\n    isSymbol = __webpack_require__(/*! ./isSymbol */ \"./node_modules/lodash/isSymbol.js\");\n\n/** Used as references for various `Number` constants. */\nvar NAN = 0 / 0;\n\n/** Used to detect bad signed hexadecimal string values. */\nvar reIsBadHex = /^[-+]0x[0-9a-f]+$/i;\n\n/** Used to detect binary string values. */\nvar reIsBinary = /^0b[01]+$/i;\n\n/** Used to detect octal string values. */\nvar reIsOctal = /^0o[0-7]+$/i;\n\n/** Built-in method references without a dependency on `root`. */\nvar freeParseInt = parseInt;\n\n/**\n * Converts `value` to a number.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to process.\n * @returns {number} Returns the number.\n * @example\n *\n * _.toNumber(3.2);\n * // => 3.2\n *\n * _.toNumber(Number.MIN_VALUE);\n * // => 5e-324\n *\n * _.toNumber(Infinity);\n * // => Infinity\n *\n * _.toNumber('3.2');\n * // => 3.2\n */\nfunction toNumber(value) {\n  if (typeof value == 'number') {\n    return value;\n  }\n  if (isSymbol(value)) {\n    return NAN;\n  }\n  if (isObject(value)) {\n    var other = typeof value.valueOf == 'function' ? value.valueOf() : value;\n    value = isObject(other) ? (other + '') : other;\n  }\n  if (typeof value != 'string') {\n    return value === 0 ? value : +value;\n  }\n  value = baseTrim(value);\n  var isBinary = reIsBinary.test(value);\n  return (isBinary || reIsOctal.test(value))\n    ? freeParseInt(value.slice(2), isBinary ? 2 : 8)\n    : (reIsBadHex.test(value) ? NAN : +value);\n}\n\nmodule.exports = toNumber;\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lodash/toNumber.js?");

/***/ }),

/***/ "./node_modules/lru-cache/index.js":
/*!*****************************************!*\
  !*** ./node_modules/lru-cache/index.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n// A linked list to keep track of recently-used-ness\nconst Yallist = __webpack_require__(/*! yallist */ \"./node_modules/yallist/yallist.js\")\n\nconst MAX = Symbol('max')\nconst LENGTH = Symbol('length')\nconst LENGTH_CALCULATOR = Symbol('lengthCalculator')\nconst ALLOW_STALE = Symbol('allowStale')\nconst MAX_AGE = Symbol('maxAge')\nconst DISPOSE = Symbol('dispose')\nconst NO_DISPOSE_ON_SET = Symbol('noDisposeOnSet')\nconst LRU_LIST = Symbol('lruList')\nconst CACHE = Symbol('cache')\nconst UPDATE_AGE_ON_GET = Symbol('updateAgeOnGet')\n\nconst naiveLength = () => 1\n\n// lruList is a yallist where the head is the youngest\n// item, and the tail is the oldest.  the list contains the Hit\n// objects as the entries.\n// Each Hit object has a reference to its Yallist.Node.  This\n// never changes.\n//\n// cache is a Map (or PseudoMap) that matches the keys to\n// the Yallist.Node object.\nclass LRUCache {\n  constructor (options) {\n    if (typeof options === 'number')\n      options = { max: options }\n\n    if (!options)\n      options = {}\n\n    if (options.max && (typeof options.max !== 'number' || options.max < 0))\n      throw new TypeError('max must be a non-negative number')\n    // Kind of weird to have a default max of Infinity, but oh well.\n    const max = this[MAX] = options.max || Infinity\n\n    const lc = options.length || naiveLength\n    this[LENGTH_CALCULATOR] = (typeof lc !== 'function') ? naiveLength : lc\n    this[ALLOW_STALE] = options.stale || false\n    if (options.maxAge && typeof options.maxAge !== 'number')\n      throw new TypeError('maxAge must be a number')\n    this[MAX_AGE] = options.maxAge || 0\n    this[DISPOSE] = options.dispose\n    this[NO_DISPOSE_ON_SET] = options.noDisposeOnSet || false\n    this[UPDATE_AGE_ON_GET] = options.updateAgeOnGet || false\n    this.reset()\n  }\n\n  // resize the cache when the max changes.\n  set max (mL) {\n    if (typeof mL !== 'number' || mL < 0)\n      throw new TypeError('max must be a non-negative number')\n\n    this[MAX] = mL || Infinity\n    trim(this)\n  }\n  get max () {\n    return this[MAX]\n  }\n\n  set allowStale (allowStale) {\n    this[ALLOW_STALE] = !!allowStale\n  }\n  get allowStale () {\n    return this[ALLOW_STALE]\n  }\n\n  set maxAge (mA) {\n    if (typeof mA !== 'number')\n      throw new TypeError('maxAge must be a non-negative number')\n\n    this[MAX_AGE] = mA\n    trim(this)\n  }\n  get maxAge () {\n    return this[MAX_AGE]\n  }\n\n  // resize the cache when the lengthCalculator changes.\n  set lengthCalculator (lC) {\n    if (typeof lC !== 'function')\n      lC = naiveLength\n\n    if (lC !== this[LENGTH_CALCULATOR]) {\n      this[LENGTH_CALCULATOR] = lC\n      this[LENGTH] = 0\n      this[LRU_LIST].forEach(hit => {\n        hit.length = this[LENGTH_CALCULATOR](hit.value, hit.key)\n        this[LENGTH] += hit.length\n      })\n    }\n    trim(this)\n  }\n  get lengthCalculator () { return this[LENGTH_CALCULATOR] }\n\n  get length () { return this[LENGTH] }\n  get itemCount () { return this[LRU_LIST].length }\n\n  rforEach (fn, thisp) {\n    thisp = thisp || this\n    for (let walker = this[LRU_LIST].tail; walker !== null;) {\n      const prev = walker.prev\n      forEachStep(this, fn, walker, thisp)\n      walker = prev\n    }\n  }\n\n  forEach (fn, thisp) {\n    thisp = thisp || this\n    for (let walker = this[LRU_LIST].head; walker !== null;) {\n      const next = walker.next\n      forEachStep(this, fn, walker, thisp)\n      walker = next\n    }\n  }\n\n  keys () {\n    return this[LRU_LIST].toArray().map(k => k.key)\n  }\n\n  values () {\n    return this[LRU_LIST].toArray().map(k => k.value)\n  }\n\n  reset () {\n    if (this[DISPOSE] &&\n        this[LRU_LIST] &&\n        this[LRU_LIST].length) {\n      this[LRU_LIST].forEach(hit => this[DISPOSE](hit.key, hit.value))\n    }\n\n    this[CACHE] = new Map() // hash of items by key\n    this[LRU_LIST] = new Yallist() // list of items in order of use recency\n    this[LENGTH] = 0 // length of items in the list\n  }\n\n  dump () {\n    return this[LRU_LIST].map(hit =>\n      isStale(this, hit) ? false : {\n        k: hit.key,\n        v: hit.value,\n        e: hit.now + (hit.maxAge || 0)\n      }).toArray().filter(h => h)\n  }\n\n  dumpLru () {\n    return this[LRU_LIST]\n  }\n\n  set (key, value, maxAge) {\n    maxAge = maxAge || this[MAX_AGE]\n\n    if (maxAge && typeof maxAge !== 'number')\n      throw new TypeError('maxAge must be a number')\n\n    const now = maxAge ? Date.now() : 0\n    const len = this[LENGTH_CALCULATOR](value, key)\n\n    if (this[CACHE].has(key)) {\n      if (len > this[MAX]) {\n        del(this, this[CACHE].get(key))\n        return false\n      }\n\n      const node = this[CACHE].get(key)\n      const item = node.value\n\n      // dispose of the old one before overwriting\n      // split out into 2 ifs for better coverage tracking\n      if (this[DISPOSE]) {\n        if (!this[NO_DISPOSE_ON_SET])\n          this[DISPOSE](key, item.value)\n      }\n\n      item.now = now\n      item.maxAge = maxAge\n      item.value = value\n      this[LENGTH] += len - item.length\n      item.length = len\n      this.get(key)\n      trim(this)\n      return true\n    }\n\n    const hit = new Entry(key, value, len, now, maxAge)\n\n    // oversized objects fall out of cache automatically.\n    if (hit.length > this[MAX]) {\n      if (this[DISPOSE])\n        this[DISPOSE](key, value)\n\n      return false\n    }\n\n    this[LENGTH] += hit.length\n    this[LRU_LIST].unshift(hit)\n    this[CACHE].set(key, this[LRU_LIST].head)\n    trim(this)\n    return true\n  }\n\n  has (key) {\n    if (!this[CACHE].has(key)) return false\n    const hit = this[CACHE].get(key).value\n    return !isStale(this, hit)\n  }\n\n  get (key) {\n    return get(this, key, true)\n  }\n\n  peek (key) {\n    return get(this, key, false)\n  }\n\n  pop () {\n    const node = this[LRU_LIST].tail\n    if (!node)\n      return null\n\n    del(this, node)\n    return node.value\n  }\n\n  del (key) {\n    del(this, this[CACHE].get(key))\n  }\n\n  load (arr) {\n    // reset the cache\n    this.reset()\n\n    const now = Date.now()\n    // A previous serialized cache has the most recent items first\n    for (let l = arr.length - 1; l >= 0; l--) {\n      const hit = arr[l]\n      const expiresAt = hit.e || 0\n      if (expiresAt === 0)\n        // the item was created without expiration in a non aged cache\n        this.set(hit.k, hit.v)\n      else {\n        const maxAge = expiresAt - now\n        // dont add already expired items\n        if (maxAge > 0) {\n          this.set(hit.k, hit.v, maxAge)\n        }\n      }\n    }\n  }\n\n  prune () {\n    this[CACHE].forEach((value, key) => get(this, key, false))\n  }\n}\n\nconst get = (self, key, doUse) => {\n  const node = self[CACHE].get(key)\n  if (node) {\n    const hit = node.value\n    if (isStale(self, hit)) {\n      del(self, node)\n      if (!self[ALLOW_STALE])\n        return undefined\n    } else {\n      if (doUse) {\n        if (self[UPDATE_AGE_ON_GET])\n          node.value.now = Date.now()\n        self[LRU_LIST].unshiftNode(node)\n      }\n    }\n    return hit.value\n  }\n}\n\nconst isStale = (self, hit) => {\n  if (!hit || (!hit.maxAge && !self[MAX_AGE]))\n    return false\n\n  const diff = Date.now() - hit.now\n  return hit.maxAge ? diff > hit.maxAge\n    : self[MAX_AGE] && (diff > self[MAX_AGE])\n}\n\nconst trim = self => {\n  if (self[LENGTH] > self[MAX]) {\n    for (let walker = self[LRU_LIST].tail;\n      self[LENGTH] > self[MAX] && walker !== null;) {\n      // We know that we're about to delete this one, and also\n      // what the next least recently used key will be, so just\n      // go ahead and set it now.\n      const prev = walker.prev\n      del(self, walker)\n      walker = prev\n    }\n  }\n}\n\nconst del = (self, node) => {\n  if (node) {\n    const hit = node.value\n    if (self[DISPOSE])\n      self[DISPOSE](hit.key, hit.value)\n\n    self[LENGTH] -= hit.length\n    self[CACHE].delete(hit.key)\n    self[LRU_LIST].removeNode(node)\n  }\n}\n\nclass Entry {\n  constructor (key, value, length, now, maxAge) {\n    this.key = key\n    this.value = value\n    this.length = length\n    this.now = now\n    this.maxAge = maxAge || 0\n  }\n}\n\nconst forEachStep = (self, fn, node, thisp) => {\n  let hit = node.value\n  if (isStale(self, hit)) {\n    del(self, node)\n    if (!self[ALLOW_STALE])\n      hit = undefined\n  }\n  if (hit)\n    fn.call(thisp, hit.value, hit.key, self)\n}\n\nmodule.exports = LRUCache\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/lru-cache/index.js?");

/***/ }),

/***/ "./node_modules/n3/src/IRIs.js":
/*!*************************************!*\
  !*** ./node_modules/n3/src/IRIs.js ***!
  \*************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nconst RDF  = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n    XSD  = 'http://www.w3.org/2001/XMLSchema#',\n    SWAP = 'http://www.w3.org/2000/10/swap/';\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  xsd: {\n    decimal: `${XSD}decimal`,\n    boolean: `${XSD}boolean`,\n    double:  `${XSD}double`,\n    integer: `${XSD}integer`,\n    string:  `${XSD}string`,\n  },\n  rdf: {\n    type:       `${RDF}type`,\n    nil:        `${RDF}nil`,\n    first:      `${RDF}first`,\n    rest:       `${RDF}rest`,\n    langString: `${RDF}langString`,\n  },\n  owl: {\n    sameAs: 'http://www.w3.org/2002/07/owl#sameAs',\n  },\n  r: {\n    forSome: `${SWAP}reify#forSome`,\n    forAll:  `${SWAP}reify#forAll`,\n  },\n  log: {\n    implies: `${SWAP}log#implies`,\n  },\n});\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/n3/src/IRIs.js?");

/***/ }),

/***/ "./node_modules/n3/src/N3DataFactory.js":
/*!**********************************************!*\
  !*** ./node_modules/n3/src/N3DataFactory.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   BlankNode: () => (/* binding */ BlankNode),\n/* harmony export */   DefaultGraph: () => (/* binding */ DefaultGraph),\n/* harmony export */   Literal: () => (/* binding */ Literal),\n/* harmony export */   NamedNode: () => (/* binding */ NamedNode),\n/* harmony export */   Quad: () => (/* binding */ Quad),\n/* harmony export */   Term: () => (/* binding */ Term),\n/* harmony export */   Triple: () => (/* binding */ Quad),\n/* harmony export */   Variable: () => (/* binding */ Variable),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   escapeQuotes: () => (/* binding */ escapeQuotes),\n/* harmony export */   termFromId: () => (/* binding */ termFromId),\n/* harmony export */   termToId: () => (/* binding */ termToId),\n/* harmony export */   unescapeQuotes: () => (/* binding */ unescapeQuotes)\n/* harmony export */ });\n/* harmony import */ var _IRIs__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./IRIs */ \"./node_modules/n3/src/IRIs.js\");\n// N3.js implementations of the RDF/JS core data types\n// See http://rdf.js.org/data-model-spec/\n\n\n\nconst { rdf, xsd } = _IRIs__WEBPACK_IMPORTED_MODULE_0__[\"default\"];\n\n// eslint-disable-next-line prefer-const\nlet DEFAULTGRAPH;\nlet _blankNodeCounter = 0;\n\nconst escapedLiteral = /^\"(.*\".*)(?=\"[^\"]*$)/;\n\n// ## DataFactory singleton\nconst DataFactory = {\n  namedNode,\n  blankNode,\n  variable,\n  literal,\n  defaultGraph,\n  quad,\n  triple: quad,\n};\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (DataFactory);\n\n// ## Term constructor\nclass Term {\n  constructor(id) {\n    this.id = id;\n  }\n\n  // ### The value of this term\n  get value() {\n    return this.id;\n  }\n\n  // ### Returns whether this object represents the same term as the other\n  equals(other) {\n    // If both terms were created by this library,\n    // equality can be computed through ids\n    if (other instanceof Term)\n      return this.id === other.id;\n    // Otherwise, compare term type and value\n    return !!other && this.termType === other.termType &&\n                      this.value    === other.value;\n  }\n\n  // ### Implement hashCode for Immutable.js, since we implement `equals`\n  // https://immutable-js.com/docs/v4.0.0/ValueObject/#hashCode()\n  hashCode() {\n    return 0;\n  }\n\n  // ### Returns a plain object representation of this term\n  toJSON() {\n    return {\n      termType: this.termType,\n      value:    this.value,\n    };\n  }\n}\n\n\n// ## NamedNode constructor\nclass NamedNode extends Term {\n  // ### The term type of this term\n  get termType() {\n    return 'NamedNode';\n  }\n}\n\n// ## Literal constructor\nclass Literal extends Term {\n  // ### The term type of this term\n  get termType() {\n    return 'Literal';\n  }\n\n  // ### The text value of this literal\n  get value() {\n    return this.id.substring(1, this.id.lastIndexOf('\"'));\n  }\n\n  // ### The language of this literal\n  get language() {\n    // Find the last quotation mark (e.g., '\"abc\"@en-us')\n    const id = this.id;\n    let atPos = id.lastIndexOf('\"') + 1;\n    // If \"@\" it follows, return the remaining substring; empty otherwise\n    return atPos < id.length && id[atPos++] === '@' ? id.substr(atPos).toLowerCase() : '';\n  }\n\n  // ### The datatype IRI of this literal\n  get datatype() {\n    return new NamedNode(this.datatypeString);\n  }\n\n  // ### The datatype string of this literal\n  get datatypeString() {\n    // Find the last quotation mark (e.g., '\"abc\"^^http://ex.org/types#t')\n    const id = this.id, dtPos = id.lastIndexOf('\"') + 1;\n    const char = dtPos < id.length ? id[dtPos] : '';\n    // If \"^\" it follows, return the remaining substring\n    return char === '^' ? id.substr(dtPos + 2) :\n           // If \"@\" follows, return rdf:langString; xsd:string otherwise\n           (char !== '@' ? xsd.string : rdf.langString);\n  }\n\n  // ### Returns whether this object represents the same term as the other\n  equals(other) {\n    // If both literals were created by this library,\n    // equality can be computed through ids\n    if (other instanceof Literal)\n      return this.id === other.id;\n    // Otherwise, compare term type, value, language, and datatype\n    return !!other && !!other.datatype &&\n                      this.termType === other.termType &&\n                      this.value    === other.value    &&\n                      this.language === other.language &&\n                      this.datatype.value === other.datatype.value;\n  }\n\n  toJSON() {\n    return {\n      termType: this.termType,\n      value:    this.value,\n      language: this.language,\n      datatype: { termType: 'NamedNode', value: this.datatypeString },\n    };\n  }\n}\n\n// ## BlankNode constructor\nclass BlankNode extends Term {\n  constructor(name) {\n    super(`_:${name}`);\n  }\n\n  // ### The term type of this term\n  get termType() {\n    return 'BlankNode';\n  }\n\n  // ### The name of this blank node\n  get value() {\n    return this.id.substr(2);\n  }\n}\n\nclass Variable extends Term {\n  constructor(name) {\n    super(`?${name}`);\n  }\n\n  // ### The term type of this term\n  get termType() {\n    return 'Variable';\n  }\n\n  // ### The name of this variable\n  get value() {\n    return this.id.substr(1);\n  }\n}\n\n// ## DefaultGraph constructor\nclass DefaultGraph extends Term {\n  constructor() {\n    super('');\n    return DEFAULTGRAPH || this;\n  }\n\n  // ### The term type of this term\n  get termType() {\n    return 'DefaultGraph';\n  }\n\n  // ### Returns whether this object represents the same term as the other\n  equals(other) {\n    // If both terms were created by this library,\n    // equality can be computed through strict equality;\n    // otherwise, compare term types.\n    return (this === other) || (!!other && (this.termType === other.termType));\n  }\n}\n\n// ## DefaultGraph singleton\nDEFAULTGRAPH = new DefaultGraph();\n\n// ### Constructs a term from the given internal string ID\n// The third 'nested' parameter of this function is to aid\n// with recursion over nested terms. It should not be used\n// by consumers of this library.\n// See https://github.com/rdfjs/N3.js/pull/311#discussion_r1061042725\nfunction termFromId(id, factory, nested) {\n  factory = factory || DataFactory;\n\n  // Falsy value or empty string indicate the default graph\n  if (!id)\n    return factory.defaultGraph();\n\n  // Identify the term type based on the first character\n  switch (id[0]) {\n  case '?':\n    return factory.variable(id.substr(1));\n  case '_':\n    return factory.blankNode(id.substr(2));\n  case '\"':\n    // Shortcut for internal literals\n    if (factory === DataFactory)\n      return new Literal(id);\n    // Literal without datatype or language\n    if (id[id.length - 1] === '\"')\n      return factory.literal(id.substr(1, id.length - 2));\n    // Literal with datatype or language\n    const endPos = id.lastIndexOf('\"', id.length - 1);\n    return factory.literal(id.substr(1, endPos - 1),\n            id[endPos + 1] === '@' ? id.substr(endPos + 2)\n                                   : factory.namedNode(id.substr(endPos + 3)));\n  case '[':\n    id = JSON.parse(id);\n    break;\n  default:\n    if (!nested || !Array.isArray(id)) {\n      return factory.namedNode(id);\n    }\n  }\n  return factory.quad(\n    termFromId(id[0], factory, true),\n    termFromId(id[1], factory, true),\n    termFromId(id[2], factory, true),\n    id[3] && termFromId(id[3], factory, true),\n  );\n}\n\n// ### Constructs an internal string ID from the given term or ID string\n// The third 'nested' parameter of this function is to aid\n// with recursion over nested terms. It should not be used\n// by consumers of this library.\n// See https://github.com/rdfjs/N3.js/pull/311#discussion_r1061042725\nfunction termToId(term, nested) {\n  if (typeof term === 'string')\n    return term;\n  if (term instanceof Term && term.termType !== 'Quad')\n    return term.id;\n  if (!term)\n    return DEFAULTGRAPH.id;\n\n  // Term instantiated with another library\n  switch (term.termType) {\n  case 'NamedNode':    return term.value;\n  case 'BlankNode':    return `_:${term.value}`;\n  case 'Variable':     return `?${term.value}`;\n  case 'DefaultGraph': return '';\n  case 'Literal':      return `\"${term.value}\"${\n    term.language ? `@${term.language}` :\n      (term.datatype && term.datatype.value !== xsd.string ? `^^${term.datatype.value}` : '')}`;\n  case 'Quad':\n    const res = [\n      termToId(term.subject, true),\n      termToId(term.predicate, true),\n      termToId(term.object, true),\n    ];\n    if (term.graph && term.graph.termType !== 'DefaultGraph') {\n      res.push(termToId(term.graph, true));\n    }\n    return nested ? res : JSON.stringify(res);\n  default: throw new Error(`Unexpected termType: ${term.termType}`);\n  }\n}\n\n\n// ## Quad constructor\nclass Quad extends Term {\n  constructor(subject, predicate, object, graph) {\n    super('');\n    this._subject   = subject;\n    this._predicate = predicate;\n    this._object    = object;\n    this._graph     = graph || DEFAULTGRAPH;\n  }\n\n  // ### The term type of this term\n  get termType() {\n    return 'Quad';\n  }\n\n  get subject() {\n    return this._subject;\n  }\n\n  get predicate() {\n    return this._predicate;\n  }\n\n  get object() {\n    return this._object;\n  }\n\n  get graph() {\n    return this._graph;\n  }\n\n  // ### Returns a plain object representation of this quad\n  toJSON() {\n    return {\n      termType:  this.termType,\n      subject:   this._subject.toJSON(),\n      predicate: this._predicate.toJSON(),\n      object:    this._object.toJSON(),\n      graph:     this._graph.toJSON(),\n    };\n  }\n\n  // ### Returns whether this object represents the same quad as the other\n  equals(other) {\n    return !!other && this._subject.equals(other.subject)     &&\n                      this._predicate.equals(other.predicate) &&\n                      this._object.equals(other.object)       &&\n                      this._graph.equals(other.graph);\n  }\n}\n\n\n// ### Escapes the quotes within the given literal\nfunction escapeQuotes(id) {\n  return id.replace(escapedLiteral, (_, quoted) => `\"${quoted.replace(/\"/g, '\"\"')}`);\n}\n\n// ### Unescapes the quotes within the given literal\nfunction unescapeQuotes(id) {\n  return id.replace(escapedLiteral, (_, quoted) => `\"${quoted.replace(/\"\"/g, '\"')}`);\n}\n\n// ### Creates an IRI\nfunction namedNode(iri) {\n  return new NamedNode(iri);\n}\n\n// ### Creates a blank node\nfunction blankNode(name) {\n  return new BlankNode(name || `n3-${_blankNodeCounter++}`);\n}\n\n// ### Creates a literal\nfunction literal(value, languageOrDataType) {\n  // Create a language-tagged string\n  if (typeof languageOrDataType === 'string')\n    return new Literal(`\"${value}\"@${languageOrDataType.toLowerCase()}`);\n\n  // Automatically determine datatype for booleans and numbers\n  let datatype = languageOrDataType ? languageOrDataType.value : '';\n  if (datatype === '') {\n    // Convert a boolean\n    if (typeof value === 'boolean')\n      datatype = xsd.boolean;\n    // Convert an integer or double\n    else if (typeof value === 'number') {\n      if (Number.isFinite(value))\n        datatype = Number.isInteger(value) ? xsd.integer : xsd.double;\n      else {\n        datatype = xsd.double;\n        if (!Number.isNaN(value))\n          value = value > 0 ? 'INF' : '-INF';\n      }\n    }\n  }\n\n  // Create a datatyped literal\n  return (datatype === '' || datatype === xsd.string) ?\n    new Literal(`\"${value}\"`) :\n    new Literal(`\"${value}\"^^${datatype}`);\n}\n\n// ### Creates a variable\nfunction variable(name) {\n  return new Variable(name);\n}\n\n// ### Returns the default graph\nfunction defaultGraph() {\n  return DEFAULTGRAPH;\n}\n\n// ### Creates a quad\nfunction quad(subject, predicate, object, graph) {\n  return new Quad(subject, predicate, object, graph);\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/n3/src/N3DataFactory.js?");

/***/ }),

/***/ "./node_modules/n3/src/N3Lexer.js":
/*!****************************************!*\
  !*** ./node_modules/n3/src/N3Lexer.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ N3Lexer)\n/* harmony export */ });\n/* harmony import */ var buffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\");\n/* harmony import */ var queue_microtask__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! queue-microtask */ \"./node_modules/queue-microtask/index.js\");\n/* harmony import */ var queue_microtask__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(queue_microtask__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var _IRIs__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./IRIs */ \"./node_modules/n3/src/IRIs.js\");\n// **N3Lexer** tokenizes N3 documents.\n\n\n\n\nconst { xsd } = _IRIs__WEBPACK_IMPORTED_MODULE_2__[\"default\"];\n\n// Regular expression and replacement string to escape N3 strings\nconst escapeSequence = /\\\\u([a-fA-F0-9]{4})|\\\\U([a-fA-F0-9]{8})|\\\\([^])/g;\nconst escapeReplacements = {\n  '\\\\': '\\\\', \"'\": \"'\", '\"': '\"',\n  'n': '\\n', 'r': '\\r', 't': '\\t', 'f': '\\f', 'b': '\\b',\n  '_': '_', '~': '~', '.': '.', '-': '-', '!': '!', '$': '$', '&': '&',\n  '(': '(', ')': ')', '*': '*', '+': '+', ',': ',', ';': ';', '=': '=',\n  '/': '/', '?': '?', '#': '#', '@': '@', '%': '%',\n};\nconst illegalIriChars = /[\\x00-\\x20<>\\\\\"\\{\\}\\|\\^\\`]/;\n\nconst lineModeRegExps = {\n  _iri: true,\n  _unescapedIri: true,\n  _simpleQuotedString: true,\n  _langcode: true,\n  _blank: true,\n  _newline: true,\n  _comment: true,\n  _whitespace: true,\n  _endOfFile: true,\n};\nconst invalidRegExp = /$0^/;\n\n// ## Constructor\nclass N3Lexer {\n  constructor(options) {\n    // ## Regular expressions\n    // It's slightly faster to have these as properties than as in-scope variables\n    this._iri = /^<((?:[^ <>{}\\\\]|\\\\[uU])+)>[ \\t]*/; // IRI with escape sequences; needs sanity check after unescaping\n    this._unescapedIri = /^<([^\\x00-\\x20<>\\\\\"\\{\\}\\|\\^\\`]*)>[ \\t]*/; // IRI without escape sequences; no unescaping\n    this._simpleQuotedString = /^\"([^\"\\\\\\r\\n]*)\"(?=[^\"])/; // string without escape sequences\n    this._simpleApostropheString = /^'([^'\\\\\\r\\n]*)'(?=[^'])/;\n    this._langcode = /^@([a-z]+(?:-[a-z0-9]+)*)(?=[^a-z0-9\\-])/i;\n    this._prefix = /^((?:[A-Za-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02ff\\u0370-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])(?:\\.?[\\-0-9A-Z_a-z\\xb7\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u203f\\u2040\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])*)?:(?=[#\\s<])/;\n    this._prefixed = /^((?:[A-Za-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02ff\\u0370-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])(?:\\.?[\\-0-9A-Z_a-z\\xb7\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u203f\\u2040\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])*)?:((?:(?:[0-:A-Z_a-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02ff\\u0370-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff]|%[0-9a-fA-F]{2}|\\\\[!#-\\/;=?\\-@_~])(?:(?:[\\.\\-0-:A-Z_a-z\\xb7\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u203f\\u2040\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff]|%[0-9a-fA-F]{2}|\\\\[!#-\\/;=?\\-@_~])*(?:[\\-0-:A-Z_a-z\\xb7\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u203f\\u2040\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff]|%[0-9a-fA-F]{2}|\\\\[!#-\\/;=?\\-@_~]))?)?)(?:[ \\t]+|(?=\\.?[,;!\\^\\s#()\\[\\]\\{\\}\"'<>]))/;\n    this._variable = /^\\?(?:(?:[A-Z_a-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02ff\\u0370-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])(?:[\\-0-:A-Z_a-z\\xb7\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u203f\\u2040\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])*)(?=[.,;!\\^\\s#()\\[\\]\\{\\}\"'<>])/;\n    this._blank = /^_:((?:[0-9A-Z_a-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u02ff\\u0370-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])(?:\\.?[\\-0-9A-Z_a-z\\xb7\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u037d\\u037f-\\u1fff\\u200c\\u200d\\u203f\\u2040\\u2070-\\u218f\\u2c00-\\u2fef\\u3001-\\ud7ff\\uf900-\\ufdcf\\ufdf0-\\ufffd]|[\\ud800-\\udb7f][\\udc00-\\udfff])*)(?:[ \\t]+|(?=\\.?[,;:\\s#()\\[\\]\\{\\}\"'<>]))/;\n    this._number = /^[\\-+]?(?:(\\d+\\.\\d*|\\.?\\d+)[eE][\\-+]?|\\d*(\\.)?)\\d+(?=\\.?[,;:\\s#()\\[\\]\\{\\}\"'<>])/;\n    this._boolean = /^(?:true|false)(?=[.,;\\s#()\\[\\]\\{\\}\"'<>])/;\n    this._keyword = /^@[a-z]+(?=[\\s#<:])/i;\n    this._sparqlKeyword = /^(?:PREFIX|BASE|GRAPH)(?=[\\s#<])/i;\n    this._shortPredicates = /^a(?=[\\s#()\\[\\]\\{\\}\"'<>])/;\n    this._newline = /^[ \\t]*(?:#[^\\n\\r]*)?(?:\\r\\n|\\n|\\r)[ \\t]*/;\n    this._comment = /#([^\\n\\r]*)/;\n    this._whitespace = /^[ \\t]+/;\n    this._endOfFile = /^(?:#[^\\n\\r]*)?$/;\n    options = options || {};\n\n    // In line mode (N-Triples or N-Quads), only simple features may be parsed\n    if (this._lineMode = !!options.lineMode) {\n      this._n3Mode = false;\n      // Don't tokenize special literals\n      for (const key in this) {\n        if (!(key in lineModeRegExps) && this[key] instanceof RegExp)\n          this[key] = invalidRegExp;\n      }\n    }\n    // When not in line mode, enable N3 functionality by default\n    else {\n      this._n3Mode = options.n3 !== false;\n    }\n    // Don't output comment tokens by default\n    this.comments = !!options.comments;\n    // Cache the last tested closing position of long literals\n    this._literalClosingPos = 0;\n  }\n\n  // ## Private methods\n\n  // ### `_tokenizeToEnd` tokenizes as for as possible, emitting tokens through the callback\n  _tokenizeToEnd(callback, inputFinished) {\n    // Continue parsing as far as possible; the loop will return eventually\n    let input = this._input;\n    let currentLineLength = input.length;\n    while (true) {\n      // Count and skip whitespace lines\n      let whiteSpaceMatch, comment;\n      while (whiteSpaceMatch = this._newline.exec(input)) {\n        // Try to find a comment\n        if (this.comments && (comment = this._comment.exec(whiteSpaceMatch[0])))\n          emitToken('comment', comment[1], '', this._line, whiteSpaceMatch[0].length);\n        // Advance the input\n        input = input.substr(whiteSpaceMatch[0].length, input.length);\n        currentLineLength = input.length;\n        this._line++;\n      }\n      // Skip whitespace on current line\n      if (!whiteSpaceMatch && (whiteSpaceMatch = this._whitespace.exec(input)))\n        input = input.substr(whiteSpaceMatch[0].length, input.length);\n\n      // Stop for now if we're at the end\n      if (this._endOfFile.test(input)) {\n        // If the input is finished, emit EOF\n        if (inputFinished) {\n          // Try to find a final comment\n          if (this.comments && (comment = this._comment.exec(input)))\n            emitToken('comment', comment[1], '', this._line, input.length);\n          input = null;\n          emitToken('eof', '', '', this._line, 0);\n        }\n        return this._input = input;\n      }\n\n      // Look for specific token types based on the first character\n      const line = this._line, firstChar = input[0];\n      let type = '', value = '', prefix = '',\n          match = null, matchLength = 0, inconclusive = false;\n      switch (firstChar) {\n      case '^':\n        // We need at least 3 tokens lookahead to distinguish ^^<IRI> and ^^pre:fixed\n        if (input.length < 3)\n          break;\n        // Try to match a type\n        else if (input[1] === '^') {\n          this._previousMarker = '^^';\n          // Move to type IRI or prefixed name\n          input = input.substr(2);\n          if (input[0] !== '<') {\n            inconclusive = true;\n            break;\n          }\n        }\n        // If no type, it must be a path expression\n        else {\n          if (this._n3Mode) {\n            matchLength = 1;\n            type = '^';\n          }\n          break;\n        }\n        // Fall through in case the type is an IRI\n      case '<':\n        // Try to find a full IRI without escape sequences\n        if (match = this._unescapedIri.exec(input))\n          type = 'IRI', value = match[1];\n        // Try to find a full IRI with escape sequences\n        else if (match = this._iri.exec(input)) {\n          value = this._unescape(match[1]);\n          if (value === null || illegalIriChars.test(value))\n            return reportSyntaxError(this);\n          type = 'IRI';\n        }\n        // Try to find a nested triple\n        else if (input.length > 1 && input[1] === '<')\n          type = '<<', matchLength = 2;\n        // Try to find a backwards implication arrow\n        else if (this._n3Mode && input.length > 1 && input[1] === '=')\n          type = 'inverse', matchLength = 2, value = '>';\n        break;\n\n      case '>':\n        if (input.length > 1 && input[1] === '>')\n          type = '>>', matchLength = 2;\n        break;\n\n      case '_':\n        // Try to find a blank node. Since it can contain (but not end with) a dot,\n        // we always need a non-dot character before deciding it is a blank node.\n        // Therefore, try inserting a space if we're at the end of the input.\n        if ((match = this._blank.exec(input)) ||\n            inputFinished && (match = this._blank.exec(`${input} `)))\n          type = 'blank', prefix = '_', value = match[1];\n        break;\n\n      case '\"':\n        // Try to find a literal without escape sequences\n        if (match = this._simpleQuotedString.exec(input))\n          value = match[1];\n        // Try to find a literal wrapped in three pairs of quotes\n        else {\n          ({ value, matchLength } = this._parseLiteral(input));\n          if (value === null)\n            return reportSyntaxError(this);\n        }\n        if (match !== null || matchLength !== 0) {\n          type = 'literal';\n          this._literalClosingPos = 0;\n        }\n        break;\n\n      case \"'\":\n        if (!this._lineMode) {\n          // Try to find a literal without escape sequences\n          if (match = this._simpleApostropheString.exec(input))\n            value = match[1];\n          // Try to find a literal wrapped in three pairs of quotes\n          else {\n            ({ value, matchLength } = this._parseLiteral(input));\n            if (value === null)\n              return reportSyntaxError(this);\n          }\n          if (match !== null || matchLength !== 0) {\n            type = 'literal';\n            this._literalClosingPos = 0;\n          }\n        }\n        break;\n\n      case '?':\n        // Try to find a variable\n        if (this._n3Mode && (match = this._variable.exec(input)))\n          type = 'var', value = match[0];\n        break;\n\n      case '@':\n        // Try to find a language code\n        if (this._previousMarker === 'literal' && (match = this._langcode.exec(input)))\n          type = 'langcode', value = match[1];\n        // Try to find a keyword\n        else if (match = this._keyword.exec(input))\n          type = match[0];\n        break;\n\n      case '.':\n        // Try to find a dot as punctuation\n        if (input.length === 1 ? inputFinished : (input[1] < '0' || input[1] > '9')) {\n          type = '.';\n          matchLength = 1;\n          break;\n        }\n        // Fall through to numerical case (could be a decimal dot)\n\n      case '0':\n      case '1':\n      case '2':\n      case '3':\n      case '4':\n      case '5':\n      case '6':\n      case '7':\n      case '8':\n      case '9':\n      case '+':\n      case '-':\n        // Try to find a number. Since it can contain (but not end with) a dot,\n        // we always need a non-dot character before deciding it is a number.\n        // Therefore, try inserting a space if we're at the end of the input.\n        if (match = this._number.exec(input) ||\n            inputFinished && (match = this._number.exec(`${input} `))) {\n          type = 'literal', value = match[0];\n          prefix = (typeof match[1] === 'string' ? xsd.double :\n                    (typeof match[2] === 'string' ? xsd.decimal : xsd.integer));\n        }\n        break;\n\n      case 'B':\n      case 'b':\n      case 'p':\n      case 'P':\n      case 'G':\n      case 'g':\n        // Try to find a SPARQL-style keyword\n        if (match = this._sparqlKeyword.exec(input))\n          type = match[0].toUpperCase();\n        else\n          inconclusive = true;\n        break;\n\n      case 'f':\n      case 't':\n        // Try to match a boolean\n        if (match = this._boolean.exec(input))\n          type = 'literal', value = match[0], prefix = xsd.boolean;\n        else\n          inconclusive = true;\n        break;\n\n      case 'a':\n        // Try to find an abbreviated predicate\n        if (match = this._shortPredicates.exec(input))\n          type = 'abbreviation', value = 'a';\n        else\n          inconclusive = true;\n        break;\n\n      case '=':\n        // Try to find an implication arrow or equals sign\n        if (this._n3Mode && input.length > 1) {\n          type = 'abbreviation';\n          if (input[1] !== '>')\n            matchLength = 1, value = '=';\n          else\n            matchLength = 2, value = '>';\n        }\n        break;\n\n      case '!':\n        if (!this._n3Mode)\n          break;\n      case ',':\n      case ';':\n      case '[':\n      case ']':\n      case '(':\n      case ')':\n      case '}':\n        if (!this._lineMode) {\n          matchLength = 1;\n          type = firstChar;\n        }\n        break;\n      case '{':\n        // We need at least 2 tokens lookahead to distinguish \"{|\" and \"{ \"\n        if (!this._lineMode && input.length >= 2) {\n          // Try to find a quoted triple annotation start\n          if (input[1] === '|')\n            type = '{|', matchLength = 2;\n          else\n            type = firstChar, matchLength = 1;\n        }\n        break;\n      case '|':\n        // We need 2 tokens lookahead to parse \"|}\"\n        // Try to find a quoted triple annotation end\n        if (input.length >= 2 && input[1] === '}')\n          type = '|}', matchLength = 2;\n        break;\n\n      default:\n        inconclusive = true;\n      }\n\n      // Some first characters do not allow an immediate decision, so inspect more\n      if (inconclusive) {\n        // Try to find a prefix\n        if ((this._previousMarker === '@prefix' || this._previousMarker === 'PREFIX') &&\n            (match = this._prefix.exec(input)))\n          type = 'prefix', value = match[1] || '';\n        // Try to find a prefixed name. Since it can contain (but not end with) a dot,\n        // we always need a non-dot character before deciding it is a prefixed name.\n        // Therefore, try inserting a space if we're at the end of the input.\n        else if ((match = this._prefixed.exec(input)) ||\n                 inputFinished && (match = this._prefixed.exec(`${input} `)))\n          type = 'prefixed', prefix = match[1] || '', value = this._unescape(match[2]);\n      }\n\n      // A type token is special: it can only be emitted after an IRI or prefixed name is read\n      if (this._previousMarker === '^^') {\n        switch (type) {\n        case 'prefixed': type = 'type';    break;\n        case 'IRI':      type = 'typeIRI'; break;\n        default:         type = '';\n        }\n      }\n\n      // What if nothing of the above was found?\n      if (!type) {\n        // We could be in streaming mode, and then we just wait for more input to arrive.\n        // Otherwise, a syntax error has occurred in the input.\n        // One exception: error on an unaccounted linebreak (= not inside a triple-quoted literal).\n        if (inputFinished || (!/^'''|^\"\"\"/.test(input) && /\\n|\\r/.test(input)))\n          return reportSyntaxError(this);\n        else\n          return this._input = input;\n      }\n\n      // Emit the parsed token\n      const length = matchLength || match[0].length;\n      const token = emitToken(type, value, prefix, line, length);\n      this.previousToken = token;\n      this._previousMarker = type;\n\n      // Advance to next part to tokenize\n      input = input.substr(length, input.length);\n    }\n\n    // Emits the token through the callback\n    function emitToken(type, value, prefix, line, length) {\n      const start = input ? currentLineLength - input.length : currentLineLength;\n      const end = start + length;\n      const token = { type, value, prefix, line, start, end };\n      callback(null, token);\n      return token;\n    }\n    // Signals the syntax error through the callback\n    function reportSyntaxError(self) { callback(self._syntaxError(/^\\S*/.exec(input)[0])); }\n  }\n\n  // ### `_unescape` replaces N3 escape codes by their corresponding characters\n  _unescape(item) {\n    let invalid = false;\n    const replaced = item.replace(escapeSequence, (sequence, unicode4, unicode8, escapedChar) => {\n      // 4-digit unicode character\n      if (typeof unicode4 === 'string')\n        return String.fromCharCode(Number.parseInt(unicode4, 16));\n      // 8-digit unicode character\n      if (typeof unicode8 === 'string') {\n        let charCode = Number.parseInt(unicode8, 16);\n        return charCode <= 0xFFFF ? String.fromCharCode(Number.parseInt(unicode8, 16)) :\n          String.fromCharCode(0xD800 + ((charCode -= 0x10000) >> 10), 0xDC00 + (charCode & 0x3FF));\n      }\n      // fixed escape sequence\n      if (escapedChar in escapeReplacements)\n        return escapeReplacements[escapedChar];\n      // invalid escape sequence\n      invalid = true;\n      return '';\n    });\n    return invalid ? null : replaced;\n  }\n\n  // ### `_parseLiteral` parses a literal into an unescaped value\n  _parseLiteral(input) {\n    // Ensure we have enough lookahead to identify triple-quoted strings\n    if (input.length >= 3) {\n      // Identify the opening quote(s)\n      const opening = input.match(/^(?:\"\"\"|\"|'''|'|)/)[0];\n      const openingLength = opening.length;\n\n      // Find the next candidate closing quotes\n      let closingPos = Math.max(this._literalClosingPos, openingLength);\n      while ((closingPos = input.indexOf(opening, closingPos)) > 0) {\n        // Count backslashes right before the closing quotes\n        let backslashCount = 0;\n        while (input[closingPos - backslashCount - 1] === '\\\\')\n          backslashCount++;\n\n        // An even number of backslashes (in particular 0)\n        // means these are actual, non-escaped closing quotes\n        if (backslashCount % 2 === 0) {\n          // Extract and unescape the value\n          const raw = input.substring(openingLength, closingPos);\n          const lines = raw.split(/\\r\\n|\\r|\\n/).length - 1;\n          const matchLength = closingPos + openingLength;\n          // Only triple-quoted strings can be multi-line\n          if (openingLength === 1 && lines !== 0 ||\n              openingLength === 3 && this._lineMode)\n            break;\n          this._line += lines;\n          return { value: this._unescape(raw), matchLength };\n        }\n        closingPos++;\n      }\n      this._literalClosingPos = input.length - openingLength + 1;\n    }\n    return { value: '', matchLength: 0 };\n  }\n\n  // ### `_syntaxError` creates a syntax error for the given issue\n  _syntaxError(issue) {\n    this._input = null;\n    const err = new Error(`Unexpected \"${issue}\" on line ${this._line}.`);\n    err.context = {\n      token: undefined,\n      line: this._line,\n      previousToken: this.previousToken,\n    };\n    return err;\n  }\n\n  // ### Strips off any starting UTF BOM mark.\n  _readStartingBom(input) {\n    return input.startsWith('\\ufeff') ? input.substr(1) : input;\n  }\n\n  // ## Public methods\n\n  // ### `tokenize` starts the transformation of an N3 document into an array of tokens.\n  // The input can be a string or a stream.\n  tokenize(input, callback) {\n    this._line = 1;\n\n    // If the input is a string, continuously emit tokens through the callback until the end\n    if (typeof input === 'string') {\n      this._input = this._readStartingBom(input);\n      // If a callback was passed, asynchronously call it\n      if (typeof callback === 'function')\n        queue_microtask__WEBPACK_IMPORTED_MODULE_1___default()(() => this._tokenizeToEnd(callback, true));\n      // If no callback was passed, tokenize synchronously and return\n      else {\n        const tokens = [];\n        let error;\n        this._tokenizeToEnd((e, t) => e ? (error = e) : tokens.push(t), true);\n        if (error) throw error;\n        return tokens;\n      }\n    }\n    // Otherwise, the input must be a stream\n    else {\n      this._pendingBuffer = null;\n      if (typeof input.setEncoding === 'function')\n        input.setEncoding('utf8');\n      // Adds the data chunk to the buffer and parses as far as possible\n      input.on('data', data => {\n        if (this._input !== null && data.length !== 0) {\n          // Prepend any previous pending writes\n          if (this._pendingBuffer) {\n            data = buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.concat([this._pendingBuffer, data]);\n            this._pendingBuffer = null;\n          }\n          // Hold if the buffer ends in an incomplete unicode sequence\n          if (data[data.length - 1] & 0x80) {\n            this._pendingBuffer = data;\n          }\n          // Otherwise, tokenize as far as possible\n          else {\n            // Only read a BOM at the start\n            if (typeof this._input === 'undefined')\n              this._input = this._readStartingBom(typeof data === 'string' ? data : data.toString());\n            else\n              this._input += data;\n            this._tokenizeToEnd(callback, false);\n          }\n        }\n      });\n      // Parses until the end\n      input.on('end', () => {\n        if (typeof this._input === 'string')\n          this._tokenizeToEnd(callback, true);\n      });\n      input.on('error', callback);\n    }\n  }\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/n3/src/N3Lexer.js?");

/***/ }),

/***/ "./node_modules/n3/src/N3Parser.js":
/*!*****************************************!*\
  !*** ./node_modules/n3/src/N3Parser.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ N3Parser)\n/* harmony export */ });\n/* harmony import */ var _N3Lexer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./N3Lexer */ \"./node_modules/n3/src/N3Lexer.js\");\n/* harmony import */ var _N3DataFactory__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./N3DataFactory */ \"./node_modules/n3/src/N3DataFactory.js\");\n/* harmony import */ var _IRIs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./IRIs */ \"./node_modules/n3/src/IRIs.js\");\n// **N3Parser** parses N3 documents.\n\n\n\n\nlet blankNodePrefix = 0;\n\n// ## Constructor\nclass N3Parser {\n  constructor(options) {\n    this._contextStack = [];\n    this._graph = null;\n\n    // Set the document IRI\n    options = options || {};\n    this._setBase(options.baseIRI);\n    options.factory && initDataFactory(this, options.factory);\n\n    // Set supported features depending on the format\n    const format = (typeof options.format === 'string') ?\n                 options.format.match(/\\w*$/)[0].toLowerCase() : '',\n        isTurtle = /turtle/.test(format), isTriG = /trig/.test(format),\n        isNTriples = /triple/.test(format), isNQuads = /quad/.test(format),\n        isN3 = this._n3Mode = /n3/.test(format),\n        isLineMode = isNTriples || isNQuads;\n    if (!(this._supportsNamedGraphs = !(isTurtle || isN3)))\n      this._readPredicateOrNamedGraph = this._readPredicate;\n    // Support triples in other graphs\n    this._supportsQuads = !(isTurtle || isTriG || isNTriples || isN3);\n    // Support nesting of triples\n    this._supportsRDFStar = format === '' || /star|\\*$/.test(format);\n    // Disable relative IRIs in N-Triples or N-Quads mode\n    if (isLineMode)\n      this._resolveRelativeIRI = iri => { return null; };\n    this._blankNodePrefix = typeof options.blankNodePrefix !== 'string' ? '' :\n                              options.blankNodePrefix.replace(/^(?!_:)/, '_:');\n    this._lexer = options.lexer || new _N3Lexer__WEBPACK_IMPORTED_MODULE_0__[\"default\"]({ lineMode: isLineMode, n3: isN3 });\n    // Disable explicit quantifiers by default\n    this._explicitQuantifiers = !!options.explicitQuantifiers;\n  }\n\n  // ## Static class methods\n\n  // ### `_resetBlankNodePrefix` restarts blank node prefix identification\n  static _resetBlankNodePrefix() {\n    blankNodePrefix = 0;\n  }\n\n  // ## Private methods\n\n  // ### `_setBase` sets the base IRI to resolve relative IRIs\n  _setBase(baseIRI) {\n    if (!baseIRI) {\n      this._base = '';\n      this._basePath = '';\n    }\n    else {\n      // Remove fragment if present\n      const fragmentPos = baseIRI.indexOf('#');\n      if (fragmentPos >= 0)\n        baseIRI = baseIRI.substr(0, fragmentPos);\n      // Set base IRI and its components\n      this._base = baseIRI;\n      this._basePath   = baseIRI.indexOf('/') < 0 ? baseIRI :\n                         baseIRI.replace(/[^\\/?]*(?:\\?.*)?$/, '');\n      baseIRI = baseIRI.match(/^(?:([a-z][a-z0-9+.-]*:))?(?:\\/\\/[^\\/]*)?/i);\n      this._baseRoot   = baseIRI[0];\n      this._baseScheme = baseIRI[1];\n    }\n  }\n\n  // ### `_saveContext` stores the current parsing context\n  // when entering a new scope (list, blank node, formula)\n  _saveContext(type, graph, subject, predicate, object) {\n    const n3Mode = this._n3Mode;\n    this._contextStack.push({\n      type,\n      subject, predicate, object, graph,\n      inverse: n3Mode ? this._inversePredicate : false,\n      blankPrefix: n3Mode ? this._prefixes._ : '',\n      quantified: n3Mode ? this._quantified : null,\n    });\n    // The settings below only apply to N3 streams\n    if (n3Mode) {\n      // Every new scope resets the predicate direction\n      this._inversePredicate = false;\n      // In N3, blank nodes are scoped to a formula\n      // (using a dot as separator, as a blank node label cannot start with it)\n      this._prefixes._ = (this._graph ? `${this._graph.value}.` : '.');\n      // Quantifiers are scoped to a formula\n      this._quantified = Object.create(this._quantified);\n    }\n  }\n\n  // ### `_restoreContext` restores the parent context\n  // when leaving a scope (list, blank node, formula)\n  _restoreContext(type, token) {\n    // Obtain the previous context\n    const context = this._contextStack.pop();\n    if (!context || context.type !== type)\n      return this._error(`Unexpected ${token.type}`, token);\n\n    // Restore the quad of the previous context\n    this._subject   = context.subject;\n    this._predicate = context.predicate;\n    this._object    = context.object;\n    this._graph     = context.graph;\n\n    // Restore N3 context settings\n    if (this._n3Mode) {\n      this._inversePredicate = context.inverse;\n      this._prefixes._ = context.blankPrefix;\n      this._quantified = context.quantified;\n    }\n  }\n\n  // ### `_readInTopContext` reads a token when in the top context\n  _readInTopContext(token) {\n    switch (token.type) {\n    // If an EOF token arrives in the top context, signal that we're done\n    case 'eof':\n      if (this._graph !== null)\n        return this._error('Unclosed graph', token);\n      delete this._prefixes._;\n      return this._callback(null, null, this._prefixes);\n    // It could be a prefix declaration\n    case 'PREFIX':\n      this._sparqlStyle = true;\n    case '@prefix':\n      return this._readPrefix;\n    // It could be a base declaration\n    case 'BASE':\n      this._sparqlStyle = true;\n    case '@base':\n      return this._readBaseIRI;\n    // It could be a graph\n    case '{':\n      if (this._supportsNamedGraphs) {\n        this._graph = '';\n        this._subject = null;\n        return this._readSubject;\n      }\n    case 'GRAPH':\n      if (this._supportsNamedGraphs)\n        return this._readNamedGraphLabel;\n    // Otherwise, the next token must be a subject\n    default:\n      return this._readSubject(token);\n    }\n  }\n\n  // ### `_readEntity` reads an IRI, prefixed name, blank node, or variable\n  _readEntity(token, quantifier) {\n    let value;\n    switch (token.type) {\n    // Read a relative or absolute IRI\n    case 'IRI':\n    case 'typeIRI':\n      const iri = this._resolveIRI(token.value);\n      if (iri === null)\n        return this._error('Invalid IRI', token);\n      value = this._namedNode(iri);\n      break;\n    // Read a prefixed name\n    case 'type':\n    case 'prefixed':\n      const prefix = this._prefixes[token.prefix];\n      if (prefix === undefined)\n        return this._error(`Undefined prefix \"${token.prefix}:\"`, token);\n      value = this._namedNode(prefix + token.value);\n      break;\n    // Read a blank node\n    case 'blank':\n      value = this._blankNode(this._prefixes[token.prefix] + token.value);\n      break;\n    // Read a variable\n    case 'var':\n      value = this._variable(token.value.substr(1));\n      break;\n    // Everything else is not an entity\n    default:\n      return this._error(`Expected entity but got ${token.type}`, token);\n    }\n    // In N3 mode, replace the entity if it is quantified\n    if (!quantifier && this._n3Mode && (value.id in this._quantified))\n      value = this._quantified[value.id];\n    return value;\n  }\n\n  // ### `_readSubject` reads a quad's subject\n  _readSubject(token) {\n    this._predicate = null;\n    switch (token.type) {\n    case '[':\n      // Start a new quad with a new blank node as subject\n      this._saveContext('blank', this._graph,\n                        this._subject = this._blankNode(), null, null);\n      return this._readBlankNodeHead;\n    case '(':\n      // Start a new list\n      this._saveContext('list', this._graph, this.RDF_NIL, null, null);\n      this._subject = null;\n      return this._readListItem;\n    case '{':\n      // Start a new formula\n      if (!this._n3Mode)\n        return this._error('Unexpected graph', token);\n      this._saveContext('formula', this._graph,\n                        this._graph = this._blankNode(), null, null);\n      return this._readSubject;\n    case '}':\n       // No subject; the graph in which we are reading is closed instead\n      return this._readPunctuation(token);\n    case '@forSome':\n      if (!this._n3Mode)\n        return this._error('Unexpected \"@forSome\"', token);\n      this._subject = null;\n      this._predicate = this.N3_FORSOME;\n      this._quantifier = this._blankNode;\n      return this._readQuantifierList;\n    case '@forAll':\n      if (!this._n3Mode)\n        return this._error('Unexpected \"@forAll\"', token);\n      this._subject = null;\n      this._predicate = this.N3_FORALL;\n      this._quantifier = this._variable;\n      return this._readQuantifierList;\n    case 'literal':\n      if (!this._n3Mode)\n        return this._error('Unexpected literal', token);\n\n      if (token.prefix.length === 0) {\n        this._literalValue = token.value;\n        return this._completeSubjectLiteral;\n      }\n      else\n        this._subject = this._literal(token.value, this._namedNode(token.prefix));\n\n      break;\n    case '<<':\n      if (!this._supportsRDFStar)\n        return this._error('Unexpected RDF-star syntax', token);\n      this._saveContext('<<', this._graph, null, null, null);\n      this._graph = null;\n      return this._readSubject;\n    default:\n      // Read the subject entity\n      if ((this._subject = this._readEntity(token)) === undefined)\n        return;\n      // In N3 mode, the subject might be a path\n      if (this._n3Mode)\n        return this._getPathReader(this._readPredicateOrNamedGraph);\n    }\n\n    // The next token must be a predicate,\n    // or, if the subject was actually a graph IRI, a named graph\n    return this._readPredicateOrNamedGraph;\n  }\n\n  // ### `_readPredicate` reads a quad's predicate\n  _readPredicate(token) {\n    const type = token.type;\n    switch (type) {\n    case 'inverse':\n      this._inversePredicate = true;\n    case 'abbreviation':\n      this._predicate = this.ABBREVIATIONS[token.value];\n      break;\n    case '.':\n    case ']':\n    case '}':\n      // Expected predicate didn't come, must have been trailing semicolon\n      if (this._predicate === null)\n        return this._error(`Unexpected ${type}`, token);\n      this._subject = null;\n      return type === ']' ? this._readBlankNodeTail(token) : this._readPunctuation(token);\n    case ';':\n      // Additional semicolons can be safely ignored\n      return this._predicate !== null ? this._readPredicate :\n             this._error('Expected predicate but got ;', token);\n    case '[':\n      if (this._n3Mode) {\n        // Start a new quad with a new blank node as subject\n        this._saveContext('blank', this._graph, this._subject,\n                          this._subject = this._blankNode(), null);\n        return this._readBlankNodeHead;\n      }\n    case 'blank':\n      if (!this._n3Mode)\n        return this._error('Disallowed blank node as predicate', token);\n    default:\n      if ((this._predicate = this._readEntity(token)) === undefined)\n        return;\n    }\n    // The next token must be an object\n    return this._readObject;\n  }\n\n  // ### `_readObject` reads a quad's object\n  _readObject(token) {\n    switch (token.type) {\n    case 'literal':\n      // Regular literal, can still get a datatype or language\n      if (token.prefix.length === 0) {\n        this._literalValue = token.value;\n        return this._readDataTypeOrLang;\n      }\n      // Pre-datatyped string literal (prefix stores the datatype)\n      else\n        this._object = this._literal(token.value, this._namedNode(token.prefix));\n      break;\n    case '[':\n      // Start a new quad with a new blank node as subject\n      this._saveContext('blank', this._graph, this._subject, this._predicate,\n                        this._subject = this._blankNode());\n      return this._readBlankNodeHead;\n    case '(':\n      // Start a new list\n      this._saveContext('list', this._graph, this._subject, this._predicate, this.RDF_NIL);\n      this._subject = null;\n      return this._readListItem;\n    case '{':\n      // Start a new formula\n      if (!this._n3Mode)\n        return this._error('Unexpected graph', token);\n      this._saveContext('formula', this._graph, this._subject, this._predicate,\n                        this._graph = this._blankNode());\n      return this._readSubject;\n    case '<<':\n      if (!this._supportsRDFStar)\n        return this._error('Unexpected RDF-star syntax', token);\n      this._saveContext('<<', this._graph, this._subject, this._predicate, null);\n      this._graph = null;\n      return this._readSubject;\n    default:\n      // Read the object entity\n      if ((this._object = this._readEntity(token)) === undefined)\n        return;\n      // In N3 mode, the object might be a path\n      if (this._n3Mode)\n        return this._getPathReader(this._getContextEndReader());\n    }\n    return this._getContextEndReader();\n  }\n\n  // ### `_readPredicateOrNamedGraph` reads a quad's predicate, or a named graph\n  _readPredicateOrNamedGraph(token) {\n    return token.type === '{' ? this._readGraph(token) : this._readPredicate(token);\n  }\n\n  // ### `_readGraph` reads a graph\n  _readGraph(token) {\n    if (token.type !== '{')\n      return this._error(`Expected graph but got ${token.type}`, token);\n    // The \"subject\" we read is actually the GRAPH's label\n    this._graph = this._subject, this._subject = null;\n    return this._readSubject;\n  }\n\n  // ### `_readBlankNodeHead` reads the head of a blank node\n  _readBlankNodeHead(token) {\n    if (token.type === ']') {\n      this._subject = null;\n      return this._readBlankNodeTail(token);\n    }\n    else {\n      this._predicate = null;\n      return this._readPredicate(token);\n    }\n  }\n\n  // ### `_readBlankNodeTail` reads the end of a blank node\n  _readBlankNodeTail(token) {\n    if (token.type !== ']')\n      return this._readBlankNodePunctuation(token);\n\n    // Store blank node quad\n    if (this._subject !== null)\n      this._emit(this._subject, this._predicate, this._object, this._graph);\n\n    // Restore the parent context containing this blank node\n    const empty = this._predicate === null;\n    this._restoreContext('blank', token);\n    // If the blank node was the object, restore previous context and read punctuation\n    if (this._object !== null)\n      return this._getContextEndReader();\n    // If the blank node was the predicate, continue reading the object\n    else if (this._predicate !== null)\n      return this._readObject;\n    // If the blank node was the subject, continue reading the predicate\n    else\n      // If the blank node was empty, it could be a named graph label\n      return empty ? this._readPredicateOrNamedGraph : this._readPredicateAfterBlank;\n  }\n\n  // ### `_readPredicateAfterBlank` reads a predicate after an anonymous blank node\n  _readPredicateAfterBlank(token) {\n    switch (token.type) {\n    case '.':\n    case '}':\n      // No predicate is coming if the triple is terminated here\n      this._subject = null;\n      return this._readPunctuation(token);\n    default:\n      return this._readPredicate(token);\n    }\n  }\n\n  // ### `_readListItem` reads items from a list\n  _readListItem(token) {\n    let item = null,                      // The item of the list\n        list = null,                      // The list itself\n        next = this._readListItem;        // The next function to execute\n    const previousList = this._subject,   // The previous list that contains this list\n        stack = this._contextStack,       // The stack of parent contexts\n        parent = stack[stack.length - 1]; // The parent containing the current list\n\n    switch (token.type) {\n    case '[':\n      // Stack the current list quad and start a new quad with a blank node as subject\n      this._saveContext('blank', this._graph,\n                        list = this._blankNode(), this.RDF_FIRST,\n                        this._subject = item = this._blankNode());\n      next = this._readBlankNodeHead;\n      break;\n    case '(':\n      // Stack the current list quad and start a new list\n      this._saveContext('list', this._graph,\n                        list = this._blankNode(), this.RDF_FIRST, this.RDF_NIL);\n      this._subject = null;\n      break;\n    case ')':\n      // Closing the list; restore the parent context\n      this._restoreContext('list', token);\n      // If this list is contained within a parent list, return the membership quad here.\n      // This will be `<parent list element> rdf:first <this list>.`.\n      if (stack.length !== 0 && stack[stack.length - 1].type === 'list')\n        this._emit(this._subject, this._predicate, this._object, this._graph);\n      // Was this list the parent's subject?\n      if (this._predicate === null) {\n        // The next token is the predicate\n        next = this._readPredicate;\n        // No list tail if this was an empty list\n        if (this._subject === this.RDF_NIL)\n          return next;\n      }\n      // The list was in the parent context's object\n      else {\n        next = this._getContextEndReader();\n        // No list tail if this was an empty list\n        if (this._object === this.RDF_NIL)\n          return next;\n      }\n      // Close the list by making the head nil\n      list = this.RDF_NIL;\n      break;\n    case 'literal':\n      // Regular literal, can still get a datatype or language\n      if (token.prefix.length === 0) {\n        this._literalValue = token.value;\n        next = this._readListItemDataTypeOrLang;\n      }\n      // Pre-datatyped string literal (prefix stores the datatype)\n      else {\n        item = this._literal(token.value, this._namedNode(token.prefix));\n        next = this._getContextEndReader();\n      }\n      break;\n    case '{':\n      // Start a new formula\n      if (!this._n3Mode)\n        return this._error('Unexpected graph', token);\n      this._saveContext('formula', this._graph, this._subject, this._predicate,\n                        this._graph = this._blankNode());\n      return this._readSubject;\n    default:\n      if ((item = this._readEntity(token)) === undefined)\n        return;\n    }\n\n     // Create a new blank node if no item head was assigned yet\n    if (list === null)\n      this._subject = list = this._blankNode();\n\n    // Is this the first element of the list?\n    if (previousList === null) {\n      // This list is either the subject or the object of its parent\n      if (parent.predicate === null)\n        parent.subject = list;\n      else\n        parent.object = list;\n    }\n    else {\n      // Continue the previous list with the current list\n      this._emit(previousList, this.RDF_REST, list, this._graph);\n    }\n    // If an item was read, add it to the list\n    if (item !== null) {\n      // In N3 mode, the item might be a path\n      if (this._n3Mode && (token.type === 'IRI' || token.type === 'prefixed')) {\n        // Create a new context to add the item's path\n        this._saveContext('item', this._graph, list, this.RDF_FIRST, item);\n        this._subject = item, this._predicate = null;\n        // _readPath will restore the context and output the item\n        return this._getPathReader(this._readListItem);\n      }\n      // Output the item\n      this._emit(list, this.RDF_FIRST, item, this._graph);\n    }\n    return next;\n  }\n\n  // ### `_readDataTypeOrLang` reads an _optional_ datatype or language\n  _readDataTypeOrLang(token) {\n    return this._completeObjectLiteral(token, false);\n  }\n\n\n  // ### `_readListItemDataTypeOrLang` reads an _optional_ datatype or language in a list\n  _readListItemDataTypeOrLang(token) {\n    return this._completeObjectLiteral(token, true);\n  }\n\n  // ### `_completeLiteral` completes a literal with an optional datatype or language\n  _completeLiteral(token) {\n    // Create a simple string literal by default\n    let literal = this._literal(this._literalValue);\n\n    switch (token.type) {\n    // Create a datatyped literal\n    case 'type':\n    case 'typeIRI':\n      const datatype = this._readEntity(token);\n      if (datatype === undefined) return; // No datatype means an error occurred\n      literal = this._literal(this._literalValue, datatype);\n      token = null;\n      break;\n    // Create a language-tagged string\n    case 'langcode':\n      literal = this._literal(this._literalValue, token.value);\n      token = null;\n      break;\n    }\n\n    return { token, literal };\n  }\n\n  // Completes a literal in subject position\n  _completeSubjectLiteral(token) {\n    this._subject = this._completeLiteral(token).literal;\n    return this._readPredicateOrNamedGraph;\n  }\n\n  // Completes a literal in object position\n  _completeObjectLiteral(token, listItem) {\n    const completed = this._completeLiteral(token);\n    if (!completed)\n      return;\n    this._object = completed.literal;\n\n    // If this literal was part of a list, write the item\n    // (we could also check the context stack, but passing in a flag is faster)\n    if (listItem)\n      this._emit(this._subject, this.RDF_FIRST, this._object, this._graph);\n    // If the token was consumed, continue with the rest of the input\n    if (completed.token === null)\n      return this._getContextEndReader();\n    // Otherwise, consume the token now\n    else {\n      this._readCallback = this._getContextEndReader();\n      return this._readCallback(completed.token);\n    }\n  }\n\n  // ### `_readFormulaTail` reads the end of a formula\n  _readFormulaTail(token) {\n    if (token.type !== '}')\n      return this._readPunctuation(token);\n\n    // Store the last quad of the formula\n    if (this._subject !== null)\n      this._emit(this._subject, this._predicate, this._object, this._graph);\n\n    // Restore the parent context containing this formula\n    this._restoreContext('formula', token);\n    // If the formula was the subject, continue reading the predicate.\n    // If the formula was the object, read punctuation.\n    return this._object === null ? this._readPredicate : this._getContextEndReader();\n  }\n\n  // ### `_readPunctuation` reads punctuation between quads or quad parts\n  _readPunctuation(token) {\n    let next, graph = this._graph;\n    const subject = this._subject, inversePredicate = this._inversePredicate;\n    switch (token.type) {\n    // A closing brace ends a graph\n    case '}':\n      if (this._graph === null)\n        return this._error('Unexpected graph closing', token);\n      if (this._n3Mode)\n        return this._readFormulaTail(token);\n      this._graph = null;\n    // A dot just ends the statement, without sharing anything with the next\n    case '.':\n      this._subject = null;\n      next = this._contextStack.length ? this._readSubject : this._readInTopContext;\n      if (inversePredicate) this._inversePredicate = false;\n      break;\n    // Semicolon means the subject is shared; predicate and object are different\n    case ';':\n      next = this._readPredicate;\n      break;\n    // Comma means both the subject and predicate are shared; the object is different\n    case ',':\n      next = this._readObject;\n      break;\n    // {| means that the current triple is annotated with predicate-object pairs.\n    case '{|':\n      if (!this._supportsRDFStar)\n        return this._error('Unexpected RDF-star syntax', token);\n      // Continue using the last triple as quoted triple subject for the predicate-object pairs.\n      const predicate = this._predicate, object = this._object;\n      this._subject = this._quad(subject, predicate, object, this.DEFAULTGRAPH);\n      next = this._readPredicate;\n      break;\n    // |} means that the current quoted triple in annotation syntax is finalized.\n    case '|}':\n      if (this._subject.termType !== 'Quad')\n        return this._error('Unexpected asserted triple closing', token);\n      this._subject = null;\n      next = this._readPunctuation;\n      break;\n    default:\n      // An entity means this is a quad (only allowed if not already inside a graph)\n      if (this._supportsQuads && this._graph === null && (graph = this._readEntity(token)) !== undefined) {\n        next = this._readQuadPunctuation;\n        break;\n      }\n      return this._error(`Expected punctuation to follow \"${this._object.id}\"`, token);\n    }\n    // A quad has been completed now, so return it\n    if (subject !== null) {\n      const predicate = this._predicate, object = this._object;\n      if (!inversePredicate)\n        this._emit(subject, predicate, object,  graph);\n      else\n        this._emit(object,  predicate, subject, graph);\n    }\n    return next;\n  }\n\n    // ### `_readBlankNodePunctuation` reads punctuation in a blank node\n  _readBlankNodePunctuation(token) {\n    let next;\n    switch (token.type) {\n    // Semicolon means the subject is shared; predicate and object are different\n    case ';':\n      next = this._readPredicate;\n      break;\n    // Comma means both the subject and predicate are shared; the object is different\n    case ',':\n      next = this._readObject;\n      break;\n    default:\n      return this._error(`Expected punctuation to follow \"${this._object.id}\"`, token);\n    }\n    // A quad has been completed now, so return it\n    this._emit(this._subject, this._predicate, this._object, this._graph);\n    return next;\n  }\n\n  // ### `_readQuadPunctuation` reads punctuation after a quad\n  _readQuadPunctuation(token) {\n    if (token.type !== '.')\n      return this._error('Expected dot to follow quad', token);\n    return this._readInTopContext;\n  }\n\n  // ### `_readPrefix` reads the prefix of a prefix declaration\n  _readPrefix(token) {\n    if (token.type !== 'prefix')\n      return this._error('Expected prefix to follow @prefix', token);\n    this._prefix = token.value;\n    return this._readPrefixIRI;\n  }\n\n  // ### `_readPrefixIRI` reads the IRI of a prefix declaration\n  _readPrefixIRI(token) {\n    if (token.type !== 'IRI')\n      return this._error(`Expected IRI to follow prefix \"${this._prefix}:\"`, token);\n    const prefixNode = this._readEntity(token);\n    this._prefixes[this._prefix] = prefixNode.value;\n    this._prefixCallback(this._prefix, prefixNode);\n    return this._readDeclarationPunctuation;\n  }\n\n  // ### `_readBaseIRI` reads the IRI of a base declaration\n  _readBaseIRI(token) {\n    const iri = token.type === 'IRI' && this._resolveIRI(token.value);\n    if (!iri)\n      return this._error('Expected valid IRI to follow base declaration', token);\n    this._setBase(iri);\n    return this._readDeclarationPunctuation;\n  }\n\n  // ### `_readNamedGraphLabel` reads the label of a named graph\n  _readNamedGraphLabel(token) {\n    switch (token.type) {\n    case 'IRI':\n    case 'blank':\n    case 'prefixed':\n      return this._readSubject(token), this._readGraph;\n    case '[':\n      return this._readNamedGraphBlankLabel;\n    default:\n      return this._error('Invalid graph label', token);\n    }\n  }\n\n  // ### `_readNamedGraphLabel` reads a blank node label of a named graph\n  _readNamedGraphBlankLabel(token) {\n    if (token.type !== ']')\n      return this._error('Invalid graph label', token);\n    this._subject = this._blankNode();\n    return this._readGraph;\n  }\n\n  // ### `_readDeclarationPunctuation` reads the punctuation of a declaration\n  _readDeclarationPunctuation(token) {\n    // SPARQL-style declarations don't have punctuation\n    if (this._sparqlStyle) {\n      this._sparqlStyle = false;\n      return this._readInTopContext(token);\n    }\n\n    if (token.type !== '.')\n      return this._error('Expected declaration to end with a dot', token);\n    return this._readInTopContext;\n  }\n\n  // Reads a list of quantified symbols from a @forSome or @forAll statement\n  _readQuantifierList(token) {\n    let entity;\n    switch (token.type) {\n    case 'IRI':\n    case 'prefixed':\n      if ((entity = this._readEntity(token, true)) !== undefined)\n        break;\n    default:\n      return this._error(`Unexpected ${token.type}`, token);\n    }\n    // Without explicit quantifiers, map entities to a quantified entity\n    if (!this._explicitQuantifiers)\n      this._quantified[entity.id] = this._quantifier(this._blankNode().value);\n    // With explicit quantifiers, output the reified quantifier\n    else {\n      // If this is the first item, start a new quantifier list\n      if (this._subject === null)\n        this._emit(this._graph || this.DEFAULTGRAPH, this._predicate,\n                   this._subject = this._blankNode(), this.QUANTIFIERS_GRAPH);\n      // Otherwise, continue the previous list\n      else\n        this._emit(this._subject, this.RDF_REST,\n                   this._subject = this._blankNode(), this.QUANTIFIERS_GRAPH);\n      // Output the list item\n      this._emit(this._subject, this.RDF_FIRST, entity, this.QUANTIFIERS_GRAPH);\n    }\n    return this._readQuantifierPunctuation;\n  }\n\n  // Reads punctuation from a @forSome or @forAll statement\n  _readQuantifierPunctuation(token) {\n    // Read more quantifiers\n    if (token.type === ',')\n      return this._readQuantifierList;\n    // End of the quantifier list\n    else {\n      // With explicit quantifiers, close the quantifier list\n      if (this._explicitQuantifiers) {\n        this._emit(this._subject, this.RDF_REST, this.RDF_NIL, this.QUANTIFIERS_GRAPH);\n        this._subject = null;\n      }\n      // Read a dot\n      this._readCallback = this._getContextEndReader();\n      return this._readCallback(token);\n    }\n  }\n\n  // ### `_getPathReader` reads a potential path and then resumes with the given function\n  _getPathReader(afterPath) {\n    this._afterPath = afterPath;\n    return this._readPath;\n  }\n\n  // ### `_readPath` reads a potential path\n  _readPath(token) {\n    switch (token.type) {\n    // Forward path\n    case '!': return this._readForwardPath;\n    // Backward path\n    case '^': return this._readBackwardPath;\n    // Not a path; resume reading where we left off\n    default:\n      const stack = this._contextStack, parent = stack.length && stack[stack.length - 1];\n      // If we were reading a list item, we still need to output it\n      if (parent && parent.type === 'item') {\n        // The list item is the remaining subejct after reading the path\n        const item = this._subject;\n        // Switch back to the context of the list\n        this._restoreContext('item', token);\n        // Output the list item\n        this._emit(this._subject, this.RDF_FIRST, item, this._graph);\n      }\n      return this._afterPath(token);\n    }\n  }\n\n  // ### `_readForwardPath` reads a '!' path\n  _readForwardPath(token) {\n    let subject, predicate;\n    const object = this._blankNode();\n    // The next token is the predicate\n    if ((predicate = this._readEntity(token)) === undefined)\n      return;\n    // If we were reading a subject, replace the subject by the path's object\n    if (this._predicate === null)\n      subject = this._subject, this._subject = object;\n    // If we were reading an object, replace the subject by the path's object\n    else\n      subject = this._object,  this._object  = object;\n    // Emit the path's current quad and read its next section\n    this._emit(subject, predicate, object, this._graph);\n    return this._readPath;\n  }\n\n  // ### `_readBackwardPath` reads a '^' path\n  _readBackwardPath(token) {\n    const subject = this._blankNode();\n    let predicate, object;\n    // The next token is the predicate\n    if ((predicate = this._readEntity(token)) === undefined)\n      return;\n    // If we were reading a subject, replace the subject by the path's subject\n    if (this._predicate === null)\n      object = this._subject, this._subject = subject;\n    // If we were reading an object, replace the subject by the path's subject\n    else\n      object = this._object,  this._object  = subject;\n    // Emit the path's current quad and read its next section\n    this._emit(subject, predicate, object, this._graph);\n    return this._readPath;\n  }\n\n  // ### `_readRDFStarTailOrGraph` reads the graph of a nested RDF-star quad or the end of a nested RDF-star triple\n  _readRDFStarTailOrGraph(token) {\n    if (token.type !== '>>') {\n      // An entity means this is a quad (only allowed if not already inside a graph)\n      if (this._supportsQuads && this._graph === null && (this._graph = this._readEntity(token)) !== undefined)\n        return this._readRDFStarTail;\n      return this._error(`Expected >> to follow \"${this._object.id}\"`, token);\n    }\n    return this._readRDFStarTail(token);\n  }\n\n  // ### `_readRDFStarTail` reads the end of a nested RDF-star triple\n  _readRDFStarTail(token) {\n    if (token.type !== '>>')\n      return this._error(`Expected >> but got ${token.type}`, token);\n    // Read the quad and restore the previous context\n    const quad = this._quad(this._subject, this._predicate, this._object,\n      this._graph || this.DEFAULTGRAPH);\n    this._restoreContext('<<', token);\n    // If the triple was the subject, continue by reading the predicate.\n    if (this._subject === null) {\n      this._subject = quad;\n      return this._readPredicate;\n    }\n    // If the triple was the object, read context end.\n    else {\n      this._object = quad;\n      return this._getContextEndReader();\n    }\n  }\n\n  // ### `_getContextEndReader` gets the next reader function at the end of a context\n  _getContextEndReader() {\n    const contextStack = this._contextStack;\n    if (!contextStack.length)\n      return this._readPunctuation;\n\n    switch (contextStack[contextStack.length - 1].type) {\n    case 'blank':\n      return this._readBlankNodeTail;\n    case 'list':\n      return this._readListItem;\n    case 'formula':\n      return this._readFormulaTail;\n    case '<<':\n      return this._readRDFStarTailOrGraph;\n    }\n  }\n\n  // ### `_emit` sends a quad through the callback\n  _emit(subject, predicate, object, graph) {\n    this._callback(null, this._quad(subject, predicate, object, graph || this.DEFAULTGRAPH));\n  }\n\n  // ### `_error` emits an error message through the callback\n  _error(message, token) {\n    const err = new Error(`${message} on line ${token.line}.`);\n    err.context = {\n      token: token,\n      line: token.line,\n      previousToken: this._lexer.previousToken,\n    };\n    this._callback(err);\n    this._callback = noop;\n  }\n\n  // ### `_resolveIRI` resolves an IRI against the base path\n  _resolveIRI(iri) {\n    return /^[a-z][a-z0-9+.-]*:/i.test(iri) ? iri : this._resolveRelativeIRI(iri);\n  }\n\n  // ### `_resolveRelativeIRI` resolves an IRI against the base path,\n  // assuming that a base path has been set and that the IRI is indeed relative\n  _resolveRelativeIRI(iri) {\n    // An empty relative IRI indicates the base IRI\n    if (!iri.length)\n      return this._base;\n    // Decide resolving strategy based in the first character\n    switch (iri[0]) {\n    // Resolve relative fragment IRIs against the base IRI\n    case '#': return this._base + iri;\n    // Resolve relative query string IRIs by replacing the query string\n    case '?': return this._base.replace(/(?:\\?.*)?$/, iri);\n    // Resolve root-relative IRIs at the root of the base IRI\n    case '/':\n      // Resolve scheme-relative IRIs to the scheme\n      return (iri[1] === '/' ? this._baseScheme : this._baseRoot) + this._removeDotSegments(iri);\n    // Resolve all other IRIs at the base IRI's path\n    default:\n      // Relative IRIs cannot contain a colon in the first path segment\n      return (/^[^/:]*:/.test(iri)) ? null : this._removeDotSegments(this._basePath + iri);\n    }\n  }\n\n  // ### `_removeDotSegments` resolves './' and '../' path segments in an IRI as per RFC3986\n  _removeDotSegments(iri) {\n    // Don't modify the IRI if it does not contain any dot segments\n    if (!/(^|\\/)\\.\\.?($|[/#?])/.test(iri))\n      return iri;\n\n    // Start with an imaginary slash before the IRI in order to resolve trailing './' and '../'\n    const length = iri.length;\n    let result = '', i = -1, pathStart = -1, segmentStart = 0, next = '/';\n\n    while (i < length) {\n      switch (next) {\n      // The path starts with the first slash after the authority\n      case ':':\n        if (pathStart < 0) {\n          // Skip two slashes before the authority\n          if (iri[++i] === '/' && iri[++i] === '/')\n            // Skip to slash after the authority\n            while ((pathStart = i + 1) < length && iri[pathStart] !== '/')\n              i = pathStart;\n        }\n        break;\n      // Don't modify a query string or fragment\n      case '?':\n      case '#':\n        i = length;\n        break;\n      // Handle '/.' or '/..' path segments\n      case '/':\n        if (iri[i + 1] === '.') {\n          next = iri[++i + 1];\n          switch (next) {\n          // Remove a '/.' segment\n          case '/':\n            result += iri.substring(segmentStart, i - 1);\n            segmentStart = i + 1;\n            break;\n          // Remove a trailing '/.' segment\n          case undefined:\n          case '?':\n          case '#':\n            return result + iri.substring(segmentStart, i) + iri.substr(i + 1);\n          // Remove a '/..' segment\n          case '.':\n            next = iri[++i + 1];\n            if (next === undefined || next === '/' || next === '?' || next === '#') {\n              result += iri.substring(segmentStart, i - 2);\n              // Try to remove the parent path from result\n              if ((segmentStart = result.lastIndexOf('/')) >= pathStart)\n                result = result.substr(0, segmentStart);\n              // Remove a trailing '/..' segment\n              if (next !== '/')\n                return `${result}/${iri.substr(i + 1)}`;\n              segmentStart = i + 1;\n            }\n          }\n        }\n      }\n      next = iri[++i];\n    }\n    return result + iri.substring(segmentStart);\n  }\n\n  // ## Public methods\n\n  // ### `parse` parses the N3 input and emits each parsed quad through the onQuad callback.\n  parse(input, quadCallback, prefixCallback) {\n    // The second parameter accepts an object { onQuad: ..., onPrefix: ..., onComment: ...}\n    // As a second and third parameter it still accepts a separate quadCallback and prefixCallback for backward compatibility as well\n    let onQuad, onPrefix, onComment;\n    if (quadCallback && (quadCallback.onQuad || quadCallback.onPrefix || quadCallback.onComment)) {\n      onQuad = quadCallback.onQuad;\n      onPrefix = quadCallback.onPrefix;\n      onComment = quadCallback.onComment;\n    }\n    else {\n      onQuad = quadCallback;\n      onPrefix = prefixCallback;\n    }\n    // The read callback is the next function to be executed when a token arrives.\n    // We start reading in the top context.\n    this._readCallback = this._readInTopContext;\n    this._sparqlStyle = false;\n    this._prefixes = Object.create(null);\n    this._prefixes._ = this._blankNodePrefix ? this._blankNodePrefix.substr(2)\n                                             : `b${blankNodePrefix++}_`;\n    this._prefixCallback = onPrefix || noop;\n    this._inversePredicate = false;\n    this._quantified = Object.create(null);\n\n    // Parse synchronously if no quad callback is given\n    if (!onQuad) {\n      const quads = [];\n      let error;\n      this._callback = (e, t) => { e ? (error = e) : t && quads.push(t); };\n      this._lexer.tokenize(input).every(token => {\n        return this._readCallback = this._readCallback(token);\n      });\n      if (error) throw error;\n      return quads;\n    }\n\n    let processNextToken = (error, token) => {\n      if (error !== null)\n        this._callback(error), this._callback = noop;\n      else if (this._readCallback)\n        this._readCallback = this._readCallback(token);\n    };\n\n    // Enable checking for comments on every token when a commentCallback has been set\n    if (onComment) {\n      // Enable the lexer to return comments as tokens first (disabled by default)\n      this._lexer.comments = true;\n      // Patch the processNextToken function\n      processNextToken = (error, token) => {\n        if (error !== null)\n          this._callback(error), this._callback = noop;\n        else if (this._readCallback) {\n          if (token.type === 'comment')\n            onComment(token.value);\n          else\n            this._readCallback = this._readCallback(token);\n        }\n      };\n    }\n\n    // Parse asynchronously otherwise, executing the read callback when a token arrives\n    this._callback = onQuad;\n    this._lexer.tokenize(input, processNextToken);\n  }\n}\n\n// The empty function\nfunction noop() {}\n\n// Initializes the parser with the given data factory\nfunction initDataFactory(parser, factory) {\n  // Set factory methods\n  const namedNode = factory.namedNode;\n  parser._namedNode   = namedNode;\n  parser._blankNode   = factory.blankNode;\n  parser._literal     = factory.literal;\n  parser._variable    = factory.variable;\n  parser._quad        = factory.quad;\n  parser.DEFAULTGRAPH = factory.defaultGraph();\n\n  // Set common named nodes\n  parser.RDF_FIRST  = namedNode(_IRIs__WEBPACK_IMPORTED_MODULE_1__[\"default\"].rdf.first);\n  parser.RDF_REST   = namedNode(_IRIs__WEBPACK_IMPORTED_MODULE_1__[\"default\"].rdf.rest);\n  parser.RDF_NIL    = namedNode(_IRIs__WEBPACK_IMPORTED_MODULE_1__[\"default\"].rdf.nil);\n  parser.N3_FORALL  = namedNode(_IRIs__WEBPACK_IMPORTED_MODULE_1__[\"default\"].r.forAll);\n  parser.N3_FORSOME = namedNode(_IRIs__WEBPACK_IMPORTED_MODULE_1__[\"default\"].r.forSome);\n  parser.ABBREVIATIONS = {\n    'a': namedNode(_IRIs__WEBPACK_IMPORTED_MODULE_1__[\"default\"].rdf.type),\n    '=': namedNode(_IRIs__WEBPACK_IMPORTED_MODULE_1__[\"default\"].owl.sameAs),\n    '>': namedNode(_IRIs__WEBPACK_IMPORTED_MODULE_1__[\"default\"].log.implies),\n  };\n  parser.QUANTIFIERS_GRAPH = namedNode('urn:n3:quantifiers');\n}\ninitDataFactory(N3Parser.prototype, _N3DataFactory__WEBPACK_IMPORTED_MODULE_2__[\"default\"]);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/n3/src/N3Parser.js?");

/***/ }),

/***/ "./node_modules/n3/src/N3StreamParser.js":
/*!***********************************************!*\
  !*** ./node_modules/n3/src/N3StreamParser.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ N3StreamParser)\n/* harmony export */ });\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(readable_stream__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _N3Parser__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./N3Parser */ \"./node_modules/n3/src/N3Parser.js\");\n// **N3StreamParser** parses a text stream into a quad stream.\n\n\n\n// ## Constructor\nclass N3StreamParser extends readable_stream__WEBPACK_IMPORTED_MODULE_0__.Transform {\n  constructor(options) {\n    super({ decodeStrings: true });\n    this._readableState.objectMode = true;\n\n    // Set up parser with dummy stream to obtain `data` and `end` callbacks\n    const parser = new _N3Parser__WEBPACK_IMPORTED_MODULE_1__[\"default\"](options);\n    let onData, onEnd;\n\n    const callbacks = {\n        // Handle quads by pushing them down the pipeline\n      onQuad: (error, quad) => { error && this.emit('error', error) || quad && this.push(quad); },\n        // Emit prefixes through the `prefix` event\n      onPrefix: (prefix, uri) => { this.emit('prefix', prefix, uri); },\n    };\n\n    if (options && options.comments)\n      callbacks.onComment = comment => { this.emit('comment', comment); };\n\n    parser.parse({\n      on: (event, callback) => {\n        switch (event) {\n        case 'data': onData = callback; break;\n        case 'end':   onEnd = callback; break;\n        }\n      },\n    }, callbacks);\n\n    // Implement Transform methods through parser callbacks\n    this._transform = (chunk, encoding, done) => { onData(chunk); done(); };\n    this._flush = done => { onEnd(); done(); };\n  }\n\n  // ### Parses a stream of strings\n  import(stream) {\n    stream.on('data',  chunk => { this.write(chunk); });\n    stream.on('end',   ()      => { this.end(); });\n    stream.on('error', error => { this.emit('error', error); });\n    return this;\n  }\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/n3/src/N3StreamParser.js?");

/***/ }),

/***/ "./node_modules/process/browser.js":
/*!*****************************************!*\
  !*** ./node_modules/process/browser.js ***!
  \*****************************************/
/***/ ((module) => {

eval("// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/process/browser.js?");

/***/ }),

/***/ "./node_modules/queue-microtask/index.js":
/*!***********************************************!*\
  !*** ./node_modules/queue-microtask/index.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/*! queue-microtask. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\nlet promise\n\nmodule.exports = typeof queueMicrotask === 'function'\n  ? queueMicrotask.bind(typeof window !== 'undefined' ? window : __webpack_require__.g)\n  // reuse resolved promise, and allocate it lazily\n  : cb => (promise || (promise = Promise.resolve()))\n    .then(cb)\n    .catch(err => setTimeout(() => { throw err }, 0))\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/queue-microtask/index.js?");

/***/ }),

/***/ "./node_modules/rdf-canonize/lib/IdentifierIssuer.js":
/*!***********************************************************!*\
  !*** ./node_modules/rdf-canonize/lib/IdentifierIssuer.js ***!
  \***********************************************************/
/***/ ((module) => {

"use strict";
eval("/*\n * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nmodule.exports = class IdentifierIssuer {\n  /**\n   * Creates a new IdentifierIssuer. A IdentifierIssuer issues unique\n   * identifiers, keeping track of any previously issued identifiers.\n   *\n   * @param {string} prefix - The prefix to use ('<prefix><counter>').\n   * @param {Map} [existing] - An existing Map to use.\n   * @param {number} [counter] - The counter to use.\n   */\n  constructor(prefix, existing = new Map(), counter = 0) {\n    this.prefix = prefix;\n    this._existing = existing;\n    this.counter = counter;\n  }\n\n  /**\n   * Copies this IdentifierIssuer.\n   *\n   * @returns {object} - A copy of this IdentifierIssuer.\n   */\n  clone() {\n    const {prefix, _existing, counter} = this;\n    return new IdentifierIssuer(prefix, new Map(_existing), counter);\n  }\n\n  /**\n   * Gets the new identifier for the given old identifier, where if no old\n   * identifier is given a new identifier will be generated.\n   *\n   * @param {string} [old] - The old identifier to get the new identifier for.\n   *\n   * @returns {string} - The new identifier.\n   */\n  getId(old) {\n    // return existing old identifier\n    const existing = old && this._existing.get(old);\n    if(existing) {\n      return existing;\n    }\n\n    // get next identifier\n    const identifier = this.prefix + this.counter;\n    this.counter++;\n\n    // save mapping\n    if(old) {\n      this._existing.set(old, identifier);\n    }\n\n    return identifier;\n  }\n\n  /**\n   * Returns true if the given old identifer has already been assigned a new\n   * identifier.\n   *\n   * @param {string} old - The old identifier to check.\n   *\n   * @returns {boolean} - True if the old identifier has been assigned a new\n   *   identifier, false if not.\n   */\n  hasId(old) {\n    return this._existing.has(old);\n  }\n\n  /**\n   * Returns all of the IDs that have been issued new IDs in the order in\n   * which they were issued new IDs.\n   *\n   * @returns {Array} - The list of old IDs that has been issued new IDs in\n   *   order.\n   */\n  getOldIds() {\n    return [...this._existing.keys()];\n  }\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-canonize/lib/IdentifierIssuer.js?");

/***/ }),

/***/ "./node_modules/rdf-canonize/lib/MessageDigest-webcrypto.js":
/*!******************************************************************!*\
  !*** ./node_modules/rdf-canonize/lib/MessageDigest-webcrypto.js ***!
  \******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Copyright (c) 2016-2023 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst {bufferToHex, crypto} = __webpack_require__(/*! ./platform */ \"./node_modules/rdf-canonize/lib/platform-browser.js\");\n\nconst algorithmMap = new Map([\n  ['sha256', 'SHA-256'],\n  ['SHA256', 'SHA-256'],\n  ['SHA-256', 'SHA-256'],\n  ['sha384', 'SHA-384'],\n  ['SHA384', 'SHA-384'],\n  ['SHA-384', 'SHA-384'],\n  ['sha512', 'SHA-512'],\n  ['SHA512', 'SHA-512'],\n  ['SHA-512', 'SHA-512'],\n]);\n\nmodule.exports = class MessageDigest {\n  /**\n   * Creates a new WebCrypto API MessageDigest.\n   *\n   * @param {string} algorithm - The algorithm to use.\n   */\n  constructor(algorithm) {\n    // check if crypto.subtle is available\n    // check is here rather than top-level to only fail if class is used\n    if(!(crypto && crypto.subtle)) {\n      throw new Error('crypto.subtle not found.');\n    }\n    if(!algorithmMap.has(algorithm)) {\n      throw new Error(`Unsupported algorithm \"${algorithm}\".`);\n    }\n    this.algorithm = algorithmMap.get(algorithm);\n    this._content = '';\n  }\n\n  update(msg) {\n    this._content += msg;\n  }\n\n  async digest() {\n    const data = new TextEncoder().encode(this._content);\n    const buffer = await crypto.subtle.digest(this.algorithm, data);\n    return bufferToHex(buffer);\n  }\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-canonize/lib/MessageDigest-webcrypto.js?");

/***/ }),

/***/ "./node_modules/rdf-canonize/lib/NQuads.js":
/*!*************************************************!*\
  !*** ./node_modules/rdf-canonize/lib/NQuads.js ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("/*!\n * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.\n */\n\n\n// eslint-disable-next-line no-unused-vars\nconst TERMS = ['subject', 'predicate', 'object', 'graph'];\nconst RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\nconst RDF_LANGSTRING = RDF + 'langString';\nconst XSD_STRING = 'http://www.w3.org/2001/XMLSchema#string';\n\nconst TYPE_NAMED_NODE = 'NamedNode';\nconst TYPE_BLANK_NODE = 'BlankNode';\nconst TYPE_LITERAL = 'Literal';\nconst TYPE_DEFAULT_GRAPH = 'DefaultGraph';\n\n// build regexes\nconst REGEX = {};\n(() => {\n  // https://www.w3.org/TR/n-quads/#sec-grammar\n  // https://www.w3.org/TR/turtle/#grammar-production-BLANK_NODE_LABEL\n  const PN_CHARS_BASE =\n    'A-Z' + 'a-z' +\n    '\\u00C0-\\u00D6' +\n    '\\u00D8-\\u00F6' +\n    '\\u00F8-\\u02FF' +\n    '\\u0370-\\u037D' +\n    '\\u037F-\\u1FFF' +\n    '\\u200C-\\u200D' +\n    '\\u2070-\\u218F' +\n    '\\u2C00-\\u2FEF' +\n    '\\u3001-\\uD7FF' +\n    '\\uF900-\\uFDCF' +\n    '\\uFDF0-\\uFFFD';\n    // TODO:\n    //'\\u10000-\\uEFFFF';\n  const PN_CHARS_U =\n    PN_CHARS_BASE +\n    '_';\n  const PN_CHARS =\n    PN_CHARS_U +\n    '0-9' +\n    '-' +\n    '\\u00B7' +\n    '\\u0300-\\u036F' +\n    '\\u203F-\\u2040';\n  const BLANK_NODE_LABEL =\n    '_:(' +\n      '(?:[' + PN_CHARS_U + '0-9])' +\n      '(?:(?:[' + PN_CHARS + '.])*(?:[' + PN_CHARS + ']))?' +\n    ')';\n  // Older simple regex: const IRI = '(?:<([^:]+:[^>]*)>)';\n  const UCHAR4 = '\\\\\\\\u[0-9A-Fa-f]{4}';\n  const UCHAR8 = '\\\\\\\\U[0-9A-Fa-f]{8}';\n  const IRI = '(?:<((?:' +\n    '[^\\u0000-\\u0020<>\"{}|^`\\\\\\\\]' + '|' +\n    UCHAR4 + '|' +\n    UCHAR8 +\n    ')*)>)';\n  const bnode = BLANK_NODE_LABEL;\n  const plain = '\"([^\"\\\\\\\\]*(?:\\\\\\\\.[^\"\\\\\\\\]*)*)\"';\n  const datatype = '(?:\\\\^\\\\^' + IRI + ')';\n  const language = '(?:@([a-zA-Z]+(?:-[a-zA-Z0-9]+)*))';\n  const literal = '(?:' + plain + '(?:' + datatype + '|' + language + ')?)';\n  const ws = '[ \\\\t]+';\n  const wso = '[ \\\\t]*';\n\n  // define quad part regexes\n  const subject = '(?:' + IRI + '|' + bnode + ')' + ws;\n  const property = IRI + ws;\n  const object = '(?:' + IRI + '|' + bnode + '|' + literal + ')' + wso;\n  const graphName = '(?:\\\\.|(?:(?:' + IRI + '|' + bnode + ')' + wso + '\\\\.))';\n\n  // end of line and empty regexes\n  REGEX.eoln = /(?:\\r\\n)|(?:\\n)|(?:\\r)/g;\n  REGEX.empty = new RegExp('^' + wso + '$');\n\n  // full quad regex\n  REGEX.quad = new RegExp(\n    '^' + wso + subject + property + object + graphName + wso + '$');\n})();\n\nmodule.exports = class NQuads {\n  /**\n   * Parses RDF in the form of N-Quads.\n   *\n   * @param {string} input - The N-Quads input to parse.\n   *\n   * @returns {Array} - An RDF dataset (an array of quads per\n   *   https://rdf.js.org/).\n   */\n  static parse(input) {\n    // build RDF dataset\n    const dataset = [];\n\n    const graphs = {};\n\n    // split N-Quad input into lines\n    const lines = input.split(REGEX.eoln);\n    let lineNumber = 0;\n    for(const line of lines) {\n      lineNumber++;\n\n      // skip empty lines\n      if(REGEX.empty.test(line)) {\n        continue;\n      }\n\n      // parse quad\n      const match = line.match(REGEX.quad);\n      if(match === null) {\n        throw new Error('N-Quads parse error on line ' + lineNumber + '.');\n      }\n\n      // create RDF quad\n      const quad = {subject: null, predicate: null, object: null, graph: null};\n\n      // get subject\n      if(match[1] !== undefined) {\n        quad.subject = {\n          termType: TYPE_NAMED_NODE,\n          value: _iriUnescape(match[1])\n        };\n      } else {\n        quad.subject = {\n          termType: TYPE_BLANK_NODE,\n          value: match[2]\n        };\n      }\n\n      // get predicate\n      quad.predicate = {\n        termType: TYPE_NAMED_NODE,\n        value: _iriUnescape(match[3])\n      };\n\n      // get object\n      if(match[4] !== undefined) {\n        quad.object = {\n          termType: TYPE_NAMED_NODE,\n          value: _iriUnescape(match[4])\n        };\n      } else if(match[5] !== undefined) {\n        quad.object = {\n          termType: TYPE_BLANK_NODE,\n          value: match[5]\n        };\n      } else {\n        quad.object = {\n          termType: TYPE_LITERAL,\n          value: undefined,\n          datatype: {\n            termType: TYPE_NAMED_NODE\n          }\n        };\n        if(match[7] !== undefined) {\n          quad.object.datatype.value = _iriUnescape(match[7]);\n        } else if(match[8] !== undefined) {\n          quad.object.datatype.value = RDF_LANGSTRING;\n          quad.object.language = match[8];\n        } else {\n          quad.object.datatype.value = XSD_STRING;\n        }\n        quad.object.value = _stringLiteralUnescape(match[6]);\n      }\n\n      // get graph\n      if(match[9] !== undefined) {\n        quad.graph = {\n          termType: TYPE_NAMED_NODE,\n          value: _iriUnescape(match[9])\n        };\n      } else if(match[10] !== undefined) {\n        quad.graph = {\n          termType: TYPE_BLANK_NODE,\n          value: match[10]\n        };\n      } else {\n        quad.graph = {\n          termType: TYPE_DEFAULT_GRAPH,\n          value: ''\n        };\n      }\n\n      // only add quad if it is unique in its graph\n      if(!(quad.graph.value in graphs)) {\n        graphs[quad.graph.value] = [quad];\n        dataset.push(quad);\n      } else {\n        let unique = true;\n        const quads = graphs[quad.graph.value];\n        for(const q of quads) {\n          if(_compareTriples(q, quad)) {\n            unique = false;\n            break;\n          }\n        }\n        if(unique) {\n          quads.push(quad);\n          dataset.push(quad);\n        }\n      }\n    }\n\n    return dataset;\n  }\n\n  /**\n   * Converts an RDF dataset to N-Quads.\n   *\n   * @param {Array} dataset - The Array of quads RDF dataset to convert.\n   *\n   * @returns {string} - The N-Quads string.\n   */\n  static serialize(dataset) {\n    const quads = [];\n    for(const quad of dataset) {\n      quads.push(NQuads.serializeQuad(quad));\n    }\n    return quads.sort().join('');\n  }\n\n  /**\n   * Converts RDF quad components to an N-Quad string (a single quad).\n   *\n   * @param {object} s - N-Quad subject component.\n   * @param {object} p - N-Quad predicate component.\n   * @param {object} o - N-Quad object component.\n   * @param {object} g - N-Quad graph component.\n   *\n   * @returns {string} - The N-Quad.\n   */\n  static serializeQuadComponents(s, p, o, g) {\n    let nquad = '';\n\n    // subject can only be NamedNode or BlankNode\n    if(s.termType === TYPE_NAMED_NODE) {\n      nquad += `<${_iriEscape(s.value)}>`;\n    } else {\n      nquad += `_:${s.value}`;\n    }\n\n    // predicate normally a NamedNode, can be a BlankNode in generalized RDF\n    if(p.termType === TYPE_NAMED_NODE) {\n      nquad += ` <${_iriEscape(p.value)}> `;\n    } else {\n      nquad += ` _:${p.value} `;\n    }\n\n    // object is NamedNode, BlankNode, or Literal\n    if(o.termType === TYPE_NAMED_NODE) {\n      nquad += `<${_iriEscape(o.value)}>`;\n    } else if(o.termType === TYPE_BLANK_NODE) {\n      nquad += `_:${o.value}`;\n    } else {\n      nquad += `\"${_stringLiteralEscape(o.value)}\"`;\n      if(o.datatype.value === RDF_LANGSTRING) {\n        if(o.language) {\n          nquad += `@${o.language}`;\n        }\n      } else if(o.datatype.value !== XSD_STRING) {\n        nquad += `^^<${_iriEscape(o.datatype.value)}>`;\n      }\n    }\n\n    // graph can only be NamedNode or BlankNode (or DefaultGraph, but that\n    // does not add to `nquad`)\n    if(g.termType === TYPE_NAMED_NODE) {\n      nquad += ` <${_iriEscape(g.value)}>`;\n    } else if(g.termType === TYPE_BLANK_NODE) {\n      nquad += ` _:${g.value}`;\n    }\n\n    nquad += ' .\\n';\n    return nquad;\n  }\n\n  /**\n   * Converts an RDF quad to an N-Quad string (a single quad).\n   *\n   * @param {object} quad - The RDF quad convert.\n   *\n   * @returns {string} - The N-Quad string.\n   */\n  static serializeQuad(quad) {\n    return NQuads.serializeQuadComponents(\n      quad.subject, quad.predicate, quad.object, quad.graph);\n  }\n};\n\n/**\n * Compares two RDF triples for equality.\n *\n * @param {object} t1 - The first triple.\n * @param {object} t2 - The second triple.\n *\n * @returns {boolean} - True if the triples are the same, false if not.\n */\nfunction _compareTriples(t1, t2) {\n  // compare subject and object types first as it is the quickest check\n  if(!(t1.subject.termType === t2.subject.termType &&\n    t1.object.termType === t2.object.termType)) {\n    return false;\n  }\n  // compare values\n  if(!(t1.subject.value === t2.subject.value &&\n    t1.predicate.value === t2.predicate.value &&\n    t1.object.value === t2.object.value)) {\n    return false;\n  }\n  if(t1.object.termType !== TYPE_LITERAL) {\n    // no `datatype` or `language` to check\n    return true;\n  }\n  return (\n    (t1.object.datatype.termType === t2.object.datatype.termType) &&\n    (t1.object.language === t2.object.language) &&\n    (t1.object.datatype.value === t2.object.datatype.value)\n  );\n}\n\nconst _stringLiteralEscapeRegex = /[\\u0000-\\u001F\\u007F\"\\\\]/g;\nconst _stringLiteralEscapeMap = [];\nfor(let n = 0; n <= 0x7f; ++n) {\n  if(_stringLiteralEscapeRegex.test(String.fromCharCode(n))) {\n    // default UCHAR mapping\n    _stringLiteralEscapeMap[n] =\n      '\\\\u' + n.toString(16).toUpperCase().padStart(4, '0');\n    // reset regex\n    _stringLiteralEscapeRegex.lastIndex = 0;\n  }\n}\n// special ECHAR mappings\n_stringLiteralEscapeMap['\\b'.codePointAt(0)] = '\\\\b';\n_stringLiteralEscapeMap['\\t'.codePointAt(0)] = '\\\\t';\n_stringLiteralEscapeMap['\\n'.codePointAt(0)] = '\\\\n';\n_stringLiteralEscapeMap['\\f'.codePointAt(0)] = '\\\\f';\n_stringLiteralEscapeMap['\\r'.codePointAt(0)] = '\\\\r';\n_stringLiteralEscapeMap['\"' .codePointAt(0)] = '\\\\\"';\n_stringLiteralEscapeMap['\\\\'.codePointAt(0)] = '\\\\\\\\';\n\n/**\n * Escape string to N-Quads literal.\n *\n * @param {string} s - String to escape.\n *\n * @returns {string} - Escaped N-Quads literal.\n */\nfunction _stringLiteralEscape(s) {\n  if(!_stringLiteralEscapeRegex.test(s)) {\n    return s;\n  }\n  return s.replace(_stringLiteralEscapeRegex, function(match) {\n    return _stringLiteralEscapeMap[match.codePointAt(0)];\n  });\n}\n\nconst _stringLiteralUnescapeRegex =\n  /(?:\\\\([btnfr\"'\\\\]))|(?:\\\\u([0-9A-Fa-f]{4}))|(?:\\\\U([0-9A-Fa-f]{8}))/g;\n\n/**\n * Unescape N-Quads literal to string.\n *\n * @param {string} s - String to unescape.\n *\n * @returns {string} - Unescaped N-Quads literal.\n */\nfunction _stringLiteralUnescape(s) {\n  if(!_stringLiteralUnescapeRegex.test(s)) {\n    return s;\n  }\n  return s.replace(_stringLiteralUnescapeRegex, function(match, code, u, U) {\n    if(code) {\n      switch(code) {\n        case 'b': return '\\b';\n        case 't': return '\\t';\n        case 'n': return '\\n';\n        case 'f': return '\\f';\n        case 'r': return '\\r';\n        case '\"': return '\"';\n        case '\\'': return '\\'';\n        case '\\\\': return '\\\\';\n      }\n    }\n    if(u) {\n      return String.fromCharCode(parseInt(u, 16));\n    }\n    if(U) {\n      return String.fromCodePoint(parseInt(U, 16));\n    }\n  });\n}\n\nconst _iriEscapeRegex = /[\\u0000-\\u0020<>\"{}|^`\\\\]/g;\nconst _iriEscapeRegexMap = [];\nfor(let n = 0; n <= 0x7f; ++n) {\n  if(_iriEscapeRegex.test(String.fromCharCode(n))) {\n    // UCHAR mapping\n    _iriEscapeRegexMap[n] =\n      '\\\\u' + n.toString(16).toUpperCase().padStart(4, '0');\n    // reset regex\n    _iriEscapeRegex.lastIndex = 0;\n  }\n}\n\n/**\n * Escape IRI to N-Quads IRI.\n *\n * @param {string} s - IRI to escape.\n *\n * @returns {string} - Escaped N-Quads IRI.\n */\nfunction _iriEscape(s) {\n  if(!_iriEscapeRegex.test(s)) {\n    return s;\n  }\n  return s.replace(_iriEscapeRegex, function(match) {\n    return _iriEscapeRegexMap[match.codePointAt(0)];\n  });\n}\n\nconst _iriUnescapeRegex =\n  /(?:\\\\u([0-9A-Fa-f]{4}))|(?:\\\\U([0-9A-Fa-f]{8}))/g;\n\n/**\n * Unescape N-Quads IRI to IRI.\n *\n * @param {string} s - IRI to unescape.\n *\n * @returns {string} - Unescaped N-Quads IRI.\n */\nfunction _iriUnescape(s) {\n  if(!_iriUnescapeRegex.test(s)) {\n    return s;\n  }\n  return s.replace(_iriUnescapeRegex, function(match, u, U) {\n    if(u) {\n      return String.fromCharCode(parseInt(u, 16));\n    }\n    if(U) {\n      return String.fromCodePoint(parseInt(U, 16));\n    }\n  });\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-canonize/lib/NQuads.js?");

/***/ }),

/***/ "./node_modules/rdf-canonize/lib/Permuter.js":
/*!***************************************************!*\
  !*** ./node_modules/rdf-canonize/lib/Permuter.js ***!
  \***************************************************/
/***/ ((module) => {

"use strict";
eval("/*!\n * Copyright (c) 2016-2022 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nmodule.exports = class Permuter {\n  /**\n   * A Permuter iterates over all possible permutations of the given array\n   * of elements.\n   *\n   * @param {Array} list - The array of elements to iterate over.\n   */\n  constructor(list) {\n    // original array\n    this.current = list.sort();\n    // indicates whether there are more permutations\n    this.done = false;\n    // directional info for permutation algorithm\n    this.dir = new Map();\n    for(let i = 0; i < list.length; ++i) {\n      this.dir.set(list[i], true);\n    }\n  }\n\n  /**\n   * Returns true if there is another permutation.\n   *\n   * @returns {boolean} - True if there is another permutation, false if not.\n   */\n  hasNext() {\n    return !this.done;\n  }\n\n  /**\n   * Gets the next permutation. Call hasNext() to ensure there is another one\n   * first.\n   *\n   * @returns {any} - The next permutation.\n   */\n  next() {\n    // copy current permutation to return it\n    const {current, dir} = this;\n    const rval = current.slice();\n\n    /* Calculate the next permutation using the Steinhaus-Johnson-Trotter\n     permutation algorithm. */\n\n    // get largest mobile element k\n    // (mobile: element is greater than the one it is looking at)\n    let k = null;\n    let pos = 0;\n    const length = current.length;\n    for(let i = 0; i < length; ++i) {\n      const element = current[i];\n      const left = dir.get(element);\n      if((k === null || element > k) &&\n        ((left && i > 0 && element > current[i - 1]) ||\n        (!left && i < (length - 1) && element > current[i + 1]))) {\n        k = element;\n        pos = i;\n      }\n    }\n\n    // no more permutations\n    if(k === null) {\n      this.done = true;\n    } else {\n      // swap k and the element it is looking at\n      const swap = dir.get(k) ? pos - 1 : pos + 1;\n      current[pos] = current[swap];\n      current[swap] = k;\n\n      // reverse the direction of all elements larger than k\n      for(const element of current) {\n        if(element > k) {\n          dir.set(element, !dir.get(element));\n        }\n      }\n    }\n\n    return rval;\n  }\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-canonize/lib/Permuter.js?");

/***/ }),

/***/ "./node_modules/rdf-canonize/lib/RDFC10Sync.js":
/*!*****************************************************!*\
  !*** ./node_modules/rdf-canonize/lib/RDFC10Sync.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Copyright (c) 2016-2023 Digital Bazaar, Inc. All rights reserved.\n */\n\n\nconst IdentifierIssuer = __webpack_require__(/*! ./IdentifierIssuer */ \"./node_modules/rdf-canonize/lib/IdentifierIssuer.js\");\n// FIXME: do not import; convert to requiring a\n// hash factory\nconst MessageDigest = __webpack_require__(/*! ./MessageDigest */ \"./node_modules/rdf-canonize/lib/MessageDigest-webcrypto.js\");\nconst Permuter = __webpack_require__(/*! ./Permuter */ \"./node_modules/rdf-canonize/lib/Permuter.js\");\nconst NQuads = __webpack_require__(/*! ./NQuads */ \"./node_modules/rdf-canonize/lib/NQuads.js\");\n\nmodule.exports = class RDFC10Sync {\n  constructor({\n    createMessageDigest = null,\n    messageDigestAlgorithm = 'sha256',\n    canonicalIdMap = new Map(),\n    maxWorkFactor = 1,\n    maxDeepIterations = -1,\n    timeout = 0\n  } = {}) {\n    this.name = 'RDFC-1.0';\n    this.blankNodeInfo = new Map();\n    this.canonicalIssuer = new IdentifierIssuer('c14n', canonicalIdMap);\n    this.createMessageDigest = createMessageDigest ||\n      (() => new MessageDigest(messageDigestAlgorithm));\n    this.maxWorkFactor = maxWorkFactor;\n    this.maxDeepIterations = maxDeepIterations;\n    this.remainingDeepIterations = 0;\n    this.timeout = timeout;\n    if(timeout > 0) {\n      this.startTime = Date.now();\n    }\n    this.quads = null;\n  }\n\n  // 4.4) Normalization Algorithm\n  main(dataset) {\n    this.quads = dataset;\n\n    // 1) Create the normalization state.\n    // 2) For every quad in input dataset:\n    for(const quad of dataset) {\n      // 2.1) For each blank node that occurs in the quad, add a reference\n      // to the quad using the blank node identifier in the blank node to\n      // quads map, creating a new entry if necessary.\n      this._addBlankNodeQuadInfo({quad, component: quad.subject});\n      this._addBlankNodeQuadInfo({quad, component: quad.object});\n      this._addBlankNodeQuadInfo({quad, component: quad.graph});\n    }\n\n    // 3) Create a list of non-normalized blank node identifiers\n    // non-normalized identifiers and populate it using the keys from the\n    // blank node to quads map.\n    // Note: We use a map here and it was generated during step 2.\n\n    // 4) `simple` flag is skipped -- loop is optimized away. This optimization\n    // is permitted because there was a typo in the hash first degree quads\n    // algorithm in the RDFC-1.0 spec that was implemented widely making it\n    // such that it could not be fixed; the result was that the loop only\n    // needs to be run once and the first degree quad hashes will never change.\n    // 5.1-5.2 are skipped; first degree quad hashes are generated just once\n    // for all non-normalized blank nodes.\n\n    // 5.3) For each blank node identifier identifier in non-normalized\n    // identifiers:\n    const hashToBlankNodes = new Map();\n    const nonNormalized = [...this.blankNodeInfo.keys()];\n    for(const id of nonNormalized) {\n      // steps 5.3.1 and 5.3.2:\n      this._hashAndTrackBlankNode({id, hashToBlankNodes});\n    }\n\n    // 5.4) For each hash to identifier list mapping in hash to blank\n    // nodes map, lexicographically-sorted by hash:\n    const hashes = [...hashToBlankNodes.keys()].sort();\n    // optimize away second sort, gather non-unique hashes in order as we go\n    const nonUnique = [];\n    for(const hash of hashes) {\n      // 5.4.1) If the length of identifier list is greater than 1,\n      // continue to the next mapping.\n      const idList = hashToBlankNodes.get(hash);\n      if(idList.length > 1) {\n        nonUnique.push(idList);\n        continue;\n      }\n\n      // 5.4.2) Use the Issue Identifier algorithm, passing canonical\n      // issuer and the single blank node identifier in identifier\n      // list, identifier, to issue a canonical replacement identifier\n      // for identifier.\n      const id = idList[0];\n      this.canonicalIssuer.getId(id);\n\n      // Note: These steps are skipped, optimized away since the loop\n      // only needs to be run once.\n      // 5.4.3) Remove identifier from non-normalized identifiers.\n      // 5.4.4) Remove hash from the hash to blank nodes map.\n      // 5.4.5) Set simple to true.\n    }\n\n    if(this.maxDeepIterations < 0) {\n      // calculate maxDeepIterations if not explicit\n      if(this.maxWorkFactor === 0) {\n        this.maxDeepIterations = 0;\n      } else if(this.maxWorkFactor === Infinity) {\n        this.maxDeepIterations = Infinity;\n      } else {\n        const nonUniqueCount =\n          nonUnique.reduce((count, v) => count + v.length, 0);\n        this.maxDeepIterations = nonUniqueCount ** this.maxWorkFactor;\n      }\n    }\n    // handle any large inputs as Infinity\n    if(this.maxDeepIterations > Number.MAX_SAFE_INTEGER) {\n      this.maxDeepIterations = Infinity;\n    }\n    this.remainingDeepIterations = this.maxDeepIterations;\n\n    // 6) For each hash to identifier list mapping in hash to blank nodes map,\n    // lexicographically-sorted by hash:\n    // Note: sort optimized away, use `nonUnique`.\n    for(const idList of nonUnique) {\n      // 6.1) Create hash path list where each item will be a result of\n      // running the Hash N-Degree Quads algorithm.\n      const hashPathList = [];\n\n      // 6.2) For each blank node identifier identifier in identifier list:\n      for(const id of idList) {\n        // 6.2.1) If a canonical identifier has already been issued for\n        // identifier, continue to the next identifier.\n        if(this.canonicalIssuer.hasId(id)) {\n          continue;\n        }\n\n        // 6.2.2) Create temporary issuer, an identifier issuer\n        // initialized with the prefix _:b.\n        const issuer = new IdentifierIssuer('b');\n\n        // 6.2.3) Use the Issue Identifier algorithm, passing temporary\n        // issuer and identifier, to issue a new temporary blank node\n        // identifier for identifier.\n        issuer.getId(id);\n\n        // 6.2.4) Run the Hash N-Degree Quads algorithm, passing\n        // temporary issuer, and append the result to the hash path list.\n        const result = this.hashNDegreeQuads(id, issuer);\n        hashPathList.push(result);\n      }\n\n      // 6.3) For each result in the hash path list,\n      // lexicographically-sorted by the hash in result:\n      hashPathList.sort(_stringHashCompare);\n      for(const result of hashPathList) {\n        // 6.3.1) For each blank node identifier, existing identifier,\n        // that was issued a temporary identifier by identifier issuer\n        // in result, issue a canonical identifier, in the same order,\n        // using the Issue Identifier algorithm, passing canonical\n        // issuer and existing identifier.\n        const oldIds = result.issuer.getOldIds();\n        for(const id of oldIds) {\n          this.canonicalIssuer.getId(id);\n        }\n      }\n    }\n\n    /* Note: At this point all blank nodes in the set of RDF quads have been\n    assigned canonical identifiers, which have been stored in the canonical\n    issuer. Here each quad is updated by assigning each of its blank nodes\n    its new identifier. */\n\n    // 7) For each quad, quad, in input dataset:\n    const normalized = [];\n    for(const quad of this.quads) {\n      // 7.1) Create a copy, quad copy, of quad and replace any existing\n      // blank node identifiers using the canonical identifiers\n      // previously issued by canonical issuer.\n      // Note: We optimize away the copy here.\n      const nQuad = NQuads.serializeQuadComponents(\n        this._componentWithCanonicalId(quad.subject),\n        quad.predicate,\n        this._componentWithCanonicalId(quad.object),\n        this._componentWithCanonicalId(quad.graph)\n      );\n      // 7.2) Add quad copy to the normalized dataset.\n      normalized.push(nQuad);\n    }\n\n    // sort normalized output\n    normalized.sort();\n\n    // 8) Return the normalized dataset.\n    return normalized.join('');\n  }\n\n  // 4.6) Hash First Degree Quads\n  hashFirstDegreeQuads(id) {\n    // 1) Initialize nquads to an empty list. It will be used to store quads in\n    // N-Quads format.\n    const nquads = [];\n\n    // 2) Get the list of quads `quads` associated with the reference blank node\n    // identifier in the blank node to quads map.\n    const info = this.blankNodeInfo.get(id);\n    const quads = info.quads;\n\n    // 3) For each quad `quad` in `quads`:\n    for(const quad of quads) {\n      // 3.1) Serialize the quad in N-Quads format with the following special\n      // rule:\n\n      // 3.1.1) If any component in quad is an blank node, then serialize it\n      // using a special identifier as follows:\n      // 3.1.2) If the blank node's existing blank node identifier matches\n      // the reference blank node identifier then use the blank node\n      // identifier _:a, otherwise, use the blank node identifier _:z.\n      nquads.push(NQuads.serializeQuadComponents(\n        this.modifyFirstDegreeComponent(id, quad.subject, 'subject'),\n        quad.predicate,\n        this.modifyFirstDegreeComponent(id, quad.object, 'object'),\n        this.modifyFirstDegreeComponent(id, quad.graph, 'graph')\n      ));\n    }\n\n    // 4) Sort nquads in lexicographical order.\n    nquads.sort();\n\n    // 5) Return the hash that results from passing the sorted, joined nquads\n    // through the hash algorithm.\n    const md = this.createMessageDigest();\n    for(const nquad of nquads) {\n      md.update(nquad);\n    }\n    info.hash = md.digest();\n    return info.hash;\n  }\n\n  // 4.7) Hash Related Blank Node\n  hashRelatedBlankNode(related, quad, issuer, position) {\n    // 1) Initialize a string input to the value of position.\n    // Note: We use a hash object instead.\n    const md = this.createMessageDigest();\n    md.update(position);\n\n    // 2) If position is not g, append <, the value of the predicate in quad,\n    // and > to input.\n    if(position !== 'g') {\n      md.update(this.getRelatedPredicate(quad));\n    }\n\n    // 3) Set the identifier to use for related, preferring first the canonical\n    // identifier for related if issued, second the identifier issued by issuer\n    // if issued, and last, if necessary, the result of the Hash First Degree\n    // Quads algorithm, passing related.\n    let id;\n    if(this.canonicalIssuer.hasId(related)) {\n      id = '_:' + this.canonicalIssuer.getId(related);\n    } else if(issuer.hasId(related)) {\n      id = '_:' + issuer.getId(related);\n    } else {\n      id = this.blankNodeInfo.get(related).hash;\n    }\n\n    // 4) Append identifier to input.\n    md.update(id);\n\n    // 5) Return the hash that results from passing input through the hash\n    // algorithm.\n    return md.digest();\n  }\n\n  // 4.8) Hash N-Degree Quads\n  hashNDegreeQuads(id, issuer) {\n    if(this.remainingDeepIterations === 0) {\n      throw new Error(\n        `Maximum deep iterations exceeded (${this.maxDeepIterations}).`);\n    }\n    this.remainingDeepIterations--;\n\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    // Note: 2) and 3) handled within `createHashToRelated`\n    const md = this.createMessageDigest();\n    const hashToRelated = this.createHashToRelated(id, issuer);\n\n    // 4) Create an empty string, data to hash.\n    // Note: We created a hash object `md` above instead.\n\n    // 5) For each related hash to blank node list mapping in hash to related\n    // blank nodes map, sorted lexicographically by related hash:\n    const hashes = [...hashToRelated.keys()].sort();\n    for(const hash of hashes) {\n      // 5.1) Append the related hash to the data to hash.\n      md.update(hash);\n\n      // 5.2) Create a string chosen path.\n      let chosenPath = '';\n\n      // 5.3) Create an unset chosen issuer variable.\n      let chosenIssuer;\n\n      // 5.4) For each permutation of blank node list:\n      const permuter = new Permuter(hashToRelated.get(hash));\n      let i = 0;\n      while(permuter.hasNext()) {\n        const permutation = permuter.next();\n        // Note: batch permutations 3 at a time\n        if(++i % 3 === 0) {\n          if(this.timeout > 0 && Date.now() - this.startTime > this.timeout) {\n            throw new Error('Canonize timeout.');\n          }\n        }\n\n        // 5.4.1) Create a copy of issuer, issuer copy.\n        let issuerCopy = issuer.clone();\n\n        // 5.4.2) Create a string path.\n        let path = '';\n\n        // 5.4.3) Create a recursion list, to store blank node identifiers\n        // that must be recursively processed by this algorithm.\n        const recursionList = [];\n\n        // 5.4.4) For each related in permutation:\n        let nextPermutation = false;\n        for(const related of permutation) {\n          // 5.4.4.1) If a canonical identifier has been issued for\n          // related, append it to path.\n          if(this.canonicalIssuer.hasId(related)) {\n            path += '_:' + this.canonicalIssuer.getId(related);\n          } else {\n            // 5.4.4.2) Otherwise:\n            // 5.4.4.2.1) If issuer copy has not issued an identifier for\n            // related, append related to recursion list.\n            if(!issuerCopy.hasId(related)) {\n              recursionList.push(related);\n            }\n            // 5.4.4.2.2) Use the Issue Identifier algorithm, passing\n            // issuer copy and related and append the result to path.\n            path += '_:' + issuerCopy.getId(related);\n          }\n\n          // 5.4.4.3) If chosen path is not empty and the length of path\n          // is greater than or equal to the length of chosen path and\n          // path is lexicographically greater than chosen path, then\n          // skip to the next permutation.\n          // Note: Comparing path length to chosen path length can be optimized\n          // away; only compare lexicographically.\n          if(chosenPath.length !== 0 && path > chosenPath) {\n            nextPermutation = true;\n            break;\n          }\n        }\n\n        if(nextPermutation) {\n          continue;\n        }\n\n        // 5.4.5) For each related in recursion list:\n        for(const related of recursionList) {\n          // 5.4.5.1) Set result to the result of recursively executing\n          // the Hash N-Degree Quads algorithm, passing related for\n          // identifier and issuer copy for path identifier issuer.\n          const result = this.hashNDegreeQuads(related, issuerCopy);\n\n          // 5.4.5.2) Use the Issue Identifier algorithm, passing issuer\n          // copy and related and append the result to path.\n          path += '_:' + issuerCopy.getId(related);\n\n          // 5.4.5.3) Append <, the hash in result, and > to path.\n          path += `<${result.hash}>`;\n\n          // 5.4.5.4) Set issuer copy to the identifier issuer in\n          // result.\n          issuerCopy = result.issuer;\n\n          // 5.4.5.5) If chosen path is not empty and the length of path\n          // is greater than or equal to the length of chosen path and\n          // path is lexicographically greater than chosen path, then\n          // skip to the next permutation.\n          // Note: Comparing path length to chosen path length can be optimized\n          // away; only compare lexicographically.\n          if(chosenPath.length !== 0 && path > chosenPath) {\n            nextPermutation = true;\n            break;\n          }\n        }\n\n        if(nextPermutation) {\n          continue;\n        }\n\n        // 5.4.6) If chosen path is empty or path is lexicographically\n        // less than chosen path, set chosen path to path and chosen\n        // issuer to issuer copy.\n        if(chosenPath.length === 0 || path < chosenPath) {\n          chosenPath = path;\n          chosenIssuer = issuerCopy;\n        }\n      }\n\n      // 5.5) Append chosen path to data to hash.\n      md.update(chosenPath);\n\n      // 5.6) Replace issuer, by reference, with chosen issuer.\n      issuer = chosenIssuer;\n    }\n\n    // 6) Return issuer and the hash that results from passing data to hash\n    // through the hash algorithm.\n    return {hash: md.digest(), issuer};\n  }\n\n  // helper for modifying component during Hash First Degree Quads\n  modifyFirstDegreeComponent(id, component) {\n    if(component.termType !== 'BlankNode') {\n      return component;\n    }\n    /* Note: A mistake in the RDFC-1.0 spec that made its way into\n    implementations (and therefore must stay to avoid interop breakage)\n    resulted in an assigned canonical ID, if available for\n    `component.value`, not being used in place of `_:a`/`_:z`, so\n    we don't use it here. */\n    return {\n      termType: 'BlankNode',\n      value: component.value === id ? 'a' : 'z'\n    };\n  }\n\n  // helper for getting a related predicate\n  getRelatedPredicate(quad) {\n    return `<${quad.predicate.value}>`;\n  }\n\n  // helper for creating hash to related blank nodes map\n  createHashToRelated(id, issuer) {\n    // 1) Create a hash to related blank nodes map for storing hashes that\n    // identify related blank nodes.\n    const hashToRelated = new Map();\n\n    // 2) Get a reference, quads, to the list of quads in the blank node to\n    // quads map for the key identifier.\n    const quads = this.blankNodeInfo.get(id).quads;\n\n    // 3) For each quad in quads:\n    for(const quad of quads) {\n      // 3.1) For each component in quad, if component is the subject, object,\n      // or graph name and it is a blank node that is not identified by\n      // identifier:\n      // steps 3.1.1 and 3.1.2 occur in helpers:\n      this._addRelatedBlankNodeHash({\n        quad, component: quad.subject, position: 's',\n        id, issuer, hashToRelated\n      });\n      this._addRelatedBlankNodeHash({\n        quad, component: quad.object, position: 'o',\n        id, issuer, hashToRelated\n      });\n      this._addRelatedBlankNodeHash({\n        quad, component: quad.graph, position: 'g',\n        id, issuer, hashToRelated\n      });\n    }\n\n    return hashToRelated;\n  }\n\n  _hashAndTrackBlankNode({id, hashToBlankNodes}) {\n    // 5.3.1) Create a hash, hash, according to the Hash First Degree\n    // Quads algorithm.\n    const hash = this.hashFirstDegreeQuads(id);\n\n    // 5.3.2) Add hash and identifier to hash to blank nodes map,\n    // creating a new entry if necessary.\n    const idList = hashToBlankNodes.get(hash);\n    if(!idList) {\n      hashToBlankNodes.set(hash, [id]);\n    } else {\n      idList.push(id);\n    }\n  }\n\n  _addBlankNodeQuadInfo({quad, component}) {\n    if(component.termType !== 'BlankNode') {\n      return;\n    }\n    const id = component.value;\n    const info = this.blankNodeInfo.get(id);\n    if(info) {\n      info.quads.add(quad);\n    } else {\n      this.blankNodeInfo.set(id, {quads: new Set([quad]), hash: null});\n    }\n  }\n\n  _addRelatedBlankNodeHash(\n    {quad, component, position, id, issuer, hashToRelated}) {\n    if(!(component.termType === 'BlankNode' && component.value !== id)) {\n      return;\n    }\n    // 3.1.1) Set hash to the result of the Hash Related Blank Node\n    // algorithm, passing the blank node identifier for component as\n    // related, quad, path identifier issuer as issuer, and position as\n    // either s, o, or g based on whether component is a subject, object,\n    // graph name, respectively.\n    const related = component.value;\n    const hash = this.hashRelatedBlankNode(\n      related, quad, issuer, position);\n\n    // 3.1.2) Add a mapping of hash to the blank node identifier for\n    // component to hash to related blank nodes map, adding an entry as\n    // necessary.\n    const entries = hashToRelated.get(hash);\n    if(entries) {\n      entries.push(related);\n    } else {\n      hashToRelated.set(hash, [related]);\n    }\n  }\n\n  // canonical ids for 7.1\n  _componentWithCanonicalId(component) {\n    if(component.termType === 'BlankNode' &&\n      !component.value.startsWith(this.canonicalIssuer.prefix)) {\n      // create new BlankNode\n      return {\n        termType: 'BlankNode',\n        value: this.canonicalIssuer.getId(component.value)\n      };\n    }\n    return component;\n  }\n};\n\nfunction _stringHashCompare(a, b) {\n  return a.hash < b.hash ? -1 : a.hash > b.hash ? 1 : 0;\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-canonize/lib/RDFC10Sync.js?");

/***/ }),

/***/ "./node_modules/rdf-canonize/lib/platform-browser.js":
/*!***********************************************************!*\
  !*** ./node_modules/rdf-canonize/lib/platform-browser.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("/*!\n * Copyright (c) 2023 Digital Bazaar, Inc. All rights reserved.\n */\n\n\n__webpack_require__(/*! setimmediate */ \"./node_modules/setimmediate/setImmediate.js\");\n\nexports.setImmediate = setImmediate;\n\n// WebCrypto\nexports.crypto = globalThis.crypto;\n\n// precompute byte to hex table\nconst byteToHex = [];\nfor(let n = 0; n <= 0xff; ++n) {\n  byteToHex.push(n.toString(16).padStart(2, '0'));\n}\n\nexports.bufferToHex = function bufferToHex(buffer) {\n  let hex = '';\n  const bytes = new Uint8Array(buffer);\n  for(let i = 0; i < bytes.length; ++i) {\n    hex += byteToHex[bytes[i]];\n  }\n  return hex;\n};\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-canonize/lib/platform-browser.js?");

/***/ }),

/***/ "./node_modules/rdf-data-factory/index.js":
/*!************************************************!*\
  !*** ./node_modules/rdf-data-factory/index.js ***!
  \************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n__exportStar(__webpack_require__(/*! ./lib/BlankNode */ \"./node_modules/rdf-data-factory/lib/BlankNode.js\"), exports);\n__exportStar(__webpack_require__(/*! ./lib/DataFactory */ \"./node_modules/rdf-data-factory/lib/DataFactory.js\"), exports);\n__exportStar(__webpack_require__(/*! ./lib/DefaultGraph */ \"./node_modules/rdf-data-factory/lib/DefaultGraph.js\"), exports);\n__exportStar(__webpack_require__(/*! ./lib/Literal */ \"./node_modules/rdf-data-factory/lib/Literal.js\"), exports);\n__exportStar(__webpack_require__(/*! ./lib/NamedNode */ \"./node_modules/rdf-data-factory/lib/NamedNode.js\"), exports);\n__exportStar(__webpack_require__(/*! ./lib/Quad */ \"./node_modules/rdf-data-factory/lib/Quad.js\"), exports);\n__exportStar(__webpack_require__(/*! ./lib/Variable */ \"./node_modules/rdf-data-factory/lib/Variable.js\"), exports);\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-data-factory/index.js?");

/***/ }),

/***/ "./node_modules/rdf-data-factory/lib/BlankNode.js":
/*!********************************************************!*\
  !*** ./node_modules/rdf-data-factory/lib/BlankNode.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BlankNode = void 0;\n/**\n * A term that represents an RDF blank node with a label.\n */\nclass BlankNode {\n    constructor(value) {\n        this.termType = 'BlankNode';\n        this.value = value;\n    }\n    equals(other) {\n        return !!other && other.termType === 'BlankNode' && other.value === this.value;\n    }\n}\nexports.BlankNode = BlankNode;\n//# sourceMappingURL=BlankNode.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-data-factory/lib/BlankNode.js?");

/***/ }),

/***/ "./node_modules/rdf-data-factory/lib/DataFactory.js":
/*!**********************************************************!*\
  !*** ./node_modules/rdf-data-factory/lib/DataFactory.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DataFactory = void 0;\nconst BlankNode_1 = __webpack_require__(/*! ./BlankNode */ \"./node_modules/rdf-data-factory/lib/BlankNode.js\");\nconst DefaultGraph_1 = __webpack_require__(/*! ./DefaultGraph */ \"./node_modules/rdf-data-factory/lib/DefaultGraph.js\");\nconst Literal_1 = __webpack_require__(/*! ./Literal */ \"./node_modules/rdf-data-factory/lib/Literal.js\");\nconst NamedNode_1 = __webpack_require__(/*! ./NamedNode */ \"./node_modules/rdf-data-factory/lib/NamedNode.js\");\nconst Quad_1 = __webpack_require__(/*! ./Quad */ \"./node_modules/rdf-data-factory/lib/Quad.js\");\nconst Variable_1 = __webpack_require__(/*! ./Variable */ \"./node_modules/rdf-data-factory/lib/Variable.js\");\nlet dataFactoryCounter = 0;\n/**\n * A factory for instantiating RDF terms and quads.\n */\nclass DataFactory {\n    constructor(options) {\n        this.blankNodeCounter = 0;\n        options = options || {};\n        this.blankNodePrefix = options.blankNodePrefix || `df_${dataFactoryCounter++}_`;\n    }\n    /**\n     * @param value The IRI for the named node.\n     * @return A new instance of NamedNode.\n     * @see NamedNode\n     */\n    namedNode(value) {\n        return new NamedNode_1.NamedNode(value);\n    }\n    /**\n     * @param value The optional blank node identifier.\n     * @return A new instance of BlankNode.\n     *         If the `value` parameter is undefined a new identifier\n     *         for the blank node is generated for each call.\n     * @see BlankNode\n     */\n    blankNode(value) {\n        return new BlankNode_1.BlankNode(value || `${this.blankNodePrefix}${this.blankNodeCounter++}`);\n    }\n    /**\n     * @param value              The literal value.\n     * @param languageOrDatatype The optional language or datatype.\n     *                           If `languageOrDatatype` is a NamedNode,\n     *                           then it is used for the value of `NamedNode.datatype`.\n     *                           Otherwise `languageOrDatatype` is used for the value\n     *                           of `NamedNode.language`.\n     * @return A new instance of Literal.\n     * @see Literal\n     */\n    literal(value, languageOrDatatype) {\n        return new Literal_1.Literal(value, languageOrDatatype);\n    }\n    /**\n     * This method is optional.\n     * @param value The variable name\n     * @return A new instance of Variable.\n     * @see Variable\n     */\n    variable(value) {\n        return new Variable_1.Variable(value);\n    }\n    /**\n     * @return An instance of DefaultGraph.\n     */\n    defaultGraph() {\n        return DefaultGraph_1.DefaultGraph.INSTANCE;\n    }\n    /**\n     * @param subject   The quad subject term.\n     * @param predicate The quad predicate term.\n     * @param object    The quad object term.\n     * @param graph     The quad graph term.\n     * @return A new instance of Quad.\n     * @see Quad\n     */\n    quad(subject, predicate, object, graph) {\n        return new Quad_1.Quad(subject, predicate, object, graph || this.defaultGraph());\n    }\n    /**\n     * Create a deep copy of the given term using this data factory.\n     * @param original An RDF term.\n     * @return A deep copy of the given term.\n     */\n    fromTerm(original) {\n        // TODO: remove nasty any casts when this TS bug has been fixed:\n        //  https://github.com/microsoft/TypeScript/issues/26933\n        switch (original.termType) {\n            case 'NamedNode':\n                return this.namedNode(original.value);\n            case 'BlankNode':\n                return this.blankNode(original.value);\n            case 'Literal':\n                if (original.language) {\n                    return this.literal(original.value, original.language);\n                }\n                if (!original.datatype.equals(Literal_1.Literal.XSD_STRING)) {\n                    return this.literal(original.value, this.fromTerm(original.datatype));\n                }\n                return this.literal(original.value);\n            case 'Variable':\n                return this.variable(original.value);\n            case 'DefaultGraph':\n                return this.defaultGraph();\n            case 'Quad':\n                return this.quad(this.fromTerm(original.subject), this.fromTerm(original.predicate), this.fromTerm(original.object), this.fromTerm(original.graph));\n        }\n    }\n    /**\n     * Create a deep copy of the given quad using this data factory.\n     * @param original An RDF quad.\n     * @return A deep copy of the given quad.\n     */\n    fromQuad(original) {\n        return this.fromTerm(original);\n    }\n    /**\n     * Reset the internal blank node counter.\n     */\n    resetBlankNodeCounter() {\n        this.blankNodeCounter = 0;\n    }\n}\nexports.DataFactory = DataFactory;\n//# sourceMappingURL=DataFactory.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-data-factory/lib/DataFactory.js?");

/***/ }),

/***/ "./node_modules/rdf-data-factory/lib/DefaultGraph.js":
/*!***********************************************************!*\
  !*** ./node_modules/rdf-data-factory/lib/DefaultGraph.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DefaultGraph = void 0;\n/**\n * A singleton term instance that represents the default graph.\n * It's only allowed to assign a DefaultGraph to the .graph property of a Quad.\n */\nclass DefaultGraph {\n    constructor() {\n        this.termType = 'DefaultGraph';\n        this.value = '';\n        // Private constructor\n    }\n    equals(other) {\n        return !!other && other.termType === 'DefaultGraph';\n    }\n}\nexports.DefaultGraph = DefaultGraph;\nDefaultGraph.INSTANCE = new DefaultGraph();\n//# sourceMappingURL=DefaultGraph.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-data-factory/lib/DefaultGraph.js?");

/***/ }),

/***/ "./node_modules/rdf-data-factory/lib/Literal.js":
/*!******************************************************!*\
  !*** ./node_modules/rdf-data-factory/lib/Literal.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Literal = void 0;\nconst NamedNode_1 = __webpack_require__(/*! ./NamedNode */ \"./node_modules/rdf-data-factory/lib/NamedNode.js\");\n/**\n * A term that represents an RDF literal, containing a string with an optional language tag or datatype.\n */\nclass Literal {\n    constructor(value, languageOrDatatype) {\n        this.termType = 'Literal';\n        this.value = value;\n        if (typeof languageOrDatatype === 'string') {\n            this.language = languageOrDatatype;\n            this.datatype = Literal.RDF_LANGUAGE_STRING;\n        }\n        else if (languageOrDatatype) {\n            this.language = '';\n            this.datatype = languageOrDatatype;\n        }\n        else {\n            this.language = '';\n            this.datatype = Literal.XSD_STRING;\n        }\n    }\n    equals(other) {\n        return !!other && other.termType === 'Literal' && other.value === this.value &&\n            other.language === this.language && this.datatype.equals(other.datatype);\n    }\n}\nexports.Literal = Literal;\nLiteral.RDF_LANGUAGE_STRING = new NamedNode_1.NamedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#langString');\nLiteral.XSD_STRING = new NamedNode_1.NamedNode('http://www.w3.org/2001/XMLSchema#string');\n//# sourceMappingURL=Literal.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-data-factory/lib/Literal.js?");

/***/ }),

/***/ "./node_modules/rdf-data-factory/lib/NamedNode.js":
/*!********************************************************!*\
  !*** ./node_modules/rdf-data-factory/lib/NamedNode.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.NamedNode = void 0;\n/**\n * A term that contains an IRI.\n */\nclass NamedNode {\n    constructor(value) {\n        this.termType = 'NamedNode';\n        this.value = value;\n    }\n    equals(other) {\n        return !!other && other.termType === 'NamedNode' && other.value === this.value;\n    }\n}\nexports.NamedNode = NamedNode;\n//# sourceMappingURL=NamedNode.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-data-factory/lib/NamedNode.js?");

/***/ }),

/***/ "./node_modules/rdf-data-factory/lib/Quad.js":
/*!***************************************************!*\
  !*** ./node_modules/rdf-data-factory/lib/Quad.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Quad = void 0;\n/**\n * An instance of DefaultGraph represents the default graph.\n * It's only allowed to assign a DefaultGraph to the .graph property of a Quad.\n */\nclass Quad {\n    constructor(subject, predicate, object, graph) {\n        this.termType = 'Quad';\n        this.value = '';\n        this.subject = subject;\n        this.predicate = predicate;\n        this.object = object;\n        this.graph = graph;\n    }\n    equals(other) {\n        // `|| !other.termType` is for backwards-compatibility with old factories without RDF* support.\n        return !!other && (other.termType === 'Quad' || !other.termType) &&\n            this.subject.equals(other.subject) &&\n            this.predicate.equals(other.predicate) &&\n            this.object.equals(other.object) &&\n            this.graph.equals(other.graph);\n    }\n}\nexports.Quad = Quad;\n//# sourceMappingURL=Quad.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-data-factory/lib/Quad.js?");

/***/ }),

/***/ "./node_modules/rdf-data-factory/lib/Variable.js":
/*!*******************************************************!*\
  !*** ./node_modules/rdf-data-factory/lib/Variable.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Variable = void 0;\n/**\n * A term that represents a variable.\n */\nclass Variable {\n    constructor(value) {\n        this.termType = 'Variable';\n        this.value = value;\n    }\n    equals(other) {\n        return !!other && other.termType === 'Variable' && other.value === this.value;\n    }\n}\nexports.Variable = Variable;\n//# sourceMappingURL=Variable.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-data-factory/lib/Variable.js?");

/***/ }),

/***/ "./node_modules/rdfxml-streaming-parser/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/rdfxml-streaming-parser/index.js ***!
  \*******************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n__exportStar(__webpack_require__(/*! ./lib/RdfXmlParser */ \"./node_modules/rdfxml-streaming-parser/lib/RdfXmlParser.js\"), exports);\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdfxml-streaming-parser/index.js?");

/***/ }),

/***/ "./node_modules/rdfxml-streaming-parser/lib/ParseError.js":
/*!****************************************************************!*\
  !*** ./node_modules/rdfxml-streaming-parser/lib/ParseError.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ParseError = void 0;\n/**\n * An error that includes line and column in the error message.\n */\nclass ParseError extends Error {\n    constructor(parser, message) {\n        const saxParser = parser.saxParser;\n        super(parser.trackPosition ? `Line ${saxParser.line} column ${saxParser.column + 1}: ${message}` : message);\n    }\n}\nexports.ParseError = ParseError;\n//# sourceMappingURL=ParseError.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdfxml-streaming-parser/lib/ParseError.js?");

/***/ }),

/***/ "./node_modules/rdfxml-streaming-parser/lib/RdfXmlParser.js":
/*!******************************************************************!*\
  !*** ./node_modules/rdfxml-streaming-parser/lib/RdfXmlParser.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ParseType = exports.RdfXmlParser = void 0;\nconst relative_to_absolute_iri_1 = __webpack_require__(/*! relative-to-absolute-iri */ \"./node_modules/relative-to-absolute-iri/index.js\");\nconst saxes_1 = __webpack_require__(/*! @rubensworks/saxes */ \"./node_modules/@rubensworks/saxes/saxes.js\");\nconst readable_stream_1 = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\nconst ParseError_1 = __webpack_require__(/*! ./ParseError */ \"./node_modules/rdfxml-streaming-parser/lib/ParseError.js\");\nconst rdf_data_factory_1 = __webpack_require__(/*! rdf-data-factory */ \"./node_modules/rdf-data-factory/index.js\");\nconst validate_iri_1 = __webpack_require__(/*! validate-iri */ \"./node_modules/validate-iri/index.js\");\nclass RdfXmlParser extends readable_stream_1.Transform {\n    constructor(args) {\n        super({ readableObjectMode: true });\n        this.activeTagStack = [];\n        this.nodeIds = {};\n        if (args) {\n            Object.assign(this, args);\n            this.options = args;\n        }\n        if (!this.dataFactory) {\n            this.dataFactory = new rdf_data_factory_1.DataFactory();\n        }\n        if (!this.baseIRI) {\n            this.baseIRI = '';\n        }\n        if (!this.defaultGraph) {\n            this.defaultGraph = this.dataFactory.defaultGraph();\n        }\n        if (this.validateUri !== false) {\n            this.validateUri = true;\n        }\n        if (!this.iriValidationStrategy) {\n            this.iriValidationStrategy = this.validateUri ? validate_iri_1.IriValidationStrategy.Pragmatic : validate_iri_1.IriValidationStrategy.None;\n        }\n        this.saxParser = new saxes_1.SaxesParser({ xmlns: true, position: this.trackPosition });\n        this.attachSaxListeners();\n    }\n    /**\n     * Parses the given text stream into a quad stream.\n     * @param {NodeJS.EventEmitter} stream A text stream.\n     * @return {RDF.Stream} A quad stream.\n     */\n    import(stream) {\n        const output = new readable_stream_1.PassThrough({ readableObjectMode: true });\n        stream.on('error', (error) => parsed.emit('error', error));\n        stream.on('data', (data) => output.push(data));\n        stream.on('end', () => output.push(null));\n        const parsed = output.pipe(new RdfXmlParser(this.options));\n        return parsed;\n    }\n    _transform(chunk, encoding, callback) {\n        try {\n            this.saxParser.write(chunk);\n        }\n        catch (e) {\n            return callback(e);\n        }\n        callback();\n    }\n    /**\n     * Create a new parse error instance.\n     * @param {string} message An error message.\n     * @return {Error} An error instance.\n     */\n    newParseError(message) {\n        return new ParseError_1.ParseError(this, message);\n    }\n    /**\n     * Convert the given value to a IRI by taking into account the baseIRI.\n     *\n     * This will follow the RDF/XML spec for converting values with baseIRIs to a IRI.\n     *\n     * @param {string} value The value to convert to an IRI.\n     * @param {IActiveTag} activeTag The active tag.\n     * @return {NamedNode} an IRI.\n     */\n    valueToUri(value, activeTag) {\n        return this.uriToNamedNode((0, relative_to_absolute_iri_1.resolve)(value, activeTag.baseIRI));\n    }\n    /**\n     * Convert the given value URI string to a named node.\n     *\n     * This throw an error if the URI is invalid.\n     *\n     * @param {string} uri A URI string.\n     * @return {NamedNode} a named node.\n     */\n    uriToNamedNode(uri) {\n        // Validate URI\n        const uriValidationResult = (0, validate_iri_1.validateIri)(uri, this.iriValidationStrategy);\n        if (uriValidationResult instanceof Error) {\n            throw this.newParseError(uriValidationResult.message);\n        }\n        return this.dataFactory.namedNode(uri);\n    }\n    /**\n     * Validate the given value as an NCName: https://www.w3.org/TR/xml-names/#NT-NCName\n     * If it is invalid, an error will thrown emitted.\n     * @param {string} value A value.\n     */\n    validateNcname(value) {\n        // Validate term as an NCName: https://www.w3.org/TR/xml-names/#NT-NCName\n        if (!RdfXmlParser.NCNAME_MATCHER.test(value)) {\n            throw this.newParseError(`Not a valid NCName: ${value}`);\n        }\n    }\n    attachSaxListeners() {\n        this.saxParser.on('error', (error) => this.emit('error', error));\n        this.saxParser.on('opentag', this.onTag.bind(this));\n        this.saxParser.on('text', this.onText.bind(this));\n        this.saxParser.on('cdata', this.onText.bind(this));\n        this.saxParser.on('closetag', this.onCloseTag.bind(this));\n        this.saxParser.on('doctype', this.onDoctype.bind(this));\n    }\n    /**\n     * Handle the given tag.\n     * @param {SaxesTagNS} tag A SAX tag.\n     */\n    onTag(tag) {\n        // Get parent tag\n        const parentTag = this.activeTagStack.length\n            ? this.activeTagStack[this.activeTagStack.length - 1] : null;\n        let currentParseType = ParseType.RESOURCE;\n        if (parentTag) {\n            parentTag.hadChildren = true;\n            currentParseType = parentTag.childrenParseType;\n        }\n        // Check if this tag needs to be converted to a string\n        if (parentTag && parentTag.childrenStringTags) {\n            // Convert this tag to a string\n            const tagName = tag.name;\n            let attributes = '';\n            for (const attributeKey in tag.attributes) {\n                attributes += ` ${attributeKey}=\"${tag.attributes[attributeKey].value}\"`;\n            }\n            const tagContents = `${tagName}${attributes}`;\n            const tagString = `<${tagContents}>`;\n            parentTag.childrenStringTags.push(tagString);\n            // Inherit the array, so that deeper tags are appended to this same array\n            const stringActiveTag = { childrenStringTags: parentTag.childrenStringTags };\n            stringActiveTag.childrenStringEmitClosingTag = `</${tagName}>`;\n            this.activeTagStack.push(stringActiveTag);\n            // Halt any further processing\n            return;\n        }\n        const activeTag = {};\n        if (parentTag) {\n            // Inherit language scope and baseIRI from parent\n            activeTag.language = parentTag.language;\n            activeTag.baseIRI = parentTag.baseIRI;\n        }\n        else {\n            activeTag.baseIRI = this.baseIRI;\n        }\n        this.activeTagStack.push(activeTag);\n        if (currentParseType === ParseType.RESOURCE) {\n            this.onTagResource(tag, activeTag, parentTag, !parentTag);\n        }\n        else { // currentParseType === ParseType.PROPERTY\n            this.onTagProperty(tag, activeTag, parentTag);\n        }\n    }\n    /**\n     * Handle the given node element in resource-mode.\n     * @param {SaxesTagNS} tag A SAX tag.\n     * @param {IActiveTag} activeTag The currently active tag.\n     * @param {IActiveTag} parentTag The parent tag or null.\n     * @param {boolean} rootTag If we are currently processing the root tag.\n     */\n    onTagResource(tag, activeTag, parentTag, rootTag) {\n        activeTag.childrenParseType = ParseType.PROPERTY;\n        // Assume that the current node is a _typed_ node (2.13), unless we find an rdf:Description as node name\n        let typedNode = true;\n        if (tag.uri === RdfXmlParser.RDF) {\n            // Check forbidden property element names\n            if (!rootTag && RdfXmlParser.FORBIDDEN_NODE_ELEMENTS.indexOf(tag.local) >= 0) {\n                throw this.newParseError(`Illegal node element name: ${tag.local}`);\n            }\n            switch (tag.local) {\n                case 'RDF':\n                    // Tags under <rdf:RDF> must always be resources\n                    activeTag.childrenParseType = ParseType.RESOURCE;\n                case 'Description':\n                    typedNode = false;\n            }\n        }\n        const predicates = [];\n        const objects = [];\n        // Collect all attributes as triples\n        // Assign subject value only after all attributes have been processed, because baseIRI may change the final val\n        let activeSubjectValue = null;\n        let claimSubjectNodeId = false;\n        let subjectValueBlank = false;\n        let explicitType = null;\n        for (const attributeKey in tag.attributes) {\n            const attribute = tag.attributes[attributeKey];\n            if (parentTag && attribute.uri === RdfXmlParser.RDF) {\n                switch (attribute.local) {\n                    case 'about':\n                        if (activeSubjectValue) {\n                            throw this.newParseError(`Only one of rdf:about, rdf:nodeID and rdf:ID can be present, \\\nwhile ${attribute.value} and ${activeSubjectValue} where found.`);\n                        }\n                        activeSubjectValue = attribute.value;\n                        continue;\n                    case 'ID':\n                        if (activeSubjectValue) {\n                            throw this.newParseError(`Only one of rdf:about, rdf:nodeID and rdf:ID can be present, \\\nwhile ${attribute.value} and ${activeSubjectValue} where found.`);\n                        }\n                        this.validateNcname(attribute.value);\n                        activeSubjectValue = '#' + attribute.value;\n                        claimSubjectNodeId = true;\n                        continue;\n                    case 'nodeID':\n                        if (activeSubjectValue) {\n                            throw this.newParseError(`Only one of rdf:about, rdf:nodeID and rdf:ID can be present, \\\nwhile ${attribute.value} and ${activeSubjectValue} where found.`);\n                        }\n                        this.validateNcname(attribute.value);\n                        activeSubjectValue = attribute.value;\n                        subjectValueBlank = true;\n                        continue;\n                    case 'bagID':\n                        throw this.newParseError(`rdf:bagID is not supported.`);\n                    case 'type':\n                        // Emit the rdf:type later as named node instead of the default literal\n                        explicitType = attribute.value;\n                        continue;\n                    case 'aboutEach':\n                        throw this.newParseError(`rdf:aboutEach is not supported.`);\n                    case 'aboutEachPrefix':\n                        throw this.newParseError(`rdf:aboutEachPrefix is not supported.`);\n                    case 'li':\n                        throw this.newParseError(`rdf:li on node elements are not supported.`);\n                }\n            }\n            else if (attribute.uri === RdfXmlParser.XML) {\n                if (attribute.local === 'lang') {\n                    activeTag.language = attribute.value === '' ? null : attribute.value.toLowerCase();\n                    continue;\n                }\n                else if (attribute.local === 'base') {\n                    // SAX Parser does not expand xml:base, based on DOCTYPE, so we have to do it manually\n                    activeTag.baseIRI = (0, relative_to_absolute_iri_1.resolve)(attribute.value, activeTag.baseIRI);\n                    continue;\n                }\n            }\n            // Interpret attributes at this point as properties on this node,\n            // but we ignore attributes that have no prefix or known expanded URI\n            if (attribute.prefix !== 'xml' && attribute.prefix !== 'xmlns'\n                && (attribute.prefix !== '' || attribute.local !== 'xmlns')\n                && attribute.uri) {\n                predicates.push(this.uriToNamedNode(attribute.uri + attribute.local));\n                objects.push(attribute.value);\n            }\n        }\n        // Create the subject value _after_ all attributes have been processed\n        if (activeSubjectValue !== null) {\n            activeTag.subject = subjectValueBlank\n                ? this.dataFactory.blankNode(activeSubjectValue) : this.valueToUri(activeSubjectValue, activeTag);\n            if (claimSubjectNodeId) {\n                this.claimNodeId(activeTag.subject);\n            }\n        }\n        // Force the creation of a subject if it doesn't exist yet\n        if (!activeTag.subject) {\n            activeTag.subject = this.dataFactory.blankNode();\n        }\n        // Emit the type if we're at a typed node\n        if (typedNode) {\n            const type = this.uriToNamedNode(tag.uri + tag.local);\n            this.emitTriple(activeTag.subject, this.dataFactory.namedNode(RdfXmlParser.RDF + 'type'), type, parentTag ? parentTag.reifiedStatementId : null);\n        }\n        if (parentTag) {\n            // If the parent tag defined a predicate, add the current tag as property value\n            if (parentTag.predicate) {\n                if (parentTag.childrenCollectionSubject) {\n                    // RDF:List-based properties\n                    const linkTerm = this.dataFactory.blankNode();\n                    // Emit <x> <p> <current-chain> OR <previous-chain> <rdf:rest> <current-chain>\n                    this.emitTriple(parentTag.childrenCollectionSubject, parentTag.childrenCollectionPredicate, linkTerm, parentTag.reifiedStatementId);\n                    // Emit <current-chain> <rdf:first> value\n                    this.emitTriple(linkTerm, this.dataFactory.namedNode(RdfXmlParser.RDF + 'first'), activeTag.subject, activeTag.reifiedStatementId);\n                    // Store <current-chain> in the parent node\n                    parentTag.childrenCollectionSubject = linkTerm;\n                    parentTag.childrenCollectionPredicate = this.dataFactory.namedNode(RdfXmlParser.RDF + 'rest');\n                }\n                else { // !parentTag.predicateEmitted\n                    // Set-based properties\n                    this.emitTriple(parentTag.subject, parentTag.predicate, activeTag.subject, parentTag.reifiedStatementId);\n                    // Emit pending properties on the parent tag that had no defined subject yet.\n                    for (let i = 0; i < parentTag.predicateSubPredicates.length; i++) {\n                        this.emitTriple(activeTag.subject, parentTag.predicateSubPredicates[i], parentTag.predicateSubObjects[i], null);\n                    }\n                    // Cleanup so we don't emit them again when the parent tag is closed\n                    parentTag.predicateSubPredicates = [];\n                    parentTag.predicateSubObjects = [];\n                    parentTag.predicateEmitted = true;\n                }\n            }\n            // Emit all collected triples\n            for (let i = 0; i < predicates.length; i++) {\n                const object = this.dataFactory.literal(objects[i], activeTag.datatype || activeTag.language);\n                this.emitTriple(activeTag.subject, predicates[i], object, parentTag.reifiedStatementId);\n            }\n            // Emit the rdf:type as named node instead of literal\n            if (explicitType) {\n                this.emitTriple(activeTag.subject, this.dataFactory.namedNode(RdfXmlParser.RDF + 'type'), this.uriToNamedNode(explicitType), null);\n            }\n        }\n    }\n    /**\n     * Handle the given property element in property-mode.\n     * @param {SaxesTagNS} tag A SAX tag.\n     * @param {IActiveTag} activeTag The currently active tag.\n     * @param {IActiveTag} parentTag The parent tag or null.\n     */\n    onTagProperty(tag, activeTag, parentTag) {\n        activeTag.childrenParseType = ParseType.RESOURCE;\n        activeTag.subject = parentTag.subject; // Inherit parent subject\n        if (tag.uri === RdfXmlParser.RDF && tag.local === 'li') {\n            // Convert rdf:li to rdf:_x\n            if (!parentTag.listItemCounter) {\n                parentTag.listItemCounter = 1;\n            }\n            activeTag.predicate = this.uriToNamedNode(tag.uri + '_' + parentTag.listItemCounter++);\n        }\n        else {\n            activeTag.predicate = this.uriToNamedNode(tag.uri + tag.local);\n        }\n        // Check forbidden property element names\n        if (tag.uri === RdfXmlParser.RDF\n            && RdfXmlParser.FORBIDDEN_PROPERTY_ELEMENTS.indexOf(tag.local) >= 0) {\n            throw this.newParseError(`Illegal property element name: ${tag.local}`);\n        }\n        activeTag.predicateSubPredicates = [];\n        activeTag.predicateSubObjects = [];\n        let parseType = false;\n        let attributedProperty = false;\n        // Collect all attributes as triples\n        // Assign subject value only after all attributes have been processed, because baseIRI may change the final val\n        let activeSubSubjectValue = null;\n        let subSubjectValueBlank = true;\n        const predicates = [];\n        const objects = [];\n        for (const propertyAttributeKey in tag.attributes) {\n            const propertyAttribute = tag.attributes[propertyAttributeKey];\n            if (propertyAttribute.uri === RdfXmlParser.RDF) {\n                switch (propertyAttribute.local) {\n                    case 'resource':\n                        if (activeSubSubjectValue) {\n                            throw this.newParseError(`Found both rdf:resource (${propertyAttribute.value}) and rdf:nodeID (${activeSubSubjectValue}).`);\n                        }\n                        if (parseType) {\n                            throw this.newParseError(`rdf:parseType is not allowed on property elements with rdf:resource (${propertyAttribute.value})`);\n                        }\n                        activeTag.hadChildren = true;\n                        activeSubSubjectValue = propertyAttribute.value;\n                        subSubjectValueBlank = false;\n                        continue;\n                    case 'datatype':\n                        if (attributedProperty) {\n                            throw this.newParseError(`Found both non-rdf:* property attributes and rdf:datatype (${propertyAttribute.value}).`);\n                        }\n                        if (parseType) {\n                            throw this.newParseError(`rdf:parseType is not allowed on property elements with rdf:datatype (${propertyAttribute.value})`);\n                        }\n                        activeTag.datatype = this.valueToUri(propertyAttribute.value, activeTag);\n                        continue;\n                    case 'nodeID':\n                        if (attributedProperty) {\n                            throw this.newParseError(`Found both non-rdf:* property attributes and rdf:nodeID (${propertyAttribute.value}).`);\n                        }\n                        if (activeTag.hadChildren) {\n                            throw this.newParseError(`Found both rdf:resource and rdf:nodeID (${propertyAttribute.value}).`);\n                        }\n                        if (parseType) {\n                            throw this.newParseError(`rdf:parseType is not allowed on property elements with rdf:nodeID (${propertyAttribute.value})`);\n                        }\n                        this.validateNcname(propertyAttribute.value);\n                        activeTag.hadChildren = true;\n                        activeSubSubjectValue = propertyAttribute.value;\n                        subSubjectValueBlank = true;\n                        continue;\n                    case 'bagID':\n                        throw this.newParseError(`rdf:bagID is not supported.`);\n                    case 'parseType':\n                        // Validation\n                        if (attributedProperty) {\n                            throw this.newParseError(`rdf:parseType is not allowed when non-rdf:* property attributes are present`);\n                        }\n                        if (activeTag.datatype) {\n                            throw this.newParseError(`rdf:parseType is not allowed on property elements with rdf:datatype (${activeTag.datatype.value})`);\n                        }\n                        if (activeSubSubjectValue) {\n                            throw this.newParseError(`rdf:parseType is not allowed on property elements with rdf:nodeID or rdf:resource (${activeSubSubjectValue})`);\n                        }\n                        if (propertyAttribute.value === 'Resource') {\n                            parseType = true;\n                            activeTag.childrenParseType = ParseType.PROPERTY;\n                            // Turn this property element into a node element\n                            const nestedBNode = this.dataFactory.blankNode();\n                            this.emitTriple(activeTag.subject, activeTag.predicate, nestedBNode, activeTag.reifiedStatementId);\n                            activeTag.subject = nestedBNode;\n                            activeTag.predicate = null;\n                        }\n                        else if (propertyAttribute.value === 'Collection') {\n                            parseType = true;\n                            // Interpret children as being part of an rdf:List\n                            activeTag.hadChildren = true;\n                            activeTag.childrenCollectionSubject = activeTag.subject;\n                            activeTag.childrenCollectionPredicate = activeTag.predicate;\n                            subSubjectValueBlank = false;\n                        }\n                        else if (propertyAttribute.value === 'Literal') {\n                            parseType = true;\n                            // Interpret children as being part of a literal string\n                            activeTag.childrenTagsToString = true;\n                            activeTag.childrenStringTags = [];\n                        }\n                        continue;\n                    case 'ID':\n                        this.validateNcname(propertyAttribute.value);\n                        activeTag.reifiedStatementId = this.valueToUri('#' + propertyAttribute.value, activeTag);\n                        this.claimNodeId(activeTag.reifiedStatementId);\n                        continue;\n                }\n            }\n            else if (propertyAttribute.uri === RdfXmlParser.XML && propertyAttribute.local === 'lang') {\n                activeTag.language = propertyAttribute.value === ''\n                    ? null : propertyAttribute.value.toLowerCase();\n                continue;\n            }\n            // Interpret attributes at this point as properties via implicit blank nodes on the property,\n            // but we ignore attributes that have no prefix or known expanded URI\n            if (propertyAttribute.prefix !== 'xml' && propertyAttribute.prefix !== 'xmlns'\n                && (propertyAttribute.prefix !== '' || propertyAttribute.local !== 'xmlns')\n                && propertyAttribute.uri) {\n                if (parseType || activeTag.datatype) {\n                    throw this.newParseError(`Found illegal rdf:* properties on property element with attribute: ${propertyAttribute.value}`);\n                }\n                activeTag.hadChildren = true;\n                attributedProperty = true;\n                predicates.push(this.uriToNamedNode(propertyAttribute.uri + propertyAttribute.local));\n                objects.push(this.dataFactory.literal(propertyAttribute.value, activeTag.datatype || activeTag.language));\n            }\n        }\n        // Create the subject value _after_ all attributes have been processed\n        if (activeSubSubjectValue !== null) {\n            const subjectParent = activeTag.subject;\n            activeTag.subject = subSubjectValueBlank\n                ? this.dataFactory.blankNode(activeSubSubjectValue) : this.valueToUri(activeSubSubjectValue, activeTag);\n            this.emitTriple(subjectParent, activeTag.predicate, activeTag.subject, activeTag.reifiedStatementId);\n            // Emit our buffered triples\n            for (let i = 0; i < predicates.length; i++) {\n                this.emitTriple(activeTag.subject, predicates[i], objects[i], null);\n            }\n            activeTag.predicateEmitted = true;\n        }\n        else if (subSubjectValueBlank) {\n            // The current property element has no defined subject\n            // Let's buffer the properties until the child node defines a subject,\n            // or if the tag closes.\n            activeTag.predicateSubPredicates = predicates;\n            activeTag.predicateSubObjects = objects;\n            activeTag.predicateEmitted = false;\n        }\n    }\n    /**\n     * Emit the given triple to the stream.\n     * @param {Term} subject A subject term.\n     * @param {Term} predicate A predicate term.\n     * @param {Term} object An object term.\n     * @param {Term} statementId An optional resource that identifies the triple.\n     *                           If truthy, then the given triple will also be emitted reified.\n     */\n    emitTriple(subject, predicate, object, statementId) {\n        this.push(this.dataFactory.quad(subject, predicate, object, this.defaultGraph));\n        // Reify triple\n        if (statementId) {\n            this.push(this.dataFactory.quad(statementId, this.dataFactory.namedNode(RdfXmlParser.RDF + 'type'), this.dataFactory.namedNode(RdfXmlParser.RDF + 'Statement'), this.defaultGraph));\n            this.push(this.dataFactory.quad(statementId, this.dataFactory.namedNode(RdfXmlParser.RDF + 'subject'), subject, this.defaultGraph));\n            this.push(this.dataFactory.quad(statementId, this.dataFactory.namedNode(RdfXmlParser.RDF + 'predicate'), predicate, this.defaultGraph));\n            this.push(this.dataFactory.quad(statementId, this.dataFactory.namedNode(RdfXmlParser.RDF + 'object'), object, this.defaultGraph));\n        }\n    }\n    /**\n     * Register the given term as a node ID.\n     * If one was already registered, this will emit an error.\n     *\n     * This is used to check duplicate occurrences of rdf:ID in scope of the baseIRI.\n     * @param {Term} term An RDF term.\n     */\n    claimNodeId(term) {\n        if (!this.allowDuplicateRdfIds) {\n            if (this.nodeIds[term.value]) {\n                throw this.newParseError(`Found multiple occurrences of rdf:ID='${term.value}'.`);\n            }\n            this.nodeIds[term.value] = true;\n        }\n    }\n    /**\n     * Handle the given text string.\n     * @param {string} text A parsed text string.\n     */\n    onText(text) {\n        const activeTag = this.activeTagStack.length\n            ? this.activeTagStack[this.activeTagStack.length - 1] : null;\n        if (activeTag) {\n            if (activeTag.childrenStringTags) {\n                activeTag.childrenStringTags.push(text);\n            }\n            else if (activeTag.predicate) {\n                activeTag.text = text;\n            }\n        }\n    }\n    /**\n     * Handle the closing of the last tag.\n     */\n    onCloseTag() {\n        const poppedTag = this.activeTagStack.pop();\n        // If we were converting a tag to a string, and the tag was not self-closing, close it here.\n        if (poppedTag.childrenStringEmitClosingTag) {\n            poppedTag.childrenStringTags.push(poppedTag.childrenStringEmitClosingTag);\n        }\n        // Set the literal value if we were collecting XML tags to string\n        if (poppedTag.childrenTagsToString) {\n            poppedTag.datatype = this.dataFactory.namedNode(RdfXmlParser.RDF + 'XMLLiteral');\n            poppedTag.text = poppedTag.childrenStringTags.join('');\n            poppedTag.hadChildren = false; // Force a literal triple to be emitted hereafter\n        }\n        if (poppedTag.childrenCollectionSubject) {\n            // Terminate the rdf:List\n            this.emitTriple(poppedTag.childrenCollectionSubject, poppedTag.childrenCollectionPredicate, this.dataFactory.namedNode(RdfXmlParser.RDF + 'nil'), poppedTag.reifiedStatementId);\n        }\n        else if (poppedTag.predicate) {\n            if (!poppedTag.hadChildren && poppedTag.childrenParseType !== ParseType.PROPERTY) {\n                // Property element contains text\n                this.emitTriple(poppedTag.subject, poppedTag.predicate, this.dataFactory.literal(poppedTag.text || '', poppedTag.datatype || poppedTag.language), poppedTag.reifiedStatementId);\n            }\n            else if (!poppedTag.predicateEmitted) {\n                // Emit remaining properties on an anonymous property element\n                const subject = this.dataFactory.blankNode();\n                this.emitTriple(poppedTag.subject, poppedTag.predicate, subject, poppedTag.reifiedStatementId);\n                for (let i = 0; i < poppedTag.predicateSubPredicates.length; i++) {\n                    this.emitTriple(subject, poppedTag.predicateSubPredicates[i], poppedTag.predicateSubObjects[i], null);\n                }\n            }\n        }\n    }\n    /**\n     * Fetch local DOCTYPE ENTITY's and make the parser recognise them.\n     * @param {string} doctype The read doctype.\n     */\n    onDoctype(doctype) {\n        doctype.replace(/<!ENTITY\\s+([^\\s]+)\\s+[\"']([^\"']+)[\"']\\s*>/g, (match, prefix, uri) => {\n            this.saxParser.ENTITIES[prefix] = uri;\n            return '';\n        });\n    }\n}\nexports.RdfXmlParser = RdfXmlParser;\nRdfXmlParser.MIME_TYPE = 'application/rdf+xml';\nRdfXmlParser.RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\nRdfXmlParser.XML = 'http://www.w3.org/XML/1998/namespace';\nRdfXmlParser.FORBIDDEN_NODE_ELEMENTS = [\n    'RDF',\n    'ID',\n    'about',\n    'bagID',\n    'parseType',\n    'resource',\n    'nodeID',\n    'li',\n    'aboutEach',\n    'aboutEachPrefix',\n];\nRdfXmlParser.FORBIDDEN_PROPERTY_ELEMENTS = [\n    'Description',\n    'RDF',\n    'ID',\n    'about',\n    'bagID',\n    'parseType',\n    'resource',\n    'nodeID',\n    'aboutEach',\n    'aboutEachPrefix',\n];\n// tslint:disable-next-line:max-line-length\nRdfXmlParser.NCNAME_MATCHER = /^([A-Za-z\\xC0-\\xD6\\xD8-\\xF6\\u{F8}-\\u{2FF}\\u{370}-\\u{37D}\\u{37F}-\\u{1FFF}\\u{200C}-\\u{200D}\\u{2070}-\\u{218F}\\u{2C00}-\\u{2FEF}\\u{3001}-\\u{D7FF}\\u{F900}-\\u{FDCF}\\u{FDF0}-\\u{FFFD}\\u{10000}-\\u{EFFFF}_])([A-Za-z\\xC0-\\xD6\\xD8-\\xF6\\u{F8}-\\u{2FF}\\u{370}-\\u{37D}\\u{37F}-\\u{1FFF}\\u{200C}-\\u{200D}\\u{2070}-\\u{218F}\\u{2C00}-\\u{2FEF}\\u{3001}-\\u{D7FF}\\u{F900}-\\u{FDCF}\\u{FDF0}-\\u{FFFD}\\u{10000}-\\u{EFFFF}_\\-.0-9#xB7\\u{0300}-\\u{036F}\\u{203F}-\\u{2040}])*$/u;\nvar ParseType;\n(function (ParseType) {\n    ParseType[ParseType[\"RESOURCE\"] = 0] = \"RESOURCE\";\n    ParseType[ParseType[\"PROPERTY\"] = 1] = \"PROPERTY\";\n})(ParseType || (exports.ParseType = ParseType = {}));\n//# sourceMappingURL=RdfXmlParser.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdfxml-streaming-parser/lib/RdfXmlParser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/add-abort-signal.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/add-abort-signal.js ***!
  \*******************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { SymbolDispose } = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst { AbortError, codes } = __webpack_require__(/*! ../../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\")\nconst { isNodeStream, isWebStream, kControllerErrorFunction } = __webpack_require__(/*! ./utils */ \"./node_modules/readable-stream/lib/internal/streams/utils.js\")\nconst eos = __webpack_require__(/*! ./end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\")\nconst { ERR_INVALID_ARG_TYPE } = codes\nlet addAbortListener\n\n// This method is inlined here for readable-stream\n// It also does not allow for signal to not exist on the stream\n// https://github.com/nodejs/node/pull/36061#discussion_r533718029\nconst validateAbortSignal = (signal, name) => {\n  if (typeof signal !== 'object' || !('aborted' in signal)) {\n    throw new ERR_INVALID_ARG_TYPE(name, 'AbortSignal', signal)\n  }\n}\nmodule.exports.addAbortSignal = function addAbortSignal(signal, stream) {\n  validateAbortSignal(signal, 'signal')\n  if (!isNodeStream(stream) && !isWebStream(stream)) {\n    throw new ERR_INVALID_ARG_TYPE('stream', ['ReadableStream', 'WritableStream', 'Stream'], stream)\n  }\n  return module.exports.addAbortSignalNoValidate(signal, stream)\n}\nmodule.exports.addAbortSignalNoValidate = function (signal, stream) {\n  if (typeof signal !== 'object' || !('aborted' in signal)) {\n    return stream\n  }\n  const onAbort = isNodeStream(stream)\n    ? () => {\n        stream.destroy(\n          new AbortError(undefined, {\n            cause: signal.reason\n          })\n        )\n      }\n    : () => {\n        stream[kControllerErrorFunction](\n          new AbortError(undefined, {\n            cause: signal.reason\n          })\n        )\n      }\n  if (signal.aborted) {\n    onAbort()\n  } else {\n    addAbortListener = addAbortListener || (__webpack_require__(/*! ../../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\").addAbortListener)\n    const disposable = addAbortListener(signal, onAbort)\n    eos(stream, disposable[SymbolDispose])\n  }\n  return stream\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/add-abort-signal.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/buffer_list.js":
/*!**************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/buffer_list.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { StringPrototypeSlice, SymbolIterator, TypedArrayPrototypeSet, Uint8Array } = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst { Buffer } = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\nconst { inspect } = __webpack_require__(/*! ../../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\")\nmodule.exports = class BufferList {\n  constructor() {\n    this.head = null\n    this.tail = null\n    this.length = 0\n  }\n  push(v) {\n    const entry = {\n      data: v,\n      next: null\n    }\n    if (this.length > 0) this.tail.next = entry\n    else this.head = entry\n    this.tail = entry\n    ++this.length\n  }\n  unshift(v) {\n    const entry = {\n      data: v,\n      next: this.head\n    }\n    if (this.length === 0) this.tail = entry\n    this.head = entry\n    ++this.length\n  }\n  shift() {\n    if (this.length === 0) return\n    const ret = this.head.data\n    if (this.length === 1) this.head = this.tail = null\n    else this.head = this.head.next\n    --this.length\n    return ret\n  }\n  clear() {\n    this.head = this.tail = null\n    this.length = 0\n  }\n  join(s) {\n    if (this.length === 0) return ''\n    let p = this.head\n    let ret = '' + p.data\n    while ((p = p.next) !== null) ret += s + p.data\n    return ret\n  }\n  concat(n) {\n    if (this.length === 0) return Buffer.alloc(0)\n    const ret = Buffer.allocUnsafe(n >>> 0)\n    let p = this.head\n    let i = 0\n    while (p) {\n      TypedArrayPrototypeSet(ret, p.data, i)\n      i += p.data.length\n      p = p.next\n    }\n    return ret\n  }\n\n  // Consumes a specified amount of bytes or characters from the buffered data.\n  consume(n, hasStrings) {\n    const data = this.head.data\n    if (n < data.length) {\n      // `slice` is the same for buffers and strings.\n      const slice = data.slice(0, n)\n      this.head.data = data.slice(n)\n      return slice\n    }\n    if (n === data.length) {\n      // First chunk is a perfect match.\n      return this.shift()\n    }\n    // Result spans more than one buffer.\n    return hasStrings ? this._getString(n) : this._getBuffer(n)\n  }\n  first() {\n    return this.head.data\n  }\n  *[SymbolIterator]() {\n    for (let p = this.head; p; p = p.next) {\n      yield p.data\n    }\n  }\n\n  // Consumes a specified amount of characters from the buffered data.\n  _getString(n) {\n    let ret = ''\n    let p = this.head\n    let c = 0\n    do {\n      const str = p.data\n      if (n > str.length) {\n        ret += str\n        n -= str.length\n      } else {\n        if (n === str.length) {\n          ret += str\n          ++c\n          if (p.next) this.head = p.next\n          else this.head = this.tail = null\n        } else {\n          ret += StringPrototypeSlice(str, 0, n)\n          this.head = p\n          p.data = StringPrototypeSlice(str, n)\n        }\n        break\n      }\n      ++c\n    } while ((p = p.next) !== null)\n    this.length -= c\n    return ret\n  }\n\n  // Consumes a specified amount of bytes from the buffered data.\n  _getBuffer(n) {\n    const ret = Buffer.allocUnsafe(n)\n    const retLen = n\n    let p = this.head\n    let c = 0\n    do {\n      const buf = p.data\n      if (n > buf.length) {\n        TypedArrayPrototypeSet(ret, buf, retLen - n)\n        n -= buf.length\n      } else {\n        if (n === buf.length) {\n          TypedArrayPrototypeSet(ret, buf, retLen - n)\n          ++c\n          if (p.next) this.head = p.next\n          else this.head = this.tail = null\n        } else {\n          TypedArrayPrototypeSet(ret, new Uint8Array(buf.buffer, buf.byteOffset, n), retLen - n)\n          this.head = p\n          p.data = buf.slice(n)\n        }\n        break\n      }\n      ++c\n    } while ((p = p.next) !== null)\n    this.length -= c\n    return ret\n  }\n\n  // Make sure the linked list only shows the minimal necessary information.\n  [Symbol.for('nodejs.util.inspect.custom')](_, options) {\n    return inspect(this, {\n      ...options,\n      // Only inspect one level.\n      depth: 0,\n      // It should not recurse.\n      customInspect: false\n    })\n  }\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/buffer_list.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/compose.js":
/*!**********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/compose.js ***!
  \**********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { pipeline } = __webpack_require__(/*! ./pipeline */ \"./node_modules/readable-stream/lib/internal/streams/pipeline.js\")\nconst Duplex = __webpack_require__(/*! ./duplex */ \"./node_modules/readable-stream/lib/internal/streams/duplex.js\")\nconst { destroyer } = __webpack_require__(/*! ./destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\")\nconst {\n  isNodeStream,\n  isReadable,\n  isWritable,\n  isWebStream,\n  isTransformStream,\n  isWritableStream,\n  isReadableStream\n} = __webpack_require__(/*! ./utils */ \"./node_modules/readable-stream/lib/internal/streams/utils.js\")\nconst {\n  AbortError,\n  codes: { ERR_INVALID_ARG_VALUE, ERR_MISSING_ARGS }\n} = __webpack_require__(/*! ../../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\")\nconst eos = __webpack_require__(/*! ./end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\")\nmodule.exports = function compose(...streams) {\n  if (streams.length === 0) {\n    throw new ERR_MISSING_ARGS('streams')\n  }\n  if (streams.length === 1) {\n    return Duplex.from(streams[0])\n  }\n  const orgStreams = [...streams]\n  if (typeof streams[0] === 'function') {\n    streams[0] = Duplex.from(streams[0])\n  }\n  if (typeof streams[streams.length - 1] === 'function') {\n    const idx = streams.length - 1\n    streams[idx] = Duplex.from(streams[idx])\n  }\n  for (let n = 0; n < streams.length; ++n) {\n    if (!isNodeStream(streams[n]) && !isWebStream(streams[n])) {\n      // TODO(ronag): Add checks for non streams.\n      continue\n    }\n    if (\n      n < streams.length - 1 &&\n      !(isReadable(streams[n]) || isReadableStream(streams[n]) || isTransformStream(streams[n]))\n    ) {\n      throw new ERR_INVALID_ARG_VALUE(`streams[${n}]`, orgStreams[n], 'must be readable')\n    }\n    if (n > 0 && !(isWritable(streams[n]) || isWritableStream(streams[n]) || isTransformStream(streams[n]))) {\n      throw new ERR_INVALID_ARG_VALUE(`streams[${n}]`, orgStreams[n], 'must be writable')\n    }\n  }\n  let ondrain\n  let onfinish\n  let onreadable\n  let onclose\n  let d\n  function onfinished(err) {\n    const cb = onclose\n    onclose = null\n    if (cb) {\n      cb(err)\n    } else if (err) {\n      d.destroy(err)\n    } else if (!readable && !writable) {\n      d.destroy()\n    }\n  }\n  const head = streams[0]\n  const tail = pipeline(streams, onfinished)\n  const writable = !!(isWritable(head) || isWritableStream(head) || isTransformStream(head))\n  const readable = !!(isReadable(tail) || isReadableStream(tail) || isTransformStream(tail))\n\n  // TODO(ronag): Avoid double buffering.\n  // Implement Writable/Readable/Duplex traits.\n  // See, https://github.com/nodejs/node/pull/33515.\n  d = new Duplex({\n    // TODO (ronag): highWaterMark?\n    writableObjectMode: !!(head !== null && head !== undefined && head.writableObjectMode),\n    readableObjectMode: !!(tail !== null && tail !== undefined && tail.readableObjectMode),\n    writable,\n    readable\n  })\n  if (writable) {\n    if (isNodeStream(head)) {\n      d._write = function (chunk, encoding, callback) {\n        if (head.write(chunk, encoding)) {\n          callback()\n        } else {\n          ondrain = callback\n        }\n      }\n      d._final = function (callback) {\n        head.end()\n        onfinish = callback\n      }\n      head.on('drain', function () {\n        if (ondrain) {\n          const cb = ondrain\n          ondrain = null\n          cb()\n        }\n      })\n    } else if (isWebStream(head)) {\n      const writable = isTransformStream(head) ? head.writable : head\n      const writer = writable.getWriter()\n      d._write = async function (chunk, encoding, callback) {\n        try {\n          await writer.ready\n          writer.write(chunk).catch(() => {})\n          callback()\n        } catch (err) {\n          callback(err)\n        }\n      }\n      d._final = async function (callback) {\n        try {\n          await writer.ready\n          writer.close().catch(() => {})\n          onfinish = callback\n        } catch (err) {\n          callback(err)\n        }\n      }\n    }\n    const toRead = isTransformStream(tail) ? tail.readable : tail\n    eos(toRead, () => {\n      if (onfinish) {\n        const cb = onfinish\n        onfinish = null\n        cb()\n      }\n    })\n  }\n  if (readable) {\n    if (isNodeStream(tail)) {\n      tail.on('readable', function () {\n        if (onreadable) {\n          const cb = onreadable\n          onreadable = null\n          cb()\n        }\n      })\n      tail.on('end', function () {\n        d.push(null)\n      })\n      d._read = function () {\n        while (true) {\n          const buf = tail.read()\n          if (buf === null) {\n            onreadable = d._read\n            return\n          }\n          if (!d.push(buf)) {\n            return\n          }\n        }\n      }\n    } else if (isWebStream(tail)) {\n      const readable = isTransformStream(tail) ? tail.readable : tail\n      const reader = readable.getReader()\n      d._read = async function () {\n        while (true) {\n          try {\n            const { value, done } = await reader.read()\n            if (!d.push(value)) {\n              return\n            }\n            if (done) {\n              d.push(null)\n              return\n            }\n          } catch {\n            return\n          }\n        }\n      }\n    }\n  }\n  d._destroy = function (err, callback) {\n    if (!err && onclose !== null) {\n      err = new AbortError()\n    }\n    onreadable = null\n    ondrain = null\n    onfinish = null\n    if (onclose === null) {\n      callback(err)\n    } else {\n      onclose = callback\n      if (isNodeStream(tail)) {\n        destroyer(tail, err)\n      }\n    }\n  }\n  return d\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/compose.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/destroy.js":
/*!**********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/destroy.js ***!
  \**********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/* replacement start */\n\nconst process = __webpack_require__(/*! process/ */ \"./node_modules/process/browser.js\")\n\n/* replacement end */\n\nconst {\n  aggregateTwoErrors,\n  codes: { ERR_MULTIPLE_CALLBACK },\n  AbortError\n} = __webpack_require__(/*! ../../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\")\nconst { Symbol } = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst { kIsDestroyed, isDestroyed, isFinished, isServerRequest } = __webpack_require__(/*! ./utils */ \"./node_modules/readable-stream/lib/internal/streams/utils.js\")\nconst kDestroy = Symbol('kDestroy')\nconst kConstruct = Symbol('kConstruct')\nfunction checkError(err, w, r) {\n  if (err) {\n    // Avoid V8 leak, https://github.com/nodejs/node/pull/34103#issuecomment-652002364\n    err.stack // eslint-disable-line no-unused-expressions\n\n    if (w && !w.errored) {\n      w.errored = err\n    }\n    if (r && !r.errored) {\n      r.errored = err\n    }\n  }\n}\n\n// Backwards compat. cb() is undocumented and unused in core but\n// unfortunately might be used by modules.\nfunction destroy(err, cb) {\n  const r = this._readableState\n  const w = this._writableState\n  // With duplex streams we use the writable side for state.\n  const s = w || r\n  if ((w !== null && w !== undefined && w.destroyed) || (r !== null && r !== undefined && r.destroyed)) {\n    if (typeof cb === 'function') {\n      cb()\n    }\n    return this\n  }\n\n  // We set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n  checkError(err, w, r)\n  if (w) {\n    w.destroyed = true\n  }\n  if (r) {\n    r.destroyed = true\n  }\n\n  // If still constructing then defer calling _destroy.\n  if (!s.constructed) {\n    this.once(kDestroy, function (er) {\n      _destroy(this, aggregateTwoErrors(er, err), cb)\n    })\n  } else {\n    _destroy(this, err, cb)\n  }\n  return this\n}\nfunction _destroy(self, err, cb) {\n  let called = false\n  function onDestroy(err) {\n    if (called) {\n      return\n    }\n    called = true\n    const r = self._readableState\n    const w = self._writableState\n    checkError(err, w, r)\n    if (w) {\n      w.closed = true\n    }\n    if (r) {\n      r.closed = true\n    }\n    if (typeof cb === 'function') {\n      cb(err)\n    }\n    if (err) {\n      process.nextTick(emitErrorCloseNT, self, err)\n    } else {\n      process.nextTick(emitCloseNT, self)\n    }\n  }\n  try {\n    self._destroy(err || null, onDestroy)\n  } catch (err) {\n    onDestroy(err)\n  }\n}\nfunction emitErrorCloseNT(self, err) {\n  emitErrorNT(self, err)\n  emitCloseNT(self)\n}\nfunction emitCloseNT(self) {\n  const r = self._readableState\n  const w = self._writableState\n  if (w) {\n    w.closeEmitted = true\n  }\n  if (r) {\n    r.closeEmitted = true\n  }\n  if ((w !== null && w !== undefined && w.emitClose) || (r !== null && r !== undefined && r.emitClose)) {\n    self.emit('close')\n  }\n}\nfunction emitErrorNT(self, err) {\n  const r = self._readableState\n  const w = self._writableState\n  if ((w !== null && w !== undefined && w.errorEmitted) || (r !== null && r !== undefined && r.errorEmitted)) {\n    return\n  }\n  if (w) {\n    w.errorEmitted = true\n  }\n  if (r) {\n    r.errorEmitted = true\n  }\n  self.emit('error', err)\n}\nfunction undestroy() {\n  const r = this._readableState\n  const w = this._writableState\n  if (r) {\n    r.constructed = true\n    r.closed = false\n    r.closeEmitted = false\n    r.destroyed = false\n    r.errored = null\n    r.errorEmitted = false\n    r.reading = false\n    r.ended = r.readable === false\n    r.endEmitted = r.readable === false\n  }\n  if (w) {\n    w.constructed = true\n    w.destroyed = false\n    w.closed = false\n    w.closeEmitted = false\n    w.errored = null\n    w.errorEmitted = false\n    w.finalCalled = false\n    w.prefinished = false\n    w.ended = w.writable === false\n    w.ending = w.writable === false\n    w.finished = w.writable === false\n  }\n}\nfunction errorOrDestroy(stream, err, sync) {\n  // We have tests that rely on errors being emitted\n  // in the same tick, so changing this is semver major.\n  // For now when you opt-in to autoDestroy we allow\n  // the error to be emitted nextTick. In a future\n  // semver major update we should change the default to this.\n\n  const r = stream._readableState\n  const w = stream._writableState\n  if ((w !== null && w !== undefined && w.destroyed) || (r !== null && r !== undefined && r.destroyed)) {\n    return this\n  }\n  if ((r !== null && r !== undefined && r.autoDestroy) || (w !== null && w !== undefined && w.autoDestroy))\n    stream.destroy(err)\n  else if (err) {\n    // Avoid V8 leak, https://github.com/nodejs/node/pull/34103#issuecomment-652002364\n    err.stack // eslint-disable-line no-unused-expressions\n\n    if (w && !w.errored) {\n      w.errored = err\n    }\n    if (r && !r.errored) {\n      r.errored = err\n    }\n    if (sync) {\n      process.nextTick(emitErrorNT, stream, err)\n    } else {\n      emitErrorNT(stream, err)\n    }\n  }\n}\nfunction construct(stream, cb) {\n  if (typeof stream._construct !== 'function') {\n    return\n  }\n  const r = stream._readableState\n  const w = stream._writableState\n  if (r) {\n    r.constructed = false\n  }\n  if (w) {\n    w.constructed = false\n  }\n  stream.once(kConstruct, cb)\n  if (stream.listenerCount(kConstruct) > 1) {\n    // Duplex\n    return\n  }\n  process.nextTick(constructNT, stream)\n}\nfunction constructNT(stream) {\n  let called = false\n  function onConstruct(err) {\n    if (called) {\n      errorOrDestroy(stream, err !== null && err !== undefined ? err : new ERR_MULTIPLE_CALLBACK())\n      return\n    }\n    called = true\n    const r = stream._readableState\n    const w = stream._writableState\n    const s = w || r\n    if (r) {\n      r.constructed = true\n    }\n    if (w) {\n      w.constructed = true\n    }\n    if (s.destroyed) {\n      stream.emit(kDestroy, err)\n    } else if (err) {\n      errorOrDestroy(stream, err, true)\n    } else {\n      process.nextTick(emitConstructNT, stream)\n    }\n  }\n  try {\n    stream._construct((err) => {\n      process.nextTick(onConstruct, err)\n    })\n  } catch (err) {\n    process.nextTick(onConstruct, err)\n  }\n}\nfunction emitConstructNT(stream) {\n  stream.emit(kConstruct)\n}\nfunction isRequest(stream) {\n  return (stream === null || stream === undefined ? undefined : stream.setHeader) && typeof stream.abort === 'function'\n}\nfunction emitCloseLegacy(stream) {\n  stream.emit('close')\n}\nfunction emitErrorCloseLegacy(stream, err) {\n  stream.emit('error', err)\n  process.nextTick(emitCloseLegacy, stream)\n}\n\n// Normalize destroy for legacy.\nfunction destroyer(stream, err) {\n  if (!stream || isDestroyed(stream)) {\n    return\n  }\n  if (!err && !isFinished(stream)) {\n    err = new AbortError()\n  }\n\n  // TODO: Remove isRequest branches.\n  if (isServerRequest(stream)) {\n    stream.socket = null\n    stream.destroy(err)\n  } else if (isRequest(stream)) {\n    stream.abort()\n  } else if (isRequest(stream.req)) {\n    stream.req.abort()\n  } else if (typeof stream.destroy === 'function') {\n    stream.destroy(err)\n  } else if (typeof stream.close === 'function') {\n    // TODO: Don't lose err?\n    stream.close()\n  } else if (err) {\n    process.nextTick(emitErrorCloseLegacy, stream, err)\n  } else {\n    process.nextTick(emitCloseLegacy, stream)\n  }\n  if (!stream.destroyed) {\n    stream[kIsDestroyed] = true\n  }\n}\nmodule.exports = {\n  construct,\n  destroyer,\n  destroy,\n  undestroy,\n  errorOrDestroy\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/destroy.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/duplex.js":
/*!*********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/duplex.js ***!
  \*********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototype inheritance, this class\n// prototypically inherits from Readable, and then parasitically from\n// Writable.\n\n\n\nconst {\n  ObjectDefineProperties,\n  ObjectGetOwnPropertyDescriptor,\n  ObjectKeys,\n  ObjectSetPrototypeOf\n} = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nmodule.exports = Duplex\nconst Readable = __webpack_require__(/*! ./readable */ \"./node_modules/readable-stream/lib/internal/streams/readable.js\")\nconst Writable = __webpack_require__(/*! ./writable */ \"./node_modules/readable-stream/lib/internal/streams/writable.js\")\nObjectSetPrototypeOf(Duplex.prototype, Readable.prototype)\nObjectSetPrototypeOf(Duplex, Readable)\n{\n  const keys = ObjectKeys(Writable.prototype)\n  // Allow the keys array to be GC'ed.\n  for (let i = 0; i < keys.length; i++) {\n    const method = keys[i]\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method]\n  }\n}\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options)\n  Readable.call(this, options)\n  Writable.call(this, options)\n  if (options) {\n    this.allowHalfOpen = options.allowHalfOpen !== false\n    if (options.readable === false) {\n      this._readableState.readable = false\n      this._readableState.ended = true\n      this._readableState.endEmitted = true\n    }\n    if (options.writable === false) {\n      this._writableState.writable = false\n      this._writableState.ending = true\n      this._writableState.ended = true\n      this._writableState.finished = true\n    }\n  } else {\n    this.allowHalfOpen = true\n  }\n}\nObjectDefineProperties(Duplex.prototype, {\n  writable: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writable')\n  },\n  writableHighWaterMark: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableHighWaterMark')\n  },\n  writableObjectMode: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableObjectMode')\n  },\n  writableBuffer: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableBuffer')\n  },\n  writableLength: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableLength')\n  },\n  writableFinished: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableFinished')\n  },\n  writableCorked: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableCorked')\n  },\n  writableEnded: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableEnded')\n  },\n  writableNeedDrain: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableNeedDrain')\n  },\n  destroyed: {\n    __proto__: null,\n    get() {\n      if (this._readableState === undefined || this._writableState === undefined) {\n        return false\n      }\n      return this._readableState.destroyed && this._writableState.destroyed\n    },\n    set(value) {\n      // Backward compatibility, the user is explicitly\n      // managing destroyed.\n      if (this._readableState && this._writableState) {\n        this._readableState.destroyed = value\n        this._writableState.destroyed = value\n      }\n    }\n  }\n})\nlet webStreamsAdapters\n\n// Lazy to avoid circular references\nfunction lazyWebStreams() {\n  if (webStreamsAdapters === undefined) webStreamsAdapters = {}\n  return webStreamsAdapters\n}\nDuplex.fromWeb = function (pair, options) {\n  return lazyWebStreams().newStreamDuplexFromReadableWritablePair(pair, options)\n}\nDuplex.toWeb = function (duplex) {\n  return lazyWebStreams().newReadableWritablePairFromDuplex(duplex)\n}\nlet duplexify\nDuplex.from = function (body) {\n  if (!duplexify) {\n    duplexify = __webpack_require__(/*! ./duplexify */ \"./node_modules/readable-stream/lib/internal/streams/duplexify.js\")\n  }\n  return duplexify(body, 'body')\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/duplex.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/duplexify.js":
/*!************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/duplexify.js ***!
  \************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* replacement start */\n\nconst process = __webpack_require__(/*! process/ */ \"./node_modules/process/browser.js\")\n\n/* replacement end */\n\n;('use strict')\nconst bufferModule = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\nconst {\n  isReadable,\n  isWritable,\n  isIterable,\n  isNodeStream,\n  isReadableNodeStream,\n  isWritableNodeStream,\n  isDuplexNodeStream,\n  isReadableStream,\n  isWritableStream\n} = __webpack_require__(/*! ./utils */ \"./node_modules/readable-stream/lib/internal/streams/utils.js\")\nconst eos = __webpack_require__(/*! ./end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\")\nconst {\n  AbortError,\n  codes: { ERR_INVALID_ARG_TYPE, ERR_INVALID_RETURN_VALUE }\n} = __webpack_require__(/*! ../../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\")\nconst { destroyer } = __webpack_require__(/*! ./destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\")\nconst Duplex = __webpack_require__(/*! ./duplex */ \"./node_modules/readable-stream/lib/internal/streams/duplex.js\")\nconst Readable = __webpack_require__(/*! ./readable */ \"./node_modules/readable-stream/lib/internal/streams/readable.js\")\nconst Writable = __webpack_require__(/*! ./writable */ \"./node_modules/readable-stream/lib/internal/streams/writable.js\")\nconst { createDeferredPromise } = __webpack_require__(/*! ../../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\")\nconst from = __webpack_require__(/*! ./from */ \"./node_modules/readable-stream/lib/internal/streams/from.js\")\nconst Blob = globalThis.Blob || bufferModule.Blob\nconst isBlob =\n  typeof Blob !== 'undefined'\n    ? function isBlob(b) {\n        return b instanceof Blob\n      }\n    : function isBlob(b) {\n        return false\n      }\nconst AbortController = globalThis.AbortController || (__webpack_require__(/*! abort-controller */ \"./node_modules/abort-controller/browser.js\").AbortController)\nconst { FunctionPrototypeCall } = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\n\n// This is needed for pre node 17.\nclass Duplexify extends Duplex {\n  constructor(options) {\n    super(options)\n\n    // https://github.com/nodejs/node/pull/34385\n\n    if ((options === null || options === undefined ? undefined : options.readable) === false) {\n      this._readableState.readable = false\n      this._readableState.ended = true\n      this._readableState.endEmitted = true\n    }\n    if ((options === null || options === undefined ? undefined : options.writable) === false) {\n      this._writableState.writable = false\n      this._writableState.ending = true\n      this._writableState.ended = true\n      this._writableState.finished = true\n    }\n  }\n}\nmodule.exports = function duplexify(body, name) {\n  if (isDuplexNodeStream(body)) {\n    return body\n  }\n  if (isReadableNodeStream(body)) {\n    return _duplexify({\n      readable: body\n    })\n  }\n  if (isWritableNodeStream(body)) {\n    return _duplexify({\n      writable: body\n    })\n  }\n  if (isNodeStream(body)) {\n    return _duplexify({\n      writable: false,\n      readable: false\n    })\n  }\n  if (isReadableStream(body)) {\n    return _duplexify({\n      readable: Readable.fromWeb(body)\n    })\n  }\n  if (isWritableStream(body)) {\n    return _duplexify({\n      writable: Writable.fromWeb(body)\n    })\n  }\n  if (typeof body === 'function') {\n    const { value, write, final, destroy } = fromAsyncGen(body)\n    if (isIterable(value)) {\n      return from(Duplexify, value, {\n        // TODO (ronag): highWaterMark?\n        objectMode: true,\n        write,\n        final,\n        destroy\n      })\n    }\n    const then = value === null || value === undefined ? undefined : value.then\n    if (typeof then === 'function') {\n      let d\n      const promise = FunctionPrototypeCall(\n        then,\n        value,\n        (val) => {\n          if (val != null) {\n            throw new ERR_INVALID_RETURN_VALUE('nully', 'body', val)\n          }\n        },\n        (err) => {\n          destroyer(d, err)\n        }\n      )\n      return (d = new Duplexify({\n        // TODO (ronag): highWaterMark?\n        objectMode: true,\n        readable: false,\n        write,\n        final(cb) {\n          final(async () => {\n            try {\n              await promise\n              process.nextTick(cb, null)\n            } catch (err) {\n              process.nextTick(cb, err)\n            }\n          })\n        },\n        destroy\n      }))\n    }\n    throw new ERR_INVALID_RETURN_VALUE('Iterable, AsyncIterable or AsyncFunction', name, value)\n  }\n  if (isBlob(body)) {\n    return duplexify(body.arrayBuffer())\n  }\n  if (isIterable(body)) {\n    return from(Duplexify, body, {\n      // TODO (ronag): highWaterMark?\n      objectMode: true,\n      writable: false\n    })\n  }\n  if (\n    isReadableStream(body === null || body === undefined ? undefined : body.readable) &&\n    isWritableStream(body === null || body === undefined ? undefined : body.writable)\n  ) {\n    return Duplexify.fromWeb(body)\n  }\n  if (\n    typeof (body === null || body === undefined ? undefined : body.writable) === 'object' ||\n    typeof (body === null || body === undefined ? undefined : body.readable) === 'object'\n  ) {\n    const readable =\n      body !== null && body !== undefined && body.readable\n        ? isReadableNodeStream(body === null || body === undefined ? undefined : body.readable)\n          ? body === null || body === undefined\n            ? undefined\n            : body.readable\n          : duplexify(body.readable)\n        : undefined\n    const writable =\n      body !== null && body !== undefined && body.writable\n        ? isWritableNodeStream(body === null || body === undefined ? undefined : body.writable)\n          ? body === null || body === undefined\n            ? undefined\n            : body.writable\n          : duplexify(body.writable)\n        : undefined\n    return _duplexify({\n      readable,\n      writable\n    })\n  }\n  const then = body === null || body === undefined ? undefined : body.then\n  if (typeof then === 'function') {\n    let d\n    FunctionPrototypeCall(\n      then,\n      body,\n      (val) => {\n        if (val != null) {\n          d.push(val)\n        }\n        d.push(null)\n      },\n      (err) => {\n        destroyer(d, err)\n      }\n    )\n    return (d = new Duplexify({\n      objectMode: true,\n      writable: false,\n      read() {}\n    }))\n  }\n  throw new ERR_INVALID_ARG_TYPE(\n    name,\n    [\n      'Blob',\n      'ReadableStream',\n      'WritableStream',\n      'Stream',\n      'Iterable',\n      'AsyncIterable',\n      'Function',\n      '{ readable, writable } pair',\n      'Promise'\n    ],\n    body\n  )\n}\nfunction fromAsyncGen(fn) {\n  let { promise, resolve } = createDeferredPromise()\n  const ac = new AbortController()\n  const signal = ac.signal\n  const value = fn(\n    (async function* () {\n      while (true) {\n        const _promise = promise\n        promise = null\n        const { chunk, done, cb } = await _promise\n        process.nextTick(cb)\n        if (done) return\n        if (signal.aborted)\n          throw new AbortError(undefined, {\n            cause: signal.reason\n          })\n        ;({ promise, resolve } = createDeferredPromise())\n        yield chunk\n      }\n    })(),\n    {\n      signal\n    }\n  )\n  return {\n    value,\n    write(chunk, encoding, cb) {\n      const _resolve = resolve\n      resolve = null\n      _resolve({\n        chunk,\n        done: false,\n        cb\n      })\n    },\n    final(cb) {\n      const _resolve = resolve\n      resolve = null\n      _resolve({\n        done: true,\n        cb\n      })\n    },\n    destroy(err, cb) {\n      ac.abort()\n      cb(err)\n    }\n  }\n}\nfunction _duplexify(pair) {\n  const r = pair.readable && typeof pair.readable.read !== 'function' ? Readable.wrap(pair.readable) : pair.readable\n  const w = pair.writable\n  let readable = !!isReadable(r)\n  let writable = !!isWritable(w)\n  let ondrain\n  let onfinish\n  let onreadable\n  let onclose\n  let d\n  function onfinished(err) {\n    const cb = onclose\n    onclose = null\n    if (cb) {\n      cb(err)\n    } else if (err) {\n      d.destroy(err)\n    }\n  }\n\n  // TODO(ronag): Avoid double buffering.\n  // Implement Writable/Readable/Duplex traits.\n  // See, https://github.com/nodejs/node/pull/33515.\n  d = new Duplexify({\n    // TODO (ronag): highWaterMark?\n    readableObjectMode: !!(r !== null && r !== undefined && r.readableObjectMode),\n    writableObjectMode: !!(w !== null && w !== undefined && w.writableObjectMode),\n    readable,\n    writable\n  })\n  if (writable) {\n    eos(w, (err) => {\n      writable = false\n      if (err) {\n        destroyer(r, err)\n      }\n      onfinished(err)\n    })\n    d._write = function (chunk, encoding, callback) {\n      if (w.write(chunk, encoding)) {\n        callback()\n      } else {\n        ondrain = callback\n      }\n    }\n    d._final = function (callback) {\n      w.end()\n      onfinish = callback\n    }\n    w.on('drain', function () {\n      if (ondrain) {\n        const cb = ondrain\n        ondrain = null\n        cb()\n      }\n    })\n    w.on('finish', function () {\n      if (onfinish) {\n        const cb = onfinish\n        onfinish = null\n        cb()\n      }\n    })\n  }\n  if (readable) {\n    eos(r, (err) => {\n      readable = false\n      if (err) {\n        destroyer(r, err)\n      }\n      onfinished(err)\n    })\n    r.on('readable', function () {\n      if (onreadable) {\n        const cb = onreadable\n        onreadable = null\n        cb()\n      }\n    })\n    r.on('end', function () {\n      d.push(null)\n    })\n    d._read = function () {\n      while (true) {\n        const buf = r.read()\n        if (buf === null) {\n          onreadable = d._read\n          return\n        }\n        if (!d.push(buf)) {\n          return\n        }\n      }\n    }\n  }\n  d._destroy = function (err, callback) {\n    if (!err && onclose !== null) {\n      err = new AbortError()\n    }\n    onreadable = null\n    ondrain = null\n    onfinish = null\n    if (onclose === null) {\n      callback(err)\n    } else {\n      onclose = callback\n      destroyer(w, err)\n      destroyer(r, err)\n    }\n  }\n  return d\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/duplexify.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/end-of-stream.js":
/*!****************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/end-of-stream.js ***!
  \****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* replacement start */\n\nconst process = __webpack_require__(/*! process/ */ \"./node_modules/process/browser.js\")\n\n/* replacement end */\n// Ported from https://github.com/mafintosh/end-of-stream with\n// permission from the author, Mathias Buus (@mafintosh).\n\n;('use strict')\nconst { AbortError, codes } = __webpack_require__(/*! ../../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\")\nconst { ERR_INVALID_ARG_TYPE, ERR_STREAM_PREMATURE_CLOSE } = codes\nconst { kEmptyObject, once } = __webpack_require__(/*! ../../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\")\nconst { validateAbortSignal, validateFunction, validateObject, validateBoolean } = __webpack_require__(/*! ../validators */ \"./node_modules/readable-stream/lib/internal/validators.js\")\nconst { Promise, PromisePrototypeThen, SymbolDispose } = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst {\n  isClosed,\n  isReadable,\n  isReadableNodeStream,\n  isReadableStream,\n  isReadableFinished,\n  isReadableErrored,\n  isWritable,\n  isWritableNodeStream,\n  isWritableStream,\n  isWritableFinished,\n  isWritableErrored,\n  isNodeStream,\n  willEmitClose: _willEmitClose,\n  kIsClosedPromise\n} = __webpack_require__(/*! ./utils */ \"./node_modules/readable-stream/lib/internal/streams/utils.js\")\nlet addAbortListener\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function'\n}\nconst nop = () => {}\nfunction eos(stream, options, callback) {\n  var _options$readable, _options$writable\n  if (arguments.length === 2) {\n    callback = options\n    options = kEmptyObject\n  } else if (options == null) {\n    options = kEmptyObject\n  } else {\n    validateObject(options, 'options')\n  }\n  validateFunction(callback, 'callback')\n  validateAbortSignal(options.signal, 'options.signal')\n  callback = once(callback)\n  if (isReadableStream(stream) || isWritableStream(stream)) {\n    return eosWeb(stream, options, callback)\n  }\n  if (!isNodeStream(stream)) {\n    throw new ERR_INVALID_ARG_TYPE('stream', ['ReadableStream', 'WritableStream', 'Stream'], stream)\n  }\n  const readable =\n    (_options$readable = options.readable) !== null && _options$readable !== undefined\n      ? _options$readable\n      : isReadableNodeStream(stream)\n  const writable =\n    (_options$writable = options.writable) !== null && _options$writable !== undefined\n      ? _options$writable\n      : isWritableNodeStream(stream)\n  const wState = stream._writableState\n  const rState = stream._readableState\n  const onlegacyfinish = () => {\n    if (!stream.writable) {\n      onfinish()\n    }\n  }\n\n  // TODO (ronag): Improve soft detection to include core modules and\n  // common ecosystem modules that do properly emit 'close' but fail\n  // this generic check.\n  let willEmitClose =\n    _willEmitClose(stream) && isReadableNodeStream(stream) === readable && isWritableNodeStream(stream) === writable\n  let writableFinished = isWritableFinished(stream, false)\n  const onfinish = () => {\n    writableFinished = true\n    // Stream should not be destroyed here. If it is that\n    // means that user space is doing something differently and\n    // we cannot trust willEmitClose.\n    if (stream.destroyed) {\n      willEmitClose = false\n    }\n    if (willEmitClose && (!stream.readable || readable)) {\n      return\n    }\n    if (!readable || readableFinished) {\n      callback.call(stream)\n    }\n  }\n  let readableFinished = isReadableFinished(stream, false)\n  const onend = () => {\n    readableFinished = true\n    // Stream should not be destroyed here. If it is that\n    // means that user space is doing something differently and\n    // we cannot trust willEmitClose.\n    if (stream.destroyed) {\n      willEmitClose = false\n    }\n    if (willEmitClose && (!stream.writable || writable)) {\n      return\n    }\n    if (!writable || writableFinished) {\n      callback.call(stream)\n    }\n  }\n  const onerror = (err) => {\n    callback.call(stream, err)\n  }\n  let closed = isClosed(stream)\n  const onclose = () => {\n    closed = true\n    const errored = isWritableErrored(stream) || isReadableErrored(stream)\n    if (errored && typeof errored !== 'boolean') {\n      return callback.call(stream, errored)\n    }\n    if (readable && !readableFinished && isReadableNodeStream(stream, true)) {\n      if (!isReadableFinished(stream, false)) return callback.call(stream, new ERR_STREAM_PREMATURE_CLOSE())\n    }\n    if (writable && !writableFinished) {\n      if (!isWritableFinished(stream, false)) return callback.call(stream, new ERR_STREAM_PREMATURE_CLOSE())\n    }\n    callback.call(stream)\n  }\n  const onclosed = () => {\n    closed = true\n    const errored = isWritableErrored(stream) || isReadableErrored(stream)\n    if (errored && typeof errored !== 'boolean') {\n      return callback.call(stream, errored)\n    }\n    callback.call(stream)\n  }\n  const onrequest = () => {\n    stream.req.on('finish', onfinish)\n  }\n  if (isRequest(stream)) {\n    stream.on('complete', onfinish)\n    if (!willEmitClose) {\n      stream.on('abort', onclose)\n    }\n    if (stream.req) {\n      onrequest()\n    } else {\n      stream.on('request', onrequest)\n    }\n  } else if (writable && !wState) {\n    // legacy streams\n    stream.on('end', onlegacyfinish)\n    stream.on('close', onlegacyfinish)\n  }\n\n  // Not all streams will emit 'close' after 'aborted'.\n  if (!willEmitClose && typeof stream.aborted === 'boolean') {\n    stream.on('aborted', onclose)\n  }\n  stream.on('end', onend)\n  stream.on('finish', onfinish)\n  if (options.error !== false) {\n    stream.on('error', onerror)\n  }\n  stream.on('close', onclose)\n  if (closed) {\n    process.nextTick(onclose)\n  } else if (\n    (wState !== null && wState !== undefined && wState.errorEmitted) ||\n    (rState !== null && rState !== undefined && rState.errorEmitted)\n  ) {\n    if (!willEmitClose) {\n      process.nextTick(onclosed)\n    }\n  } else if (\n    !readable &&\n    (!willEmitClose || isReadable(stream)) &&\n    (writableFinished || isWritable(stream) === false)\n  ) {\n    process.nextTick(onclosed)\n  } else if (\n    !writable &&\n    (!willEmitClose || isWritable(stream)) &&\n    (readableFinished || isReadable(stream) === false)\n  ) {\n    process.nextTick(onclosed)\n  } else if (rState && stream.req && stream.aborted) {\n    process.nextTick(onclosed)\n  }\n  const cleanup = () => {\n    callback = nop\n    stream.removeListener('aborted', onclose)\n    stream.removeListener('complete', onfinish)\n    stream.removeListener('abort', onclose)\n    stream.removeListener('request', onrequest)\n    if (stream.req) stream.req.removeListener('finish', onfinish)\n    stream.removeListener('end', onlegacyfinish)\n    stream.removeListener('close', onlegacyfinish)\n    stream.removeListener('finish', onfinish)\n    stream.removeListener('end', onend)\n    stream.removeListener('error', onerror)\n    stream.removeListener('close', onclose)\n  }\n  if (options.signal && !closed) {\n    const abort = () => {\n      // Keep it because cleanup removes it.\n      const endCallback = callback\n      cleanup()\n      endCallback.call(\n        stream,\n        new AbortError(undefined, {\n          cause: options.signal.reason\n        })\n      )\n    }\n    if (options.signal.aborted) {\n      process.nextTick(abort)\n    } else {\n      addAbortListener = addAbortListener || (__webpack_require__(/*! ../../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\").addAbortListener)\n      const disposable = addAbortListener(options.signal, abort)\n      const originalCallback = callback\n      callback = once((...args) => {\n        disposable[SymbolDispose]()\n        originalCallback.apply(stream, args)\n      })\n    }\n  }\n  return cleanup\n}\nfunction eosWeb(stream, options, callback) {\n  let isAborted = false\n  let abort = nop\n  if (options.signal) {\n    abort = () => {\n      isAborted = true\n      callback.call(\n        stream,\n        new AbortError(undefined, {\n          cause: options.signal.reason\n        })\n      )\n    }\n    if (options.signal.aborted) {\n      process.nextTick(abort)\n    } else {\n      addAbortListener = addAbortListener || (__webpack_require__(/*! ../../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\").addAbortListener)\n      const disposable = addAbortListener(options.signal, abort)\n      const originalCallback = callback\n      callback = once((...args) => {\n        disposable[SymbolDispose]()\n        originalCallback.apply(stream, args)\n      })\n    }\n  }\n  const resolverFn = (...args) => {\n    if (!isAborted) {\n      process.nextTick(() => callback.apply(stream, args))\n    }\n  }\n  PromisePrototypeThen(stream[kIsClosedPromise].promise, resolverFn, resolverFn)\n  return nop\n}\nfunction finished(stream, opts) {\n  var _opts\n  let autoCleanup = false\n  if (opts === null) {\n    opts = kEmptyObject\n  }\n  if ((_opts = opts) !== null && _opts !== undefined && _opts.cleanup) {\n    validateBoolean(opts.cleanup, 'cleanup')\n    autoCleanup = opts.cleanup\n  }\n  return new Promise((resolve, reject) => {\n    const cleanup = eos(stream, opts, (err) => {\n      if (autoCleanup) {\n        cleanup()\n      }\n      if (err) {\n        reject(err)\n      } else {\n        resolve()\n      }\n    })\n  })\n}\nmodule.exports = eos\nmodule.exports.finished = finished\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/end-of-stream.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/from.js":
/*!*******************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/from.js ***!
  \*******************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/* replacement start */\n\nconst process = __webpack_require__(/*! process/ */ \"./node_modules/process/browser.js\")\n\n/* replacement end */\n\nconst { PromisePrototypeThen, SymbolAsyncIterator, SymbolIterator } = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst { Buffer } = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\nconst { ERR_INVALID_ARG_TYPE, ERR_STREAM_NULL_VALUES } = (__webpack_require__(/*! ../../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\").codes)\nfunction from(Readable, iterable, opts) {\n  let iterator\n  if (typeof iterable === 'string' || iterable instanceof Buffer) {\n    return new Readable({\n      objectMode: true,\n      ...opts,\n      read() {\n        this.push(iterable)\n        this.push(null)\n      }\n    })\n  }\n  let isAsync\n  if (iterable && iterable[SymbolAsyncIterator]) {\n    isAsync = true\n    iterator = iterable[SymbolAsyncIterator]()\n  } else if (iterable && iterable[SymbolIterator]) {\n    isAsync = false\n    iterator = iterable[SymbolIterator]()\n  } else {\n    throw new ERR_INVALID_ARG_TYPE('iterable', ['Iterable'], iterable)\n  }\n  const readable = new Readable({\n    objectMode: true,\n    highWaterMark: 1,\n    // TODO(ronag): What options should be allowed?\n    ...opts\n  })\n\n  // Flag to protect against _read\n  // being called before last iteration completion.\n  let reading = false\n  readable._read = function () {\n    if (!reading) {\n      reading = true\n      next()\n    }\n  }\n  readable._destroy = function (error, cb) {\n    PromisePrototypeThen(\n      close(error),\n      () => process.nextTick(cb, error),\n      // nextTick is here in case cb throws\n      (e) => process.nextTick(cb, e || error)\n    )\n  }\n  async function close(error) {\n    const hadError = error !== undefined && error !== null\n    const hasThrow = typeof iterator.throw === 'function'\n    if (hadError && hasThrow) {\n      const { value, done } = await iterator.throw(error)\n      await value\n      if (done) {\n        return\n      }\n    }\n    if (typeof iterator.return === 'function') {\n      const { value } = await iterator.return()\n      await value\n    }\n  }\n  async function next() {\n    for (;;) {\n      try {\n        const { value, done } = isAsync ? await iterator.next() : iterator.next()\n        if (done) {\n          readable.push(null)\n        } else {\n          const res = value && typeof value.then === 'function' ? await value : value\n          if (res === null) {\n            reading = false\n            throw new ERR_STREAM_NULL_VALUES()\n          } else if (readable.push(res)) {\n            continue\n          } else {\n            reading = false\n          }\n        }\n      } catch (err) {\n        readable.destroy(err)\n      }\n      break\n    }\n  }\n  return readable\n}\nmodule.exports = from\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/from.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/legacy.js":
/*!*********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/legacy.js ***!
  \*********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { ArrayIsArray, ObjectSetPrototypeOf } = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst { EventEmitter: EE } = __webpack_require__(/*! events */ \"./node_modules/events/events.js\")\nfunction Stream(opts) {\n  EE.call(this, opts)\n}\nObjectSetPrototypeOf(Stream.prototype, EE.prototype)\nObjectSetPrototypeOf(Stream, EE)\nStream.prototype.pipe = function (dest, options) {\n  const source = this\n  function ondata(chunk) {\n    if (dest.writable && dest.write(chunk) === false && source.pause) {\n      source.pause()\n    }\n  }\n  source.on('data', ondata)\n  function ondrain() {\n    if (source.readable && source.resume) {\n      source.resume()\n    }\n  }\n  dest.on('drain', ondrain)\n\n  // If the 'end' option is not supplied, dest.end() will be called when\n  // source gets the 'end' or 'close' events.  Only dest.end() once.\n  if (!dest._isStdio && (!options || options.end !== false)) {\n    source.on('end', onend)\n    source.on('close', onclose)\n  }\n  let didOnEnd = false\n  function onend() {\n    if (didOnEnd) return\n    didOnEnd = true\n    dest.end()\n  }\n  function onclose() {\n    if (didOnEnd) return\n    didOnEnd = true\n    if (typeof dest.destroy === 'function') dest.destroy()\n  }\n\n  // Don't leave dangling pipes when there are errors.\n  function onerror(er) {\n    cleanup()\n    if (EE.listenerCount(this, 'error') === 0) {\n      this.emit('error', er)\n    }\n  }\n  prependListener(source, 'error', onerror)\n  prependListener(dest, 'error', onerror)\n\n  // Remove all the event listeners that were added.\n  function cleanup() {\n    source.removeListener('data', ondata)\n    dest.removeListener('drain', ondrain)\n    source.removeListener('end', onend)\n    source.removeListener('close', onclose)\n    source.removeListener('error', onerror)\n    dest.removeListener('error', onerror)\n    source.removeListener('end', cleanup)\n    source.removeListener('close', cleanup)\n    dest.removeListener('close', cleanup)\n  }\n  source.on('end', cleanup)\n  source.on('close', cleanup)\n  dest.on('close', cleanup)\n  dest.emit('pipe', source)\n\n  // Allow for unix-like usage: A.pipe(B).pipe(C)\n  return dest\n}\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn)\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn)\n  else if (ArrayIsArray(emitter._events[event])) emitter._events[event].unshift(fn)\n  else emitter._events[event] = [fn, emitter._events[event]]\n}\nmodule.exports = {\n  Stream,\n  prependListener\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/legacy.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/operators.js":
/*!************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/operators.js ***!
  \************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst AbortController = globalThis.AbortController || (__webpack_require__(/*! abort-controller */ \"./node_modules/abort-controller/browser.js\").AbortController)\nconst {\n  codes: { ERR_INVALID_ARG_VALUE, ERR_INVALID_ARG_TYPE, ERR_MISSING_ARGS, ERR_OUT_OF_RANGE },\n  AbortError\n} = __webpack_require__(/*! ../../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\")\nconst { validateAbortSignal, validateInteger, validateObject } = __webpack_require__(/*! ../validators */ \"./node_modules/readable-stream/lib/internal/validators.js\")\nconst kWeakHandler = (__webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\").Symbol)('kWeak')\nconst kResistStopPropagation = (__webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\").Symbol)('kResistStopPropagation')\nconst { finished } = __webpack_require__(/*! ./end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\")\nconst staticCompose = __webpack_require__(/*! ./compose */ \"./node_modules/readable-stream/lib/internal/streams/compose.js\")\nconst { addAbortSignalNoValidate } = __webpack_require__(/*! ./add-abort-signal */ \"./node_modules/readable-stream/lib/internal/streams/add-abort-signal.js\")\nconst { isWritable, isNodeStream } = __webpack_require__(/*! ./utils */ \"./node_modules/readable-stream/lib/internal/streams/utils.js\")\nconst { deprecate } = __webpack_require__(/*! ../../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\")\nconst {\n  ArrayPrototypePush,\n  Boolean,\n  MathFloor,\n  Number,\n  NumberIsNaN,\n  Promise,\n  PromiseReject,\n  PromiseResolve,\n  PromisePrototypeThen,\n  Symbol\n} = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst kEmpty = Symbol('kEmpty')\nconst kEof = Symbol('kEof')\nfunction compose(stream, options) {\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  if (isNodeStream(stream) && !isWritable(stream)) {\n    throw new ERR_INVALID_ARG_VALUE('stream', stream, 'must be writable')\n  }\n  const composedStream = staticCompose(this, stream)\n  if (options !== null && options !== undefined && options.signal) {\n    // Not validating as we already validated before\n    addAbortSignalNoValidate(options.signal, composedStream)\n  }\n  return composedStream\n}\nfunction map(fn, options) {\n  if (typeof fn !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)\n  }\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  let concurrency = 1\n  if ((options === null || options === undefined ? undefined : options.concurrency) != null) {\n    concurrency = MathFloor(options.concurrency)\n  }\n  let highWaterMark = concurrency - 1\n  if ((options === null || options === undefined ? undefined : options.highWaterMark) != null) {\n    highWaterMark = MathFloor(options.highWaterMark)\n  }\n  validateInteger(concurrency, 'options.concurrency', 1)\n  validateInteger(highWaterMark, 'options.highWaterMark', 0)\n  highWaterMark += concurrency\n  return async function* map() {\n    const signal = (__webpack_require__(/*! ../../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\").AbortSignalAny)(\n      [options === null || options === undefined ? undefined : options.signal].filter(Boolean)\n    )\n    const stream = this\n    const queue = []\n    const signalOpt = {\n      signal\n    }\n    let next\n    let resume\n    let done = false\n    let cnt = 0\n    function onCatch() {\n      done = true\n      afterItemProcessed()\n    }\n    function afterItemProcessed() {\n      cnt -= 1\n      maybeResume()\n    }\n    function maybeResume() {\n      if (resume && !done && cnt < concurrency && queue.length < highWaterMark) {\n        resume()\n        resume = null\n      }\n    }\n    async function pump() {\n      try {\n        for await (let val of stream) {\n          if (done) {\n            return\n          }\n          if (signal.aborted) {\n            throw new AbortError()\n          }\n          try {\n            val = fn(val, signalOpt)\n            if (val === kEmpty) {\n              continue\n            }\n            val = PromiseResolve(val)\n          } catch (err) {\n            val = PromiseReject(err)\n          }\n          cnt += 1\n          PromisePrototypeThen(val, afterItemProcessed, onCatch)\n          queue.push(val)\n          if (next) {\n            next()\n            next = null\n          }\n          if (!done && (queue.length >= highWaterMark || cnt >= concurrency)) {\n            await new Promise((resolve) => {\n              resume = resolve\n            })\n          }\n        }\n        queue.push(kEof)\n      } catch (err) {\n        const val = PromiseReject(err)\n        PromisePrototypeThen(val, afterItemProcessed, onCatch)\n        queue.push(val)\n      } finally {\n        done = true\n        if (next) {\n          next()\n          next = null\n        }\n      }\n    }\n    pump()\n    try {\n      while (true) {\n        while (queue.length > 0) {\n          const val = await queue[0]\n          if (val === kEof) {\n            return\n          }\n          if (signal.aborted) {\n            throw new AbortError()\n          }\n          if (val !== kEmpty) {\n            yield val\n          }\n          queue.shift()\n          maybeResume()\n        }\n        await new Promise((resolve) => {\n          next = resolve\n        })\n      }\n    } finally {\n      done = true\n      if (resume) {\n        resume()\n        resume = null\n      }\n    }\n  }.call(this)\n}\nfunction asIndexedPairs(options = undefined) {\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  return async function* asIndexedPairs() {\n    let index = 0\n    for await (const val of this) {\n      var _options$signal\n      if (\n        options !== null &&\n        options !== undefined &&\n        (_options$signal = options.signal) !== null &&\n        _options$signal !== undefined &&\n        _options$signal.aborted\n      ) {\n        throw new AbortError({\n          cause: options.signal.reason\n        })\n      }\n      yield [index++, val]\n    }\n  }.call(this)\n}\nasync function some(fn, options = undefined) {\n  for await (const unused of filter.call(this, fn, options)) {\n    return true\n  }\n  return false\n}\nasync function every(fn, options = undefined) {\n  if (typeof fn !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)\n  }\n  // https://en.wikipedia.org/wiki/De_Morgan%27s_laws\n  return !(await some.call(\n    this,\n    async (...args) => {\n      return !(await fn(...args))\n    },\n    options\n  ))\n}\nasync function find(fn, options) {\n  for await (const result of filter.call(this, fn, options)) {\n    return result\n  }\n  return undefined\n}\nasync function forEach(fn, options) {\n  if (typeof fn !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)\n  }\n  async function forEachFn(value, options) {\n    await fn(value, options)\n    return kEmpty\n  }\n  // eslint-disable-next-line no-unused-vars\n  for await (const unused of map.call(this, forEachFn, options));\n}\nfunction filter(fn, options) {\n  if (typeof fn !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)\n  }\n  async function filterFn(value, options) {\n    if (await fn(value, options)) {\n      return value\n    }\n    return kEmpty\n  }\n  return map.call(this, filterFn, options)\n}\n\n// Specific to provide better error to reduce since the argument is only\n// missing if the stream has no items in it - but the code is still appropriate\nclass ReduceAwareErrMissingArgs extends ERR_MISSING_ARGS {\n  constructor() {\n    super('reduce')\n    this.message = 'Reduce of an empty stream requires an initial value'\n  }\n}\nasync function reduce(reducer, initialValue, options) {\n  var _options$signal2\n  if (typeof reducer !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE('reducer', ['Function', 'AsyncFunction'], reducer)\n  }\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  let hasInitialValue = arguments.length > 1\n  if (\n    options !== null &&\n    options !== undefined &&\n    (_options$signal2 = options.signal) !== null &&\n    _options$signal2 !== undefined &&\n    _options$signal2.aborted\n  ) {\n    const err = new AbortError(undefined, {\n      cause: options.signal.reason\n    })\n    this.once('error', () => {}) // The error is already propagated\n    await finished(this.destroy(err))\n    throw err\n  }\n  const ac = new AbortController()\n  const signal = ac.signal\n  if (options !== null && options !== undefined && options.signal) {\n    const opts = {\n      once: true,\n      [kWeakHandler]: this,\n      [kResistStopPropagation]: true\n    }\n    options.signal.addEventListener('abort', () => ac.abort(), opts)\n  }\n  let gotAnyItemFromStream = false\n  try {\n    for await (const value of this) {\n      var _options$signal3\n      gotAnyItemFromStream = true\n      if (\n        options !== null &&\n        options !== undefined &&\n        (_options$signal3 = options.signal) !== null &&\n        _options$signal3 !== undefined &&\n        _options$signal3.aborted\n      ) {\n        throw new AbortError()\n      }\n      if (!hasInitialValue) {\n        initialValue = value\n        hasInitialValue = true\n      } else {\n        initialValue = await reducer(initialValue, value, {\n          signal\n        })\n      }\n    }\n    if (!gotAnyItemFromStream && !hasInitialValue) {\n      throw new ReduceAwareErrMissingArgs()\n    }\n  } finally {\n    ac.abort()\n  }\n  return initialValue\n}\nasync function toArray(options) {\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  const result = []\n  for await (const val of this) {\n    var _options$signal4\n    if (\n      options !== null &&\n      options !== undefined &&\n      (_options$signal4 = options.signal) !== null &&\n      _options$signal4 !== undefined &&\n      _options$signal4.aborted\n    ) {\n      throw new AbortError(undefined, {\n        cause: options.signal.reason\n      })\n    }\n    ArrayPrototypePush(result, val)\n  }\n  return result\n}\nfunction flatMap(fn, options) {\n  const values = map.call(this, fn, options)\n  return async function* flatMap() {\n    for await (const val of values) {\n      yield* val\n    }\n  }.call(this)\n}\nfunction toIntegerOrInfinity(number) {\n  // We coerce here to align with the spec\n  // https://github.com/tc39/proposal-iterator-helpers/issues/169\n  number = Number(number)\n  if (NumberIsNaN(number)) {\n    return 0\n  }\n  if (number < 0) {\n    throw new ERR_OUT_OF_RANGE('number', '>= 0', number)\n  }\n  return number\n}\nfunction drop(number, options = undefined) {\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  number = toIntegerOrInfinity(number)\n  return async function* drop() {\n    var _options$signal5\n    if (\n      options !== null &&\n      options !== undefined &&\n      (_options$signal5 = options.signal) !== null &&\n      _options$signal5 !== undefined &&\n      _options$signal5.aborted\n    ) {\n      throw new AbortError()\n    }\n    for await (const val of this) {\n      var _options$signal6\n      if (\n        options !== null &&\n        options !== undefined &&\n        (_options$signal6 = options.signal) !== null &&\n        _options$signal6 !== undefined &&\n        _options$signal6.aborted\n      ) {\n        throw new AbortError()\n      }\n      if (number-- <= 0) {\n        yield val\n      }\n    }\n  }.call(this)\n}\nfunction take(number, options = undefined) {\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  number = toIntegerOrInfinity(number)\n  return async function* take() {\n    var _options$signal7\n    if (\n      options !== null &&\n      options !== undefined &&\n      (_options$signal7 = options.signal) !== null &&\n      _options$signal7 !== undefined &&\n      _options$signal7.aborted\n    ) {\n      throw new AbortError()\n    }\n    for await (const val of this) {\n      var _options$signal8\n      if (\n        options !== null &&\n        options !== undefined &&\n        (_options$signal8 = options.signal) !== null &&\n        _options$signal8 !== undefined &&\n        _options$signal8.aborted\n      ) {\n        throw new AbortError()\n      }\n      if (number-- > 0) {\n        yield val\n      }\n\n      // Don't get another item from iterator in case we reached the end\n      if (number <= 0) {\n        return\n      }\n    }\n  }.call(this)\n}\nmodule.exports.streamReturningOperators = {\n  asIndexedPairs: deprecate(asIndexedPairs, 'readable.asIndexedPairs will be removed in a future version.'),\n  drop,\n  filter,\n  flatMap,\n  map,\n  take,\n  compose\n}\nmodule.exports.promiseReturningOperators = {\n  every,\n  forEach,\n  reduce,\n  toArray,\n  some,\n  find\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/operators.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/passthrough.js":
/*!**************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/passthrough.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n\n\nconst { ObjectSetPrototypeOf } = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nmodule.exports = PassThrough\nconst Transform = __webpack_require__(/*! ./transform */ \"./node_modules/readable-stream/lib/internal/streams/transform.js\")\nObjectSetPrototypeOf(PassThrough.prototype, Transform.prototype)\nObjectSetPrototypeOf(PassThrough, Transform)\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options)\n  Transform.call(this, options)\n}\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk)\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/passthrough.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/pipeline.js":
/*!***********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/pipeline.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* replacement start */\n\nconst process = __webpack_require__(/*! process/ */ \"./node_modules/process/browser.js\")\n\n/* replacement end */\n// Ported from https://github.com/mafintosh/pump with\n// permission from the author, Mathias Buus (@mafintosh).\n\n;('use strict')\nconst { ArrayIsArray, Promise, SymbolAsyncIterator, SymbolDispose } = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst eos = __webpack_require__(/*! ./end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\")\nconst { once } = __webpack_require__(/*! ../../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\")\nconst destroyImpl = __webpack_require__(/*! ./destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\")\nconst Duplex = __webpack_require__(/*! ./duplex */ \"./node_modules/readable-stream/lib/internal/streams/duplex.js\")\nconst {\n  aggregateTwoErrors,\n  codes: {\n    ERR_INVALID_ARG_TYPE,\n    ERR_INVALID_RETURN_VALUE,\n    ERR_MISSING_ARGS,\n    ERR_STREAM_DESTROYED,\n    ERR_STREAM_PREMATURE_CLOSE\n  },\n  AbortError\n} = __webpack_require__(/*! ../../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\")\nconst { validateFunction, validateAbortSignal } = __webpack_require__(/*! ../validators */ \"./node_modules/readable-stream/lib/internal/validators.js\")\nconst {\n  isIterable,\n  isReadable,\n  isReadableNodeStream,\n  isNodeStream,\n  isTransformStream,\n  isWebStream,\n  isReadableStream,\n  isReadableFinished\n} = __webpack_require__(/*! ./utils */ \"./node_modules/readable-stream/lib/internal/streams/utils.js\")\nconst AbortController = globalThis.AbortController || (__webpack_require__(/*! abort-controller */ \"./node_modules/abort-controller/browser.js\").AbortController)\nlet PassThrough\nlet Readable\nlet addAbortListener\nfunction destroyer(stream, reading, writing) {\n  let finished = false\n  stream.on('close', () => {\n    finished = true\n  })\n  const cleanup = eos(\n    stream,\n    {\n      readable: reading,\n      writable: writing\n    },\n    (err) => {\n      finished = !err\n    }\n  )\n  return {\n    destroy: (err) => {\n      if (finished) return\n      finished = true\n      destroyImpl.destroyer(stream, err || new ERR_STREAM_DESTROYED('pipe'))\n    },\n    cleanup\n  }\n}\nfunction popCallback(streams) {\n  // Streams should never be an empty array. It should always contain at least\n  // a single stream. Therefore optimize for the average case instead of\n  // checking for length === 0 as well.\n  validateFunction(streams[streams.length - 1], 'streams[stream.length - 1]')\n  return streams.pop()\n}\nfunction makeAsyncIterable(val) {\n  if (isIterable(val)) {\n    return val\n  } else if (isReadableNodeStream(val)) {\n    // Legacy streams are not Iterable.\n    return fromReadable(val)\n  }\n  throw new ERR_INVALID_ARG_TYPE('val', ['Readable', 'Iterable', 'AsyncIterable'], val)\n}\nasync function* fromReadable(val) {\n  if (!Readable) {\n    Readable = __webpack_require__(/*! ./readable */ \"./node_modules/readable-stream/lib/internal/streams/readable.js\")\n  }\n  yield* Readable.prototype[SymbolAsyncIterator].call(val)\n}\nasync function pumpToNode(iterable, writable, finish, { end }) {\n  let error\n  let onresolve = null\n  const resume = (err) => {\n    if (err) {\n      error = err\n    }\n    if (onresolve) {\n      const callback = onresolve\n      onresolve = null\n      callback()\n    }\n  }\n  const wait = () =>\n    new Promise((resolve, reject) => {\n      if (error) {\n        reject(error)\n      } else {\n        onresolve = () => {\n          if (error) {\n            reject(error)\n          } else {\n            resolve()\n          }\n        }\n      }\n    })\n  writable.on('drain', resume)\n  const cleanup = eos(\n    writable,\n    {\n      readable: false\n    },\n    resume\n  )\n  try {\n    if (writable.writableNeedDrain) {\n      await wait()\n    }\n    for await (const chunk of iterable) {\n      if (!writable.write(chunk)) {\n        await wait()\n      }\n    }\n    if (end) {\n      writable.end()\n      await wait()\n    }\n    finish()\n  } catch (err) {\n    finish(error !== err ? aggregateTwoErrors(error, err) : err)\n  } finally {\n    cleanup()\n    writable.off('drain', resume)\n  }\n}\nasync function pumpToWeb(readable, writable, finish, { end }) {\n  if (isTransformStream(writable)) {\n    writable = writable.writable\n  }\n  // https://streams.spec.whatwg.org/#example-manual-write-with-backpressure\n  const writer = writable.getWriter()\n  try {\n    for await (const chunk of readable) {\n      await writer.ready\n      writer.write(chunk).catch(() => {})\n    }\n    await writer.ready\n    if (end) {\n      await writer.close()\n    }\n    finish()\n  } catch (err) {\n    try {\n      await writer.abort(err)\n      finish(err)\n    } catch (err) {\n      finish(err)\n    }\n  }\n}\nfunction pipeline(...streams) {\n  return pipelineImpl(streams, once(popCallback(streams)))\n}\nfunction pipelineImpl(streams, callback, opts) {\n  if (streams.length === 1 && ArrayIsArray(streams[0])) {\n    streams = streams[0]\n  }\n  if (streams.length < 2) {\n    throw new ERR_MISSING_ARGS('streams')\n  }\n  const ac = new AbortController()\n  const signal = ac.signal\n  const outerSignal = opts === null || opts === undefined ? undefined : opts.signal\n\n  // Need to cleanup event listeners if last stream is readable\n  // https://github.com/nodejs/node/issues/35452\n  const lastStreamCleanup = []\n  validateAbortSignal(outerSignal, 'options.signal')\n  function abort() {\n    finishImpl(new AbortError())\n  }\n  addAbortListener = addAbortListener || (__webpack_require__(/*! ../../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\").addAbortListener)\n  let disposable\n  if (outerSignal) {\n    disposable = addAbortListener(outerSignal, abort)\n  }\n  let error\n  let value\n  const destroys = []\n  let finishCount = 0\n  function finish(err) {\n    finishImpl(err, --finishCount === 0)\n  }\n  function finishImpl(err, final) {\n    var _disposable\n    if (err && (!error || error.code === 'ERR_STREAM_PREMATURE_CLOSE')) {\n      error = err\n    }\n    if (!error && !final) {\n      return\n    }\n    while (destroys.length) {\n      destroys.shift()(error)\n    }\n    ;(_disposable = disposable) === null || _disposable === undefined ? undefined : _disposable[SymbolDispose]()\n    ac.abort()\n    if (final) {\n      if (!error) {\n        lastStreamCleanup.forEach((fn) => fn())\n      }\n      process.nextTick(callback, error, value)\n    }\n  }\n  let ret\n  for (let i = 0; i < streams.length; i++) {\n    const stream = streams[i]\n    const reading = i < streams.length - 1\n    const writing = i > 0\n    const end = reading || (opts === null || opts === undefined ? undefined : opts.end) !== false\n    const isLastStream = i === streams.length - 1\n    if (isNodeStream(stream)) {\n      if (end) {\n        const { destroy, cleanup } = destroyer(stream, reading, writing)\n        destroys.push(destroy)\n        if (isReadable(stream) && isLastStream) {\n          lastStreamCleanup.push(cleanup)\n        }\n      }\n\n      // Catch stream errors that occur after pipe/pump has completed.\n      function onError(err) {\n        if (err && err.name !== 'AbortError' && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {\n          finish(err)\n        }\n      }\n      stream.on('error', onError)\n      if (isReadable(stream) && isLastStream) {\n        lastStreamCleanup.push(() => {\n          stream.removeListener('error', onError)\n        })\n      }\n    }\n    if (i === 0) {\n      if (typeof stream === 'function') {\n        ret = stream({\n          signal\n        })\n        if (!isIterable(ret)) {\n          throw new ERR_INVALID_RETURN_VALUE('Iterable, AsyncIterable or Stream', 'source', ret)\n        }\n      } else if (isIterable(stream) || isReadableNodeStream(stream) || isTransformStream(stream)) {\n        ret = stream\n      } else {\n        ret = Duplex.from(stream)\n      }\n    } else if (typeof stream === 'function') {\n      if (isTransformStream(ret)) {\n        var _ret\n        ret = makeAsyncIterable((_ret = ret) === null || _ret === undefined ? undefined : _ret.readable)\n      } else {\n        ret = makeAsyncIterable(ret)\n      }\n      ret = stream(ret, {\n        signal\n      })\n      if (reading) {\n        if (!isIterable(ret, true)) {\n          throw new ERR_INVALID_RETURN_VALUE('AsyncIterable', `transform[${i - 1}]`, ret)\n        }\n      } else {\n        var _ret2\n        if (!PassThrough) {\n          PassThrough = __webpack_require__(/*! ./passthrough */ \"./node_modules/readable-stream/lib/internal/streams/passthrough.js\")\n        }\n\n        // If the last argument to pipeline is not a stream\n        // we must create a proxy stream so that pipeline(...)\n        // always returns a stream which can be further\n        // composed through `.pipe(stream)`.\n\n        const pt = new PassThrough({\n          objectMode: true\n        })\n\n        // Handle Promises/A+ spec, `then` could be a getter that throws on\n        // second use.\n        const then = (_ret2 = ret) === null || _ret2 === undefined ? undefined : _ret2.then\n        if (typeof then === 'function') {\n          finishCount++\n          then.call(\n            ret,\n            (val) => {\n              value = val\n              if (val != null) {\n                pt.write(val)\n              }\n              if (end) {\n                pt.end()\n              }\n              process.nextTick(finish)\n            },\n            (err) => {\n              pt.destroy(err)\n              process.nextTick(finish, err)\n            }\n          )\n        } else if (isIterable(ret, true)) {\n          finishCount++\n          pumpToNode(ret, pt, finish, {\n            end\n          })\n        } else if (isReadableStream(ret) || isTransformStream(ret)) {\n          const toRead = ret.readable || ret\n          finishCount++\n          pumpToNode(toRead, pt, finish, {\n            end\n          })\n        } else {\n          throw new ERR_INVALID_RETURN_VALUE('AsyncIterable or Promise', 'destination', ret)\n        }\n        ret = pt\n        const { destroy, cleanup } = destroyer(ret, false, true)\n        destroys.push(destroy)\n        if (isLastStream) {\n          lastStreamCleanup.push(cleanup)\n        }\n      }\n    } else if (isNodeStream(stream)) {\n      if (isReadableNodeStream(ret)) {\n        finishCount += 2\n        const cleanup = pipe(ret, stream, finish, {\n          end\n        })\n        if (isReadable(stream) && isLastStream) {\n          lastStreamCleanup.push(cleanup)\n        }\n      } else if (isTransformStream(ret) || isReadableStream(ret)) {\n        const toRead = ret.readable || ret\n        finishCount++\n        pumpToNode(toRead, stream, finish, {\n          end\n        })\n      } else if (isIterable(ret)) {\n        finishCount++\n        pumpToNode(ret, stream, finish, {\n          end\n        })\n      } else {\n        throw new ERR_INVALID_ARG_TYPE(\n          'val',\n          ['Readable', 'Iterable', 'AsyncIterable', 'ReadableStream', 'TransformStream'],\n          ret\n        )\n      }\n      ret = stream\n    } else if (isWebStream(stream)) {\n      if (isReadableNodeStream(ret)) {\n        finishCount++\n        pumpToWeb(makeAsyncIterable(ret), stream, finish, {\n          end\n        })\n      } else if (isReadableStream(ret) || isIterable(ret)) {\n        finishCount++\n        pumpToWeb(ret, stream, finish, {\n          end\n        })\n      } else if (isTransformStream(ret)) {\n        finishCount++\n        pumpToWeb(ret.readable, stream, finish, {\n          end\n        })\n      } else {\n        throw new ERR_INVALID_ARG_TYPE(\n          'val',\n          ['Readable', 'Iterable', 'AsyncIterable', 'ReadableStream', 'TransformStream'],\n          ret\n        )\n      }\n      ret = stream\n    } else {\n      ret = Duplex.from(stream)\n    }\n  }\n  if (\n    (signal !== null && signal !== undefined && signal.aborted) ||\n    (outerSignal !== null && outerSignal !== undefined && outerSignal.aborted)\n  ) {\n    process.nextTick(abort)\n  }\n  return ret\n}\nfunction pipe(src, dst, finish, { end }) {\n  let ended = false\n  dst.on('close', () => {\n    if (!ended) {\n      // Finish if the destination closes before the source has completed.\n      finish(new ERR_STREAM_PREMATURE_CLOSE())\n    }\n  })\n  src.pipe(dst, {\n    end: false\n  }) // If end is true we already will have a listener to end dst.\n\n  if (end) {\n    // Compat. Before node v10.12.0 stdio used to throw an error so\n    // pipe() did/does not end() stdio destinations.\n    // Now they allow it but \"secretly\" don't close the underlying fd.\n\n    function endFn() {\n      ended = true\n      dst.end()\n    }\n    if (isReadableFinished(src)) {\n      // End the destination if the source has already ended.\n      process.nextTick(endFn)\n    } else {\n      src.once('end', endFn)\n    }\n  } else {\n    finish()\n  }\n  eos(\n    src,\n    {\n      readable: true,\n      writable: false\n    },\n    (err) => {\n      const rState = src._readableState\n      if (\n        err &&\n        err.code === 'ERR_STREAM_PREMATURE_CLOSE' &&\n        rState &&\n        rState.ended &&\n        !rState.errored &&\n        !rState.errorEmitted\n      ) {\n        // Some readable streams will emit 'close' before 'end'. However, since\n        // this is on the readable side 'end' should still be emitted if the\n        // stream has been ended and no error emitted. This should be allowed in\n        // favor of backwards compatibility. Since the stream is piped to a\n        // destination this should not result in any observable difference.\n        // We don't need to check if this is a writable premature close since\n        // eos will only fail with premature close on the reading side for\n        // duplex streams.\n        src.once('end', finish).once('error', finish)\n      } else {\n        finish(err)\n      }\n    }\n  )\n  return eos(\n    dst,\n    {\n      readable: false,\n      writable: true\n    },\n    finish\n  )\n}\nmodule.exports = {\n  pipelineImpl,\n  pipeline\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/pipeline.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/readable.js":
/*!***********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/readable.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* replacement start */\n\nconst process = __webpack_require__(/*! process/ */ \"./node_modules/process/browser.js\")\n\n/* replacement end */\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n;('use strict')\nconst {\n  ArrayPrototypeIndexOf,\n  NumberIsInteger,\n  NumberIsNaN,\n  NumberParseInt,\n  ObjectDefineProperties,\n  ObjectKeys,\n  ObjectSetPrototypeOf,\n  Promise,\n  SafeSet,\n  SymbolAsyncDispose,\n  SymbolAsyncIterator,\n  Symbol\n} = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nmodule.exports = Readable\nReadable.ReadableState = ReadableState\nconst { EventEmitter: EE } = __webpack_require__(/*! events */ \"./node_modules/events/events.js\")\nconst { Stream, prependListener } = __webpack_require__(/*! ./legacy */ \"./node_modules/readable-stream/lib/internal/streams/legacy.js\")\nconst { Buffer } = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\nconst { addAbortSignal } = __webpack_require__(/*! ./add-abort-signal */ \"./node_modules/readable-stream/lib/internal/streams/add-abort-signal.js\")\nconst eos = __webpack_require__(/*! ./end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\")\nlet debug = (__webpack_require__(/*! ../../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\").debuglog)('stream', (fn) => {\n  debug = fn\n})\nconst BufferList = __webpack_require__(/*! ./buffer_list */ \"./node_modules/readable-stream/lib/internal/streams/buffer_list.js\")\nconst destroyImpl = __webpack_require__(/*! ./destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\")\nconst { getHighWaterMark, getDefaultHighWaterMark } = __webpack_require__(/*! ./state */ \"./node_modules/readable-stream/lib/internal/streams/state.js\")\nconst {\n  aggregateTwoErrors,\n  codes: {\n    ERR_INVALID_ARG_TYPE,\n    ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_OUT_OF_RANGE,\n    ERR_STREAM_PUSH_AFTER_EOF,\n    ERR_STREAM_UNSHIFT_AFTER_END_EVENT\n  },\n  AbortError\n} = __webpack_require__(/*! ../../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\")\nconst { validateObject } = __webpack_require__(/*! ../validators */ \"./node_modules/readable-stream/lib/internal/validators.js\")\nconst kPaused = Symbol('kPaused')\nconst { StringDecoder } = __webpack_require__(/*! string_decoder */ \"./node_modules/string_decoder/lib/string_decoder.js\")\nconst from = __webpack_require__(/*! ./from */ \"./node_modules/readable-stream/lib/internal/streams/from.js\")\nObjectSetPrototypeOf(Readable.prototype, Stream.prototype)\nObjectSetPrototypeOf(Readable, Stream)\nconst nop = () => {}\nconst { errorOrDestroy } = destroyImpl\nconst kObjectMode = 1 << 0\nconst kEnded = 1 << 1\nconst kEndEmitted = 1 << 2\nconst kReading = 1 << 3\nconst kConstructed = 1 << 4\nconst kSync = 1 << 5\nconst kNeedReadable = 1 << 6\nconst kEmittedReadable = 1 << 7\nconst kReadableListening = 1 << 8\nconst kResumeScheduled = 1 << 9\nconst kErrorEmitted = 1 << 10\nconst kEmitClose = 1 << 11\nconst kAutoDestroy = 1 << 12\nconst kDestroyed = 1 << 13\nconst kClosed = 1 << 14\nconst kCloseEmitted = 1 << 15\nconst kMultiAwaitDrain = 1 << 16\nconst kReadingMore = 1 << 17\nconst kDataEmitted = 1 << 18\n\n// TODO(benjamingr) it is likely slower to do it this way than with free functions\nfunction makeBitMapDescriptor(bit) {\n  return {\n    enumerable: false,\n    get() {\n      return (this.state & bit) !== 0\n    },\n    set(value) {\n      if (value) this.state |= bit\n      else this.state &= ~bit\n    }\n  }\n}\nObjectDefineProperties(ReadableState.prototype, {\n  objectMode: makeBitMapDescriptor(kObjectMode),\n  ended: makeBitMapDescriptor(kEnded),\n  endEmitted: makeBitMapDescriptor(kEndEmitted),\n  reading: makeBitMapDescriptor(kReading),\n  // Stream is still being constructed and cannot be\n  // destroyed until construction finished or failed.\n  // Async construction is opt in, therefore we start as\n  // constructed.\n  constructed: makeBitMapDescriptor(kConstructed),\n  // A flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  sync: makeBitMapDescriptor(kSync),\n  // Whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  needReadable: makeBitMapDescriptor(kNeedReadable),\n  emittedReadable: makeBitMapDescriptor(kEmittedReadable),\n  readableListening: makeBitMapDescriptor(kReadableListening),\n  resumeScheduled: makeBitMapDescriptor(kResumeScheduled),\n  // True if the error was already emitted and should not be thrown again.\n  errorEmitted: makeBitMapDescriptor(kErrorEmitted),\n  emitClose: makeBitMapDescriptor(kEmitClose),\n  autoDestroy: makeBitMapDescriptor(kAutoDestroy),\n  // Has it been destroyed.\n  destroyed: makeBitMapDescriptor(kDestroyed),\n  // Indicates whether the stream has finished destroying.\n  closed: makeBitMapDescriptor(kClosed),\n  // True if close has been emitted or would have been emitted\n  // depending on emitClose.\n  closeEmitted: makeBitMapDescriptor(kCloseEmitted),\n  multiAwaitDrain: makeBitMapDescriptor(kMultiAwaitDrain),\n  // If true, a maybeReadMore has been scheduled.\n  readingMore: makeBitMapDescriptor(kReadingMore),\n  dataEmitted: makeBitMapDescriptor(kDataEmitted)\n})\nfunction ReadableState(options, stream, isDuplex) {\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof __webpack_require__(/*! ./duplex */ \"./node_modules/readable-stream/lib/internal/streams/duplex.js\")\n\n  // Bit map field to store ReadableState more effciently with 1 bit per field\n  // instead of a V8 slot per field.\n  this.state = kEmitClose | kAutoDestroy | kConstructed | kSync\n  // Object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away.\n  if (options && options.objectMode) this.state |= kObjectMode\n  if (isDuplex && options && options.readableObjectMode) this.state |= kObjectMode\n\n  // The point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  this.highWaterMark = options\n    ? getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex)\n    : getDefaultHighWaterMark(false)\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift().\n  this.buffer = new BufferList()\n  this.length = 0\n  this.pipes = []\n  this.flowing = null\n  this[kPaused] = null\n\n  // Should close be emitted on destroy. Defaults to true.\n  if (options && options.emitClose === false) this.state &= ~kEmitClose\n\n  // Should .destroy() be called after 'end' (and potentially 'finish').\n  if (options && options.autoDestroy === false) this.state &= ~kAutoDestroy\n\n  // Indicates whether the stream has errored. When true no further\n  // _read calls, 'data' or 'readable' events should occur. This is needed\n  // since when autoDestroy is disabled we need a way to tell whether the\n  // stream has failed.\n  this.errored = null\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = (options && options.defaultEncoding) || 'utf8'\n\n  // Ref the piped dest which we need a drain event on it\n  // type: null | Writable | Set<Writable>.\n  this.awaitDrainWriters = null\n  this.decoder = null\n  this.encoding = null\n  if (options && options.encoding) {\n    this.decoder = new StringDecoder(options.encoding)\n    this.encoding = options.encoding\n  }\n}\nfunction Readable(options) {\n  if (!(this instanceof Readable)) return new Readable(options)\n\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5.\n  const isDuplex = this instanceof __webpack_require__(/*! ./duplex */ \"./node_modules/readable-stream/lib/internal/streams/duplex.js\")\n  this._readableState = new ReadableState(options, this, isDuplex)\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read\n    if (typeof options.destroy === 'function') this._destroy = options.destroy\n    if (typeof options.construct === 'function') this._construct = options.construct\n    if (options.signal && !isDuplex) addAbortSignal(options.signal, this)\n  }\n  Stream.call(this, options)\n  destroyImpl.construct(this, () => {\n    if (this._readableState.needReadable) {\n      maybeReadMore(this, this._readableState)\n    }\n  })\n}\nReadable.prototype.destroy = destroyImpl.destroy\nReadable.prototype._undestroy = destroyImpl.undestroy\nReadable.prototype._destroy = function (err, cb) {\n  cb(err)\n}\nReadable.prototype[EE.captureRejectionSymbol] = function (err) {\n  this.destroy(err)\n}\nReadable.prototype[SymbolAsyncDispose] = function () {\n  let error\n  if (!this.destroyed) {\n    error = this.readableEnded ? null : new AbortError()\n    this.destroy(error)\n  }\n  return new Promise((resolve, reject) => eos(this, (err) => (err && err !== error ? reject(err) : resolve(null))))\n}\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  return readableAddChunk(this, chunk, encoding, false)\n}\n\n// Unshift should *always* be something directly out of read().\nReadable.prototype.unshift = function (chunk, encoding) {\n  return readableAddChunk(this, chunk, encoding, true)\n}\nfunction readableAddChunk(stream, chunk, encoding, addToFront) {\n  debug('readableAddChunk', chunk)\n  const state = stream._readableState\n  let err\n  if ((state.state & kObjectMode) === 0) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding\n      if (state.encoding !== encoding) {\n        if (addToFront && state.encoding) {\n          // When unshifting, if state.encoding is set, we have to save\n          // the string in the BufferList with the state encoding.\n          chunk = Buffer.from(chunk, encoding).toString(state.encoding)\n        } else {\n          chunk = Buffer.from(chunk, encoding)\n          encoding = ''\n        }\n      }\n    } else if (chunk instanceof Buffer) {\n      encoding = ''\n    } else if (Stream._isUint8Array(chunk)) {\n      chunk = Stream._uint8ArrayToBuffer(chunk)\n      encoding = ''\n    } else if (chunk != null) {\n      err = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk)\n    }\n  }\n  if (err) {\n    errorOrDestroy(stream, err)\n  } else if (chunk === null) {\n    state.state &= ~kReading\n    onEofChunk(stream, state)\n  } else if ((state.state & kObjectMode) !== 0 || (chunk && chunk.length > 0)) {\n    if (addToFront) {\n      if ((state.state & kEndEmitted) !== 0) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT())\n      else if (state.destroyed || state.errored) return false\n      else addChunk(stream, state, chunk, true)\n    } else if (state.ended) {\n      errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF())\n    } else if (state.destroyed || state.errored) {\n      return false\n    } else {\n      state.state &= ~kReading\n      if (state.decoder && !encoding) {\n        chunk = state.decoder.write(chunk)\n        if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false)\n        else maybeReadMore(stream, state)\n      } else {\n        addChunk(stream, state, chunk, false)\n      }\n    }\n  } else if (!addToFront) {\n    state.state &= ~kReading\n    maybeReadMore(stream, state)\n  }\n\n  // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0)\n}\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync && stream.listenerCount('data') > 0) {\n    // Use the guard to avoid creating `Set()` repeatedly\n    // when we have multiple pipes.\n    if ((state.state & kMultiAwaitDrain) !== 0) {\n      state.awaitDrainWriters.clear()\n    } else {\n      state.awaitDrainWriters = null\n    }\n    state.dataEmitted = true\n    stream.emit('data', chunk)\n  } else {\n    // Update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length\n    if (addToFront) state.buffer.unshift(chunk)\n    else state.buffer.push(chunk)\n    if ((state.state & kNeedReadable) !== 0) emitReadable(stream)\n  }\n  maybeReadMore(stream, state)\n}\nReadable.prototype.isPaused = function () {\n  const state = this._readableState\n  return state[kPaused] === true || state.flowing === false\n}\n\n// Backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  const decoder = new StringDecoder(enc)\n  this._readableState.decoder = decoder\n  // If setEncoding(null), decoder.encoding equals utf8.\n  this._readableState.encoding = this._readableState.decoder.encoding\n  const buffer = this._readableState.buffer\n  // Iterate over current buffer to convert already stored Buffers:\n  let content = ''\n  for (const data of buffer) {\n    content += decoder.write(data)\n  }\n  buffer.clear()\n  if (content !== '') buffer.push(content)\n  this._readableState.length = content.length\n  return this\n}\n\n// Don't raise the hwm > 1GB.\nconst MAX_HWM = 0x40000000\nfunction computeNewHighWaterMark(n) {\n  if (n > MAX_HWM) {\n    throw new ERR_OUT_OF_RANGE('size', '<= 1GiB', n)\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts.\n    n--\n    n |= n >>> 1\n    n |= n >>> 2\n    n |= n >>> 4\n    n |= n >>> 8\n    n |= n >>> 16\n    n++\n  }\n  return n\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || (state.length === 0 && state.ended)) return 0\n  if ((state.state & kObjectMode) !== 0) return 1\n  if (NumberIsNaN(n)) {\n    // Only flow one buffer at a time.\n    if (state.flowing && state.length) return state.buffer.first().length\n    return state.length\n  }\n  if (n <= state.length) return n\n  return state.ended ? state.length : 0\n}\n\n// You can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n)\n  // Same as parseInt(undefined, 10), however V8 7.3 performance regressed\n  // in this scenario, so we are doing it manually.\n  if (n === undefined) {\n    n = NaN\n  } else if (!NumberIsInteger(n)) {\n    n = NumberParseInt(n, 10)\n  }\n  const state = this._readableState\n  const nOrig = n\n\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n)\n  if (n !== 0) state.state &= ~kEmittedReadable\n\n  // If we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (\n    n === 0 &&\n    state.needReadable &&\n    ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)\n  ) {\n    debug('read: emitReadable', state.length, state.ended)\n    if (state.length === 0 && state.ended) endReadable(this)\n    else emitReadable(this)\n    return null\n  }\n  n = howMuchToRead(n, state)\n\n  // If we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this)\n    return null\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  let doRead = (state.state & kNeedReadable) !== 0\n  debug('need readable', doRead)\n\n  // If we currently have less than the highWaterMark, then also read some.\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true\n    debug('length less than watermark', doRead)\n  }\n\n  // However, if we've ended, then there's no point, if we're already\n  // reading, then it's unnecessary, if we're constructing we have to wait,\n  // and if we're destroyed or errored, then it's not allowed,\n  if (state.ended || state.reading || state.destroyed || state.errored || !state.constructed) {\n    doRead = false\n    debug('reading, ended or constructing', doRead)\n  } else if (doRead) {\n    debug('do read')\n    state.state |= kReading | kSync\n    // If the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.state |= kNeedReadable\n\n    // Call internal read method\n    try {\n      this._read(state.highWaterMark)\n    } catch (err) {\n      errorOrDestroy(this, err)\n    }\n    state.state &= ~kSync\n\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state)\n  }\n  let ret\n  if (n > 0) ret = fromList(n, state)\n  else ret = null\n  if (ret === null) {\n    state.needReadable = state.length <= state.highWaterMark\n    n = 0\n  } else {\n    state.length -= n\n    if (state.multiAwaitDrain) {\n      state.awaitDrainWriters.clear()\n    } else {\n      state.awaitDrainWriters = null\n    }\n  }\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this)\n  }\n  if (ret !== null && !state.errorEmitted && !state.closeEmitted) {\n    state.dataEmitted = true\n    this.emit('data', ret)\n  }\n  return ret\n}\nfunction onEofChunk(stream, state) {\n  debug('onEofChunk')\n  if (state.ended) return\n  if (state.decoder) {\n    const chunk = state.decoder.end()\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk)\n      state.length += state.objectMode ? 1 : chunk.length\n    }\n  }\n  state.ended = true\n  if (state.sync) {\n    // If we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call.\n    emitReadable(stream)\n  } else {\n    // Emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false\n    state.emittedReadable = true\n    // We have to emit readable now that we are EOF. Modules\n    // in the ecosystem (e.g. dicer) rely on this event being sync.\n    emitReadable_(stream)\n  }\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  const state = stream._readableState\n  debug('emitReadable', state.needReadable, state.emittedReadable)\n  state.needReadable = false\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing)\n    state.emittedReadable = true\n    process.nextTick(emitReadable_, stream)\n  }\n}\nfunction emitReadable_(stream) {\n  const state = stream._readableState\n  debug('emitReadable_', state.destroyed, state.length, state.ended)\n  if (!state.destroyed && !state.errored && (state.length || state.ended)) {\n    stream.emit('readable')\n    state.emittedReadable = false\n  }\n\n  // The stream needs another readable event if:\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark\n  flow(stream)\n}\n\n// At this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore && state.constructed) {\n    state.readingMore = true\n    process.nextTick(maybeReadMore_, stream, state)\n  }\n}\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (\n    !state.reading &&\n    !state.ended &&\n    (state.length < state.highWaterMark || (state.flowing && state.length === 0))\n  ) {\n    const len = state.length\n    debug('maybeReadMore read 0')\n    stream.read(0)\n    if (len === state.length)\n      // Didn't get any data, stop spinning.\n      break\n  }\n  state.readingMore = false\n}\n\n// Abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  throw new ERR_METHOD_NOT_IMPLEMENTED('_read()')\n}\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  const src = this\n  const state = this._readableState\n  if (state.pipes.length === 1) {\n    if (!state.multiAwaitDrain) {\n      state.multiAwaitDrain = true\n      state.awaitDrainWriters = new SafeSet(state.awaitDrainWriters ? [state.awaitDrainWriters] : [])\n    }\n  }\n  state.pipes.push(dest)\n  debug('pipe count=%d opts=%j', state.pipes.length, pipeOpts)\n  const doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr\n  const endFn = doEnd ? onend : unpipe\n  if (state.endEmitted) process.nextTick(endFn)\n  else src.once('end', endFn)\n  dest.on('unpipe', onunpipe)\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe')\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true\n        cleanup()\n      }\n    }\n  }\n  function onend() {\n    debug('onend')\n    dest.end()\n  }\n  let ondrain\n  let cleanedUp = false\n  function cleanup() {\n    debug('cleanup')\n    // Cleanup event handlers once the pipe is broken.\n    dest.removeListener('close', onclose)\n    dest.removeListener('finish', onfinish)\n    if (ondrain) {\n      dest.removeListener('drain', ondrain)\n    }\n    dest.removeListener('error', onerror)\n    dest.removeListener('unpipe', onunpipe)\n    src.removeListener('end', onend)\n    src.removeListener('end', unpipe)\n    src.removeListener('data', ondata)\n    cleanedUp = true\n\n    // If the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (ondrain && state.awaitDrainWriters && (!dest._writableState || dest._writableState.needDrain)) ondrain()\n  }\n  function pause() {\n    // If the user unpiped during `dest.write()`, it is possible\n    // to get stuck in a permanently paused state if that write\n    // also returned false.\n    // => Check whether `dest` is still a piping destination.\n    if (!cleanedUp) {\n      if (state.pipes.length === 1 && state.pipes[0] === dest) {\n        debug('false write response, pause', 0)\n        state.awaitDrainWriters = dest\n        state.multiAwaitDrain = false\n      } else if (state.pipes.length > 1 && state.pipes.includes(dest)) {\n        debug('false write response, pause', state.awaitDrainWriters.size)\n        state.awaitDrainWriters.add(dest)\n      }\n      src.pause()\n    }\n    if (!ondrain) {\n      // When the dest drains, it reduces the awaitDrain counter\n      // on the source.  This would be more elegant with a .once()\n      // handler in flow(), but adding and removing repeatedly is\n      // too slow.\n      ondrain = pipeOnDrain(src, dest)\n      dest.on('drain', ondrain)\n    }\n  }\n  src.on('data', ondata)\n  function ondata(chunk) {\n    debug('ondata')\n    const ret = dest.write(chunk)\n    debug('dest.write', ret)\n    if (ret === false) {\n      pause()\n    }\n  }\n\n  // If the dest has an error, then stop piping into it.\n  // However, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er)\n    unpipe()\n    dest.removeListener('error', onerror)\n    if (dest.listenerCount('error') === 0) {\n      const s = dest._writableState || dest._readableState\n      if (s && !s.errorEmitted) {\n        // User incorrectly emitted 'error' directly on the stream.\n        errorOrDestroy(dest, er)\n      } else {\n        dest.emit('error', er)\n      }\n    }\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror)\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish)\n    unpipe()\n  }\n  dest.once('close', onclose)\n  function onfinish() {\n    debug('onfinish')\n    dest.removeListener('close', onclose)\n    unpipe()\n  }\n  dest.once('finish', onfinish)\n  function unpipe() {\n    debug('unpipe')\n    src.unpipe(dest)\n  }\n\n  // Tell the dest that it's being piped to.\n  dest.emit('pipe', src)\n\n  // Start the flow if it hasn't been started already.\n\n  if (dest.writableNeedDrain === true) {\n    pause()\n  } else if (!state.flowing) {\n    debug('pipe resume')\n    src.resume()\n  }\n  return dest\n}\nfunction pipeOnDrain(src, dest) {\n  return function pipeOnDrainFunctionResult() {\n    const state = src._readableState\n\n    // `ondrain` will call directly,\n    // `this` maybe not a reference to dest,\n    // so we use the real dest here.\n    if (state.awaitDrainWriters === dest) {\n      debug('pipeOnDrain', 1)\n      state.awaitDrainWriters = null\n    } else if (state.multiAwaitDrain) {\n      debug('pipeOnDrain', state.awaitDrainWriters.size)\n      state.awaitDrainWriters.delete(dest)\n    }\n    if ((!state.awaitDrainWriters || state.awaitDrainWriters.size === 0) && src.listenerCount('data')) {\n      src.resume()\n    }\n  }\n}\nReadable.prototype.unpipe = function (dest) {\n  const state = this._readableState\n  const unpipeInfo = {\n    hasUnpiped: false\n  }\n\n  // If we're not piping anywhere, then do nothing.\n  if (state.pipes.length === 0) return this\n  if (!dest) {\n    // remove all.\n    const dests = state.pipes\n    state.pipes = []\n    this.pause()\n    for (let i = 0; i < dests.length; i++)\n      dests[i].emit('unpipe', this, {\n        hasUnpiped: false\n      })\n    return this\n  }\n\n  // Try to find the right one.\n  const index = ArrayPrototypeIndexOf(state.pipes, dest)\n  if (index === -1) return this\n  state.pipes.splice(index, 1)\n  if (state.pipes.length === 0) this.pause()\n  dest.emit('unpipe', this, unpipeInfo)\n  return this\n}\n\n// Set up data events if they are asked for\n// Ensure readable listeners eventually get something.\nReadable.prototype.on = function (ev, fn) {\n  const res = Stream.prototype.on.call(this, ev, fn)\n  const state = this._readableState\n  if (ev === 'data') {\n    // Update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0\n\n    // Try start flowing on next tick if stream isn't explicitly paused.\n    if (state.flowing !== false) this.resume()\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true\n      state.flowing = false\n      state.emittedReadable = false\n      debug('on readable', state.length, state.reading)\n      if (state.length) {\n        emitReadable(this)\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this)\n      }\n    }\n  }\n  return res\n}\nReadable.prototype.addListener = Readable.prototype.on\nReadable.prototype.removeListener = function (ev, fn) {\n  const res = Stream.prototype.removeListener.call(this, ev, fn)\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this)\n  }\n  return res\n}\nReadable.prototype.off = Readable.prototype.removeListener\nReadable.prototype.removeAllListeners = function (ev) {\n  const res = Stream.prototype.removeAllListeners.apply(this, arguments)\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this)\n  }\n  return res\n}\nfunction updateReadableListening(self) {\n  const state = self._readableState\n  state.readableListening = self.listenerCount('readable') > 0\n  if (state.resumeScheduled && state[kPaused] === false) {\n    // Flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true\n\n    // Crude way to check if we should resume.\n  } else if (self.listenerCount('data') > 0) {\n    self.resume()\n  } else if (!state.readableListening) {\n    state.flowing = null\n  }\n}\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0')\n  self.read(0)\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  const state = this._readableState\n  if (!state.flowing) {\n    debug('resume')\n    // We flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume().\n    state.flowing = !state.readableListening\n    resume(this, state)\n  }\n  state[kPaused] = false\n  return this\n}\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true\n    process.nextTick(resume_, stream, state)\n  }\n}\nfunction resume_(stream, state) {\n  debug('resume', state.reading)\n  if (!state.reading) {\n    stream.read(0)\n  }\n  state.resumeScheduled = false\n  stream.emit('resume')\n  flow(stream)\n  if (state.flowing && !state.reading) stream.read(0)\n}\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing)\n  if (this._readableState.flowing !== false) {\n    debug('pause')\n    this._readableState.flowing = false\n    this.emit('pause')\n  }\n  this._readableState[kPaused] = true\n  return this\n}\nfunction flow(stream) {\n  const state = stream._readableState\n  debug('flow', state.flowing)\n  while (state.flowing && stream.read() !== null);\n}\n\n// Wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  let paused = false\n\n  // TODO (ronag): Should this.destroy(err) emit\n  // 'error' on the wrapped stream? Would require\n  // a static factory method, e.g. Readable.wrap(stream).\n\n  stream.on('data', (chunk) => {\n    if (!this.push(chunk) && stream.pause) {\n      paused = true\n      stream.pause()\n    }\n  })\n  stream.on('end', () => {\n    this.push(null)\n  })\n  stream.on('error', (err) => {\n    errorOrDestroy(this, err)\n  })\n  stream.on('close', () => {\n    this.destroy()\n  })\n  stream.on('destroy', () => {\n    this.destroy()\n  })\n  this._read = () => {\n    if (paused && stream.resume) {\n      paused = false\n      stream.resume()\n    }\n  }\n\n  // Proxy all the other methods. Important when wrapping filters and duplexes.\n  const streamKeys = ObjectKeys(stream)\n  for (let j = 1; j < streamKeys.length; j++) {\n    const i = streamKeys[j]\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = stream[i].bind(stream)\n    }\n  }\n  return this\n}\nReadable.prototype[SymbolAsyncIterator] = function () {\n  return streamToAsyncIterator(this)\n}\nReadable.prototype.iterator = function (options) {\n  if (options !== undefined) {\n    validateObject(options, 'options')\n  }\n  return streamToAsyncIterator(this, options)\n}\nfunction streamToAsyncIterator(stream, options) {\n  if (typeof stream.read !== 'function') {\n    stream = Readable.wrap(stream, {\n      objectMode: true\n    })\n  }\n  const iter = createAsyncIterator(stream, options)\n  iter.stream = stream\n  return iter\n}\nasync function* createAsyncIterator(stream, options) {\n  let callback = nop\n  function next(resolve) {\n    if (this === stream) {\n      callback()\n      callback = nop\n    } else {\n      callback = resolve\n    }\n  }\n  stream.on('readable', next)\n  let error\n  const cleanup = eos(\n    stream,\n    {\n      writable: false\n    },\n    (err) => {\n      error = err ? aggregateTwoErrors(error, err) : null\n      callback()\n      callback = nop\n    }\n  )\n  try {\n    while (true) {\n      const chunk = stream.destroyed ? null : stream.read()\n      if (chunk !== null) {\n        yield chunk\n      } else if (error) {\n        throw error\n      } else if (error === null) {\n        return\n      } else {\n        await new Promise(next)\n      }\n    }\n  } catch (err) {\n    error = aggregateTwoErrors(error, err)\n    throw error\n  } finally {\n    if (\n      (error || (options === null || options === undefined ? undefined : options.destroyOnReturn) !== false) &&\n      (error === undefined || stream._readableState.autoDestroy)\n    ) {\n      destroyImpl.destroyer(stream, null)\n    } else {\n      stream.off('readable', next)\n      cleanup()\n    }\n  }\n}\n\n// Making it explicit these properties are not enumerable\n// because otherwise some prototype manipulation in\n// userland will fail.\nObjectDefineProperties(Readable.prototype, {\n  readable: {\n    __proto__: null,\n    get() {\n      const r = this._readableState\n      // r.readable === false means that this is part of a Duplex stream\n      // where the readable side was disabled upon construction.\n      // Compat. The user might manually disable readable side through\n      // deprecated setter.\n      return !!r && r.readable !== false && !r.destroyed && !r.errorEmitted && !r.endEmitted\n    },\n    set(val) {\n      // Backwards compat.\n      if (this._readableState) {\n        this._readableState.readable = !!val\n      }\n    }\n  },\n  readableDidRead: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return this._readableState.dataEmitted\n    }\n  },\n  readableAborted: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return !!(\n        this._readableState.readable !== false &&\n        (this._readableState.destroyed || this._readableState.errored) &&\n        !this._readableState.endEmitted\n      )\n    }\n  },\n  readableHighWaterMark: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return this._readableState.highWaterMark\n    }\n  },\n  readableBuffer: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return this._readableState && this._readableState.buffer\n    }\n  },\n  readableFlowing: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return this._readableState.flowing\n    },\n    set: function (state) {\n      if (this._readableState) {\n        this._readableState.flowing = state\n      }\n    }\n  },\n  readableLength: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState.length\n    }\n  },\n  readableObjectMode: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.objectMode : false\n    }\n  },\n  readableEncoding: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.encoding : null\n    }\n  },\n  errored: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.errored : null\n    }\n  },\n  closed: {\n    __proto__: null,\n    get() {\n      return this._readableState ? this._readableState.closed : false\n    }\n  },\n  destroyed: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.destroyed : false\n    },\n    set(value) {\n      // We ignore the value if the stream\n      // has not been initialized yet.\n      if (!this._readableState) {\n        return\n      }\n\n      // Backward compatibility, the user is explicitly\n      // managing destroyed.\n      this._readableState.destroyed = value\n    }\n  },\n  readableEnded: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.endEmitted : false\n    }\n  }\n})\nObjectDefineProperties(ReadableState.prototype, {\n  // Legacy getter for `pipesCount`.\n  pipesCount: {\n    __proto__: null,\n    get() {\n      return this.pipes.length\n    }\n  },\n  // Legacy property for `paused`.\n  paused: {\n    __proto__: null,\n    get() {\n      return this[kPaused] !== false\n    },\n    set(value) {\n      this[kPaused] = !!value\n    }\n  }\n})\n\n// Exposed for testing purposes only.\nReadable._fromList = fromList\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered.\n  if (state.length === 0) return null\n  let ret\n  if (state.objectMode) ret = state.buffer.shift()\n  else if (!n || n >= state.length) {\n    // Read it all, truncate the list.\n    if (state.decoder) ret = state.buffer.join('')\n    else if (state.buffer.length === 1) ret = state.buffer.first()\n    else ret = state.buffer.concat(state.length)\n    state.buffer.clear()\n  } else {\n    // read part of list.\n    ret = state.buffer.consume(n, state.decoder)\n  }\n  return ret\n}\nfunction endReadable(stream) {\n  const state = stream._readableState\n  debug('endReadable', state.endEmitted)\n  if (!state.endEmitted) {\n    state.ended = true\n    process.nextTick(endReadableNT, state, stream)\n  }\n}\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length)\n\n  // Check that we didn't get one last unshift.\n  if (!state.errored && !state.closeEmitted && !state.endEmitted && state.length === 0) {\n    state.endEmitted = true\n    stream.emit('end')\n    if (stream.writable && stream.allowHalfOpen === false) {\n      process.nextTick(endWritableNT, stream)\n    } else if (state.autoDestroy) {\n      // In case of duplex streams we need a way to detect\n      // if the writable side is ready for autoDestroy as well.\n      const wState = stream._writableState\n      const autoDestroy =\n        !wState ||\n        (wState.autoDestroy &&\n          // We don't expect the writable to ever 'finish'\n          // if writable is explicitly set to false.\n          (wState.finished || wState.writable === false))\n      if (autoDestroy) {\n        stream.destroy()\n      }\n    }\n  }\n}\nfunction endWritableNT(stream) {\n  const writable = stream.writable && !stream.writableEnded && !stream.destroyed\n  if (writable) {\n    stream.end()\n  }\n}\nReadable.from = function (iterable, opts) {\n  return from(Readable, iterable, opts)\n}\nlet webStreamsAdapters\n\n// Lazy to avoid circular references\nfunction lazyWebStreams() {\n  if (webStreamsAdapters === undefined) webStreamsAdapters = {}\n  return webStreamsAdapters\n}\nReadable.fromWeb = function (readableStream, options) {\n  return lazyWebStreams().newStreamReadableFromReadableStream(readableStream, options)\n}\nReadable.toWeb = function (streamReadable, options) {\n  return lazyWebStreams().newReadableStreamFromStreamReadable(streamReadable, options)\n}\nReadable.wrap = function (src, options) {\n  var _ref, _src$readableObjectMo\n  return new Readable({\n    objectMode:\n      (_ref =\n        (_src$readableObjectMo = src.readableObjectMode) !== null && _src$readableObjectMo !== undefined\n          ? _src$readableObjectMo\n          : src.objectMode) !== null && _ref !== undefined\n        ? _ref\n        : true,\n    ...options,\n    destroy(err, callback) {\n      destroyImpl.destroyer(src, err)\n      callback(err)\n    }\n  }).wrap(src)\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/readable.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/state.js":
/*!********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/state.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { MathFloor, NumberIsInteger } = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst { validateInteger } = __webpack_require__(/*! ../validators */ \"./node_modules/readable-stream/lib/internal/validators.js\")\nconst { ERR_INVALID_ARG_VALUE } = (__webpack_require__(/*! ../../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\").codes)\nlet defaultHighWaterMarkBytes = 16 * 1024\nlet defaultHighWaterMarkObjectMode = 16\nfunction highWaterMarkFrom(options, isDuplex, duplexKey) {\n  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null\n}\nfunction getDefaultHighWaterMark(objectMode) {\n  return objectMode ? defaultHighWaterMarkObjectMode : defaultHighWaterMarkBytes\n}\nfunction setDefaultHighWaterMark(objectMode, value) {\n  validateInteger(value, 'value', 0)\n  if (objectMode) {\n    defaultHighWaterMarkObjectMode = value\n  } else {\n    defaultHighWaterMarkBytes = value\n  }\n}\nfunction getHighWaterMark(state, options, duplexKey, isDuplex) {\n  const hwm = highWaterMarkFrom(options, isDuplex, duplexKey)\n  if (hwm != null) {\n    if (!NumberIsInteger(hwm) || hwm < 0) {\n      const name = isDuplex ? `options.${duplexKey}` : 'options.highWaterMark'\n      throw new ERR_INVALID_ARG_VALUE(name, hwm)\n    }\n    return MathFloor(hwm)\n  }\n\n  // Default value\n  return getDefaultHighWaterMark(state.objectMode)\n}\nmodule.exports = {\n  getHighWaterMark,\n  getDefaultHighWaterMark,\n  setDefaultHighWaterMark\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/state.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/transform.js":
/*!************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/transform.js ***!
  \************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n\n\nconst { ObjectSetPrototypeOf, Symbol } = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nmodule.exports = Transform\nconst { ERR_METHOD_NOT_IMPLEMENTED } = (__webpack_require__(/*! ../../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\").codes)\nconst Duplex = __webpack_require__(/*! ./duplex */ \"./node_modules/readable-stream/lib/internal/streams/duplex.js\")\nconst { getHighWaterMark } = __webpack_require__(/*! ./state */ \"./node_modules/readable-stream/lib/internal/streams/state.js\")\nObjectSetPrototypeOf(Transform.prototype, Duplex.prototype)\nObjectSetPrototypeOf(Transform, Duplex)\nconst kCallback = Symbol('kCallback')\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options)\n\n  // TODO (ronag): This should preferably always be\n  // applied but would be semver-major. Or even better;\n  // make Transform a Readable with the Writable interface.\n  const readableHighWaterMark = options ? getHighWaterMark(this, options, 'readableHighWaterMark', true) : null\n  if (readableHighWaterMark === 0) {\n    // A Duplex will buffer both on the writable and readable side while\n    // a Transform just wants to buffer hwm number of elements. To avoid\n    // buffering twice we disable buffering on the writable side.\n    options = {\n      ...options,\n      highWaterMark: null,\n      readableHighWaterMark,\n      // TODO (ronag): 0 is not optimal since we have\n      // a \"bug\" where we check needDrain before calling _write and not after.\n      // Refs: https://github.com/nodejs/node/pull/32887\n      // Refs: https://github.com/nodejs/node/pull/35941\n      writableHighWaterMark: options.writableHighWaterMark || 0\n    }\n  }\n  Duplex.call(this, options)\n\n  // We have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false\n  this[kCallback] = null\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform\n    if (typeof options.flush === 'function') this._flush = options.flush\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  // Backwards compat. Some Transform streams incorrectly implement _final\n  // instead of or in addition to _flush. By using 'prefinish' instead of\n  // implementing _final we continue supporting this unfortunate use case.\n  this.on('prefinish', prefinish)\n}\nfunction final(cb) {\n  if (typeof this._flush === 'function' && !this.destroyed) {\n    this._flush((er, data) => {\n      if (er) {\n        if (cb) {\n          cb(er)\n        } else {\n          this.destroy(er)\n        }\n        return\n      }\n      if (data != null) {\n        this.push(data)\n      }\n      this.push(null)\n      if (cb) {\n        cb()\n      }\n    })\n  } else {\n    this.push(null)\n    if (cb) {\n      cb()\n    }\n  }\n}\nfunction prefinish() {\n  if (this._final !== final) {\n    final.call(this)\n  }\n}\nTransform.prototype._final = final\nTransform.prototype._transform = function (chunk, encoding, callback) {\n  throw new ERR_METHOD_NOT_IMPLEMENTED('_transform()')\n}\nTransform.prototype._write = function (chunk, encoding, callback) {\n  const rState = this._readableState\n  const wState = this._writableState\n  const length = rState.length\n  this._transform(chunk, encoding, (err, val) => {\n    if (err) {\n      callback(err)\n      return\n    }\n    if (val != null) {\n      this.push(val)\n    }\n    if (\n      wState.ended ||\n      // Backwards compat.\n      length === rState.length ||\n      // Backwards compat.\n      rState.length < rState.highWaterMark\n    ) {\n      callback()\n    } else {\n      this[kCallback] = callback\n    }\n  })\n}\nTransform.prototype._read = function () {\n  if (this[kCallback]) {\n    const callback = this[kCallback]\n    this[kCallback] = null\n    callback()\n  }\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/transform.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/utils.js":
/*!********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/utils.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { SymbolAsyncIterator, SymbolIterator, SymbolFor } = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\n\n// We need to use SymbolFor to make these globally available\n// for interopt with readable-stream, i.e. readable-stream\n// and node core needs to be able to read/write private state\n// from each other for proper interoperability.\nconst kIsDestroyed = SymbolFor('nodejs.stream.destroyed')\nconst kIsErrored = SymbolFor('nodejs.stream.errored')\nconst kIsReadable = SymbolFor('nodejs.stream.readable')\nconst kIsWritable = SymbolFor('nodejs.stream.writable')\nconst kIsDisturbed = SymbolFor('nodejs.stream.disturbed')\nconst kIsClosedPromise = SymbolFor('nodejs.webstream.isClosedPromise')\nconst kControllerErrorFunction = SymbolFor('nodejs.webstream.controllerErrorFunction')\nfunction isReadableNodeStream(obj, strict = false) {\n  var _obj$_readableState\n  return !!(\n    (\n      obj &&\n      typeof obj.pipe === 'function' &&\n      typeof obj.on === 'function' &&\n      (!strict || (typeof obj.pause === 'function' && typeof obj.resume === 'function')) &&\n      (!obj._writableState ||\n        ((_obj$_readableState = obj._readableState) === null || _obj$_readableState === undefined\n          ? undefined\n          : _obj$_readableState.readable) !== false) &&\n      // Duplex\n      (!obj._writableState || obj._readableState)\n    ) // Writable has .pipe.\n  )\n}\n\nfunction isWritableNodeStream(obj) {\n  var _obj$_writableState\n  return !!(\n    (\n      obj &&\n      typeof obj.write === 'function' &&\n      typeof obj.on === 'function' &&\n      (!obj._readableState ||\n        ((_obj$_writableState = obj._writableState) === null || _obj$_writableState === undefined\n          ? undefined\n          : _obj$_writableState.writable) !== false)\n    ) // Duplex\n  )\n}\n\nfunction isDuplexNodeStream(obj) {\n  return !!(\n    obj &&\n    typeof obj.pipe === 'function' &&\n    obj._readableState &&\n    typeof obj.on === 'function' &&\n    typeof obj.write === 'function'\n  )\n}\nfunction isNodeStream(obj) {\n  return (\n    obj &&\n    (obj._readableState ||\n      obj._writableState ||\n      (typeof obj.write === 'function' && typeof obj.on === 'function') ||\n      (typeof obj.pipe === 'function' && typeof obj.on === 'function'))\n  )\n}\nfunction isReadableStream(obj) {\n  return !!(\n    obj &&\n    !isNodeStream(obj) &&\n    typeof obj.pipeThrough === 'function' &&\n    typeof obj.getReader === 'function' &&\n    typeof obj.cancel === 'function'\n  )\n}\nfunction isWritableStream(obj) {\n  return !!(obj && !isNodeStream(obj) && typeof obj.getWriter === 'function' && typeof obj.abort === 'function')\n}\nfunction isTransformStream(obj) {\n  return !!(obj && !isNodeStream(obj) && typeof obj.readable === 'object' && typeof obj.writable === 'object')\n}\nfunction isWebStream(obj) {\n  return isReadableStream(obj) || isWritableStream(obj) || isTransformStream(obj)\n}\nfunction isIterable(obj, isAsync) {\n  if (obj == null) return false\n  if (isAsync === true) return typeof obj[SymbolAsyncIterator] === 'function'\n  if (isAsync === false) return typeof obj[SymbolIterator] === 'function'\n  return typeof obj[SymbolAsyncIterator] === 'function' || typeof obj[SymbolIterator] === 'function'\n}\nfunction isDestroyed(stream) {\n  if (!isNodeStream(stream)) return null\n  const wState = stream._writableState\n  const rState = stream._readableState\n  const state = wState || rState\n  return !!(stream.destroyed || stream[kIsDestroyed] || (state !== null && state !== undefined && state.destroyed))\n}\n\n// Have been end():d.\nfunction isWritableEnded(stream) {\n  if (!isWritableNodeStream(stream)) return null\n  if (stream.writableEnded === true) return true\n  const wState = stream._writableState\n  if (wState !== null && wState !== undefined && wState.errored) return false\n  if (typeof (wState === null || wState === undefined ? undefined : wState.ended) !== 'boolean') return null\n  return wState.ended\n}\n\n// Have emitted 'finish'.\nfunction isWritableFinished(stream, strict) {\n  if (!isWritableNodeStream(stream)) return null\n  if (stream.writableFinished === true) return true\n  const wState = stream._writableState\n  if (wState !== null && wState !== undefined && wState.errored) return false\n  if (typeof (wState === null || wState === undefined ? undefined : wState.finished) !== 'boolean') return null\n  return !!(wState.finished || (strict === false && wState.ended === true && wState.length === 0))\n}\n\n// Have been push(null):d.\nfunction isReadableEnded(stream) {\n  if (!isReadableNodeStream(stream)) return null\n  if (stream.readableEnded === true) return true\n  const rState = stream._readableState\n  if (!rState || rState.errored) return false\n  if (typeof (rState === null || rState === undefined ? undefined : rState.ended) !== 'boolean') return null\n  return rState.ended\n}\n\n// Have emitted 'end'.\nfunction isReadableFinished(stream, strict) {\n  if (!isReadableNodeStream(stream)) return null\n  const rState = stream._readableState\n  if (rState !== null && rState !== undefined && rState.errored) return false\n  if (typeof (rState === null || rState === undefined ? undefined : rState.endEmitted) !== 'boolean') return null\n  return !!(rState.endEmitted || (strict === false && rState.ended === true && rState.length === 0))\n}\nfunction isReadable(stream) {\n  if (stream && stream[kIsReadable] != null) return stream[kIsReadable]\n  if (typeof (stream === null || stream === undefined ? undefined : stream.readable) !== 'boolean') return null\n  if (isDestroyed(stream)) return false\n  return isReadableNodeStream(stream) && stream.readable && !isReadableFinished(stream)\n}\nfunction isWritable(stream) {\n  if (stream && stream[kIsWritable] != null) return stream[kIsWritable]\n  if (typeof (stream === null || stream === undefined ? undefined : stream.writable) !== 'boolean') return null\n  if (isDestroyed(stream)) return false\n  return isWritableNodeStream(stream) && stream.writable && !isWritableEnded(stream)\n}\nfunction isFinished(stream, opts) {\n  if (!isNodeStream(stream)) {\n    return null\n  }\n  if (isDestroyed(stream)) {\n    return true\n  }\n  if ((opts === null || opts === undefined ? undefined : opts.readable) !== false && isReadable(stream)) {\n    return false\n  }\n  if ((opts === null || opts === undefined ? undefined : opts.writable) !== false && isWritable(stream)) {\n    return false\n  }\n  return true\n}\nfunction isWritableErrored(stream) {\n  var _stream$_writableStat, _stream$_writableStat2\n  if (!isNodeStream(stream)) {\n    return null\n  }\n  if (stream.writableErrored) {\n    return stream.writableErrored\n  }\n  return (_stream$_writableStat =\n    (_stream$_writableStat2 = stream._writableState) === null || _stream$_writableStat2 === undefined\n      ? undefined\n      : _stream$_writableStat2.errored) !== null && _stream$_writableStat !== undefined\n    ? _stream$_writableStat\n    : null\n}\nfunction isReadableErrored(stream) {\n  var _stream$_readableStat, _stream$_readableStat2\n  if (!isNodeStream(stream)) {\n    return null\n  }\n  if (stream.readableErrored) {\n    return stream.readableErrored\n  }\n  return (_stream$_readableStat =\n    (_stream$_readableStat2 = stream._readableState) === null || _stream$_readableStat2 === undefined\n      ? undefined\n      : _stream$_readableStat2.errored) !== null && _stream$_readableStat !== undefined\n    ? _stream$_readableStat\n    : null\n}\nfunction isClosed(stream) {\n  if (!isNodeStream(stream)) {\n    return null\n  }\n  if (typeof stream.closed === 'boolean') {\n    return stream.closed\n  }\n  const wState = stream._writableState\n  const rState = stream._readableState\n  if (\n    typeof (wState === null || wState === undefined ? undefined : wState.closed) === 'boolean' ||\n    typeof (rState === null || rState === undefined ? undefined : rState.closed) === 'boolean'\n  ) {\n    return (\n      (wState === null || wState === undefined ? undefined : wState.closed) ||\n      (rState === null || rState === undefined ? undefined : rState.closed)\n    )\n  }\n  if (typeof stream._closed === 'boolean' && isOutgoingMessage(stream)) {\n    return stream._closed\n  }\n  return null\n}\nfunction isOutgoingMessage(stream) {\n  return (\n    typeof stream._closed === 'boolean' &&\n    typeof stream._defaultKeepAlive === 'boolean' &&\n    typeof stream._removedConnection === 'boolean' &&\n    typeof stream._removedContLen === 'boolean'\n  )\n}\nfunction isServerResponse(stream) {\n  return typeof stream._sent100 === 'boolean' && isOutgoingMessage(stream)\n}\nfunction isServerRequest(stream) {\n  var _stream$req\n  return (\n    typeof stream._consuming === 'boolean' &&\n    typeof stream._dumped === 'boolean' &&\n    ((_stream$req = stream.req) === null || _stream$req === undefined ? undefined : _stream$req.upgradeOrConnect) ===\n      undefined\n  )\n}\nfunction willEmitClose(stream) {\n  if (!isNodeStream(stream)) return null\n  const wState = stream._writableState\n  const rState = stream._readableState\n  const state = wState || rState\n  return (\n    (!state && isServerResponse(stream)) || !!(state && state.autoDestroy && state.emitClose && state.closed === false)\n  )\n}\nfunction isDisturbed(stream) {\n  var _stream$kIsDisturbed\n  return !!(\n    stream &&\n    ((_stream$kIsDisturbed = stream[kIsDisturbed]) !== null && _stream$kIsDisturbed !== undefined\n      ? _stream$kIsDisturbed\n      : stream.readableDidRead || stream.readableAborted)\n  )\n}\nfunction isErrored(stream) {\n  var _ref,\n    _ref2,\n    _ref3,\n    _ref4,\n    _ref5,\n    _stream$kIsErrored,\n    _stream$_readableStat3,\n    _stream$_writableStat3,\n    _stream$_readableStat4,\n    _stream$_writableStat4\n  return !!(\n    stream &&\n    ((_ref =\n      (_ref2 =\n        (_ref3 =\n          (_ref4 =\n            (_ref5 =\n              (_stream$kIsErrored = stream[kIsErrored]) !== null && _stream$kIsErrored !== undefined\n                ? _stream$kIsErrored\n                : stream.readableErrored) !== null && _ref5 !== undefined\n              ? _ref5\n              : stream.writableErrored) !== null && _ref4 !== undefined\n            ? _ref4\n            : (_stream$_readableStat3 = stream._readableState) === null || _stream$_readableStat3 === undefined\n            ? undefined\n            : _stream$_readableStat3.errorEmitted) !== null && _ref3 !== undefined\n          ? _ref3\n          : (_stream$_writableStat3 = stream._writableState) === null || _stream$_writableStat3 === undefined\n          ? undefined\n          : _stream$_writableStat3.errorEmitted) !== null && _ref2 !== undefined\n        ? _ref2\n        : (_stream$_readableStat4 = stream._readableState) === null || _stream$_readableStat4 === undefined\n        ? undefined\n        : _stream$_readableStat4.errored) !== null && _ref !== undefined\n      ? _ref\n      : (_stream$_writableStat4 = stream._writableState) === null || _stream$_writableStat4 === undefined\n      ? undefined\n      : _stream$_writableStat4.errored)\n  )\n}\nmodule.exports = {\n  isDestroyed,\n  kIsDestroyed,\n  isDisturbed,\n  kIsDisturbed,\n  isErrored,\n  kIsErrored,\n  isReadable,\n  kIsReadable,\n  kIsClosedPromise,\n  kControllerErrorFunction,\n  kIsWritable,\n  isClosed,\n  isDuplexNodeStream,\n  isFinished,\n  isIterable,\n  isReadableNodeStream,\n  isReadableStream,\n  isReadableEnded,\n  isReadableFinished,\n  isReadableErrored,\n  isNodeStream,\n  isWebStream,\n  isWritable,\n  isWritableNodeStream,\n  isWritableStream,\n  isWritableEnded,\n  isWritableFinished,\n  isWritableErrored,\n  isServerRequest,\n  isServerResponse,\n  willEmitClose,\n  isTransformStream\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/utils.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/writable.js":
/*!***********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/writable.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* replacement start */\n\nconst process = __webpack_require__(/*! process/ */ \"./node_modules/process/browser.js\")\n\n/* replacement end */\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n;('use strict')\nconst {\n  ArrayPrototypeSlice,\n  Error,\n  FunctionPrototypeSymbolHasInstance,\n  ObjectDefineProperty,\n  ObjectDefineProperties,\n  ObjectSetPrototypeOf,\n  StringPrototypeToLowerCase,\n  Symbol,\n  SymbolHasInstance\n} = __webpack_require__(/*! ../../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nmodule.exports = Writable\nWritable.WritableState = WritableState\nconst { EventEmitter: EE } = __webpack_require__(/*! events */ \"./node_modules/events/events.js\")\nconst Stream = (__webpack_require__(/*! ./legacy */ \"./node_modules/readable-stream/lib/internal/streams/legacy.js\").Stream)\nconst { Buffer } = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\nconst destroyImpl = __webpack_require__(/*! ./destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\")\nconst { addAbortSignal } = __webpack_require__(/*! ./add-abort-signal */ \"./node_modules/readable-stream/lib/internal/streams/add-abort-signal.js\")\nconst { getHighWaterMark, getDefaultHighWaterMark } = __webpack_require__(/*! ./state */ \"./node_modules/readable-stream/lib/internal/streams/state.js\")\nconst {\n  ERR_INVALID_ARG_TYPE,\n  ERR_METHOD_NOT_IMPLEMENTED,\n  ERR_MULTIPLE_CALLBACK,\n  ERR_STREAM_CANNOT_PIPE,\n  ERR_STREAM_DESTROYED,\n  ERR_STREAM_ALREADY_FINISHED,\n  ERR_STREAM_NULL_VALUES,\n  ERR_STREAM_WRITE_AFTER_END,\n  ERR_UNKNOWN_ENCODING\n} = (__webpack_require__(/*! ../../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\").codes)\nconst { errorOrDestroy } = destroyImpl\nObjectSetPrototypeOf(Writable.prototype, Stream.prototype)\nObjectSetPrototypeOf(Writable, Stream)\nfunction nop() {}\nconst kOnFinished = Symbol('kOnFinished')\nfunction WritableState(options, stream, isDuplex) {\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream,\n  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof __webpack_require__(/*! ./duplex */ \"./node_modules/readable-stream/lib/internal/streams/duplex.js\")\n\n  // Object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!(options && options.objectMode)\n  if (isDuplex) this.objectMode = this.objectMode || !!(options && options.writableObjectMode)\n\n  // The point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write().\n  this.highWaterMark = options\n    ? getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex)\n    : getDefaultHighWaterMark(false)\n\n  // if _final has been called.\n  this.finalCalled = false\n\n  // drain event flag.\n  this.needDrain = false\n  // At the start of calling end()\n  this.ending = false\n  // When end() has been called, and returned.\n  this.ended = false\n  // When 'finish' is emitted.\n  this.finished = false\n\n  // Has it been destroyed\n  this.destroyed = false\n\n  // Should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  const noDecode = !!(options && options.decodeStrings === false)\n  this.decodeStrings = !noDecode\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = (options && options.defaultEncoding) || 'utf8'\n\n  // Not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0\n\n  // A flag to see when we're in the middle of a write.\n  this.writing = false\n\n  // When true all writes will be buffered until .uncork() call.\n  this.corked = 0\n\n  // A flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true\n\n  // A flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false\n\n  // The callback that's passed to _write(chunk, cb).\n  this.onwrite = onwrite.bind(undefined, stream)\n\n  // The callback that the user supplies to write(chunk, encoding, cb).\n  this.writecb = null\n\n  // The amount that is being written when _write is called.\n  this.writelen = 0\n\n  // Storage for data passed to the afterWrite() callback in case of\n  // synchronous _write() completion.\n  this.afterWriteTickInfo = null\n  resetBuffer(this)\n\n  // Number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted.\n  this.pendingcb = 0\n\n  // Stream is still being constructed and cannot be\n  // destroyed until construction finished or failed.\n  // Async construction is opt in, therefore we start as\n  // constructed.\n  this.constructed = true\n\n  // Emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams.\n  this.prefinished = false\n\n  // True if the error was already emitted and should not be thrown again.\n  this.errorEmitted = false\n\n  // Should close be emitted on destroy. Defaults to true.\n  this.emitClose = !options || options.emitClose !== false\n\n  // Should .destroy() be called after 'finish' (and potentially 'end').\n  this.autoDestroy = !options || options.autoDestroy !== false\n\n  // Indicates whether the stream has errored. When true all write() calls\n  // should return false. This is needed since when autoDestroy\n  // is disabled we need a way to tell whether the stream has failed.\n  this.errored = null\n\n  // Indicates whether the stream has finished destroying.\n  this.closed = false\n\n  // True if close has been emitted or would have been emitted\n  // depending on emitClose.\n  this.closeEmitted = false\n  this[kOnFinished] = []\n}\nfunction resetBuffer(state) {\n  state.buffered = []\n  state.bufferedIndex = 0\n  state.allBuffers = true\n  state.allNoop = true\n}\nWritableState.prototype.getBuffer = function getBuffer() {\n  return ArrayPrototypeSlice(this.buffered, this.bufferedIndex)\n}\nObjectDefineProperty(WritableState.prototype, 'bufferedRequestCount', {\n  __proto__: null,\n  get() {\n    return this.buffered.length - this.bufferedIndex\n  }\n})\nfunction Writable(options) {\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the WritableState constructor, at least with V8 6.5.\n  const isDuplex = this instanceof __webpack_require__(/*! ./duplex */ \"./node_modules/readable-stream/lib/internal/streams/duplex.js\")\n  if (!isDuplex && !FunctionPrototypeSymbolHasInstance(Writable, this)) return new Writable(options)\n  this._writableState = new WritableState(options, this, isDuplex)\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write\n    if (typeof options.writev === 'function') this._writev = options.writev\n    if (typeof options.destroy === 'function') this._destroy = options.destroy\n    if (typeof options.final === 'function') this._final = options.final\n    if (typeof options.construct === 'function') this._construct = options.construct\n    if (options.signal) addAbortSignal(options.signal, this)\n  }\n  Stream.call(this, options)\n  destroyImpl.construct(this, () => {\n    const state = this._writableState\n    if (!state.writing) {\n      clearBuffer(this, state)\n    }\n    finishMaybe(this, state)\n  })\n}\nObjectDefineProperty(Writable, SymbolHasInstance, {\n  __proto__: null,\n  value: function (object) {\n    if (FunctionPrototypeSymbolHasInstance(this, object)) return true\n    if (this !== Writable) return false\n    return object && object._writableState instanceof WritableState\n  }\n})\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE())\n}\nfunction _write(stream, chunk, encoding, cb) {\n  const state = stream._writableState\n  if (typeof encoding === 'function') {\n    cb = encoding\n    encoding = state.defaultEncoding\n  } else {\n    if (!encoding) encoding = state.defaultEncoding\n    else if (encoding !== 'buffer' && !Buffer.isEncoding(encoding)) throw new ERR_UNKNOWN_ENCODING(encoding)\n    if (typeof cb !== 'function') cb = nop\n  }\n  if (chunk === null) {\n    throw new ERR_STREAM_NULL_VALUES()\n  } else if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      if (state.decodeStrings !== false) {\n        chunk = Buffer.from(chunk, encoding)\n        encoding = 'buffer'\n      }\n    } else if (chunk instanceof Buffer) {\n      encoding = 'buffer'\n    } else if (Stream._isUint8Array(chunk)) {\n      chunk = Stream._uint8ArrayToBuffer(chunk)\n      encoding = 'buffer'\n    } else {\n      throw new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk)\n    }\n  }\n  let err\n  if (state.ending) {\n    err = new ERR_STREAM_WRITE_AFTER_END()\n  } else if (state.destroyed) {\n    err = new ERR_STREAM_DESTROYED('write')\n  }\n  if (err) {\n    process.nextTick(cb, err)\n    errorOrDestroy(stream, err, true)\n    return err\n  }\n  state.pendingcb++\n  return writeOrBuffer(stream, state, chunk, encoding, cb)\n}\nWritable.prototype.write = function (chunk, encoding, cb) {\n  return _write(this, chunk, encoding, cb) === true\n}\nWritable.prototype.cork = function () {\n  this._writableState.corked++\n}\nWritable.prototype.uncork = function () {\n  const state = this._writableState\n  if (state.corked) {\n    state.corked--\n    if (!state.writing) clearBuffer(this, state)\n  }\n}\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = StringPrototypeToLowerCase(encoding)\n  if (!Buffer.isEncoding(encoding)) throw new ERR_UNKNOWN_ENCODING(encoding)\n  this._writableState.defaultEncoding = encoding\n  return this\n}\n\n// If we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, chunk, encoding, callback) {\n  const len = state.objectMode ? 1 : chunk.length\n  state.length += len\n\n  // stream._write resets state.length\n  const ret = state.length < state.highWaterMark\n  // We must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true\n  if (state.writing || state.corked || state.errored || !state.constructed) {\n    state.buffered.push({\n      chunk,\n      encoding,\n      callback\n    })\n    if (state.allBuffers && encoding !== 'buffer') {\n      state.allBuffers = false\n    }\n    if (state.allNoop && callback !== nop) {\n      state.allNoop = false\n    }\n  } else {\n    state.writelen = len\n    state.writecb = callback\n    state.writing = true\n    state.sync = true\n    stream._write(chunk, encoding, state.onwrite)\n    state.sync = false\n  }\n\n  // Return false if errored or destroyed in order to break\n  // any synchronous while(stream.write(data)) loops.\n  return ret && !state.errored && !state.destroyed\n}\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len\n  state.writecb = cb\n  state.writing = true\n  state.sync = true\n  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'))\n  else if (writev) stream._writev(chunk, state.onwrite)\n  else stream._write(chunk, encoding, state.onwrite)\n  state.sync = false\n}\nfunction onwriteError(stream, state, er, cb) {\n  --state.pendingcb\n  cb(er)\n  // Ensure callbacks are invoked even when autoDestroy is\n  // not enabled. Passing `er` here doesn't make sense since\n  // it's related to one specific write, not to the buffered\n  // writes.\n  errorBuffer(state)\n  // This can emit error, but error must always follow cb.\n  errorOrDestroy(stream, er)\n}\nfunction onwrite(stream, er) {\n  const state = stream._writableState\n  const sync = state.sync\n  const cb = state.writecb\n  if (typeof cb !== 'function') {\n    errorOrDestroy(stream, new ERR_MULTIPLE_CALLBACK())\n    return\n  }\n  state.writing = false\n  state.writecb = null\n  state.length -= state.writelen\n  state.writelen = 0\n  if (er) {\n    // Avoid V8 leak, https://github.com/nodejs/node/pull/34103#issuecomment-652002364\n    er.stack // eslint-disable-line no-unused-expressions\n\n    if (!state.errored) {\n      state.errored = er\n    }\n\n    // In case of duplex streams we need to notify the readable side of the\n    // error.\n    if (stream._readableState && !stream._readableState.errored) {\n      stream._readableState.errored = er\n    }\n    if (sync) {\n      process.nextTick(onwriteError, stream, state, er, cb)\n    } else {\n      onwriteError(stream, state, er, cb)\n    }\n  } else {\n    if (state.buffered.length > state.bufferedIndex) {\n      clearBuffer(stream, state)\n    }\n    if (sync) {\n      // It is a common case that the callback passed to .write() is always\n      // the same. In that case, we do not schedule a new nextTick(), but\n      // rather just increase a counter, to improve performance and avoid\n      // memory allocations.\n      if (state.afterWriteTickInfo !== null && state.afterWriteTickInfo.cb === cb) {\n        state.afterWriteTickInfo.count++\n      } else {\n        state.afterWriteTickInfo = {\n          count: 1,\n          cb,\n          stream,\n          state\n        }\n        process.nextTick(afterWriteTick, state.afterWriteTickInfo)\n      }\n    } else {\n      afterWrite(stream, state, 1, cb)\n    }\n  }\n}\nfunction afterWriteTick({ stream, state, count, cb }) {\n  state.afterWriteTickInfo = null\n  return afterWrite(stream, state, count, cb)\n}\nfunction afterWrite(stream, state, count, cb) {\n  const needDrain = !state.ending && !stream.destroyed && state.length === 0 && state.needDrain\n  if (needDrain) {\n    state.needDrain = false\n    stream.emit('drain')\n  }\n  while (count-- > 0) {\n    state.pendingcb--\n    cb()\n  }\n  if (state.destroyed) {\n    errorBuffer(state)\n  }\n  finishMaybe(stream, state)\n}\n\n// If there's something in the buffer waiting, then invoke callbacks.\nfunction errorBuffer(state) {\n  if (state.writing) {\n    return\n  }\n  for (let n = state.bufferedIndex; n < state.buffered.length; ++n) {\n    var _state$errored\n    const { chunk, callback } = state.buffered[n]\n    const len = state.objectMode ? 1 : chunk.length\n    state.length -= len\n    callback(\n      (_state$errored = state.errored) !== null && _state$errored !== undefined\n        ? _state$errored\n        : new ERR_STREAM_DESTROYED('write')\n    )\n  }\n  const onfinishCallbacks = state[kOnFinished].splice(0)\n  for (let i = 0; i < onfinishCallbacks.length; i++) {\n    var _state$errored2\n    onfinishCallbacks[i](\n      (_state$errored2 = state.errored) !== null && _state$errored2 !== undefined\n        ? _state$errored2\n        : new ERR_STREAM_DESTROYED('end')\n    )\n  }\n  resetBuffer(state)\n}\n\n// If there's something in the buffer waiting, then process it.\nfunction clearBuffer(stream, state) {\n  if (state.corked || state.bufferProcessing || state.destroyed || !state.constructed) {\n    return\n  }\n  const { buffered, bufferedIndex, objectMode } = state\n  const bufferedLength = buffered.length - bufferedIndex\n  if (!bufferedLength) {\n    return\n  }\n  let i = bufferedIndex\n  state.bufferProcessing = true\n  if (bufferedLength > 1 && stream._writev) {\n    state.pendingcb -= bufferedLength - 1\n    const callback = state.allNoop\n      ? nop\n      : (err) => {\n          for (let n = i; n < buffered.length; ++n) {\n            buffered[n].callback(err)\n          }\n        }\n    // Make a copy of `buffered` if it's going to be used by `callback` above,\n    // since `doWrite` will mutate the array.\n    const chunks = state.allNoop && i === 0 ? buffered : ArrayPrototypeSlice(buffered, i)\n    chunks.allBuffers = state.allBuffers\n    doWrite(stream, state, true, state.length, chunks, '', callback)\n    resetBuffer(state)\n  } else {\n    do {\n      const { chunk, encoding, callback } = buffered[i]\n      buffered[i++] = null\n      const len = objectMode ? 1 : chunk.length\n      doWrite(stream, state, false, len, chunk, encoding, callback)\n    } while (i < buffered.length && !state.writing)\n    if (i === buffered.length) {\n      resetBuffer(state)\n    } else if (i > 256) {\n      buffered.splice(0, i)\n      state.bufferedIndex = 0\n    } else {\n      state.bufferedIndex = i\n    }\n  }\n  state.bufferProcessing = false\n}\nWritable.prototype._write = function (chunk, encoding, cb) {\n  if (this._writev) {\n    this._writev(\n      [\n        {\n          chunk,\n          encoding\n        }\n      ],\n      cb\n    )\n  } else {\n    throw new ERR_METHOD_NOT_IMPLEMENTED('_write()')\n  }\n}\nWritable.prototype._writev = null\nWritable.prototype.end = function (chunk, encoding, cb) {\n  const state = this._writableState\n  if (typeof chunk === 'function') {\n    cb = chunk\n    chunk = null\n    encoding = null\n  } else if (typeof encoding === 'function') {\n    cb = encoding\n    encoding = null\n  }\n  let err\n  if (chunk !== null && chunk !== undefined) {\n    const ret = _write(this, chunk, encoding)\n    if (ret instanceof Error) {\n      err = ret\n    }\n  }\n\n  // .end() fully uncorks.\n  if (state.corked) {\n    state.corked = 1\n    this.uncork()\n  }\n  if (err) {\n    // Do nothing...\n  } else if (!state.errored && !state.ending) {\n    // This is forgiving in terms of unnecessary calls to end() and can hide\n    // logic errors. However, usually such errors are harmless and causing a\n    // hard error can be disproportionately destructive. It is not always\n    // trivial for the user to determine whether end() needs to be called\n    // or not.\n\n    state.ending = true\n    finishMaybe(this, state, true)\n    state.ended = true\n  } else if (state.finished) {\n    err = new ERR_STREAM_ALREADY_FINISHED('end')\n  } else if (state.destroyed) {\n    err = new ERR_STREAM_DESTROYED('end')\n  }\n  if (typeof cb === 'function') {\n    if (err || state.finished) {\n      process.nextTick(cb, err)\n    } else {\n      state[kOnFinished].push(cb)\n    }\n  }\n  return this\n}\nfunction needFinish(state) {\n  return (\n    state.ending &&\n    !state.destroyed &&\n    state.constructed &&\n    state.length === 0 &&\n    !state.errored &&\n    state.buffered.length === 0 &&\n    !state.finished &&\n    !state.writing &&\n    !state.errorEmitted &&\n    !state.closeEmitted\n  )\n}\nfunction callFinal(stream, state) {\n  let called = false\n  function onFinish(err) {\n    if (called) {\n      errorOrDestroy(stream, err !== null && err !== undefined ? err : ERR_MULTIPLE_CALLBACK())\n      return\n    }\n    called = true\n    state.pendingcb--\n    if (err) {\n      const onfinishCallbacks = state[kOnFinished].splice(0)\n      for (let i = 0; i < onfinishCallbacks.length; i++) {\n        onfinishCallbacks[i](err)\n      }\n      errorOrDestroy(stream, err, state.sync)\n    } else if (needFinish(state)) {\n      state.prefinished = true\n      stream.emit('prefinish')\n      // Backwards compat. Don't check state.sync here.\n      // Some streams assume 'finish' will be emitted\n      // asynchronously relative to _final callback.\n      state.pendingcb++\n      process.nextTick(finish, stream, state)\n    }\n  }\n  state.sync = true\n  state.pendingcb++\n  try {\n    stream._final(onFinish)\n  } catch (err) {\n    onFinish(err)\n  }\n  state.sync = false\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function' && !state.destroyed) {\n      state.finalCalled = true\n      callFinal(stream, state)\n    } else {\n      state.prefinished = true\n      stream.emit('prefinish')\n    }\n  }\n}\nfunction finishMaybe(stream, state, sync) {\n  if (needFinish(state)) {\n    prefinish(stream, state)\n    if (state.pendingcb === 0) {\n      if (sync) {\n        state.pendingcb++\n        process.nextTick(\n          (stream, state) => {\n            if (needFinish(state)) {\n              finish(stream, state)\n            } else {\n              state.pendingcb--\n            }\n          },\n          stream,\n          state\n        )\n      } else if (needFinish(state)) {\n        state.pendingcb++\n        finish(stream, state)\n      }\n    }\n  }\n}\nfunction finish(stream, state) {\n  state.pendingcb--\n  state.finished = true\n  const onfinishCallbacks = state[kOnFinished].splice(0)\n  for (let i = 0; i < onfinishCallbacks.length; i++) {\n    onfinishCallbacks[i]()\n  }\n  stream.emit('finish')\n  if (state.autoDestroy) {\n    // In case of duplex streams we need a way to detect\n    // if the readable side is ready for autoDestroy as well.\n    const rState = stream._readableState\n    const autoDestroy =\n      !rState ||\n      (rState.autoDestroy &&\n        // We don't expect the readable to ever 'end'\n        // if readable is explicitly set to false.\n        (rState.endEmitted || rState.readable === false))\n    if (autoDestroy) {\n      stream.destroy()\n    }\n  }\n}\nObjectDefineProperties(Writable.prototype, {\n  closed: {\n    __proto__: null,\n    get() {\n      return this._writableState ? this._writableState.closed : false\n    }\n  },\n  destroyed: {\n    __proto__: null,\n    get() {\n      return this._writableState ? this._writableState.destroyed : false\n    },\n    set(value) {\n      // Backward compatibility, the user is explicitly managing destroyed.\n      if (this._writableState) {\n        this._writableState.destroyed = value\n      }\n    }\n  },\n  writable: {\n    __proto__: null,\n    get() {\n      const w = this._writableState\n      // w.writable === false means that this is part of a Duplex stream\n      // where the writable side was disabled upon construction.\n      // Compat. The user might manually disable writable side through\n      // deprecated setter.\n      return !!w && w.writable !== false && !w.destroyed && !w.errored && !w.ending && !w.ended\n    },\n    set(val) {\n      // Backwards compatible.\n      if (this._writableState) {\n        this._writableState.writable = !!val\n      }\n    }\n  },\n  writableFinished: {\n    __proto__: null,\n    get() {\n      return this._writableState ? this._writableState.finished : false\n    }\n  },\n  writableObjectMode: {\n    __proto__: null,\n    get() {\n      return this._writableState ? this._writableState.objectMode : false\n    }\n  },\n  writableBuffer: {\n    __proto__: null,\n    get() {\n      return this._writableState && this._writableState.getBuffer()\n    }\n  },\n  writableEnded: {\n    __proto__: null,\n    get() {\n      return this._writableState ? this._writableState.ending : false\n    }\n  },\n  writableNeedDrain: {\n    __proto__: null,\n    get() {\n      const wState = this._writableState\n      if (!wState) return false\n      return !wState.destroyed && !wState.ending && wState.needDrain\n    }\n  },\n  writableHighWaterMark: {\n    __proto__: null,\n    get() {\n      return this._writableState && this._writableState.highWaterMark\n    }\n  },\n  writableCorked: {\n    __proto__: null,\n    get() {\n      return this._writableState ? this._writableState.corked : 0\n    }\n  },\n  writableLength: {\n    __proto__: null,\n    get() {\n      return this._writableState && this._writableState.length\n    }\n  },\n  errored: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._writableState ? this._writableState.errored : null\n    }\n  },\n  writableAborted: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return !!(\n        this._writableState.writable !== false &&\n        (this._writableState.destroyed || this._writableState.errored) &&\n        !this._writableState.finished\n      )\n    }\n  }\n})\nconst destroy = destroyImpl.destroy\nWritable.prototype.destroy = function (err, cb) {\n  const state = this._writableState\n\n  // Invoke pending callbacks.\n  if (!state.destroyed && (state.bufferedIndex < state.buffered.length || state[kOnFinished].length)) {\n    process.nextTick(errorBuffer, state)\n  }\n  destroy.call(this, err, cb)\n  return this\n}\nWritable.prototype._undestroy = destroyImpl.undestroy\nWritable.prototype._destroy = function (err, cb) {\n  cb(err)\n}\nWritable.prototype[EE.captureRejectionSymbol] = function (err) {\n  this.destroy(err)\n}\nlet webStreamsAdapters\n\n// Lazy to avoid circular references\nfunction lazyWebStreams() {\n  if (webStreamsAdapters === undefined) webStreamsAdapters = {}\n  return webStreamsAdapters\n}\nWritable.fromWeb = function (writableStream, options) {\n  return lazyWebStreams().newStreamWritableFromWritableStream(writableStream, options)\n}\nWritable.toWeb = function (streamWritable) {\n  return lazyWebStreams().newWritableStreamFromStreamWritable(streamWritable)\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/streams/writable.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/validators.js":
/*!*****************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/validators.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("/* eslint jsdoc/require-jsdoc: \"error\" */\n\n\n\nconst {\n  ArrayIsArray,\n  ArrayPrototypeIncludes,\n  ArrayPrototypeJoin,\n  ArrayPrototypeMap,\n  NumberIsInteger,\n  NumberIsNaN,\n  NumberMAX_SAFE_INTEGER,\n  NumberMIN_SAFE_INTEGER,\n  NumberParseInt,\n  ObjectPrototypeHasOwnProperty,\n  RegExpPrototypeExec,\n  String,\n  StringPrototypeToUpperCase,\n  StringPrototypeTrim\n} = __webpack_require__(/*! ../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst {\n  hideStackFrames,\n  codes: { ERR_SOCKET_BAD_PORT, ERR_INVALID_ARG_TYPE, ERR_INVALID_ARG_VALUE, ERR_OUT_OF_RANGE, ERR_UNKNOWN_SIGNAL }\n} = __webpack_require__(/*! ../ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\")\nconst { normalizeEncoding } = __webpack_require__(/*! ../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\")\nconst { isAsyncFunction, isArrayBufferView } = (__webpack_require__(/*! ../ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\").types)\nconst signals = {}\n\n/**\n * @param {*} value\n * @returns {boolean}\n */\nfunction isInt32(value) {\n  return value === (value | 0)\n}\n\n/**\n * @param {*} value\n * @returns {boolean}\n */\nfunction isUint32(value) {\n  return value === value >>> 0\n}\nconst octalReg = /^[0-7]+$/\nconst modeDesc = 'must be a 32-bit unsigned integer or an octal string'\n\n/**\n * Parse and validate values that will be converted into mode_t (the S_*\n * constants). Only valid numbers and octal strings are allowed. They could be\n * converted to 32-bit unsigned integers or non-negative signed integers in the\n * C++ land, but any value higher than 0o777 will result in platform-specific\n * behaviors.\n * @param {*} value Values to be validated\n * @param {string} name Name of the argument\n * @param {number} [def] If specified, will be returned for invalid values\n * @returns {number}\n */\nfunction parseFileMode(value, name, def) {\n  if (typeof value === 'undefined') {\n    value = def\n  }\n  if (typeof value === 'string') {\n    if (RegExpPrototypeExec(octalReg, value) === null) {\n      throw new ERR_INVALID_ARG_VALUE(name, value, modeDesc)\n    }\n    value = NumberParseInt(value, 8)\n  }\n  validateUint32(value, name)\n  return value\n}\n\n/**\n * @callback validateInteger\n * @param {*} value\n * @param {string} name\n * @param {number} [min]\n * @param {number} [max]\n * @returns {asserts value is number}\n */\n\n/** @type {validateInteger} */\nconst validateInteger = hideStackFrames((value, name, min = NumberMIN_SAFE_INTEGER, max = NumberMAX_SAFE_INTEGER) => {\n  if (typeof value !== 'number') throw new ERR_INVALID_ARG_TYPE(name, 'number', value)\n  if (!NumberIsInteger(value)) throw new ERR_OUT_OF_RANGE(name, 'an integer', value)\n  if (value < min || value > max) throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value)\n})\n\n/**\n * @callback validateInt32\n * @param {*} value\n * @param {string} name\n * @param {number} [min]\n * @param {number} [max]\n * @returns {asserts value is number}\n */\n\n/** @type {validateInt32} */\nconst validateInt32 = hideStackFrames((value, name, min = -2147483648, max = 2147483647) => {\n  // The defaults for min and max correspond to the limits of 32-bit integers.\n  if (typeof value !== 'number') {\n    throw new ERR_INVALID_ARG_TYPE(name, 'number', value)\n  }\n  if (!NumberIsInteger(value)) {\n    throw new ERR_OUT_OF_RANGE(name, 'an integer', value)\n  }\n  if (value < min || value > max) {\n    throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value)\n  }\n})\n\n/**\n * @callback validateUint32\n * @param {*} value\n * @param {string} name\n * @param {number|boolean} [positive=false]\n * @returns {asserts value is number}\n */\n\n/** @type {validateUint32} */\nconst validateUint32 = hideStackFrames((value, name, positive = false) => {\n  if (typeof value !== 'number') {\n    throw new ERR_INVALID_ARG_TYPE(name, 'number', value)\n  }\n  if (!NumberIsInteger(value)) {\n    throw new ERR_OUT_OF_RANGE(name, 'an integer', value)\n  }\n  const min = positive ? 1 : 0\n  // 2 ** 32 === 4294967296\n  const max = 4294967295\n  if (value < min || value > max) {\n    throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value)\n  }\n})\n\n/**\n * @callback validateString\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is string}\n */\n\n/** @type {validateString} */\nfunction validateString(value, name) {\n  if (typeof value !== 'string') throw new ERR_INVALID_ARG_TYPE(name, 'string', value)\n}\n\n/**\n * @callback validateNumber\n * @param {*} value\n * @param {string} name\n * @param {number} [min]\n * @param {number} [max]\n * @returns {asserts value is number}\n */\n\n/** @type {validateNumber} */\nfunction validateNumber(value, name, min = undefined, max) {\n  if (typeof value !== 'number') throw new ERR_INVALID_ARG_TYPE(name, 'number', value)\n  if (\n    (min != null && value < min) ||\n    (max != null && value > max) ||\n    ((min != null || max != null) && NumberIsNaN(value))\n  ) {\n    throw new ERR_OUT_OF_RANGE(\n      name,\n      `${min != null ? `>= ${min}` : ''}${min != null && max != null ? ' && ' : ''}${max != null ? `<= ${max}` : ''}`,\n      value\n    )\n  }\n}\n\n/**\n * @callback validateOneOf\n * @template T\n * @param {T} value\n * @param {string} name\n * @param {T[]} oneOf\n */\n\n/** @type {validateOneOf} */\nconst validateOneOf = hideStackFrames((value, name, oneOf) => {\n  if (!ArrayPrototypeIncludes(oneOf, value)) {\n    const allowed = ArrayPrototypeJoin(\n      ArrayPrototypeMap(oneOf, (v) => (typeof v === 'string' ? `'${v}'` : String(v))),\n      ', '\n    )\n    const reason = 'must be one of: ' + allowed\n    throw new ERR_INVALID_ARG_VALUE(name, value, reason)\n  }\n})\n\n/**\n * @callback validateBoolean\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is boolean}\n */\n\n/** @type {validateBoolean} */\nfunction validateBoolean(value, name) {\n  if (typeof value !== 'boolean') throw new ERR_INVALID_ARG_TYPE(name, 'boolean', value)\n}\n\n/**\n * @param {any} options\n * @param {string} key\n * @param {boolean} defaultValue\n * @returns {boolean}\n */\nfunction getOwnPropertyValueOrDefault(options, key, defaultValue) {\n  return options == null || !ObjectPrototypeHasOwnProperty(options, key) ? defaultValue : options[key]\n}\n\n/**\n * @callback validateObject\n * @param {*} value\n * @param {string} name\n * @param {{\n *   allowArray?: boolean,\n *   allowFunction?: boolean,\n *   nullable?: boolean\n * }} [options]\n */\n\n/** @type {validateObject} */\nconst validateObject = hideStackFrames((value, name, options = null) => {\n  const allowArray = getOwnPropertyValueOrDefault(options, 'allowArray', false)\n  const allowFunction = getOwnPropertyValueOrDefault(options, 'allowFunction', false)\n  const nullable = getOwnPropertyValueOrDefault(options, 'nullable', false)\n  if (\n    (!nullable && value === null) ||\n    (!allowArray && ArrayIsArray(value)) ||\n    (typeof value !== 'object' && (!allowFunction || typeof value !== 'function'))\n  ) {\n    throw new ERR_INVALID_ARG_TYPE(name, 'Object', value)\n  }\n})\n\n/**\n * @callback validateDictionary - We are using the Web IDL Standard definition\n *                                of \"dictionary\" here, which means any value\n *                                whose Type is either Undefined, Null, or\n *                                Object (which includes functions).\n * @param {*} value\n * @param {string} name\n * @see https://webidl.spec.whatwg.org/#es-dictionary\n * @see https://tc39.es/ecma262/#table-typeof-operator-results\n */\n\n/** @type {validateDictionary} */\nconst validateDictionary = hideStackFrames((value, name) => {\n  if (value != null && typeof value !== 'object' && typeof value !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE(name, 'a dictionary', value)\n  }\n})\n\n/**\n * @callback validateArray\n * @param {*} value\n * @param {string} name\n * @param {number} [minLength]\n * @returns {asserts value is any[]}\n */\n\n/** @type {validateArray} */\nconst validateArray = hideStackFrames((value, name, minLength = 0) => {\n  if (!ArrayIsArray(value)) {\n    throw new ERR_INVALID_ARG_TYPE(name, 'Array', value)\n  }\n  if (value.length < minLength) {\n    const reason = `must be longer than ${minLength}`\n    throw new ERR_INVALID_ARG_VALUE(name, value, reason)\n  }\n})\n\n/**\n * @callback validateStringArray\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is string[]}\n */\n\n/** @type {validateStringArray} */\nfunction validateStringArray(value, name) {\n  validateArray(value, name)\n  for (let i = 0; i < value.length; i++) {\n    validateString(value[i], `${name}[${i}]`)\n  }\n}\n\n/**\n * @callback validateBooleanArray\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is boolean[]}\n */\n\n/** @type {validateBooleanArray} */\nfunction validateBooleanArray(value, name) {\n  validateArray(value, name)\n  for (let i = 0; i < value.length; i++) {\n    validateBoolean(value[i], `${name}[${i}]`)\n  }\n}\n\n/**\n * @callback validateAbortSignalArray\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is AbortSignal[]}\n */\n\n/** @type {validateAbortSignalArray} */\nfunction validateAbortSignalArray(value, name) {\n  validateArray(value, name)\n  for (let i = 0; i < value.length; i++) {\n    const signal = value[i]\n    const indexedName = `${name}[${i}]`\n    if (signal == null) {\n      throw new ERR_INVALID_ARG_TYPE(indexedName, 'AbortSignal', signal)\n    }\n    validateAbortSignal(signal, indexedName)\n  }\n}\n\n/**\n * @param {*} signal\n * @param {string} [name='signal']\n * @returns {asserts signal is keyof signals}\n */\nfunction validateSignalName(signal, name = 'signal') {\n  validateString(signal, name)\n  if (signals[signal] === undefined) {\n    if (signals[StringPrototypeToUpperCase(signal)] !== undefined) {\n      throw new ERR_UNKNOWN_SIGNAL(signal + ' (signals must use all capital letters)')\n    }\n    throw new ERR_UNKNOWN_SIGNAL(signal)\n  }\n}\n\n/**\n * @callback validateBuffer\n * @param {*} buffer\n * @param {string} [name='buffer']\n * @returns {asserts buffer is ArrayBufferView}\n */\n\n/** @type {validateBuffer} */\nconst validateBuffer = hideStackFrames((buffer, name = 'buffer') => {\n  if (!isArrayBufferView(buffer)) {\n    throw new ERR_INVALID_ARG_TYPE(name, ['Buffer', 'TypedArray', 'DataView'], buffer)\n  }\n})\n\n/**\n * @param {string} data\n * @param {string} encoding\n */\nfunction validateEncoding(data, encoding) {\n  const normalizedEncoding = normalizeEncoding(encoding)\n  const length = data.length\n  if (normalizedEncoding === 'hex' && length % 2 !== 0) {\n    throw new ERR_INVALID_ARG_VALUE('encoding', encoding, `is invalid for data of length ${length}`)\n  }\n}\n\n/**\n * Check that the port number is not NaN when coerced to a number,\n * is an integer and that it falls within the legal range of port numbers.\n * @param {*} port\n * @param {string} [name='Port']\n * @param {boolean} [allowZero=true]\n * @returns {number}\n */\nfunction validatePort(port, name = 'Port', allowZero = true) {\n  if (\n    (typeof port !== 'number' && typeof port !== 'string') ||\n    (typeof port === 'string' && StringPrototypeTrim(port).length === 0) ||\n    +port !== +port >>> 0 ||\n    port > 0xffff ||\n    (port === 0 && !allowZero)\n  ) {\n    throw new ERR_SOCKET_BAD_PORT(name, port, allowZero)\n  }\n  return port | 0\n}\n\n/**\n * @callback validateAbortSignal\n * @param {*} signal\n * @param {string} name\n */\n\n/** @type {validateAbortSignal} */\nconst validateAbortSignal = hideStackFrames((signal, name) => {\n  if (signal !== undefined && (signal === null || typeof signal !== 'object' || !('aborted' in signal))) {\n    throw new ERR_INVALID_ARG_TYPE(name, 'AbortSignal', signal)\n  }\n})\n\n/**\n * @callback validateFunction\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is Function}\n */\n\n/** @type {validateFunction} */\nconst validateFunction = hideStackFrames((value, name) => {\n  if (typeof value !== 'function') throw new ERR_INVALID_ARG_TYPE(name, 'Function', value)\n})\n\n/**\n * @callback validatePlainFunction\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is Function}\n */\n\n/** @type {validatePlainFunction} */\nconst validatePlainFunction = hideStackFrames((value, name) => {\n  if (typeof value !== 'function' || isAsyncFunction(value)) throw new ERR_INVALID_ARG_TYPE(name, 'Function', value)\n})\n\n/**\n * @callback validateUndefined\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is undefined}\n */\n\n/** @type {validateUndefined} */\nconst validateUndefined = hideStackFrames((value, name) => {\n  if (value !== undefined) throw new ERR_INVALID_ARG_TYPE(name, 'undefined', value)\n})\n\n/**\n * @template T\n * @param {T} value\n * @param {string} name\n * @param {T[]} union\n */\nfunction validateUnion(value, name, union) {\n  if (!ArrayPrototypeIncludes(union, value)) {\n    throw new ERR_INVALID_ARG_TYPE(name, `('${ArrayPrototypeJoin(union, '|')}')`, value)\n  }\n}\n\n/*\n  The rules for the Link header field are described here:\n  https://www.rfc-editor.org/rfc/rfc8288.html#section-3\n\n  This regex validates any string surrounded by angle brackets\n  (not necessarily a valid URI reference) followed by zero or more\n  link-params separated by semicolons.\n*/\nconst linkValueRegExp = /^(?:<[^>]*>)(?:\\s*;\\s*[^;\"\\s]+(?:=(\")?[^;\"\\s]*\\1)?)*$/\n\n/**\n * @param {any} value\n * @param {string} name\n */\nfunction validateLinkHeaderFormat(value, name) {\n  if (typeof value === 'undefined' || !RegExpPrototypeExec(linkValueRegExp, value)) {\n    throw new ERR_INVALID_ARG_VALUE(\n      name,\n      value,\n      'must be an array or string of format \"</styles.css>; rel=preload; as=style\"'\n    )\n  }\n}\n\n/**\n * @param {any} hints\n * @return {string}\n */\nfunction validateLinkHeaderValue(hints) {\n  if (typeof hints === 'string') {\n    validateLinkHeaderFormat(hints, 'hints')\n    return hints\n  } else if (ArrayIsArray(hints)) {\n    const hintsLength = hints.length\n    let result = ''\n    if (hintsLength === 0) {\n      return result\n    }\n    for (let i = 0; i < hintsLength; i++) {\n      const link = hints[i]\n      validateLinkHeaderFormat(link, 'hints')\n      result += link\n      if (i !== hintsLength - 1) {\n        result += ', '\n      }\n    }\n    return result\n  }\n  throw new ERR_INVALID_ARG_VALUE(\n    'hints',\n    hints,\n    'must be an array or string of format \"</styles.css>; rel=preload; as=style\"'\n  )\n}\nmodule.exports = {\n  isInt32,\n  isUint32,\n  parseFileMode,\n  validateArray,\n  validateStringArray,\n  validateBooleanArray,\n  validateAbortSignalArray,\n  validateBoolean,\n  validateBuffer,\n  validateDictionary,\n  validateEncoding,\n  validateFunction,\n  validateInt32,\n  validateInteger,\n  validateNumber,\n  validateObject,\n  validateOneOf,\n  validatePlainFunction,\n  validatePort,\n  validateSignalName,\n  validateString,\n  validateUint32,\n  validateUndefined,\n  validateUnion,\n  validateAbortSignal,\n  validateLinkHeaderValue\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/internal/validators.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/ours/browser.js":
/*!**********************************************************!*\
  !*** ./node_modules/readable-stream/lib/ours/browser.js ***!
  \**********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst CustomStream = __webpack_require__(/*! ../stream */ \"./node_modules/readable-stream/lib/stream.js\")\nconst promises = __webpack_require__(/*! ../stream/promises */ \"./node_modules/readable-stream/lib/stream/promises.js\")\nconst originalDestroy = CustomStream.Readable.destroy\nmodule.exports = CustomStream.Readable\n\n// Explicit export naming is needed for ESM\nmodule.exports._uint8ArrayToBuffer = CustomStream._uint8ArrayToBuffer\nmodule.exports._isUint8Array = CustomStream._isUint8Array\nmodule.exports.isDisturbed = CustomStream.isDisturbed\nmodule.exports.isErrored = CustomStream.isErrored\nmodule.exports.isReadable = CustomStream.isReadable\nmodule.exports.Readable = CustomStream.Readable\nmodule.exports.Writable = CustomStream.Writable\nmodule.exports.Duplex = CustomStream.Duplex\nmodule.exports.Transform = CustomStream.Transform\nmodule.exports.PassThrough = CustomStream.PassThrough\nmodule.exports.addAbortSignal = CustomStream.addAbortSignal\nmodule.exports.finished = CustomStream.finished\nmodule.exports.destroy = CustomStream.destroy\nmodule.exports.destroy = originalDestroy\nmodule.exports.pipeline = CustomStream.pipeline\nmodule.exports.compose = CustomStream.compose\nObject.defineProperty(CustomStream, 'promises', {\n  configurable: true,\n  enumerable: true,\n  get() {\n    return promises\n  }\n})\nmodule.exports.Stream = CustomStream.Stream\n\n// Allow default importing\nmodule.exports[\"default\"] = module.exports\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/ours/browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/ours/errors.js":
/*!*********************************************************!*\
  !*** ./node_modules/readable-stream/lib/ours/errors.js ***!
  \*********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { format, inspect, AggregateError: CustomAggregateError } = __webpack_require__(/*! ./util */ \"./node_modules/readable-stream/lib/ours/util.js\")\n\n/*\n  This file is a reduced and adapted version of the main lib/internal/errors.js file defined at\n\n  https://github.com/nodejs/node/blob/master/lib/internal/errors.js\n\n  Don't try to replace with the original file and keep it up to date (starting from E(...) definitions)\n  with the upstream file.\n*/\n\nconst AggregateError = globalThis.AggregateError || CustomAggregateError\nconst kIsNodeError = Symbol('kIsNodeError')\nconst kTypes = [\n  'string',\n  'function',\n  'number',\n  'object',\n  // Accept 'Function' and 'Object' as alternative to the lower cased version.\n  'Function',\n  'Object',\n  'boolean',\n  'bigint',\n  'symbol'\n]\nconst classRegExp = /^([A-Z][a-z0-9]*)+$/\nconst nodeInternalPrefix = '__node_internal_'\nconst codes = {}\nfunction assert(value, message) {\n  if (!value) {\n    throw new codes.ERR_INTERNAL_ASSERTION(message)\n  }\n}\n\n// Only use this for integers! Decimal numbers do not work with this function.\nfunction addNumericalSeparator(val) {\n  let res = ''\n  let i = val.length\n  const start = val[0] === '-' ? 1 : 0\n  for (; i >= start + 4; i -= 3) {\n    res = `_${val.slice(i - 3, i)}${res}`\n  }\n  return `${val.slice(0, i)}${res}`\n}\nfunction getMessage(key, msg, args) {\n  if (typeof msg === 'function') {\n    assert(\n      msg.length <= args.length,\n      // Default options do not count.\n      `Code: ${key}; The provided arguments length (${args.length}) does not match the required ones (${msg.length}).`\n    )\n    return msg(...args)\n  }\n  const expectedLength = (msg.match(/%[dfijoOs]/g) || []).length\n  assert(\n    expectedLength === args.length,\n    `Code: ${key}; The provided arguments length (${args.length}) does not match the required ones (${expectedLength}).`\n  )\n  if (args.length === 0) {\n    return msg\n  }\n  return format(msg, ...args)\n}\nfunction E(code, message, Base) {\n  if (!Base) {\n    Base = Error\n  }\n  class NodeError extends Base {\n    constructor(...args) {\n      super(getMessage(code, message, args))\n    }\n    toString() {\n      return `${this.name} [${code}]: ${this.message}`\n    }\n  }\n  Object.defineProperties(NodeError.prototype, {\n    name: {\n      value: Base.name,\n      writable: true,\n      enumerable: false,\n      configurable: true\n    },\n    toString: {\n      value() {\n        return `${this.name} [${code}]: ${this.message}`\n      },\n      writable: true,\n      enumerable: false,\n      configurable: true\n    }\n  })\n  NodeError.prototype.code = code\n  NodeError.prototype[kIsNodeError] = true\n  codes[code] = NodeError\n}\nfunction hideStackFrames(fn) {\n  // We rename the functions that will be hidden to cut off the stacktrace\n  // at the outermost one\n  const hidden = nodeInternalPrefix + fn.name\n  Object.defineProperty(fn, 'name', {\n    value: hidden\n  })\n  return fn\n}\nfunction aggregateTwoErrors(innerError, outerError) {\n  if (innerError && outerError && innerError !== outerError) {\n    if (Array.isArray(outerError.errors)) {\n      // If `outerError` is already an `AggregateError`.\n      outerError.errors.push(innerError)\n      return outerError\n    }\n    const err = new AggregateError([outerError, innerError], outerError.message)\n    err.code = outerError.code\n    return err\n  }\n  return innerError || outerError\n}\nclass AbortError extends Error {\n  constructor(message = 'The operation was aborted', options = undefined) {\n    if (options !== undefined && typeof options !== 'object') {\n      throw new codes.ERR_INVALID_ARG_TYPE('options', 'Object', options)\n    }\n    super(message, options)\n    this.code = 'ABORT_ERR'\n    this.name = 'AbortError'\n  }\n}\nE('ERR_ASSERTION', '%s', Error)\nE(\n  'ERR_INVALID_ARG_TYPE',\n  (name, expected, actual) => {\n    assert(typeof name === 'string', \"'name' must be a string\")\n    if (!Array.isArray(expected)) {\n      expected = [expected]\n    }\n    let msg = 'The '\n    if (name.endsWith(' argument')) {\n      // For cases like 'first argument'\n      msg += `${name} `\n    } else {\n      msg += `\"${name}\" ${name.includes('.') ? 'property' : 'argument'} `\n    }\n    msg += 'must be '\n    const types = []\n    const instances = []\n    const other = []\n    for (const value of expected) {\n      assert(typeof value === 'string', 'All expected entries have to be of type string')\n      if (kTypes.includes(value)) {\n        types.push(value.toLowerCase())\n      } else if (classRegExp.test(value)) {\n        instances.push(value)\n      } else {\n        assert(value !== 'object', 'The value \"object\" should be written as \"Object\"')\n        other.push(value)\n      }\n    }\n\n    // Special handle `object` in case other instances are allowed to outline\n    // the differences between each other.\n    if (instances.length > 0) {\n      const pos = types.indexOf('object')\n      if (pos !== -1) {\n        types.splice(types, pos, 1)\n        instances.push('Object')\n      }\n    }\n    if (types.length > 0) {\n      switch (types.length) {\n        case 1:\n          msg += `of type ${types[0]}`\n          break\n        case 2:\n          msg += `one of type ${types[0]} or ${types[1]}`\n          break\n        default: {\n          const last = types.pop()\n          msg += `one of type ${types.join(', ')}, or ${last}`\n        }\n      }\n      if (instances.length > 0 || other.length > 0) {\n        msg += ' or '\n      }\n    }\n    if (instances.length > 0) {\n      switch (instances.length) {\n        case 1:\n          msg += `an instance of ${instances[0]}`\n          break\n        case 2:\n          msg += `an instance of ${instances[0]} or ${instances[1]}`\n          break\n        default: {\n          const last = instances.pop()\n          msg += `an instance of ${instances.join(', ')}, or ${last}`\n        }\n      }\n      if (other.length > 0) {\n        msg += ' or '\n      }\n    }\n    switch (other.length) {\n      case 0:\n        break\n      case 1:\n        if (other[0].toLowerCase() !== other[0]) {\n          msg += 'an '\n        }\n        msg += `${other[0]}`\n        break\n      case 2:\n        msg += `one of ${other[0]} or ${other[1]}`\n        break\n      default: {\n        const last = other.pop()\n        msg += `one of ${other.join(', ')}, or ${last}`\n      }\n    }\n    if (actual == null) {\n      msg += `. Received ${actual}`\n    } else if (typeof actual === 'function' && actual.name) {\n      msg += `. Received function ${actual.name}`\n    } else if (typeof actual === 'object') {\n      var _actual$constructor\n      if (\n        (_actual$constructor = actual.constructor) !== null &&\n        _actual$constructor !== undefined &&\n        _actual$constructor.name\n      ) {\n        msg += `. Received an instance of ${actual.constructor.name}`\n      } else {\n        const inspected = inspect(actual, {\n          depth: -1\n        })\n        msg += `. Received ${inspected}`\n      }\n    } else {\n      let inspected = inspect(actual, {\n        colors: false\n      })\n      if (inspected.length > 25) {\n        inspected = `${inspected.slice(0, 25)}...`\n      }\n      msg += `. Received type ${typeof actual} (${inspected})`\n    }\n    return msg\n  },\n  TypeError\n)\nE(\n  'ERR_INVALID_ARG_VALUE',\n  (name, value, reason = 'is invalid') => {\n    let inspected = inspect(value)\n    if (inspected.length > 128) {\n      inspected = inspected.slice(0, 128) + '...'\n    }\n    const type = name.includes('.') ? 'property' : 'argument'\n    return `The ${type} '${name}' ${reason}. Received ${inspected}`\n  },\n  TypeError\n)\nE(\n  'ERR_INVALID_RETURN_VALUE',\n  (input, name, value) => {\n    var _value$constructor\n    const type =\n      value !== null &&\n      value !== undefined &&\n      (_value$constructor = value.constructor) !== null &&\n      _value$constructor !== undefined &&\n      _value$constructor.name\n        ? `instance of ${value.constructor.name}`\n        : `type ${typeof value}`\n    return `Expected ${input} to be returned from the \"${name}\"` + ` function but got ${type}.`\n  },\n  TypeError\n)\nE(\n  'ERR_MISSING_ARGS',\n  (...args) => {\n    assert(args.length > 0, 'At least one arg needs to be specified')\n    let msg\n    const len = args.length\n    args = (Array.isArray(args) ? args : [args]).map((a) => `\"${a}\"`).join(' or ')\n    switch (len) {\n      case 1:\n        msg += `The ${args[0]} argument`\n        break\n      case 2:\n        msg += `The ${args[0]} and ${args[1]} arguments`\n        break\n      default:\n        {\n          const last = args.pop()\n          msg += `The ${args.join(', ')}, and ${last} arguments`\n        }\n        break\n    }\n    return `${msg} must be specified`\n  },\n  TypeError\n)\nE(\n  'ERR_OUT_OF_RANGE',\n  (str, range, input) => {\n    assert(range, 'Missing \"range\" argument')\n    let received\n    if (Number.isInteger(input) && Math.abs(input) > 2 ** 32) {\n      received = addNumericalSeparator(String(input))\n    } else if (typeof input === 'bigint') {\n      received = String(input)\n      if (input > 2n ** 32n || input < -(2n ** 32n)) {\n        received = addNumericalSeparator(received)\n      }\n      received += 'n'\n    } else {\n      received = inspect(input)\n    }\n    return `The value of \"${str}\" is out of range. It must be ${range}. Received ${received}`\n  },\n  RangeError\n)\nE('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times', Error)\nE('ERR_METHOD_NOT_IMPLEMENTED', 'The %s method is not implemented', Error)\nE('ERR_STREAM_ALREADY_FINISHED', 'Cannot call %s after a stream was finished', Error)\nE('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable', Error)\nE('ERR_STREAM_DESTROYED', 'Cannot call %s after a stream was destroyed', Error)\nE('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError)\nE('ERR_STREAM_PREMATURE_CLOSE', 'Premature close', Error)\nE('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF', Error)\nE('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event', Error)\nE('ERR_STREAM_WRITE_AFTER_END', 'write after end', Error)\nE('ERR_UNKNOWN_ENCODING', 'Unknown encoding: %s', TypeError)\nmodule.exports = {\n  AbortError,\n  aggregateTwoErrors: hideStackFrames(aggregateTwoErrors),\n  hideStackFrames,\n  codes\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/ours/errors.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/ours/primordials.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/ours/primordials.js ***!
  \**************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*\n  This file is a reduced and adapted version of the main lib/internal/per_context/primordials.js file defined at\n\n  https://github.com/nodejs/node/blob/master/lib/internal/per_context/primordials.js\n\n  Don't try to replace with the original file and keep it up to date with the upstream file.\n*/\nmodule.exports = {\n  ArrayIsArray(self) {\n    return Array.isArray(self)\n  },\n  ArrayPrototypeIncludes(self, el) {\n    return self.includes(el)\n  },\n  ArrayPrototypeIndexOf(self, el) {\n    return self.indexOf(el)\n  },\n  ArrayPrototypeJoin(self, sep) {\n    return self.join(sep)\n  },\n  ArrayPrototypeMap(self, fn) {\n    return self.map(fn)\n  },\n  ArrayPrototypePop(self, el) {\n    return self.pop(el)\n  },\n  ArrayPrototypePush(self, el) {\n    return self.push(el)\n  },\n  ArrayPrototypeSlice(self, start, end) {\n    return self.slice(start, end)\n  },\n  Error,\n  FunctionPrototypeCall(fn, thisArgs, ...args) {\n    return fn.call(thisArgs, ...args)\n  },\n  FunctionPrototypeSymbolHasInstance(self, instance) {\n    return Function.prototype[Symbol.hasInstance].call(self, instance)\n  },\n  MathFloor: Math.floor,\n  Number,\n  NumberIsInteger: Number.isInteger,\n  NumberIsNaN: Number.isNaN,\n  NumberMAX_SAFE_INTEGER: Number.MAX_SAFE_INTEGER,\n  NumberMIN_SAFE_INTEGER: Number.MIN_SAFE_INTEGER,\n  NumberParseInt: Number.parseInt,\n  ObjectDefineProperties(self, props) {\n    return Object.defineProperties(self, props)\n  },\n  ObjectDefineProperty(self, name, prop) {\n    return Object.defineProperty(self, name, prop)\n  },\n  ObjectGetOwnPropertyDescriptor(self, name) {\n    return Object.getOwnPropertyDescriptor(self, name)\n  },\n  ObjectKeys(obj) {\n    return Object.keys(obj)\n  },\n  ObjectSetPrototypeOf(target, proto) {\n    return Object.setPrototypeOf(target, proto)\n  },\n  Promise,\n  PromisePrototypeCatch(self, fn) {\n    return self.catch(fn)\n  },\n  PromisePrototypeThen(self, thenFn, catchFn) {\n    return self.then(thenFn, catchFn)\n  },\n  PromiseReject(err) {\n    return Promise.reject(err)\n  },\n  PromiseResolve(val) {\n    return Promise.resolve(val)\n  },\n  ReflectApply: Reflect.apply,\n  RegExpPrototypeTest(self, value) {\n    return self.test(value)\n  },\n  SafeSet: Set,\n  String,\n  StringPrototypeSlice(self, start, end) {\n    return self.slice(start, end)\n  },\n  StringPrototypeToLowerCase(self) {\n    return self.toLowerCase()\n  },\n  StringPrototypeToUpperCase(self) {\n    return self.toUpperCase()\n  },\n  StringPrototypeTrim(self) {\n    return self.trim()\n  },\n  Symbol,\n  SymbolFor: Symbol.for,\n  SymbolAsyncIterator: Symbol.asyncIterator,\n  SymbolHasInstance: Symbol.hasInstance,\n  SymbolIterator: Symbol.iterator,\n  SymbolDispose: Symbol.dispose || Symbol('Symbol.dispose'),\n  SymbolAsyncDispose: Symbol.asyncDispose || Symbol('Symbol.asyncDispose'),\n  TypedArrayPrototypeSet(self, buf, len) {\n    return self.set(buf, len)\n  },\n  Boolean: Boolean,\n  Uint8Array\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/ours/primordials.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/ours/util.js":
/*!*******************************************************!*\
  !*** ./node_modules/readable-stream/lib/ours/util.js ***!
  \*******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst bufferModule = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\nconst { kResistStopPropagation, SymbolDispose } = __webpack_require__(/*! ./primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst AbortSignal = globalThis.AbortSignal || (__webpack_require__(/*! abort-controller */ \"./node_modules/abort-controller/browser.js\").AbortSignal)\nconst AbortController = globalThis.AbortController || (__webpack_require__(/*! abort-controller */ \"./node_modules/abort-controller/browser.js\").AbortController)\nconst AsyncFunction = Object.getPrototypeOf(async function () {}).constructor\nconst Blob = globalThis.Blob || bufferModule.Blob\n/* eslint-disable indent */\nconst isBlob =\n  typeof Blob !== 'undefined'\n    ? function isBlob(b) {\n        // eslint-disable-next-line indent\n        return b instanceof Blob\n      }\n    : function isBlob(b) {\n        return false\n      }\n/* eslint-enable indent */\n\nconst validateAbortSignal = (signal, name) => {\n  if (signal !== undefined && (signal === null || typeof signal !== 'object' || !('aborted' in signal))) {\n    throw new ERR_INVALID_ARG_TYPE(name, 'AbortSignal', signal)\n  }\n}\nconst validateFunction = (value, name) => {\n  if (typeof value !== 'function') throw new ERR_INVALID_ARG_TYPE(name, 'Function', value)\n}\n\n// This is a simplified version of AggregateError\nclass AggregateError extends Error {\n  constructor(errors) {\n    if (!Array.isArray(errors)) {\n      throw new TypeError(`Expected input to be an Array, got ${typeof errors}`)\n    }\n    let message = ''\n    for (let i = 0; i < errors.length; i++) {\n      message += `    ${errors[i].stack}\\n`\n    }\n    super(message)\n    this.name = 'AggregateError'\n    this.errors = errors\n  }\n}\nmodule.exports = {\n  AggregateError,\n  kEmptyObject: Object.freeze({}),\n  once(callback) {\n    let called = false\n    return function (...args) {\n      if (called) {\n        return\n      }\n      called = true\n      callback.apply(this, args)\n    }\n  },\n  createDeferredPromise: function () {\n    let resolve\n    let reject\n\n    // eslint-disable-next-line promise/param-names\n    const promise = new Promise((res, rej) => {\n      resolve = res\n      reject = rej\n    })\n    return {\n      promise,\n      resolve,\n      reject\n    }\n  },\n  promisify(fn) {\n    return new Promise((resolve, reject) => {\n      fn((err, ...args) => {\n        if (err) {\n          return reject(err)\n        }\n        return resolve(...args)\n      })\n    })\n  },\n  debuglog() {\n    return function () {}\n  },\n  format(format, ...args) {\n    // Simplified version of https://nodejs.org/api/util.html#utilformatformat-args\n    return format.replace(/%([sdifj])/g, function (...[_unused, type]) {\n      const replacement = args.shift()\n      if (type === 'f') {\n        return replacement.toFixed(6)\n      } else if (type === 'j') {\n        return JSON.stringify(replacement)\n      } else if (type === 's' && typeof replacement === 'object') {\n        const ctor = replacement.constructor !== Object ? replacement.constructor.name : ''\n        return `${ctor} {}`.trim()\n      } else {\n        return replacement.toString()\n      }\n    })\n  },\n  inspect(value) {\n    // Vastly simplified version of https://nodejs.org/api/util.html#utilinspectobject-options\n    switch (typeof value) {\n      case 'string':\n        if (value.includes(\"'\")) {\n          if (!value.includes('\"')) {\n            return `\"${value}\"`\n          } else if (!value.includes('`') && !value.includes('${')) {\n            return `\\`${value}\\``\n          }\n        }\n        return `'${value}'`\n      case 'number':\n        if (isNaN(value)) {\n          return 'NaN'\n        } else if (Object.is(value, -0)) {\n          return String(value)\n        }\n        return value\n      case 'bigint':\n        return `${String(value)}n`\n      case 'boolean':\n      case 'undefined':\n        return String(value)\n      case 'object':\n        return '{}'\n    }\n  },\n  types: {\n    isAsyncFunction(fn) {\n      return fn instanceof AsyncFunction\n    },\n    isArrayBufferView(arr) {\n      return ArrayBuffer.isView(arr)\n    }\n  },\n  isBlob,\n  deprecate(fn, message) {\n    return fn\n  },\n  addAbortListener:\n    (__webpack_require__(/*! events */ \"./node_modules/events/events.js\").addAbortListener) ||\n    function addAbortListener(signal, listener) {\n      if (signal === undefined) {\n        throw new ERR_INVALID_ARG_TYPE('signal', 'AbortSignal', signal)\n      }\n      validateAbortSignal(signal, 'signal')\n      validateFunction(listener, 'listener')\n      let removeEventListener\n      if (signal.aborted) {\n        queueMicrotask(() => listener())\n      } else {\n        signal.addEventListener('abort', listener, {\n          __proto__: null,\n          once: true,\n          [kResistStopPropagation]: true\n        })\n        removeEventListener = () => {\n          signal.removeEventListener('abort', listener)\n        }\n      }\n      return {\n        __proto__: null,\n        [SymbolDispose]() {\n          var _removeEventListener\n          ;(_removeEventListener = removeEventListener) === null || _removeEventListener === undefined\n            ? undefined\n            : _removeEventListener()\n        }\n      }\n    },\n  AbortSignalAny:\n    AbortSignal.any ||\n    function AbortSignalAny(signals) {\n      // Fast path if there is only one signal.\n      if (signals.length === 1) {\n        return signals[0]\n      }\n      const ac = new AbortController()\n      const abort = () => ac.abort()\n      signals.forEach((signal) => {\n        validateAbortSignal(signal, 'signals')\n        signal.addEventListener('abort', abort, {\n          once: true\n        })\n      })\n      ac.signal.addEventListener(\n        'abort',\n        () => {\n          signals.forEach((signal) => signal.removeEventListener('abort', abort))\n        },\n        {\n          once: true\n        }\n      )\n      return ac.signal\n    }\n}\nmodule.exports.promisify.custom = Symbol.for('nodejs.util.promisify.custom')\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/ours/util.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/stream.js":
/*!****************************************************!*\
  !*** ./node_modules/readable-stream/lib/stream.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/* replacement start */\n\nconst { Buffer } = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\n\n/* replacement end */\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n;('use strict')\nconst { ObjectDefineProperty, ObjectKeys, ReflectApply } = __webpack_require__(/*! ./ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst {\n  promisify: { custom: customPromisify }\n} = __webpack_require__(/*! ./ours/util */ \"./node_modules/readable-stream/lib/ours/util.js\")\nconst { streamReturningOperators, promiseReturningOperators } = __webpack_require__(/*! ./internal/streams/operators */ \"./node_modules/readable-stream/lib/internal/streams/operators.js\")\nconst {\n  codes: { ERR_ILLEGAL_CONSTRUCTOR }\n} = __webpack_require__(/*! ./ours/errors */ \"./node_modules/readable-stream/lib/ours/errors.js\")\nconst compose = __webpack_require__(/*! ./internal/streams/compose */ \"./node_modules/readable-stream/lib/internal/streams/compose.js\")\nconst { setDefaultHighWaterMark, getDefaultHighWaterMark } = __webpack_require__(/*! ./internal/streams/state */ \"./node_modules/readable-stream/lib/internal/streams/state.js\")\nconst { pipeline } = __webpack_require__(/*! ./internal/streams/pipeline */ \"./node_modules/readable-stream/lib/internal/streams/pipeline.js\")\nconst { destroyer } = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\")\nconst eos = __webpack_require__(/*! ./internal/streams/end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\")\nconst internalBuffer = {}\nconst promises = __webpack_require__(/*! ./stream/promises */ \"./node_modules/readable-stream/lib/stream/promises.js\")\nconst utils = __webpack_require__(/*! ./internal/streams/utils */ \"./node_modules/readable-stream/lib/internal/streams/utils.js\")\nconst Stream = (module.exports = __webpack_require__(/*! ./internal/streams/legacy */ \"./node_modules/readable-stream/lib/internal/streams/legacy.js\").Stream)\nStream.isDestroyed = utils.isDestroyed\nStream.isDisturbed = utils.isDisturbed\nStream.isErrored = utils.isErrored\nStream.isReadable = utils.isReadable\nStream.isWritable = utils.isWritable\nStream.Readable = __webpack_require__(/*! ./internal/streams/readable */ \"./node_modules/readable-stream/lib/internal/streams/readable.js\")\nfor (const key of ObjectKeys(streamReturningOperators)) {\n  const op = streamReturningOperators[key]\n  function fn(...args) {\n    if (new.target) {\n      throw ERR_ILLEGAL_CONSTRUCTOR()\n    }\n    return Stream.Readable.from(ReflectApply(op, this, args))\n  }\n  ObjectDefineProperty(fn, 'name', {\n    __proto__: null,\n    value: op.name\n  })\n  ObjectDefineProperty(fn, 'length', {\n    __proto__: null,\n    value: op.length\n  })\n  ObjectDefineProperty(Stream.Readable.prototype, key, {\n    __proto__: null,\n    value: fn,\n    enumerable: false,\n    configurable: true,\n    writable: true\n  })\n}\nfor (const key of ObjectKeys(promiseReturningOperators)) {\n  const op = promiseReturningOperators[key]\n  function fn(...args) {\n    if (new.target) {\n      throw ERR_ILLEGAL_CONSTRUCTOR()\n    }\n    return ReflectApply(op, this, args)\n  }\n  ObjectDefineProperty(fn, 'name', {\n    __proto__: null,\n    value: op.name\n  })\n  ObjectDefineProperty(fn, 'length', {\n    __proto__: null,\n    value: op.length\n  })\n  ObjectDefineProperty(Stream.Readable.prototype, key, {\n    __proto__: null,\n    value: fn,\n    enumerable: false,\n    configurable: true,\n    writable: true\n  })\n}\nStream.Writable = __webpack_require__(/*! ./internal/streams/writable */ \"./node_modules/readable-stream/lib/internal/streams/writable.js\")\nStream.Duplex = __webpack_require__(/*! ./internal/streams/duplex */ \"./node_modules/readable-stream/lib/internal/streams/duplex.js\")\nStream.Transform = __webpack_require__(/*! ./internal/streams/transform */ \"./node_modules/readable-stream/lib/internal/streams/transform.js\")\nStream.PassThrough = __webpack_require__(/*! ./internal/streams/passthrough */ \"./node_modules/readable-stream/lib/internal/streams/passthrough.js\")\nStream.pipeline = pipeline\nconst { addAbortSignal } = __webpack_require__(/*! ./internal/streams/add-abort-signal */ \"./node_modules/readable-stream/lib/internal/streams/add-abort-signal.js\")\nStream.addAbortSignal = addAbortSignal\nStream.finished = eos\nStream.destroy = destroyer\nStream.compose = compose\nStream.setDefaultHighWaterMark = setDefaultHighWaterMark\nStream.getDefaultHighWaterMark = getDefaultHighWaterMark\nObjectDefineProperty(Stream, 'promises', {\n  __proto__: null,\n  configurable: true,\n  enumerable: true,\n  get() {\n    return promises\n  }\n})\nObjectDefineProperty(pipeline, customPromisify, {\n  __proto__: null,\n  enumerable: true,\n  get() {\n    return promises.pipeline\n  }\n})\nObjectDefineProperty(eos, customPromisify, {\n  __proto__: null,\n  enumerable: true,\n  get() {\n    return promises.finished\n  }\n})\n\n// Backwards-compat with node 0.4.x\nStream.Stream = Stream\nStream._isUint8Array = function isUint8Array(value) {\n  return value instanceof Uint8Array\n}\nStream._uint8ArrayToBuffer = function _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk.buffer, chunk.byteOffset, chunk.byteLength)\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/stream.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/stream/promises.js":
/*!*************************************************************!*\
  !*** ./node_modules/readable-stream/lib/stream/promises.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nconst { ArrayPrototypePop, Promise } = __webpack_require__(/*! ../ours/primordials */ \"./node_modules/readable-stream/lib/ours/primordials.js\")\nconst { isIterable, isNodeStream, isWebStream } = __webpack_require__(/*! ../internal/streams/utils */ \"./node_modules/readable-stream/lib/internal/streams/utils.js\")\nconst { pipelineImpl: pl } = __webpack_require__(/*! ../internal/streams/pipeline */ \"./node_modules/readable-stream/lib/internal/streams/pipeline.js\")\nconst { finished } = __webpack_require__(/*! ../internal/streams/end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\")\n__webpack_require__(/*! ../../lib/stream.js */ \"./node_modules/readable-stream/lib/stream.js\")\nfunction pipeline(...streams) {\n  return new Promise((resolve, reject) => {\n    let signal\n    let end\n    const lastArg = streams[streams.length - 1]\n    if (\n      lastArg &&\n      typeof lastArg === 'object' &&\n      !isNodeStream(lastArg) &&\n      !isIterable(lastArg) &&\n      !isWebStream(lastArg)\n    ) {\n      const options = ArrayPrototypePop(streams)\n      signal = options.signal\n      end = options.end\n    }\n    pl(\n      streams,\n      (err, value) => {\n        if (err) {\n          reject(err)\n        } else {\n          resolve(value)\n        }\n      },\n      {\n        signal,\n        end\n      }\n    )\n  })\n}\nmodule.exports = {\n  finished,\n  pipeline\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/readable-stream/lib/stream/promises.js?");

/***/ }),

/***/ "./node_modules/relative-to-absolute-iri/index.js":
/*!********************************************************!*\
  !*** ./node_modules/relative-to-absolute-iri/index.js ***!
  \********************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n__exportStar(__webpack_require__(/*! ./lib/Resolve */ \"./node_modules/relative-to-absolute-iri/lib/Resolve.js\"), exports);\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/relative-to-absolute-iri/index.js?");

/***/ }),

/***/ "./node_modules/relative-to-absolute-iri/lib/Resolve.js":
/*!**************************************************************!*\
  !*** ./node_modules/relative-to-absolute-iri/lib/Resolve.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.removeDotSegmentsOfPath = exports.removeDotSegments = exports.resolve = void 0;\n/**\n * Convert the given relative IRI to an absolute IRI\n * by taking into account the given optional baseIRI.\n *\n * @param {string} relativeIRI The relative IRI to convert to an absolute IRI.\n * @param {string} baseIRI The optional base IRI.\n * @return {string} an absolute IRI.\n */\nfunction resolve(relativeIRI, baseIRI) {\n    baseIRI = baseIRI || '';\n    const baseFragmentPos = baseIRI.indexOf('#');\n    // Ignore any fragments in the base IRI\n    if (baseFragmentPos > 0) {\n        baseIRI = baseIRI.substr(0, baseFragmentPos);\n    }\n    // Convert empty value directly to base IRI\n    if (!relativeIRI.length) {\n        // At this point, the baseIRI MUST be absolute, otherwise we error\n        if (baseIRI.indexOf(':') < 0) {\n            throw new Error(`Found invalid baseIRI '${baseIRI}' for value '${relativeIRI}'`);\n        }\n        return baseIRI;\n    }\n    // If the value starts with a query character, concat directly (but strip the existing query)\n    if (relativeIRI.startsWith('?')) {\n        const baseQueryPos = baseIRI.indexOf('?');\n        if (baseQueryPos > 0) {\n            baseIRI = baseIRI.substr(0, baseQueryPos);\n        }\n        return baseIRI + relativeIRI;\n    }\n    // If the value starts with a fragment character, concat directly\n    if (relativeIRI.startsWith('#')) {\n        return baseIRI + relativeIRI;\n    }\n    // Ignore baseIRI if it is empty\n    if (!baseIRI.length) {\n        const relativeColonPos = relativeIRI.indexOf(':');\n        if (relativeColonPos < 0) {\n            throw new Error(`Found invalid relative IRI '${relativeIRI}' for a missing baseIRI`);\n        }\n        return removeDotSegmentsOfPath(relativeIRI, relativeColonPos);\n    }\n    // Ignore baseIRI if the value is absolute\n    const valueColonPos = relativeIRI.indexOf(':');\n    if (valueColonPos >= 0) {\n        return removeDotSegmentsOfPath(relativeIRI, valueColonPos);\n    }\n    // At this point, the baseIRI MUST be absolute, otherwise we error\n    const baseColonPos = baseIRI.indexOf(':');\n    if (baseColonPos < 0) {\n        throw new Error(`Found invalid baseIRI '${baseIRI}' for value '${relativeIRI}'`);\n    }\n    const baseIRIScheme = baseIRI.substr(0, baseColonPos + 1);\n    // Inherit the baseIRI scheme if the value starts with '//'\n    if (relativeIRI.indexOf('//') === 0) {\n        return baseIRIScheme + removeDotSegmentsOfPath(relativeIRI, valueColonPos);\n    }\n    // Check cases where '://' occurs in the baseIRI, and where there is no '/' after a ':' anymore.\n    let baseSlashAfterColonPos;\n    if (baseIRI.indexOf('//', baseColonPos) === baseColonPos + 1) {\n        // If there is no additional '/' after the '//'.\n        baseSlashAfterColonPos = baseIRI.indexOf('/', baseColonPos + 3);\n        if (baseSlashAfterColonPos < 0) {\n            // If something other than a '/' follows the '://', append the value after a '/',\n            // otherwise, prefix the value with only the baseIRI scheme.\n            if (baseIRI.length > baseColonPos + 3) {\n                return baseIRI + '/' + removeDotSegmentsOfPath(relativeIRI, valueColonPos);\n            }\n            else {\n                return baseIRIScheme + removeDotSegmentsOfPath(relativeIRI, valueColonPos);\n            }\n        }\n    }\n    else {\n        // If there is not even a single '/' after the ':'\n        baseSlashAfterColonPos = baseIRI.indexOf('/', baseColonPos + 1);\n        if (baseSlashAfterColonPos < 0) {\n            // If we don't have a '/' after the ':',\n            // prefix the value with only the baseIRI scheme.\n            return baseIRIScheme + removeDotSegmentsOfPath(relativeIRI, valueColonPos);\n        }\n    }\n    // If the value starts with a '/', then prefix it with everything before the first effective slash of the base IRI.\n    if (relativeIRI.indexOf('/') === 0) {\n        return baseIRI.substr(0, baseSlashAfterColonPos) + removeDotSegments(relativeIRI);\n    }\n    let baseIRIPath = baseIRI.substr(baseSlashAfterColonPos);\n    const baseIRILastSlashPos = baseIRIPath.lastIndexOf('/');\n    // Ignore everything after the last '/' in the baseIRI path\n    if (baseIRILastSlashPos >= 0 && baseIRILastSlashPos < baseIRIPath.length - 1) {\n        baseIRIPath = baseIRIPath.substr(0, baseIRILastSlashPos + 1);\n        // Also remove the first character of the relative path if it starts with '.' (and not '..' or './')\n        // This change is only allowed if there is something else following the path\n        if (relativeIRI[0] === '.' && relativeIRI[1] !== '.' && relativeIRI[1] !== '/' && relativeIRI[2]) {\n            relativeIRI = relativeIRI.substr(1);\n        }\n    }\n    // Prefix the value with the baseIRI path where\n    relativeIRI = baseIRIPath + relativeIRI;\n    // Remove dot segment from the IRI\n    relativeIRI = removeDotSegments(relativeIRI);\n    // Prefix our transformed value with the part of the baseIRI until the first '/' after the first ':'.\n    return baseIRI.substr(0, baseSlashAfterColonPos) + relativeIRI;\n}\nexports.resolve = resolve;\n/**\n * Remove dot segments from the given path,\n * as described in https://www.ietf.org/rfc/rfc3986.txt (page 32).\n * @param {string} path An IRI path.\n * @return {string} A path, will always start with a '/'.\n */\nfunction removeDotSegments(path) {\n    // Prepare a buffer with segments between each '/.\n    // Each segment represents an array of characters.\n    const segmentBuffers = [];\n    let i = 0;\n    while (i < path.length) {\n        // Remove '/.' or '/..'\n        switch (path[i]) {\n            case '/':\n                if (path[i + 1] === '.') {\n                    if (path[i + 2] === '.') {\n                        // Start a new segment if we find an invalid character after the '.'\n                        if (!isCharacterAllowedAfterRelativePathSegment(path[i + 3])) {\n                            segmentBuffers.push([]);\n                            i++;\n                            break;\n                        }\n                        // Go to parent directory,\n                        // so we remove a parent segment\n                        segmentBuffers.pop();\n                        // Ensure that we end with a slash if there is a trailing '/..'\n                        if (!path[i + 3]) {\n                            segmentBuffers.push([]);\n                        }\n                        i += 3;\n                    }\n                    else {\n                        // Start a new segment if we find an invalid character after the '.'\n                        if (!isCharacterAllowedAfterRelativePathSegment(path[i + 2])) {\n                            segmentBuffers.push([]);\n                            i++;\n                            break;\n                        }\n                        // Ensure that we end with a slash if there is a trailing '/.'\n                        if (!path[i + 2]) {\n                            segmentBuffers.push([]);\n                        }\n                        // Go to the current directory,\n                        // so we do nothing\n                        i += 2;\n                    }\n                }\n                else {\n                    // Start a new segment\n                    segmentBuffers.push([]);\n                    i++;\n                }\n                break;\n            case '#':\n            case '?':\n                // Query and fragment string should be appended unchanged\n                if (!segmentBuffers.length) {\n                    segmentBuffers.push([]);\n                }\n                segmentBuffers[segmentBuffers.length - 1].push(path.substr(i));\n                // Break the while loop\n                i = path.length;\n                break;\n            default:\n                // Not a special character, just append it to our buffer\n                if (!segmentBuffers.length) {\n                    segmentBuffers.push([]);\n                }\n                segmentBuffers[segmentBuffers.length - 1].push(path[i]);\n                i++;\n                break;\n        }\n    }\n    return '/' + segmentBuffers.map((buffer) => buffer.join('')).join('/');\n}\nexports.removeDotSegments = removeDotSegments;\n/**\n * Removes dot segments of the given IRI.\n * @param {string} iri An IRI (or part of IRI).\n * @param {number} colonPosition The position of the first ':' in the IRI.\n * @return {string} The IRI where dot segments were removed.\n */\nfunction removeDotSegmentsOfPath(iri, colonPosition) {\n    // Determine where we should start looking for the first '/' that indicates the start of the path\n    let searchOffset = colonPosition + 1;\n    if (colonPosition >= 0) {\n        if (iri[colonPosition + 1] === '/' && iri[colonPosition + 2] === '/') {\n            searchOffset = colonPosition + 3;\n        }\n    }\n    else {\n        if (iri[0] === '/' && iri[1] === '/') {\n            searchOffset = 2;\n        }\n    }\n    // Determine the path\n    const pathSeparator = iri.indexOf('/', searchOffset);\n    if (pathSeparator < 0) {\n        return iri;\n    }\n    const base = iri.substr(0, pathSeparator);\n    const path = iri.substr(pathSeparator);\n    // Remove dot segments from the path\n    return base + removeDotSegments(path);\n}\nexports.removeDotSegmentsOfPath = removeDotSegmentsOfPath;\nfunction isCharacterAllowedAfterRelativePathSegment(character) {\n    return !character || character === '#' || character === '?' || character === '/';\n}\n//# sourceMappingURL=Resolve.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/relative-to-absolute-iri/lib/Resolve.js?");

/***/ }),

/***/ "./node_modules/setimmediate/setImmediate.js":
/*!***************************************************!*\
  !*** ./node_modules/setimmediate/setImmediate.js ***!
  \***************************************************/
/***/ (function(__unused_webpack_module, __unused_webpack_exports, __webpack_require__) {

eval("/* provided dependency */ var process = __webpack_require__(/*! process/browser */ \"./node_modules/process/browser.js\");\n(function (global, undefined) {\n    \"use strict\";\n\n    if (global.setImmediate) {\n        return;\n    }\n\n    var nextHandle = 1; // Spec says greater than zero\n    var tasksByHandle = {};\n    var currentlyRunningATask = false;\n    var doc = global.document;\n    var registerImmediate;\n\n    function setImmediate(callback) {\n      // Callback can either be a function or a string\n      if (typeof callback !== \"function\") {\n        callback = new Function(\"\" + callback);\n      }\n      // Copy function arguments\n      var args = new Array(arguments.length - 1);\n      for (var i = 0; i < args.length; i++) {\n          args[i] = arguments[i + 1];\n      }\n      // Store and register the task\n      var task = { callback: callback, args: args };\n      tasksByHandle[nextHandle] = task;\n      registerImmediate(nextHandle);\n      return nextHandle++;\n    }\n\n    function clearImmediate(handle) {\n        delete tasksByHandle[handle];\n    }\n\n    function run(task) {\n        var callback = task.callback;\n        var args = task.args;\n        switch (args.length) {\n        case 0:\n            callback();\n            break;\n        case 1:\n            callback(args[0]);\n            break;\n        case 2:\n            callback(args[0], args[1]);\n            break;\n        case 3:\n            callback(args[0], args[1], args[2]);\n            break;\n        default:\n            callback.apply(undefined, args);\n            break;\n        }\n    }\n\n    function runIfPresent(handle) {\n        // From the spec: \"Wait until any invocations of this algorithm started before this one have completed.\"\n        // So if we're currently running a task, we'll need to delay this invocation.\n        if (currentlyRunningATask) {\n            // Delay by doing a setTimeout. setImmediate was tried instead, but in Firefox 7 it generated a\n            // \"too much recursion\" error.\n            setTimeout(runIfPresent, 0, handle);\n        } else {\n            var task = tasksByHandle[handle];\n            if (task) {\n                currentlyRunningATask = true;\n                try {\n                    run(task);\n                } finally {\n                    clearImmediate(handle);\n                    currentlyRunningATask = false;\n                }\n            }\n        }\n    }\n\n    function installNextTickImplementation() {\n        registerImmediate = function(handle) {\n            process.nextTick(function () { runIfPresent(handle); });\n        };\n    }\n\n    function canUsePostMessage() {\n        // The test against `importScripts` prevents this implementation from being installed inside a web worker,\n        // where `global.postMessage` means something completely different and can't be used for this purpose.\n        if (global.postMessage && !global.importScripts) {\n            var postMessageIsAsynchronous = true;\n            var oldOnMessage = global.onmessage;\n            global.onmessage = function() {\n                postMessageIsAsynchronous = false;\n            };\n            global.postMessage(\"\", \"*\");\n            global.onmessage = oldOnMessage;\n            return postMessageIsAsynchronous;\n        }\n    }\n\n    function installPostMessageImplementation() {\n        // Installs an event handler on `global` for the `message` event: see\n        // * https://developer.mozilla.org/en/DOM/window.postMessage\n        // * http://www.whatwg.org/specs/web-apps/current-work/multipage/comms.html#crossDocumentMessages\n\n        var messagePrefix = \"setImmediate$\" + Math.random() + \"$\";\n        var onGlobalMessage = function(event) {\n            if (event.source === global &&\n                typeof event.data === \"string\" &&\n                event.data.indexOf(messagePrefix) === 0) {\n                runIfPresent(+event.data.slice(messagePrefix.length));\n            }\n        };\n\n        if (global.addEventListener) {\n            global.addEventListener(\"message\", onGlobalMessage, false);\n        } else {\n            global.attachEvent(\"onmessage\", onGlobalMessage);\n        }\n\n        registerImmediate = function(handle) {\n            global.postMessage(messagePrefix + handle, \"*\");\n        };\n    }\n\n    function installMessageChannelImplementation() {\n        var channel = new MessageChannel();\n        channel.port1.onmessage = function(event) {\n            var handle = event.data;\n            runIfPresent(handle);\n        };\n\n        registerImmediate = function(handle) {\n            channel.port2.postMessage(handle);\n        };\n    }\n\n    function installReadyStateChangeImplementation() {\n        var html = doc.documentElement;\n        registerImmediate = function(handle) {\n            // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n            // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n            var script = doc.createElement(\"script\");\n            script.onreadystatechange = function () {\n                runIfPresent(handle);\n                script.onreadystatechange = null;\n                html.removeChild(script);\n                script = null;\n            };\n            html.appendChild(script);\n        };\n    }\n\n    function installSetTimeoutImplementation() {\n        registerImmediate = function(handle) {\n            setTimeout(runIfPresent, 0, handle);\n        };\n    }\n\n    // If supported, we should attach to the prototype of global, since that is where setTimeout et al. live.\n    var attachTo = Object.getPrototypeOf && Object.getPrototypeOf(global);\n    attachTo = attachTo && attachTo.setTimeout ? attachTo : global;\n\n    // Don't get fooled by e.g. browserify environments.\n    if ({}.toString.call(global.process) === \"[object process]\") {\n        // For Node.js before 0.9\n        installNextTickImplementation();\n\n    } else if (canUsePostMessage()) {\n        // For non-IE10 modern browsers\n        installPostMessageImplementation();\n\n    } else if (global.MessageChannel) {\n        // For web workers, where supported\n        installMessageChannelImplementation();\n\n    } else if (doc && \"onreadystatechange\" in doc.createElement(\"script\")) {\n        // For IE 6–8\n        installReadyStateChangeImplementation();\n\n    } else {\n        // For older browsers\n        installSetTimeoutImplementation();\n    }\n\n    attachTo.setImmediate = setImmediate;\n    attachTo.clearImmediate = clearImmediate;\n}(typeof self === \"undefined\" ? typeof __webpack_require__.g === \"undefined\" ? this : __webpack_require__.g : self));\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/setimmediate/setImmediate.js?");

/***/ }),

/***/ "./node_modules/string_decoder/lib/string_decoder.js":
/*!***********************************************************!*\
  !*** ./node_modules/string_decoder/lib/string_decoder.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar Buffer = (__webpack_require__(/*! safe-buffer */ \"./node_modules/string_decoder/node_modules/safe-buffer/index.js\").Buffer);\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}\n\n//# sourceURL=webpack://FormAMatic/./node_modules/string_decoder/lib/string_decoder.js?");

/***/ }),

/***/ "./node_modules/string_decoder/node_modules/safe-buffer/index.js":
/*!***********************************************************************!*\
  !*** ./node_modules/string_decoder/node_modules/safe-buffer/index.js ***!
  \***********************************************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\n/* eslint-disable node/no-deprecated-api */\nvar buffer = __webpack_require__(/*! buffer */ \"./node_modules/buffer/index.js\")\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.prototype = Object.create(Buffer.prototype)\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/string_decoder/node_modules/safe-buffer/index.js?");

/***/ }),

/***/ "./node_modules/validate-iri/index.js":
/*!********************************************!*\
  !*** ./node_modules/validate-iri/index.js ***!
  \********************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n__exportStar(__webpack_require__(/*! ./lib/Validate */ \"./node_modules/validate-iri/lib/Validate.js\"), exports);\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/validate-iri/index.js?");

/***/ }),

/***/ "./node_modules/validate-iri/lib/Validate.js":
/*!***************************************************!*\
  !*** ./node_modules/validate-iri/lib/Validate.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.validateIri = exports.IriValidationStrategy = void 0;\nfunction buildAbsoluteIriRfc3987Regex() {\n    // The syntax is defined in https://www.rfc-editor.org/rfc/rfc3987#section-2.2\n    // Rules are defined in reversed order\n    const sub_delims_raw = `!$&'()*+,;=`;\n    const sub_delims = `[${sub_delims_raw}]`;\n    const pct_encoded = `%[a-fA-F0-9]{2}`;\n    const dec_octet = '([0-9]|[1-9][0-9]|1[0-9][0-9]|2[0-4][0-9]|25[0-5])';\n    const ipv4address = `${dec_octet}\\\\.${dec_octet}\\\\.${dec_octet}\\\\.${dec_octet}`;\n    const h16 = `[a-fA-F0-9]{1,4}`;\n    const ls32 = `(${h16}:${h16}|${ipv4address})`;\n    const ipv6address = `((${h16}:){6}${ls32}|::(${h16}:){5}${ls32}|(${h16})?::(${h16}:){4}${ls32}|((${h16}:){0,1}${h16})?::(${h16}:){3}${ls32}|((${h16}:){0,2}${h16})?::(${h16}:){2}${ls32}|((${h16}:){0,3}${h16})?::${h16}:${ls32}|((${h16}:){0,4}${h16})?::${ls32}|((${h16}:){0,5}${h16})?::${h16}|((${h16}:){0,6}${h16})?::)`;\n    const ipvfuture = `v[a-fA-F0-9]+\\\\.(${sub_delims}|${sub_delims}|\":)+`;\n    const ip_literal = `\\\\[(${ipv6address}|${ipvfuture})\\\\]`;\n    const port = `[0-9]*`;\n    const scheme = `[a-zA-Z][a-zA-Z0-9+\\\\-.]*`;\n    const iprivate_raw = `\\u{E000}-\\u{F8FF}\\u{F0000}-\\u{FFFFD}\\u{100000}-\\u{10FFFD}`;\n    const iprivate = `[${iprivate_raw}]`;\n    const ucschar_raw = `\\u{A0}-\\u{D7FF}\\u{F900}-\\u{FDCF}\\u{FDF0}-\\u{FFEF}\\u{10000}-\\u{1FFFD}\\u{20000}-\\u{2FFFD}\\u{30000}-\\u{3FFFD}\\u{40000}-\\u{4FFFD}\\u{50000}-\\u{5FFFD}\\u{60000}-\\u{6FFFD}\\u{70000}-\\u{7FFFD}\\u{80000}-\\u{8FFFD}\\u{90000}-\\u{9FFFD}\\u{A0000}-\\u{AFFFD}\\u{B0000}-\\u{BFFFD}\\u{C0000}-\\u{CFFFD}\\u{D0000}-\\u{DFFFD}\\u{E1000}-\\u{EFFFD}`;\n    const iunreserved_raw = `a-zA-Z0-9\\\\-._~${ucschar_raw}`;\n    const iunreserved = `[${iunreserved_raw}]`;\n    const ipchar = `(${iunreserved}|${pct_encoded}|${sub_delims}|[:@])*`;\n    const ifragment = `(${ipchar}|[\\\\/?])*`;\n    const iquery = `(${ipchar}|${iprivate}|[\\\\/?])*`;\n    const isegment_nz = `(${ipchar})+`;\n    const isegment = `(${ipchar})*`;\n    const ipath_empty = '';\n    const ipath_rootless = `${isegment_nz}(\\\\/${isegment})*`;\n    const ipath_absolute = `\\\\/(${isegment_nz}(\\\\/${isegment})*)?`;\n    const ipath_abempty = `(\\\\/${isegment})*`;\n    const ireg_name = `(${iunreserved}|${pct_encoded}|${sub_delims})*`;\n    const ihost = `(${ip_literal}|${ipv4address}|${ireg_name})`;\n    const iuserinfo = `(${iunreserved}|${pct_encoded}|${sub_delims}|:)*`;\n    const iauthority = `(${iuserinfo}@)?${ihost}(:${port})?`;\n    const ihier_part = `(\\\\/\\\\/${iauthority}${ipath_abempty}|${ipath_absolute}|${ipath_rootless}|${ipath_empty})`;\n    const iri = `^${scheme}:${ihier_part}(\\\\?${iquery})?(#${ifragment})?$`;\n    return new RegExp(iri, 'u');\n}\nconst STRICT_IRI_REGEX = buildAbsoluteIriRfc3987Regex();\n// eslint-disable-next-line no-control-regex\nconst PRAGMATIC_IRI_REGEX = /^[A-Za-z][\\d+-.A-Za-z]*:[^\\u0000-\\u0020\"<>\\\\^`{|}]*$/u;\n/**\n * Possible ways of validating an IRI\n */\nvar IriValidationStrategy;\n(function (IriValidationStrategy) {\n    /**\n     * Validates the IRI according to RFC 3987.\n     */\n    IriValidationStrategy[\"Strict\"] = \"strict\";\n    /**\n     * Validates that the IRI has a valid scheme and does not contain any character forbidden by the Turtle specification.\n     */\n    IriValidationStrategy[\"Pragmatic\"] = \"pragmatic\";\n    /**\n     * Does not validate the IRI at all.\n     */\n    IriValidationStrategy[\"None\"] = \"none\";\n})(IriValidationStrategy = exports.IriValidationStrategy || (exports.IriValidationStrategy = {}));\n/**\n * Validate a given IRI according to the given strategy.\n *\n * By default the IRI is fully validated according to RFC 3987.\n * But it is possible to do a lighter a faster validation using the \"pragmatic\" strategy.\n *\n * @param {string} iri a string that may be an IRI.\n * @param {IriValidationStrategy} strategy IRI validation strategy.\n * @return {Error | undefined} An error if the IRI is invalid, or undefined if it is valid.\n */\nfunction validateIri(iri, strategy = IriValidationStrategy.Strict) {\n    switch (strategy) {\n        case IriValidationStrategy.Strict:\n            return STRICT_IRI_REGEX.test(iri) ? undefined : new Error(`Invalid IRI according to RFC 3987: '${iri}'`);\n        case IriValidationStrategy.Pragmatic:\n            return PRAGMATIC_IRI_REGEX.test(iri) ? undefined : new Error(`Invalid IRI according to RDF Turtle: '${iri}'`);\n        case IriValidationStrategy.None:\n            return undefined;\n        default:\n            return new Error(`Not supported validation strategy \"${strategy}\"`);\n    }\n}\nexports.validateIri = validateIri;\n//# sourceMappingURL=Validate.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/validate-iri/lib/Validate.js?");

/***/ }),

/***/ "./node_modules/xmlchars/xml/1.0/ed5.js":
/*!**********************************************!*\
  !*** ./node_modules/xmlchars/xml/1.0/ed5.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n/**\n * Character classes and associated utilities for the 5th edition of XML 1.0.\n *\n * @author Louis-Dominique Dubeau\n * @license MIT\n * @copyright Louis-Dominique Dubeau\n */\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n//\n// Fragments.\n//\nexports.CHAR = \"\\t\\n\\r -\\uD7FF\\uE000-\\uFFFD\\uD800\\uDC00-\\uDBFF\\uDFFF\";\nexports.S = \" \\t\\r\\n\";\n// tslint:disable-next-line:max-line-length\nexports.NAME_START_CHAR = \":A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\uD800\\uDC00-\\uDB7F\\uDFFF\";\nexports.NAME_CHAR = \"-\" + exports.NAME_START_CHAR + \".0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040\";\n//\n// Regular expressions.\n//\nexports.CHAR_RE = new RegExp(\"^[\" + exports.CHAR + \"]$\", \"u\");\nexports.S_RE = new RegExp(\"^[\" + exports.S + \"]+$\", \"u\");\nexports.NAME_START_CHAR_RE = new RegExp(\"^[\" + exports.NAME_START_CHAR + \"]$\", \"u\");\nexports.NAME_CHAR_RE = new RegExp(\"^[\" + exports.NAME_CHAR + \"]$\", \"u\");\nexports.NAME_RE = new RegExp(\"^[\" + exports.NAME_START_CHAR + \"][\" + exports.NAME_CHAR + \"]*$\", \"u\");\nexports.NMTOKEN_RE = new RegExp(\"^[\" + exports.NAME_CHAR + \"]+$\", \"u\");\nvar TAB = 9;\nvar NL = 0xA;\nvar CR = 0xD;\nvar SPACE = 0x20;\n//\n// Lists.\n//\n/** All characters in the ``S`` production. */\nexports.S_LIST = [SPACE, NL, CR, TAB];\n/**\n * Determines whether a codepoint matches the ``CHAR`` production.\n *\n * @param c The code point.\n *\n * @returns ``true`` if the codepoint matches ``CHAR``.\n */\nfunction isChar(c) {\n    return (c >= SPACE && c <= 0xD7FF) ||\n        c === NL || c === CR || c === TAB ||\n        (c >= 0xE000 && c <= 0xFFFD) ||\n        (c >= 0x10000 && c <= 0x10FFFF);\n}\nexports.isChar = isChar;\n/**\n * Determines whether a codepoint matches the ``S`` (space) production.\n *\n * @param c The code point.\n *\n * @returns ``true`` if the codepoint matches ``S``.\n */\nfunction isS(c) {\n    return c === SPACE || c === NL || c === CR || c === TAB;\n}\nexports.isS = isS;\n/**\n * Determines whether a codepoint matches the ``NAME_START_CHAR`` production.\n *\n * @param c The code point.\n *\n * @returns ``true`` if the codepoint matches ``NAME_START_CHAR``.\n */\nfunction isNameStartChar(c) {\n    return ((c >= 0x41 && c <= 0x5A) ||\n        (c >= 0x61 && c <= 0x7A) ||\n        c === 0x3A ||\n        c === 0x5F ||\n        c === 0x200C ||\n        c === 0x200D ||\n        (c >= 0xC0 && c <= 0xD6) ||\n        (c >= 0xD8 && c <= 0xF6) ||\n        (c >= 0x00F8 && c <= 0x02FF) ||\n        (c >= 0x0370 && c <= 0x037D) ||\n        (c >= 0x037F && c <= 0x1FFF) ||\n        (c >= 0x2070 && c <= 0x218F) ||\n        (c >= 0x2C00 && c <= 0x2FEF) ||\n        (c >= 0x3001 && c <= 0xD7FF) ||\n        (c >= 0xF900 && c <= 0xFDCF) ||\n        (c >= 0xFDF0 && c <= 0xFFFD) ||\n        (c >= 0x10000 && c <= 0xEFFFF));\n}\nexports.isNameStartChar = isNameStartChar;\n/**\n * Determines whether a codepoint matches the ``NAME_CHAR`` production.\n *\n * @param c The code point.\n *\n * @returns ``true`` if the codepoint matches ``NAME_CHAR``.\n */\nfunction isNameChar(c) {\n    return isNameStartChar(c) ||\n        (c >= 0x30 && c <= 0x39) ||\n        c === 0x2D ||\n        c === 0x2E ||\n        c === 0xB7 ||\n        (c >= 0x0300 && c <= 0x036F) ||\n        (c >= 0x203F && c <= 0x2040);\n}\nexports.isNameChar = isNameChar;\n//# sourceMappingURL=ed5.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/xmlchars/xml/1.0/ed5.js?");

/***/ }),

/***/ "./node_modules/xmlchars/xml/1.1/ed2.js":
/*!**********************************************!*\
  !*** ./node_modules/xmlchars/xml/1.1/ed2.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n/**\n * Character classes and associated utilities for the 2nd edition of XML 1.1.\n *\n * @author Louis-Dominique Dubeau\n * @license MIT\n * @copyright Louis-Dominique Dubeau\n */\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n//\n// Fragments.\n//\nexports.CHAR = \"\\u0001-\\uD7FF\\uE000-\\uFFFD\\uD800\\uDC00-\\uDBFF\\uDFFF\";\nexports.RESTRICTED_CHAR = \"\\u0001-\\u0008\\u000B\\u000C\\u000E-\\u001F\\u007F-\\u0084\\u0086-\\u009F\";\nexports.S = \" \\t\\r\\n\";\n// tslint:disable-next-line:max-line-length\nexports.NAME_START_CHAR = \":A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\uD800\\uDC00-\\uDB7F\\uDFFF\";\nexports.NAME_CHAR = \"-\" + exports.NAME_START_CHAR + \".0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040\";\n//\n// Regular expressions.\n//\nexports.CHAR_RE = new RegExp(\"^[\" + exports.CHAR + \"]$\", \"u\");\nexports.RESTRICTED_CHAR_RE = new RegExp(\"^[\" + exports.RESTRICTED_CHAR + \"]$\", \"u\");\nexports.S_RE = new RegExp(\"^[\" + exports.S + \"]+$\", \"u\");\nexports.NAME_START_CHAR_RE = new RegExp(\"^[\" + exports.NAME_START_CHAR + \"]$\", \"u\");\nexports.NAME_CHAR_RE = new RegExp(\"^[\" + exports.NAME_CHAR + \"]$\", \"u\");\nexports.NAME_RE = new RegExp(\"^[\" + exports.NAME_START_CHAR + \"][\" + exports.NAME_CHAR + \"]*$\", \"u\");\nexports.NMTOKEN_RE = new RegExp(\"^[\" + exports.NAME_CHAR + \"]+$\", \"u\");\nvar TAB = 9;\nvar NL = 0xA;\nvar CR = 0xD;\nvar SPACE = 0x20;\n//\n// Lists.\n//\n/** All characters in the ``S`` production. */\nexports.S_LIST = [SPACE, NL, CR, TAB];\n/**\n * Determines whether a codepoint matches the ``CHAR`` production.\n *\n * @param c The code point.\n *\n * @returns ``true`` if the codepoint matches ``CHAR``.\n */\nfunction isChar(c) {\n    return (c >= 0x0001 && c <= 0xD7FF) ||\n        (c >= 0xE000 && c <= 0xFFFD) ||\n        (c >= 0x10000 && c <= 0x10FFFF);\n}\nexports.isChar = isChar;\n/**\n * Determines whether a codepoint matches the ``RESTRICTED_CHAR`` production.\n *\n * @param c The code point.\n *\n * @returns ``true`` if the codepoint matches ``RESTRICTED_CHAR``.\n */\nfunction isRestrictedChar(c) {\n    return (c >= 0x1 && c <= 0x8) ||\n        c === 0xB ||\n        c === 0xC ||\n        (c >= 0xE && c <= 0x1F) ||\n        (c >= 0x7F && c <= 0x84) ||\n        (c >= 0x86 && c <= 0x9F);\n}\nexports.isRestrictedChar = isRestrictedChar;\n/**\n * Determines whether a codepoint matches the ``CHAR`` production and does not\n * match the ``RESTRICTED_CHAR`` production. ``isCharAndNotRestricted(x)`` is\n * equivalent to ``isChar(x) && !isRestrictedChar(x)``. This function is faster\n * than running the two-call equivalent.\n *\n * @param c The code point.\n *\n * @returns ``true`` if the codepoint matches ``CHAR`` and does not match\n * ``RESTRICTED_CHAR``.\n */\nfunction isCharAndNotRestricted(c) {\n    return (c === 0x9) ||\n        (c === 0xA) ||\n        (c === 0xD) ||\n        (c > 0x1F && c < 0x7F) ||\n        (c === 0x85) ||\n        (c > 0x9F && c <= 0xD7FF) ||\n        (c >= 0xE000 && c <= 0xFFFD) ||\n        (c >= 0x10000 && c <= 0x10FFFF);\n}\nexports.isCharAndNotRestricted = isCharAndNotRestricted;\n/**\n * Determines whether a codepoint matches the ``S`` (space) production.\n *\n * @param c The code point.\n *\n * @returns ``true`` if the codepoint matches ``S``.\n */\nfunction isS(c) {\n    return c === SPACE || c === NL || c === CR || c === TAB;\n}\nexports.isS = isS;\n/**\n * Determines whether a codepoint matches the ``NAME_START_CHAR`` production.\n *\n * @param c The code point.\n *\n * @returns ``true`` if the codepoint matches ``NAME_START_CHAR``.\n */\n// tslint:disable-next-line:cyclomatic-complexity\nfunction isNameStartChar(c) {\n    return ((c >= 0x41 && c <= 0x5A) ||\n        (c >= 0x61 && c <= 0x7A) ||\n        c === 0x3A ||\n        c === 0x5F ||\n        c === 0x200C ||\n        c === 0x200D ||\n        (c >= 0xC0 && c <= 0xD6) ||\n        (c >= 0xD8 && c <= 0xF6) ||\n        (c >= 0x00F8 && c <= 0x02FF) ||\n        (c >= 0x0370 && c <= 0x037D) ||\n        (c >= 0x037F && c <= 0x1FFF) ||\n        (c >= 0x2070 && c <= 0x218F) ||\n        (c >= 0x2C00 && c <= 0x2FEF) ||\n        (c >= 0x3001 && c <= 0xD7FF) ||\n        (c >= 0xF900 && c <= 0xFDCF) ||\n        (c >= 0xFDF0 && c <= 0xFFFD) ||\n        (c >= 0x10000 && c <= 0xEFFFF));\n}\nexports.isNameStartChar = isNameStartChar;\n/**\n * Determines whether a codepoint matches the ``NAME_CHAR`` production.\n *\n * @param c The code point.\n *\n * @returns ``true`` if the codepoint matches ``NAME_CHAR``.\n */\nfunction isNameChar(c) {\n    return isNameStartChar(c) ||\n        (c >= 0x30 && c <= 0x39) ||\n        c === 0x2D ||\n        c === 0x2E ||\n        c === 0xB7 ||\n        (c >= 0x0300 && c <= 0x036F) ||\n        (c >= 0x203F && c <= 0x2040);\n}\nexports.isNameChar = isNameChar;\n//# sourceMappingURL=ed2.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/xmlchars/xml/1.1/ed2.js?");

/***/ }),

/***/ "./node_modules/xmlchars/xmlns/1.0/ed3.js":
/*!************************************************!*\
  !*** ./node_modules/xmlchars/xmlns/1.0/ed3.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n/**\n * Character class utilities for XML NS 1.0 edition 3.\n *\n * @author Louis-Dominique Dubeau\n * @license MIT\n * @copyright Louis-Dominique Dubeau\n */\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n//\n// Fragments.\n//\n// tslint:disable-next-line:max-line-length\nexports.NC_NAME_START_CHAR = \"A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\uD800\\uDC00-\\uDB7F\\uDFFF\";\nexports.NC_NAME_CHAR = \"-\" + exports.NC_NAME_START_CHAR + \".0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040\";\n//\n// Regular expressions.\n//\nexports.NC_NAME_START_CHAR_RE = new RegExp(\"^[\" + exports.NC_NAME_START_CHAR + \"]$\", \"u\");\nexports.NC_NAME_CHAR_RE = new RegExp(\"^[\" + exports.NC_NAME_CHAR + \"]$\", \"u\");\nexports.NC_NAME_RE = new RegExp(\"^[\" + exports.NC_NAME_START_CHAR + \"][\" + exports.NC_NAME_CHAR + \"]*$\", \"u\");\n/**\n * Determines whether a codepoint matches [[NC_NAME_START_CHAR]].\n *\n * @param c The code point.\n *\n * @returns ``true`` if the codepoint matches.\n */\n// tslint:disable-next-line:cyclomatic-complexity\nfunction isNCNameStartChar(c) {\n    return ((c >= 0x41 && c <= 0x5A) ||\n        c === 0x5F ||\n        (c >= 0x61 && c <= 0x7A) ||\n        (c >= 0xC0 && c <= 0xD6) ||\n        (c >= 0xD8 && c <= 0xF6) ||\n        (c >= 0x00F8 && c <= 0x02FF) ||\n        (c >= 0x0370 && c <= 0x037D) ||\n        (c >= 0x037F && c <= 0x1FFF) ||\n        (c >= 0x200C && c <= 0x200D) ||\n        (c >= 0x2070 && c <= 0x218F) ||\n        (c >= 0x2C00 && c <= 0x2FEF) ||\n        (c >= 0x3001 && c <= 0xD7FF) ||\n        (c >= 0xF900 && c <= 0xFDCF) ||\n        (c >= 0xFDF0 && c <= 0xFFFD) ||\n        (c >= 0x10000 && c <= 0xEFFFF));\n}\nexports.isNCNameStartChar = isNCNameStartChar;\n/**\n * Determines whether a codepoint matches [[NC_NAME_CHAR]].\n *\n * @param c The code point.\n *\n * @returns ``true`` if the codepoint matches.\n */\nfunction isNCNameChar(c) {\n    return isNCNameStartChar(c) ||\n        (c === 0x2D ||\n            c === 0x2E ||\n            (c >= 0x30 && c <= 0x39) ||\n            c === 0x00B7 ||\n            (c >= 0x0300 && c <= 0x036F) ||\n            (c >= 0x203F && c <= 0x2040));\n}\nexports.isNCNameChar = isNCNameChar;\n//# sourceMappingURL=ed3.js.map\n\n//# sourceURL=webpack://FormAMatic/./node_modules/xmlchars/xmlns/1.0/ed3.js?");

/***/ }),

/***/ "./node_modules/yallist/iterator.js":
/*!******************************************!*\
  !*** ./node_modules/yallist/iterator.js ***!
  \******************************************/
/***/ ((module) => {

"use strict";
eval("\nmodule.exports = function (Yallist) {\n  Yallist.prototype[Symbol.iterator] = function* () {\n    for (let walker = this.head; walker; walker = walker.next) {\n      yield walker.value\n    }\n  }\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/yallist/iterator.js?");

/***/ }),

/***/ "./node_modules/yallist/yallist.js":
/*!*****************************************!*\
  !*** ./node_modules/yallist/yallist.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nmodule.exports = Yallist\n\nYallist.Node = Node\nYallist.create = Yallist\n\nfunction Yallist (list) {\n  var self = this\n  if (!(self instanceof Yallist)) {\n    self = new Yallist()\n  }\n\n  self.tail = null\n  self.head = null\n  self.length = 0\n\n  if (list && typeof list.forEach === 'function') {\n    list.forEach(function (item) {\n      self.push(item)\n    })\n  } else if (arguments.length > 0) {\n    for (var i = 0, l = arguments.length; i < l; i++) {\n      self.push(arguments[i])\n    }\n  }\n\n  return self\n}\n\nYallist.prototype.removeNode = function (node) {\n  if (node.list !== this) {\n    throw new Error('removing node which does not belong to this list')\n  }\n\n  var next = node.next\n  var prev = node.prev\n\n  if (next) {\n    next.prev = prev\n  }\n\n  if (prev) {\n    prev.next = next\n  }\n\n  if (node === this.head) {\n    this.head = next\n  }\n  if (node === this.tail) {\n    this.tail = prev\n  }\n\n  node.list.length--\n  node.next = null\n  node.prev = null\n  node.list = null\n\n  return next\n}\n\nYallist.prototype.unshiftNode = function (node) {\n  if (node === this.head) {\n    return\n  }\n\n  if (node.list) {\n    node.list.removeNode(node)\n  }\n\n  var head = this.head\n  node.list = this\n  node.next = head\n  if (head) {\n    head.prev = node\n  }\n\n  this.head = node\n  if (!this.tail) {\n    this.tail = node\n  }\n  this.length++\n}\n\nYallist.prototype.pushNode = function (node) {\n  if (node === this.tail) {\n    return\n  }\n\n  if (node.list) {\n    node.list.removeNode(node)\n  }\n\n  var tail = this.tail\n  node.list = this\n  node.prev = tail\n  if (tail) {\n    tail.next = node\n  }\n\n  this.tail = node\n  if (!this.head) {\n    this.head = node\n  }\n  this.length++\n}\n\nYallist.prototype.push = function () {\n  for (var i = 0, l = arguments.length; i < l; i++) {\n    push(this, arguments[i])\n  }\n  return this.length\n}\n\nYallist.prototype.unshift = function () {\n  for (var i = 0, l = arguments.length; i < l; i++) {\n    unshift(this, arguments[i])\n  }\n  return this.length\n}\n\nYallist.prototype.pop = function () {\n  if (!this.tail) {\n    return undefined\n  }\n\n  var res = this.tail.value\n  this.tail = this.tail.prev\n  if (this.tail) {\n    this.tail.next = null\n  } else {\n    this.head = null\n  }\n  this.length--\n  return res\n}\n\nYallist.prototype.shift = function () {\n  if (!this.head) {\n    return undefined\n  }\n\n  var res = this.head.value\n  this.head = this.head.next\n  if (this.head) {\n    this.head.prev = null\n  } else {\n    this.tail = null\n  }\n  this.length--\n  return res\n}\n\nYallist.prototype.forEach = function (fn, thisp) {\n  thisp = thisp || this\n  for (var walker = this.head, i = 0; walker !== null; i++) {\n    fn.call(thisp, walker.value, i, this)\n    walker = walker.next\n  }\n}\n\nYallist.prototype.forEachReverse = function (fn, thisp) {\n  thisp = thisp || this\n  for (var walker = this.tail, i = this.length - 1; walker !== null; i--) {\n    fn.call(thisp, walker.value, i, this)\n    walker = walker.prev\n  }\n}\n\nYallist.prototype.get = function (n) {\n  for (var i = 0, walker = this.head; walker !== null && i < n; i++) {\n    // abort out of the list early if we hit a cycle\n    walker = walker.next\n  }\n  if (i === n && walker !== null) {\n    return walker.value\n  }\n}\n\nYallist.prototype.getReverse = function (n) {\n  for (var i = 0, walker = this.tail; walker !== null && i < n; i++) {\n    // abort out of the list early if we hit a cycle\n    walker = walker.prev\n  }\n  if (i === n && walker !== null) {\n    return walker.value\n  }\n}\n\nYallist.prototype.map = function (fn, thisp) {\n  thisp = thisp || this\n  var res = new Yallist()\n  for (var walker = this.head; walker !== null;) {\n    res.push(fn.call(thisp, walker.value, this))\n    walker = walker.next\n  }\n  return res\n}\n\nYallist.prototype.mapReverse = function (fn, thisp) {\n  thisp = thisp || this\n  var res = new Yallist()\n  for (var walker = this.tail; walker !== null;) {\n    res.push(fn.call(thisp, walker.value, this))\n    walker = walker.prev\n  }\n  return res\n}\n\nYallist.prototype.reduce = function (fn, initial) {\n  var acc\n  var walker = this.head\n  if (arguments.length > 1) {\n    acc = initial\n  } else if (this.head) {\n    walker = this.head.next\n    acc = this.head.value\n  } else {\n    throw new TypeError('Reduce of empty list with no initial value')\n  }\n\n  for (var i = 0; walker !== null; i++) {\n    acc = fn(acc, walker.value, i)\n    walker = walker.next\n  }\n\n  return acc\n}\n\nYallist.prototype.reduceReverse = function (fn, initial) {\n  var acc\n  var walker = this.tail\n  if (arguments.length > 1) {\n    acc = initial\n  } else if (this.tail) {\n    walker = this.tail.prev\n    acc = this.tail.value\n  } else {\n    throw new TypeError('Reduce of empty list with no initial value')\n  }\n\n  for (var i = this.length - 1; walker !== null; i--) {\n    acc = fn(acc, walker.value, i)\n    walker = walker.prev\n  }\n\n  return acc\n}\n\nYallist.prototype.toArray = function () {\n  var arr = new Array(this.length)\n  for (var i = 0, walker = this.head; walker !== null; i++) {\n    arr[i] = walker.value\n    walker = walker.next\n  }\n  return arr\n}\n\nYallist.prototype.toArrayReverse = function () {\n  var arr = new Array(this.length)\n  for (var i = 0, walker = this.tail; walker !== null; i++) {\n    arr[i] = walker.value\n    walker = walker.prev\n  }\n  return arr\n}\n\nYallist.prototype.slice = function (from, to) {\n  to = to || this.length\n  if (to < 0) {\n    to += this.length\n  }\n  from = from || 0\n  if (from < 0) {\n    from += this.length\n  }\n  var ret = new Yallist()\n  if (to < from || to < 0) {\n    return ret\n  }\n  if (from < 0) {\n    from = 0\n  }\n  if (to > this.length) {\n    to = this.length\n  }\n  for (var i = 0, walker = this.head; walker !== null && i < from; i++) {\n    walker = walker.next\n  }\n  for (; walker !== null && i < to; i++, walker = walker.next) {\n    ret.push(walker.value)\n  }\n  return ret\n}\n\nYallist.prototype.sliceReverse = function (from, to) {\n  to = to || this.length\n  if (to < 0) {\n    to += this.length\n  }\n  from = from || 0\n  if (from < 0) {\n    from += this.length\n  }\n  var ret = new Yallist()\n  if (to < from || to < 0) {\n    return ret\n  }\n  if (from < 0) {\n    from = 0\n  }\n  if (to > this.length) {\n    to = this.length\n  }\n  for (var i = this.length, walker = this.tail; walker !== null && i > to; i--) {\n    walker = walker.prev\n  }\n  for (; walker !== null && i > from; i--, walker = walker.prev) {\n    ret.push(walker.value)\n  }\n  return ret\n}\n\nYallist.prototype.splice = function (start, deleteCount, ...nodes) {\n  if (start > this.length) {\n    start = this.length - 1\n  }\n  if (start < 0) {\n    start = this.length + start;\n  }\n\n  for (var i = 0, walker = this.head; walker !== null && i < start; i++) {\n    walker = walker.next\n  }\n\n  var ret = []\n  for (var i = 0; walker && i < deleteCount; i++) {\n    ret.push(walker.value)\n    walker = this.removeNode(walker)\n  }\n  if (walker === null) {\n    walker = this.tail\n  }\n\n  if (walker !== this.head && walker !== this.tail) {\n    walker = walker.prev\n  }\n\n  for (var i = 0; i < nodes.length; i++) {\n    walker = insert(this, walker, nodes[i])\n  }\n  return ret;\n}\n\nYallist.prototype.reverse = function () {\n  var head = this.head\n  var tail = this.tail\n  for (var walker = head; walker !== null; walker = walker.prev) {\n    var p = walker.prev\n    walker.prev = walker.next\n    walker.next = p\n  }\n  this.head = tail\n  this.tail = head\n  return this\n}\n\nfunction insert (self, node, value) {\n  var inserted = node === self.head ?\n    new Node(value, null, node, self) :\n    new Node(value, node, node.next, self)\n\n  if (inserted.next === null) {\n    self.tail = inserted\n  }\n  if (inserted.prev === null) {\n    self.head = inserted\n  }\n\n  self.length++\n\n  return inserted\n}\n\nfunction push (self, item) {\n  self.tail = new Node(item, self.tail, null, self)\n  if (!self.head) {\n    self.head = self.tail\n  }\n  self.length++\n}\n\nfunction unshift (self, item) {\n  self.head = new Node(item, null, self.head, self)\n  if (!self.tail) {\n    self.tail = self.head\n  }\n  self.length++\n}\n\nfunction Node (value, prev, next, list) {\n  if (!(this instanceof Node)) {\n    return new Node(value, prev, next, list)\n  }\n\n  this.list = list\n  this.value = value\n\n  if (prev) {\n    prev.next = this\n    this.prev = prev\n  } else {\n    this.prev = null\n  }\n\n  if (next) {\n    next.prev = this\n    this.next = next\n  } else {\n    this.next = null\n  }\n}\n\ntry {\n  // add if support for Symbol.iterator is present\n  __webpack_require__(/*! ./iterator.js */ \"./node_modules/yallist/iterator.js\")(Yallist)\n} catch (er) {}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/yallist/yallist.js?");

/***/ }),

/***/ "?f4a3":
/*!*************************************!*\
  !*** rdf-canonize-native (ignored) ***!
  \*************************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://FormAMatic/rdf-canonize-native_(ignored)?");

/***/ }),

/***/ "./node_modules/@rdfjs/data-model/Factory.js":
/*!***************************************************!*\
  !*** ./node_modules/@rdfjs/data-model/Factory.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _lib_BlankNode_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/BlankNode.js */ \"./node_modules/@rdfjs/data-model/lib/BlankNode.js\");\n/* harmony import */ var _lib_DefaultGraph_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/DefaultGraph.js */ \"./node_modules/@rdfjs/data-model/lib/DefaultGraph.js\");\n/* harmony import */ var _lib_fromTerm_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/fromTerm.js */ \"./node_modules/@rdfjs/data-model/lib/fromTerm.js\");\n/* harmony import */ var _lib_Literal_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./lib/Literal.js */ \"./node_modules/@rdfjs/data-model/lib/Literal.js\");\n/* harmony import */ var _lib_NamedNode_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./lib/NamedNode.js */ \"./node_modules/@rdfjs/data-model/lib/NamedNode.js\");\n/* harmony import */ var _lib_Quad_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./lib/Quad.js */ \"./node_modules/@rdfjs/data-model/lib/Quad.js\");\n/* harmony import */ var _lib_Variable_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./lib/Variable.js */ \"./node_modules/@rdfjs/data-model/lib/Variable.js\");\n\n\n\n\n\n\n\n\nconst langStringDatatype = new _lib_NamedNode_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]('http://www.w3.org/1999/02/22-rdf-syntax-ns#langString')\nconst stringDatatype = new _lib_NamedNode_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]('http://www.w3.org/2001/XMLSchema#string')\n\nclass DataFactory {\n  constructor () {\n    this.init()\n  }\n\n  init () {\n    this._data = {\n      blankNodeCounter: 0,\n      defaultGraph: new _lib_DefaultGraph_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]()\n    }\n  }\n\n  namedNode (value) {\n    return new _lib_NamedNode_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"](value)\n  }\n\n  blankNode (value) {\n    value = value || ('b' + (++this._data.blankNodeCounter))\n\n    return new _lib_BlankNode_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"](value)\n  }\n\n  literal (value, languageOrDatatype) {\n    if (typeof languageOrDatatype === 'string') {\n      return new _lib_Literal_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"](value, languageOrDatatype, langStringDatatype)\n    } else {\n      return new _lib_Literal_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"](value, '', languageOrDatatype || stringDatatype)\n    }\n  }\n\n  variable (value) {\n    return new _lib_Variable_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"](value)\n  }\n\n  defaultGraph () {\n    return this._data.defaultGraph\n  }\n\n  quad (subject, predicate, object, graph = this.defaultGraph()) {\n    return new _lib_Quad_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"](subject, predicate, object, graph)\n  }\n\n  fromTerm (original) {\n    return (0,_lib_fromTerm_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(this, original)\n  }\n\n  fromQuad (original) {\n    return (0,_lib_fromTerm_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(this, original)\n  }\n}\n\nDataFactory.exports = [\n  'blankNode',\n  'defaultGraph',\n  'fromQuad',\n  'fromTerm',\n  'literal',\n  'namedNode',\n  'quad',\n  'variable'\n]\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (DataFactory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/data-model/Factory.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/data-model/index.js":
/*!*************************************************!*\
  !*** ./node_modules/@rdfjs/data-model/index.js ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _Factory_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Factory.js */ \"./node_modules/@rdfjs/data-model/Factory.js\");\n\n\nconst factory = new _Factory_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (factory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/data-model/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/data-model/lib/BlankNode.js":
/*!*********************************************************!*\
  !*** ./node_modules/@rdfjs/data-model/lib/BlankNode.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass BlankNode {\n  constructor (id) {\n    this.value = id\n  }\n\n  equals (other) {\n    return !!other && other.termType === this.termType && other.value === this.value\n  }\n}\n\nBlankNode.prototype.termType = 'BlankNode'\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (BlankNode);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/data-model/lib/BlankNode.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/data-model/lib/DefaultGraph.js":
/*!************************************************************!*\
  !*** ./node_modules/@rdfjs/data-model/lib/DefaultGraph.js ***!
  \************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass DefaultGraph {\n  equals (other) {\n    return !!other && other.termType === this.termType\n  }\n}\n\nDefaultGraph.prototype.termType = 'DefaultGraph'\nDefaultGraph.prototype.value = ''\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (DefaultGraph);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/data-model/lib/DefaultGraph.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/data-model/lib/Literal.js":
/*!*******************************************************!*\
  !*** ./node_modules/@rdfjs/data-model/lib/Literal.js ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass Literal {\n  constructor (value, language, datatype) {\n    this.value = value\n    this.language = language\n    this.datatype = datatype\n  }\n\n  equals (other) {\n    return !!other &&\n      other.termType === this.termType &&\n      other.value === this.value &&\n      other.language === this.language &&\n      other.datatype.equals(this.datatype)\n  }\n}\n\nLiteral.prototype.termType = 'Literal'\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Literal);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/data-model/lib/Literal.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/data-model/lib/NamedNode.js":
/*!*********************************************************!*\
  !*** ./node_modules/@rdfjs/data-model/lib/NamedNode.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass NamedNode {\n  constructor (iri) {\n    this.value = iri\n  }\n\n  equals (other) {\n    return !!other && other.termType === this.termType && other.value === this.value\n  }\n}\n\nNamedNode.prototype.termType = 'NamedNode'\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (NamedNode);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/data-model/lib/NamedNode.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/data-model/lib/Quad.js":
/*!****************************************************!*\
  !*** ./node_modules/@rdfjs/data-model/lib/Quad.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass Quad {\n  constructor (subject, predicate, object, graph) {\n    this.subject = subject\n    this.predicate = predicate\n    this.object = object\n    this.graph = graph\n  }\n\n  equals (other) {\n    // `|| !other.termType` is for backwards-compatibility with old factories without RDF* support.\n    return !!other &&\n      (other.termType === 'Quad' || !other.termType) &&\n      other.subject.equals(this.subject) &&\n      other.predicate.equals(this.predicate) &&\n      other.object.equals(this.object) &&\n      other.graph.equals(this.graph)\n  }\n}\n\nQuad.prototype.termType = 'Quad'\nQuad.prototype.value = ''\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Quad);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/data-model/lib/Quad.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/data-model/lib/Variable.js":
/*!********************************************************!*\
  !*** ./node_modules/@rdfjs/data-model/lib/Variable.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass Variable {\n  constructor (name) {\n    this.value = name\n  }\n\n  equals (other) {\n    return !!other && other.termType === this.termType && other.value === this.value\n  }\n}\n\nVariable.prototype.termType = 'Variable'\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Variable);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/data-model/lib/Variable.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/data-model/lib/fromTerm.js":
/*!********************************************************!*\
  !*** ./node_modules/@rdfjs/data-model/lib/fromTerm.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction fromTerm (factory, original) {\n  if (!original) {\n    return null\n  }\n\n  if (original.termType === 'BlankNode') {\n    return factory.blankNode(original.value)\n  }\n\n  if (original.termType === 'DefaultGraph') {\n    return factory.defaultGraph()\n  }\n\n  if (original.termType === 'Literal') {\n    return factory.literal(original.value, original.language || factory.namedNode(original.datatype.value))\n  }\n\n  if (original.termType === 'NamedNode') {\n    return factory.namedNode(original.value)\n  }\n\n  if (original.termType === 'Quad') {\n    const subject = factory.fromTerm(original.subject)\n    const predicate = factory.fromTerm(original.predicate)\n    const object = factory.fromTerm(original.object)\n    const graph = factory.fromTerm(original.graph)\n\n    return factory.quad(subject, predicate, object, graph)\n  }\n\n  if (original.termType === 'Variable') {\n    return factory.variable(original.value)\n  }\n\n  throw new Error(`unknown termType ${original.termType}`)\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (fromTerm);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/data-model/lib/fromTerm.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/dataset/DatasetCore.js":
/*!****************************************************!*\
  !*** ./node_modules/@rdfjs/dataset/DatasetCore.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction isString (s) {\n  return typeof s === 'string' || s instanceof String\n}\n\nconst xsdString = 'http://www.w3.org/2001/XMLSchema#string'\n\nfunction termToId (term) {\n  if (typeof term === 'string') {\n    return term\n  }\n\n  if (!term) {\n    return ''\n  }\n\n  if (typeof term.id !== 'undefined' && term.termType !== 'Quad') {\n    return term.id\n  }\n\n  let subject, predicate, object, graph\n\n  // Term instantiated with another library\n  switch (term.termType) {\n    case 'NamedNode':\n      return term.value\n\n    case 'BlankNode':\n      return `_:${term.value}`\n\n    case 'Variable':\n      return `?${term.value}`\n\n    case 'DefaultGraph':\n      return ''\n\n    case 'Literal':\n      if (term.language) {\n        return `\"${term.value}\"@${term.language}`\n      }\n\n      return `\"${term.value}\"${term.datatype && term.datatype.value !== xsdString ? `^^${term.datatype.value}` : ''}`\n\n    case 'Quad':\n      // To identify RDF* quad components, we escape quotes by doubling them.\n      // This avoids the overhead of backslash parsing of Turtle-like syntaxes.\n      subject = escapeQuotes(termToId(term.subject))\n      predicate = escapeQuotes(termToId(term.predicate))\n      object = escapeQuotes(termToId(term.object))\n      graph = term.graph.termType === 'DefaultGraph' ? '' : ` ${termToId(term.graph)}`\n\n      return `<<${subject} ${predicate} ${object}${graph}>>`\n\n    default:\n      throw new Error(`Unexpected termType: ${term.termType}`)\n  }\n}\n\nconst escapedLiteral = /^\"(.*\".*)(?=\"[^\"]*$)/\n\nfunction escapeQuotes (id) {\n  return id.replace(escapedLiteral, (_, quoted) => `\"${quoted.replace(/\"/g, '\"\"')}`)\n}\n\nclass DatasetCore {\n  constructor (quads) {\n    // The number of quads is initially zero\n    this._size = 0\n    // `_graphs` contains subject, predicate, and object indexes per graph\n    this._graphs = Object.create(null)\n    // `_ids` maps entities such as `http://xmlns.com/foaf/0.1/name` to numbers,\n    // saving memory by using only numbers as keys in `_graphs`\n    this._id = 0\n    this._ids = Object.create(null)\n    this._ids['><'] = 0 // dummy entry, so the first actual key is non-zero\n    this._entities = Object.create(null) // inverse of `_ids`\n\n    this._quads = new Map()\n\n    // Add quads if passed\n    if (quads) {\n      for (const quad of quads) {\n        this.add(quad)\n      }\n    }\n  }\n\n  get size () {\n    // Return the quad count if if was cached\n    let size = this._size\n\n    if (size !== null) {\n      return size\n    }\n\n    // Calculate the number of quads by counting to the deepest level\n    size = 0\n    const graphs = this._graphs\n    let subjects, subject\n\n    for (const graphKey in graphs) {\n      for (const subjectKey in (subjects = graphs[graphKey].subjects)) {\n        for (const predicateKey in (subject = subjects[subjectKey])) {\n          size += Object.keys(subject[predicateKey]).length\n        }\n      }\n    }\n\n    this._size = size\n\n    return this._size\n  }\n\n  add (quad) {\n    // Convert terms to internal string representation\n    let subject = termToId(quad.subject)\n    let predicate = termToId(quad.predicate)\n    let object = termToId(quad.object)\n    const graph = termToId(quad.graph)\n\n    // Find the graph that will contain the triple\n    let graphItem = this._graphs[graph]\n    // Create the graph if it doesn't exist yet\n    if (!graphItem) {\n      graphItem = this._graphs[graph] = { subjects: {}, predicates: {}, objects: {} }\n      // Freezing a graph helps subsequent `add` performance,\n      // and properties will never be modified anyway\n      Object.freeze(graphItem)\n    }\n\n    // Since entities can often be long IRIs, we avoid storing them in every index.\n    // Instead, we have a separate index that maps entities to numbers,\n    // which are then used as keys in the other indexes.\n    const ids = this._ids\n    const entities = this._entities\n    subject = ids[subject] || (ids[entities[++this._id] = subject] = this._id)\n    predicate = ids[predicate] || (ids[entities[++this._id] = predicate] = this._id)\n    object = ids[object] || (ids[entities[++this._id] = object] = this._id)\n\n    this._addToIndex(graphItem.subjects, subject, predicate, object)\n    this._addToIndex(graphItem.predicates, predicate, object, subject)\n    this._addToIndex(graphItem.objects, object, subject, predicate)\n\n    this._setQuad(subject, predicate, object, graph, quad)\n\n    // The cached quad count is now invalid\n    this._size = null\n\n    return this\n  }\n\n  delete (quad) {\n    // Convert terms to internal string representation\n    let subject = termToId(quad.subject)\n    let predicate = termToId(quad.predicate)\n    let object = termToId(quad.object)\n    const graph = termToId(quad.graph)\n\n    // Find internal identifiers for all components\n    // and verify the quad exists.\n    const ids = this._ids\n    const graphs = this._graphs\n    let graphItem, subjects, predicates\n\n    if (!(subject = ids[subject]) || !(predicate = ids[predicate]) ||\n      !(object = ids[object]) || !(graphItem = graphs[graph]) ||\n      !(subjects = graphItem.subjects[subject]) ||\n      !(predicates = subjects[predicate]) ||\n      !(object in predicates)\n    ) {\n      return this\n    }\n\n    // Remove it from all indexes\n    this._removeFromIndex(graphItem.subjects, subject, predicate, object)\n    this._removeFromIndex(graphItem.predicates, predicate, object, subject)\n    this._removeFromIndex(graphItem.objects, object, subject, predicate)\n\n    if (this._size !== null) {\n      this._size--\n    }\n\n    this._deleteQuad(subject, predicate, object, graph)\n\n    // Remove the graph if it is empty\n    for (subject in graphItem.subjects) { // eslint-disable-line no-unreachable-loop\n      return this\n    }\n\n    delete graphs[graph]\n\n    return this\n  }\n\n  has (quad) {\n    // Convert terms to internal string representation\n    const subject = termToId(quad.subject)\n    const predicate = termToId(quad.predicate)\n    const object = termToId(quad.object)\n    const graph = termToId(quad.graph)\n\n    const graphItem = this._graphs[graph]\n\n    if (!graphItem) {\n      return false\n    }\n\n    const ids = this._ids\n    let subjectId, predicateId, objectId\n\n    // Translate IRIs to internal index keys.\n    if (\n      (isString(subject) && !(subjectId = ids[subject])) ||\n      (isString(predicate) && !(predicateId = ids[predicate])) ||\n      (isString(object) && !(objectId = ids[object]))\n    ) {\n      return false\n    }\n\n    return this._countInIndex(graphItem.objects, objectId, subjectId, predicateId) === 1\n  }\n\n  match (subject, predicate, object, graph) {\n    return this._createDataset(this._match(subject, predicate, object, graph))\n  }\n\n  [Symbol.iterator] () {\n    return this._match()[Symbol.iterator]()\n  }\n\n  // ## Private methods\n\n  // ### `_addToIndex` adds a quad to a three-layered index.\n  // Returns if the index has changed, if the entry did not already exist.\n  _addToIndex (index0, key0, key1, key2) {\n    // Create layers as necessary\n    const index1 = index0[key0] || (index0[key0] = {})\n    const index2 = index1[key1] || (index1[key1] = {})\n    // Setting the key to _any_ value signals the presence of the quad\n    const existed = key2 in index2\n\n    if (!existed) {\n      index2[key2] = null\n    }\n\n    return !existed\n  }\n\n  // ### `_removeFromIndex` removes a quad from a three-layered index\n  _removeFromIndex (index0, key0, key1, key2) {\n    // Remove the quad from the index\n    const index1 = index0[key0]\n    const index2 = index1[key1]\n    delete index2[key2]\n\n    // Remove intermediary index layers if they are empty\n    for (const key in index2) { // eslint-disable-line no-unreachable-loop\n      return\n    }\n\n    delete index1[key1]\n\n    for (const key in index1) { // eslint-disable-line no-unreachable-loop\n      return\n    }\n\n    delete index0[key0]\n  }\n\n  // ### `_findInIndex` finds a set of quads in a three-layered index.\n  // The index base is `index0` and the keys at each level are `key0`, `key1`, and `key2`.\n  // Any of these keys can be undefined, which is interpreted as a wildcard.\n  // `name0`, `name1`, and `name2` are the names of the keys at each level,\n  // used when reconstructing the resulting quad\n  // (for instance: _subject_, _predicate_, and _object_).\n  // Finally, `graph` will be the graph of the created quads.\n  // If `callback` is given, each result is passed through it\n  // and iteration halts when it returns truthy for any quad.\n  // If instead `array` is given, each result is added to the array.\n  _findInIndex (index0, key0, key1, key2, name0, name1, name2, graph, callback, array) {\n    let tmp, index1, index2\n\n    // If a key is specified, use only that part of index 0.\n    if (key0) {\n      (tmp = index0, index0 = {})[key0] = tmp[key0]\n    }\n\n    for (const value0 in index0) {\n      index1 = index0[value0]\n\n      if (index1) {\n        // If a key is specified, use only that part of index 1.\n        if (key1) {\n          (tmp = index1, index1 = {})[key1] = tmp[key1]\n        }\n\n        for (const value1 in index1) {\n          index2 = index1[value1]\n\n          if (index2) {\n            // If a key is specified, use only that part of index 2, if it exists.\n            const values = key2 ? (key2 in index2 ? [key2] : []) : Object.keys(index2)\n            // Create quads for all items found in index 2.\n            for (let l = 0; l < values.length; l++) {\n              const parts = {\n                [name0]: value0,\n                [name1]: value1,\n                [name2]: values[l]\n              }\n\n              const quad = this._getQuad(parts.subject, parts.predicate, parts.object, graph)\n\n              if (array) {\n                array.push(quad)\n              } else if (callback(quad)) {\n                return true\n              }\n            }\n          }\n        }\n      }\n    }\n\n    return array\n  }\n\n  // ### `_countInIndex` counts matching quads in a three-layered index.\n  // The index base is `index0` and the keys at each level are `key0`, `key1`, and `key2`.\n  // Any of these keys can be undefined, which is interpreted as a wildcard.\n  _countInIndex (index0, key0, key1, key2) {\n    let count = 0\n    let tmp, index1, index2\n\n    // If a key is specified, count only that part of index 0\n    if (key0) {\n      (tmp = index0, index0 = {})[key0] = tmp[key0]\n    }\n\n    for (const value0 in index0) {\n      index1 = index0[value0]\n\n      if (index1) {\n        // If a key is specified, count only that part of index 1\n        if (key1) {\n          (tmp = index1, index1 = {})[key1] = tmp[key1]\n        }\n\n        for (const value1 in index1) {\n          index2 = index1[value1]\n\n          if (index2) {\n            if (key2) {\n              // If a key is specified, count the quad if it exists\n              (key2 in index2) && count++\n            } else {\n              // Otherwise, count all quads\n              count += Object.keys(index2).length\n            }\n          }\n        }\n      }\n    }\n\n    return count\n  }\n\n  // ### `_getGraphs` returns an array with the given graph,\n  // or all graphs if the argument is null or undefined.\n  _getGraphs (graph) {\n    if (!isString(graph)) {\n      return this._graphs\n    }\n\n    return {\n      [graph]: this._graphs[graph]\n    }\n  }\n\n  _match (subject, predicate, object, graph) {\n    // Convert terms to internal string representation\n    subject = subject && termToId(subject)\n    predicate = predicate && termToId(predicate)\n    object = object && termToId(object)\n    graph = graph && termToId(graph)\n\n    const quads = []\n    const graphs = this._getGraphs(graph)\n    const ids = this._ids\n    let content, subjectId, predicateId, objectId\n\n    // Translate IRIs to internal index keys.\n    if (\n      (isString(subject) && !(subjectId = ids[subject])) ||\n      (isString(predicate) && !(predicateId = ids[predicate])) ||\n      (isString(object) && !(objectId = ids[object]))\n    ) {\n      return quads\n    }\n\n    for (const graphId in graphs) {\n      content = graphs[graphId]\n\n      // Only if the specified graph contains triples, there can be results\n      if (content) {\n        // Choose the optimal index, based on what fields are present\n        if (subjectId) {\n          if (objectId) {\n            // If subject and object are given, the object index will be the fastest\n            this._findInIndex(content.objects, objectId, subjectId, predicateId, 'object', 'subject', 'predicate', graphId, null, quads)\n          } else {\n            // If only subject and possibly predicate are given, the subject index will be the fastest\n            this._findInIndex(content.subjects, subjectId, predicateId, null, 'subject', 'predicate', 'object', graphId, null, quads)\n          }\n        } else if (predicateId) {\n          // if only predicate and possibly object are given, the predicate index will be the fastest\n          this._findInIndex(content.predicates, predicateId, objectId, null, 'predicate', 'object', 'subject', graphId, null, quads)\n        } else if (objectId) {\n          // If only object is given, the object index will be the fastest\n          this._findInIndex(content.objects, objectId, null, null, 'object', 'subject', 'predicate', graphId, null, quads)\n        } else {\n          // If nothing is given, iterate subjects and predicates first\n          this._findInIndex(content.subjects, null, null, null, 'subject', 'predicate', 'object', graphId, null, quads)\n        }\n      }\n    }\n\n    return quads\n  }\n\n  _getQuad (subjectId, predicateId, objectId, graphId) {\n    return this._quads.get(this._toId(subjectId, predicateId, objectId, graphId))\n  }\n\n  _setQuad (subjectId, predicateId, objectId, graphId, quad) {\n    this._quads.set(this._toId(subjectId, predicateId, objectId, graphId), quad)\n  }\n\n  _deleteQuad (subjectId, predicateId, objectId, graphId) {\n    this._quads.delete(this._toId(subjectId, predicateId, objectId, graphId))\n  }\n\n  _createDataset (quads) {\n    return new this.constructor(quads)\n  }\n\n  _toId (subjectId, predicateId, objectId, graphId) {\n    return `${subjectId}:${predicateId}:${objectId}:${graphId}`\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (DatasetCore);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/dataset/DatasetCore.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/environment/Environment.js":
/*!********************************************************!*\
  !*** ./node_modules/@rdfjs/environment/Environment.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass Environment {\n  constructor (factories, { bind = false } = {}) {\n    this._factories = factories.slice()\n\n    for (const factory of this._factories) {\n      if (typeof factory.prototype.init === 'function') {\n        factory.prototype.init.call(this)\n      }\n\n      for (const method of factory.exports || []) {\n        if (bind) {\n          this[method] = factory.prototype[method].bind(this)\n        } else {\n          this[method] = factory.prototype[method]\n        }\n      }\n    }\n  }\n\n  clone () {\n    const env = new Environment(this._factories)\n\n    for (const factory of env._factories) {\n      if (typeof factory.prototype.clone === 'function') {\n        factory.prototype.clone.call(env, this)\n      }\n    }\n\n    return env\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Environment);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/environment/Environment.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/fetch-lite/Factory.js":
/*!***************************************************!*\
  !*** ./node_modules/@rdfjs/fetch-lite/Factory.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./index.js */ \"./node_modules/@rdfjs/fetch-lite/index.js\");\n\n\nfunction createFetch (context) {\n  const result = function (url, options = {}) {\n    const factory = typeof context.dataset === 'function' ? context : null\n\n    return (0,_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(url, {\n      fetch: context._fetch.fetch,\n      formats: context.formats,\n      ...options,\n      factory\n    })\n  }\n\n  result.config = function (key, value) {\n    context._fetch[key] = value\n  }\n\n  result.Headers = _index_js__WEBPACK_IMPORTED_MODULE_0__.Headers\n\n  return result\n}\n\nclass FetchFactory {\n  init () {\n    this._fetch = {\n      fetch: null\n    }\n\n    this.fetch = createFetch(this)\n  }\n\n  clone (original) {\n    for (const [key, value] of Object.entries(original._fetch)) {\n      this._fetch[key] = value\n    }\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (FetchFactory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/fetch-lite/Factory.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/fetch-lite/index.js":
/*!*************************************************!*\
  !*** ./node_modules/@rdfjs/fetch-lite/index.js ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Headers: () => (/* reexport safe */ nodeify_fetch__WEBPACK_IMPORTED_MODULE_0__.Headers),\n/* harmony export */   \"default\": () => (/* binding */ rdfFetch)\n/* harmony export */ });\n/* harmony import */ var nodeify_fetch__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! nodeify-fetch */ \"./node_modules/nodeify-fetch/browser.js\");\n/* harmony import */ var _lib_patchRequest_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/patchRequest.js */ \"./node_modules/@rdfjs/fetch-lite/lib/patchRequest.js\");\n/* harmony import */ var _lib_patchResponse_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/patchResponse.js */ \"./node_modules/@rdfjs/fetch-lite/lib/patchResponse.js\");\n\n\n\n\nasync function rdfFetch (url, options = {}) {\n  const factory = options.factory\n  const fetch = options.fetch || nodeify_fetch__WEBPACK_IMPORTED_MODULE_0__[\"default\"]\n  const formats = options.formats\n\n  if (!formats) {\n    throw new Error('no formats given')\n  }\n\n  options = (0,_lib_patchRequest_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(options, formats)\n\n  const res = await fetch(url, options)\n\n  return (0,_lib_patchResponse_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(res, factory, fetch, formats.parsers)\n}\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/fetch-lite/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/fetch-lite/lib/attachDataset.js":
/*!*************************************************************!*\
  !*** ./node_modules/@rdfjs/fetch-lite/lib/attachDataset.js ***!
  \*************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _fromStream_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./fromStream.js */ \"./node_modules/@rdfjs/fetch-lite/lib/fromStream.js\");\n\n\nfunction attachDataset (res, factory) {\n  res.dataset = async () => {\n    const stream = await res.quadStream()\n    return (0,_fromStream_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(factory.dataset(), stream)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (attachDataset);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/fetch-lite/lib/attachDataset.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/fetch-lite/lib/attachQuadStream.js":
/*!****************************************************************!*\
  !*** ./node_modules/@rdfjs/fetch-lite/lib/attachQuadStream.js ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _jsonldContextLinkUrl_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./jsonldContextLinkUrl.js */ \"./node_modules/@rdfjs/fetch-lite/lib/jsonldContextLinkUrl.js\");\n\n\nfunction attachQuadStream (res, fetch, parsers) {\n  res.quadStream = async () => {\n    if (!res.headers.get('content-type')) {\n      throw new Error('Content-Type header missing: couldn\\'t determine parser')\n    }\n\n    // content type from headers without encoding, if given\n    let contentType = res.headers.get('content-type').split(';')[0]\n\n    // JSON-LD context URL from headers\n    const contextLinkUrl = (0,_jsonldContextLinkUrl_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(res, contentType)\n\n    // use JSON-LD content type if there is a context URL\n    if (contextLinkUrl) {\n      contentType = 'application/ld+json'\n    }\n\n    // is there a parser for the content?\n    if (!parsers.has(contentType)) {\n      return Promise.reject(new Error(`unknown content type: ${contentType}`))\n    }\n\n    let jsonldContext\n    if (contextLinkUrl) {\n      jsonldContext = await fetch(contextLinkUrl).then(res => res.json())\n    }\n\n    // parse the content using baseIRI and content\n    return parsers.import(contentType, res.body, {\n      baseIRI: res.url,\n      context: jsonldContext\n    })\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (attachQuadStream);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/fetch-lite/lib/attachQuadStream.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/fetch-lite/lib/fromStream.js":
/*!**********************************************************!*\
  !*** ./node_modules/@rdfjs/fetch-lite/lib/fromStream.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nasync function fromStream (dataset, stream) {\n  for await (const quad of stream) {\n    dataset.add(quad)\n  }\n\n  return dataset\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (fromStream);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/fetch-lite/lib/fromStream.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/fetch-lite/lib/jsonldContextLinkUrl.js":
/*!********************************************************************!*\
  !*** ./node_modules/@rdfjs/fetch-lite/lib/jsonldContextLinkUrl.js ***!
  \********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nconst linkRegExp = /<(.*)>/\n\nfunction jsonldContextLinkUrl (res, contentType) {\n  // only search for a context link when the content type is application/json\n  if (contentType !== 'application/json') {\n    return null\n  }\n\n  // no header link at all\n  if (!res.headers.has('link')) {\n    return null\n  }\n\n  // get all links and trim them\n  const links = res.headers.get('link').split(',').map(link => link.trim())\n\n  // filter the context link\n  const contextLink = links.find(link => link.includes('rel=\"http://www.w3.org/ns/json-ld#context\"'))\n\n  // no context link found\n  if (!contextLink) {\n    return null\n  }\n\n  // extract the URL\n  const contextUrl = (linkRegExp.exec(contextLink) || []).slice(-1)[0]\n\n  // invalid link format\n  if (!contextUrl) {\n    return null\n  }\n\n  // resolve the URL\n  return (new URL(contextUrl, res.url)).toString()\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (jsonldContextLinkUrl);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/fetch-lite/lib/jsonldContextLinkUrl.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/fetch-lite/lib/patchRequest.js":
/*!************************************************************!*\
  !*** ./node_modules/@rdfjs/fetch-lite/lib/patchRequest.js ***!
  \************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var is_stream__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! is-stream */ \"./node_modules/is-stream/index.js\");\n/* harmony import */ var nodeify_fetch__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! nodeify-fetch */ \"./node_modules/nodeify-fetch/browser.js\");\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n\n\n\n\nfunction patchRequest (options, formats) {\n  options.headers = new nodeify_fetch__WEBPACK_IMPORTED_MODULE_0__.Headers(options.headers)\n\n  // if no accept header is defined, list all of the parsers map\n  if (!options.headers.has('accept')) {\n    options.headers.set('accept', [...formats.parsers.keys()].join(', '))\n  }\n\n  // nothing to do if there is no content to send\n  if (!options.body) {\n    return options\n  }\n\n  // don't touch string content\n  if (typeof options.body === 'string') {\n    return options\n  }\n\n  // content-type defined but no serializer available for the media type available\n  let contentType = options.headers.get('content-type')\n\n  if (contentType && !formats.serializers.has(contentType)) {\n    throw new Error(`no serializer found for media type: ${options.headers.get('content-type')}`)\n  }\n\n  // if no content-type was defined, use the first in the serializer map\n  if (!contentType) {\n    contentType = formats.serializers.keys().next().value\n\n    options.headers.set('content-type', contentType)\n  }\n\n  // if body is an iterable, replace it with a stream\n  if (!(0,is_stream__WEBPACK_IMPORTED_MODULE_2__.isReadableStream)(options.body) && options.body[Symbol.iterator]) {\n    options.body = readable_stream__WEBPACK_IMPORTED_MODULE_1__.Readable.from(options.body)\n  }\n\n  // replace body quad stream with the serializer stream\n  options.body = formats.serializers.import(contentType, options.body)\n\n  return options\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (patchRequest);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/fetch-lite/lib/patchRequest.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/fetch-lite/lib/patchResponse.js":
/*!*************************************************************!*\
  !*** ./node_modules/@rdfjs/fetch-lite/lib/patchResponse.js ***!
  \*************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _attachDataset_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./attachDataset.js */ \"./node_modules/@rdfjs/fetch-lite/lib/attachDataset.js\");\n/* harmony import */ var _attachQuadStream_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./attachQuadStream.js */ \"./node_modules/@rdfjs/fetch-lite/lib/attachQuadStream.js\");\n\n\n\nfunction patchResponse (res, factory, fetch, parsers) {\n  const contentHeader = [...res.headers.keys()].some(header => header.startsWith('content-'))\n  const chunkedEncoding = res.headers.get('transfer-encoding') === 'chunked'\n  const hasBody = contentHeader || chunkedEncoding\n\n  // only attach .quadStream() and .dataset() if there is a body\n  if (hasBody) {\n    (0,_attachQuadStream_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(res, fetch, parsers)\n\n    if (factory) {\n      (0,_attachDataset_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(res, factory)\n    }\n  }\n\n  return res\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (patchResponse);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/fetch-lite/lib/patchResponse.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/formats/Factory.js":
/*!************************************************!*\
  !*** ./node_modules/@rdfjs/formats/Factory.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _lib_Formats_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/Formats.js */ \"./node_modules/@rdfjs/formats/lib/Formats.js\");\n\n\nclass Factory {\n  init () {\n    this.formats = new _lib_Formats_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]({ factory: this })\n  }\n\n  clone (original) {\n    this.formats.import(original.formats)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Factory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/formats/Factory.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/formats/index.js":
/*!**********************************************!*\
  !*** ./node_modules/@rdfjs/formats/index.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   JsonLdParser: () => (/* reexport safe */ _rdfjs_parser_jsonld__WEBPACK_IMPORTED_MODULE_0__[\"default\"]),\n/* harmony export */   JsonLdSerializer: () => (/* reexport safe */ _lib_JsonLdSerializer_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"]),\n/* harmony export */   N3Parser: () => (/* reexport safe */ _rdfjs_parser_n3__WEBPACK_IMPORTED_MODULE_1__[\"default\"]),\n/* harmony export */   NTriplesSerializer: () => (/* reexport safe */ _rdfjs_serializer_ntriples__WEBPACK_IMPORTED_MODULE_2__[\"default\"]),\n/* harmony export */   PrettyJsonLdSerializer: () => (/* reexport safe */ _lib_PrettyJsonLdSerializer_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"]),\n/* harmony export */   RdfXmlParser: () => (/* reexport safe */ _lib_RdfXmlParser_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"]),\n/* harmony export */   TurtleSerializer: () => (/* reexport safe */ _rdfjs_serializer_turtle__WEBPACK_IMPORTED_MODULE_3__[\"default\"]),\n/* harmony export */   \"default\": () => (/* binding */ formats)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_parser_jsonld__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/parser-jsonld */ \"./node_modules/@rdfjs/parser-jsonld/index.js\");\n/* harmony import */ var _rdfjs_parser_n3__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/parser-n3 */ \"./node_modules/@rdfjs/parser-n3/index.js\");\n/* harmony import */ var _rdfjs_serializer_ntriples__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @rdfjs/serializer-ntriples */ \"./node_modules/@rdfjs/serializer-ntriples/index.js\");\n/* harmony import */ var _rdfjs_serializer_turtle__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @rdfjs/serializer-turtle */ \"./node_modules/@rdfjs/serializer-turtle/index.js\");\n/* harmony import */ var _rdfjs_sink_map__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @rdfjs/sink-map */ \"./node_modules/@rdfjs/sink-map/index.js\");\n/* harmony import */ var _lib_JsonLdSerializer_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./lib/JsonLdSerializer.js */ \"./node_modules/@rdfjs/formats/lib/JsonLdSerializer.js\");\n/* harmony import */ var _lib_PrettyJsonLdSerializer_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./lib/PrettyJsonLdSerializer.js */ \"./node_modules/@rdfjs/formats/lib/PrettyJsonLdSerializer.js\");\n/* harmony import */ var _lib_RdfXmlParser_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./lib/RdfXmlParser.js */ \"./node_modules/@rdfjs/formats/lib/RdfXmlParser.js\");\n\n\n\n\n\n\n\n\n\nconst parsers = new _rdfjs_sink_map__WEBPACK_IMPORTED_MODULE_4__[\"default\"]([\n  ['application/ld+json', new _rdfjs_parser_jsonld__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()],\n  ['application/trig', new _rdfjs_parser_n3__WEBPACK_IMPORTED_MODULE_1__[\"default\"]()],\n  ['application/n-quads', new _rdfjs_parser_n3__WEBPACK_IMPORTED_MODULE_1__[\"default\"]()],\n  ['application/n-triples', new _rdfjs_parser_n3__WEBPACK_IMPORTED_MODULE_1__[\"default\"]()],\n  ['text/n3', new _rdfjs_parser_n3__WEBPACK_IMPORTED_MODULE_1__[\"default\"]()],\n  ['text/turtle', new _rdfjs_parser_n3__WEBPACK_IMPORTED_MODULE_1__[\"default\"]()],\n  ['application/rdf+xml', new _lib_RdfXmlParser_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"]()]\n])\n\nconst serializers = new _rdfjs_sink_map__WEBPACK_IMPORTED_MODULE_4__[\"default\"]([\n  ['application/ld+json', new _lib_JsonLdSerializer_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"]()],\n  ['application/n-quads', new _rdfjs_serializer_ntriples__WEBPACK_IMPORTED_MODULE_2__[\"default\"]()],\n  ['application/n-triples', new _rdfjs_serializer_ntriples__WEBPACK_IMPORTED_MODULE_2__[\"default\"]()],\n  ['text/n3', new _rdfjs_serializer_ntriples__WEBPACK_IMPORTED_MODULE_2__[\"default\"]()],\n  ['text/turtle', new _rdfjs_serializer_ntriples__WEBPACK_IMPORTED_MODULE_2__[\"default\"]()]\n])\n\nconst formats = {\n  parsers,\n  serializers\n}\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/formats/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/formats/lib/Formats.js":
/*!****************************************************!*\
  !*** ./node_modules/@rdfjs/formats/lib/Formats.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_sink_map__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/sink-map */ \"./node_modules/@rdfjs/sink-map/index.js\");\n\n\nclass Formats {\n  constructor ({ factory }) {\n    this.factory = factory\n    this.parsers = new _rdfjs_sink_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n    this.serializers = new _rdfjs_sink_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n  }\n\n  import (other) {\n    if (other.parsers) {\n      for (const [mediaType, parser] of other.parsers) {\n        this.parsers.set(mediaType, new parser.constructor({ factory: this.factory }))\n      }\n    }\n\n    if (other.serializers) {\n      for (const [mediaType, serializer] of other.serializers) {\n        this.serializers.set(mediaType, new serializer.constructor({ factory: this.factory }))\n      }\n    }\n\n    return this\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Formats);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/formats/lib/Formats.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/formats/lib/JsonLdSerializer.js":
/*!*************************************************************!*\
  !*** ./node_modules/@rdfjs/formats/lib/JsonLdSerializer.js ***!
  \*************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_serializer_jsonld__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/serializer-jsonld */ \"./node_modules/@rdfjs/serializer-jsonld/index.js\");\n\n\nclass JsonLdSerializer extends _rdfjs_serializer_jsonld__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  constructor ({ ...args } = {}) {\n    super({ ...args, encoding: 'string' })\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (JsonLdSerializer);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/formats/lib/JsonLdSerializer.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/formats/lib/PrettyJsonLdSerializer.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@rdfjs/formats/lib/PrettyJsonLdSerializer.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_serializer_jsonld_ext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/serializer-jsonld-ext */ \"./node_modules/@rdfjs/serializer-jsonld-ext/index.js\");\n\n\nclass PrettyJsonLdSerializer extends _rdfjs_serializer_jsonld_ext__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  constructor ({ ...args } = {}) {\n    super({\n      ...args,\n      compact: true,\n      encoding: 'string',\n      prettyPrint: true\n    })\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (PrettyJsonLdSerializer);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/formats/lib/PrettyJsonLdSerializer.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/formats/lib/RdfXmlParser.js":
/*!*********************************************************!*\
  !*** ./node_modules/@rdfjs/formats/lib/RdfXmlParser.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var rdfxml_streaming_parser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! rdfxml-streaming-parser */ \"./node_modules/rdfxml-streaming-parser/index.js\");\n\n\nclass RdfXmlParser extends rdfxml_streaming_parser__WEBPACK_IMPORTED_MODULE_0__.RdfXmlParser {\n  constructor ({ factory, ...args } = {}) {\n    super({ ...args, dataFactory: factory })\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (RdfXmlParser);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/formats/lib/RdfXmlParser.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/formats/pretty.js":
/*!***********************************************!*\
  !*** ./node_modules/@rdfjs/formats/pretty.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_sink_map__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/sink-map */ \"./node_modules/@rdfjs/sink-map/index.js\");\n/* harmony import */ var _index_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./index.js */ \"./node_modules/@rdfjs/formats/index.js\");\n\n\n\nconst parsers = new _rdfjs_sink_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"](_index_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].parsers)\n\nconst serializers = new _rdfjs_sink_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"](_index_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"].serializers)\n\nserializers.set('application/ld+json', new _index_js__WEBPACK_IMPORTED_MODULE_1__.PrettyJsonLdSerializer())\nserializers.set('text/n3', new _index_js__WEBPACK_IMPORTED_MODULE_1__.TurtleSerializer())\nserializers.set('text/turtle', new _index_js__WEBPACK_IMPORTED_MODULE_1__.TurtleSerializer())\n\nconst formats = {\n  parsers,\n  serializers\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (formats);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/formats/pretty.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/io/Factory.js":
/*!*******************************************!*\
  !*** ./node_modules/@rdfjs/io/Factory.js ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _dataset_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./dataset.js */ \"./node_modules/@rdfjs/io/dataset.js\");\n/* harmony import */ var _stream_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./stream.js */ \"./node_modules/@rdfjs/io/stream.js\");\n\n\n\nclass Factory {\n  init () {\n    this.io = {\n      dataset: {\n        fromText: (mediaType, text, args) => _dataset_js__WEBPACK_IMPORTED_MODULE_0__.fromText(mediaType, text, { ...args, factory: this }),\n        fromURL: (url, args) => _dataset_js__WEBPACK_IMPORTED_MODULE_0__.fromURL(url, { ...args, factory: this }),\n        toText: (mediaType, dataset, args) => _dataset_js__WEBPACK_IMPORTED_MODULE_0__.toText(mediaType, dataset, { ...args, factory: this }),\n        toURL: (url, dataset, args) => _dataset_js__WEBPACK_IMPORTED_MODULE_0__.toURL(url, dataset, { ...args, factory: this })\n      },\n      stream: {\n        fromText: (mediaType, text, args) => _stream_js__WEBPACK_IMPORTED_MODULE_1__.fromText(mediaType, text, { ...args, factory: this }),\n        fromURL: (url, args) => _stream_js__WEBPACK_IMPORTED_MODULE_1__.fromURL(url, { ...args, factory: this }),\n        toText: (mediaType, stream, args) => _stream_js__WEBPACK_IMPORTED_MODULE_1__.toText(mediaType, stream, { ...args, factory: this }),\n        toURL: (url, stream, args) => _stream_js__WEBPACK_IMPORTED_MODULE_1__.toURL(url, { ...args, factory: this })\n      }\n    }\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Factory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/io/Factory.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/io/dataset.js":
/*!*******************************************!*\
  !*** ./node_modules/@rdfjs/io/dataset.js ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   fromText: () => (/* binding */ fromText),\n/* harmony export */   fromURL: () => (/* binding */ fromURL),\n/* harmony export */   toText: () => (/* binding */ toText),\n/* harmony export */   toURL: () => (/* binding */ toURL)\n/* harmony export */ });\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n/* harmony import */ var stream_chunks__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! stream-chunks */ \"./node_modules/stream-chunks/index.js\");\n/* harmony import */ var _lib_checkResponse_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/checkResponse.js */ \"./node_modules/@rdfjs/io/lib/checkResponse.js\");\n/* harmony import */ var _lib_createWriteOptions_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./lib/createWriteOptions.js */ \"./node_modules/@rdfjs/io/lib/createWriteOptions.js\");\n\n\n\n\n\n/**\n * Parse the given text with a parser matching the media type and return the quads in a dataset.\n * @param mediaType Media type that is used to look up the parser\n * @param text Text to parse\n * @param factory Factory that is used to find the parser and create the dataset\n * @param [args] Additional arguments for the parser\n * @returns {Promise<Dataset>} Parsed quads in a dataset\n */\nasync function fromText (mediaType, text, { factory, ...args }) {\n  const parser = factory.formats.parsers.get(mediaType)\n\n  if (!parser) {\n    throw new Error(`unknown media type: ${mediaType}`)\n  }\n\n  const dataset = factory.dataset()\n  const stream = parser.import(readable_stream__WEBPACK_IMPORTED_MODULE_0__.Readable.from([text]), args)\n\n  for await (const quad of stream) {\n    dataset.add(quad)\n  }\n\n  return dataset\n}\n\n/**\n * Parse the content of the given URL and return the quads in a dataset.\n * @param url URL to fetch the content from\n * @param factory Factory that is used to fetch the content and create the dataset\n * @param [mediaType] Media type that should be used, replacing the content-type header\n * @param [args] Additional arguments for the fetch request\n * @returns {Promise<Dataset>} Parsed quads in a dataset\n */\nasync function fromURL (url, { factory, mediaType, ...args }) {\n  const res = await factory.fetch(url, { ...args, method: 'GET' })\n\n  await (0,_lib_checkResponse_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(url, {}, res)\n\n  if (mediaType) {\n    res.headers.set('content-type', mediaType)\n  }\n\n  return res.dataset()\n}\n\n/**\n * Serialize the given dataset to a text using a serializer matching the given media type.\n * @param mediaType Media type that is used to look up the serializer\n * @param dataset Dataset to serialize\n * @param factory Factory that is used to find the serializer\n * @param [args] Additional arguments for the serializer\n * @returns {Promise<String>} String of the serialized quads\n */\nasync function toText (mediaType, dataset, { factory, ...args }) {\n  const serializer = factory.formats.serializers.get(mediaType)\n\n  if (!serializer) {\n    throw new Error(`unknown media type: ${mediaType}`)\n  }\n\n  const stream = serializer.import(readable_stream__WEBPACK_IMPORTED_MODULE_0__.Readable.from(dataset), args)\n\n  return (0,stream_chunks__WEBPACK_IMPORTED_MODULE_1__.decode)(stream, 'utf-8')\n}\n\n/**\n * Serialize the given dataset and push it to the given URL.\n * @param url URL to push the content to\n * @param dataset Dataset to serialize\n * @param factory Factory that is used to push the content\n * @param [args] Additional arguments for the fetch request\n * @returns {Promise<void>}\n */\nasync function toURL (url, dataset, { factory, ...args }) {\n  const options = (0,_lib_createWriteOptions_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(url, readable_stream__WEBPACK_IMPORTED_MODULE_0__.Readable.from(dataset))\n  const res = await factory.fetch(url, { ...args, ...options })\n\n  await (0,_lib_checkResponse_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(url, options, res)\n}\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/io/dataset.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/io/lib/checkResponse.js":
/*!*****************************************************!*\
  !*** ./node_modules/@rdfjs/io/lib/checkResponse.js ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nasync function checkResponse (url, options, res) {\n  const action = options.method === 'PUT' ? 'write' : 'read'\n  const direction = action === 'read' ? 'from' : 'to'\n\n  if (!res.ok) {\n    throw new Error(`can't ${action} data ${direction} <${url.toString()}>[${res.status}]: ${await res.text()}`)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (checkResponse);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/io/lib/checkResponse.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/io/lib/createWriteOptions.js":
/*!**********************************************************!*\
  !*** ./node_modules/@rdfjs/io/lib/createWriteOptions.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _mediaTypes_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../mediaTypes.js */ \"./node_modules/@rdfjs/io/mediaTypes.js\");\n\n\nfunction createWriteOptions (url, body) {\n  const headers = new Headers()\n\n  const ext = url.toString().match(/\\.([a-z]+)$/)\n  const contentType = _mediaTypes_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].get(ext && ext[1])\n\n  if (contentType) {\n    headers.set('content-type', contentType)\n  }\n\n  return {\n    method: 'PUT',\n    headers,\n    body\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (createWriteOptions);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/io/lib/createWriteOptions.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/io/mediaTypes.js":
/*!**********************************************!*\
  !*** ./node_modules/@rdfjs/io/mediaTypes.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nconst mediaTypes = new Map([\n  ['json', 'application/ld+json'],\n  ['n3', 'text/n3'],\n  ['nq', 'application/n-quads'],\n  ['nt', 'application/n-triples'],\n  ['rdf', 'application/rdf+xml'],\n  ['trig', 'application/trig'],\n  ['ttl', 'text/turtle']\n])\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (mediaTypes);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/io/mediaTypes.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/io/stream.js":
/*!******************************************!*\
  !*** ./node_modules/@rdfjs/io/stream.js ***!
  \******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   fromText: () => (/* binding */ fromText),\n/* harmony export */   fromURL: () => (/* binding */ fromURL),\n/* harmony export */   toText: () => (/* binding */ toText),\n/* harmony export */   toURL: () => (/* binding */ toURL)\n/* harmony export */ });\n/* harmony import */ var duplex_to_readable_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! duplex-to/readable.js */ \"./node_modules/duplex-to/readable.js\");\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n/* harmony import */ var stream_chunks__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! stream-chunks */ \"./node_modules/stream-chunks/index.js\");\n/* harmony import */ var _lib_checkResponse_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./lib/checkResponse.js */ \"./node_modules/@rdfjs/io/lib/checkResponse.js\");\n/* harmony import */ var _lib_createWriteOptions_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./lib/createWriteOptions.js */ \"./node_modules/@rdfjs/io/lib/createWriteOptions.js\");\n\n\n\n\n\n\n/**\n * Parse the given text with a parser matching the media type and return a stream of quads.\n * @param mediaType Media type that is used to look up the parser\n * @param text Text to parse\n * @param factory Factory that is used to find the parser\n * @param [args] Additional arguments for the parser\n * @returns {Readable} Parsed quads in a dataset\n */\nfunction fromText (mediaType, text, { factory, ...args }) {\n  const parser = factory.formats.parsers.get(mediaType)\n\n  if (!parser) {\n    return new readable_stream__WEBPACK_IMPORTED_MODULE_1__.Readable({\n      read () {\n        this.destroy(new Error(`unknown media type: ${mediaType}`))\n      }\n    })\n  }\n\n  return parser.import(readable_stream__WEBPACK_IMPORTED_MODULE_1__.Readable.from([text]), args)\n}\n\n/**\n * Parse the content of the given URL and return a stream of quads.\n * @param url URL to fetch the content from\n * @param factory Factory that is used to fetch the content and parse it\n * @param [mediaType] Media type that should be used, replacing the content-type header\n * @param [args] Additional arguments for the fetch request\n * @returns {Readable} Parsed quads in a dataset\n */\nfunction fromURL (url, { factory, mediaType, ...args }) {\n  const output = new readable_stream__WEBPACK_IMPORTED_MODULE_1__.PassThrough({ objectMode: true })\n\n  setTimeout(async () => {\n    try {\n      const res = await factory.fetch(url, { ...args, method: 'GET' })\n\n      await (0,_lib_checkResponse_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(url, {}, res)\n\n      if (mediaType) {\n        res.headers.set('content-type', mediaType)\n      }\n\n      const stream = await res.quadStream()\n\n      stream\n        .on('error', err => output.destroy(err))\n        .pipe(output)\n    } catch (err) {\n      output.destroy(err)\n    }\n  }, 0)\n\n  return (0,duplex_to_readable_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(output)\n}\n\n/**\n * Serialize the given stream of quads to a text using a serializer matching the given media type.\n * @param mediaType Media type that is used to look up the serializer\n * @param stream Stream to serialize\n * @param factory Factory that is used to find the serializer\n * @param [args] Additional arguments for the serializer\n * @returns {Promise<String>} String of the serialized quads\n */\nasync function toText (mediaType, stream, { factory, ...args }) {\n  const serializer = factory.formats.serializers.get(mediaType)\n\n  if (!serializer) {\n    throw new Error(`unknown media type: ${mediaType}`)\n  }\n\n  const textStream = serializer.import(stream, args)\n\n  return (0,stream_chunks__WEBPACK_IMPORTED_MODULE_2__.decode)(textStream, 'utf-8')\n}\n\n/**\n * Serialize the given stream of quads and push it to the given URL.\n * @param url URL to push the content to\n * @param stream Stream to serialize\n * @param factory Factory that is used to serialize the stream and push the content\n * @param [args] Additional arguments for the fetch request\n * @returns {Promise<void>}\n */\nasync function toURL (url, stream, { factory, ...args }) {\n  const options = (0,_lib_createWriteOptions_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(url, stream)\n  const res = await factory.fetch(url, { ...args, ...options })\n\n  await (0,_lib_checkResponse_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(url, options, res)\n}\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/io/stream.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/namespace/Factory.js":
/*!**************************************************!*\
  !*** ./node_modules/@rdfjs/namespace/Factory.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./index.js */ \"./node_modules/@rdfjs/namespace/index.js\");\n\n\nclass Factory {\n  namespace (baseIRI) {\n    return (0,_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(baseIRI, { factory: this })\n  }\n}\n\nFactory.exports = ['namespace']\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Factory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/namespace/Factory.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/namespace/index.js":
/*!************************************************!*\
  !*** ./node_modules/@rdfjs/namespace/index.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_data_model__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/data-model */ \"./node_modules/@rdfjs/data-model/index.js\");\n\n\nconst handler = {\n  apply: (target, thisArg, args) => target(args[0]),\n  get: (target, property) => target(property)\n}\n\nfunction namespace (baseIRI, { factory = _rdfjs_data_model__WEBPACK_IMPORTED_MODULE_0__[\"default\"] } = {}) {\n  const builder = (term = '') => factory.namedNode(`${baseIRI}${term.raw || term}`)\n\n  return typeof Proxy === 'undefined' ? builder : new Proxy(builder, handler)\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (namespace);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/namespace/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/normalize/index.js":
/*!************************************************!*\
  !*** ./node_modules/@rdfjs/normalize/index.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var rdf_canonize_lib_RDFC10Sync_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! rdf-canonize/lib/RDFC10Sync.js */ \"./node_modules/rdf-canonize/lib/RDFC10Sync.js\");\n\n\nfunction toJsonldQuad (quad) {\n  return {\n    subject: toJsonldTerm(quad.subject),\n    predicate: toJsonldTerm(quad.predicate),\n    object: toJsonldTerm(quad.object),\n    graph: toJsonldTerm(quad.graph)\n  }\n}\n\nfunction toJsonldTerm (term) {\n  if (term.termType === 'BlankNode') {\n    return {\n      termType: 'BlankNode',\n      value: `_:${term.value}`\n    }\n  }\n\n  return term\n}\n\nfunction toJsonldDataset (dataset) {\n  return [...dataset].map(quad => toJsonldQuad(quad))\n}\n\nfunction normalize (dataset) {\n  const canonize = new rdf_canonize_lib_RDFC10Sync_js__WEBPACK_IMPORTED_MODULE_0__({ maxDeepIterations: 500 })\n\n  return canonize.main(toJsonldDataset(dataset))\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (normalize);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/normalize/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/parser-jsonld/index.js":
/*!****************************************************!*\
  !*** ./node_modules/@rdfjs/parser-jsonld/index.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_sink__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/sink */ \"./node_modules/@rdfjs/sink/index.js\");\n/* harmony import */ var _lib_ParserStream_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/ParserStream.js */ \"./node_modules/@rdfjs/parser-jsonld/lib/ParserStream.js\");\n\n\n\nclass Parser extends _rdfjs_sink__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  constructor (options) {\n    super(_lib_ParserStream_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"], options)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Parser);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/parser-jsonld/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/parser-jsonld/lib/ParserStream.js":
/*!***************************************************************!*\
  !*** ./node_modules/@rdfjs/parser-jsonld/lib/ParserStream.js ***!
  \***************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_data_model__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/data-model */ \"./node_modules/@rdfjs/data-model/index.js\");\n/* harmony import */ var duplex_to_readable_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! duplex-to/readable.js */ \"./node_modules/duplex-to/readable.js\");\n/* harmony import */ var jsonld_streaming_parser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! jsonld-streaming-parser */ \"./node_modules/jsonld-streaming-parser/index.js\");\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n\n\n\n\n\nconst relativeIriProtocol = 'null:'\n\nfunction termCleanup (factory) {\n  return term => {\n    if (term.termType !== 'NamedNode') {\n      return null\n    }\n\n    if (!term.value.startsWith(relativeIriProtocol)) {\n      return null\n    }\n\n    // remove dummy protocol workaround for relative IRIs\n    return factory.namedNode(term.value.slice(relativeIriProtocol.length))\n  }\n}\n\nfunction quadCleanup (factory) {\n  const cleanup = termCleanup(factory)\n\n  return quad => {\n    const subject = cleanup(quad.subject)\n    const predicate = cleanup(quad.predicate)\n    const object = cleanup(quad.object)\n    const graph = cleanup(quad.graph)\n\n    if (subject || predicate || object || graph) {\n      return factory.quad(\n        subject || quad.subject,\n        predicate || quad.predicate,\n        object || quad.object,\n        graph || quad.graph\n      )\n    }\n\n    return quad\n  }\n}\n\nclass ParserStream {\n  constructor (input, { baseIRI = relativeIriProtocol, context = null, documentLoader, factory = _rdfjs_data_model__WEBPACK_IMPORTED_MODULE_0__[\"default\"] } = {}) {\n    const parser = new jsonld_streaming_parser__WEBPACK_IMPORTED_MODULE_3__.JsonLdParser({\n      baseIRI,\n      context,\n      dataFactory: factory,\n      documentLoader,\n      streamingProfile: false\n    })\n\n    input.pipe(parser)\n\n    const cleanup = quadCleanup(factory)\n\n    const transform = new readable_stream__WEBPACK_IMPORTED_MODULE_2__.Transform({\n      objectMode: true,\n      transform: (quad, encoding, callback) => {\n        callback(null, cleanup(quad))\n      }\n    })\n\n    parser.on('context', context => {\n      Object.entries(context).forEach(([prefix, iri]) => {\n        transform.emit('prefix', prefix, factory.namedNode(iri))\n      })\n    })\n    parser.on('error', err => transform.destroy(err))\n    parser.pipe(transform)\n\n    return (0,duplex_to_readable_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(transform)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (ParserStream);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/parser-jsonld/lib/ParserStream.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/parser-n3/index.js":
/*!************************************************!*\
  !*** ./node_modules/@rdfjs/parser-n3/index.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_sink__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/sink */ \"./node_modules/@rdfjs/sink/index.js\");\n/* harmony import */ var _lib_ParserStream_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/ParserStream.js */ \"./node_modules/@rdfjs/parser-n3/lib/ParserStream.js\");\n\n\n\nclass Parser extends _rdfjs_sink__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  constructor (options) {\n    super(_lib_ParserStream_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"], options)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Parser);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/parser-n3/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/parser-n3/lib/ParserStream.js":
/*!***********************************************************!*\
  !*** ./node_modules/@rdfjs/parser-n3/lib/ParserStream.js ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_data_model__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/data-model */ \"./node_modules/@rdfjs/data-model/index.js\");\n/* harmony import */ var duplex_to_readable_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! duplex-to/readable.js */ \"./node_modules/duplex-to/readable.js\");\n/* harmony import */ var n3__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! n3 */ \"./node_modules/n3/src/N3StreamParser.js\");\n\n\n\n\nclass ParserStream {\n  constructor (input, { baseIRI = '', factory = _rdfjs_data_model__WEBPACK_IMPORTED_MODULE_0__[\"default\"], ...rest } = {}) {\n    const boundFactory = {\n      blankNode: factory.blankNode.bind(factory),\n      defaultGraph: factory.defaultGraph.bind(factory),\n      literal: factory.literal.bind(factory),\n      namedNode: factory.namedNode.bind(factory),\n      quad: factory.quad.bind(factory)\n    }\n\n    const parser = new n3__WEBPACK_IMPORTED_MODULE_2__[\"default\"]({ baseIRI, factory: boundFactory, ...rest })\n\n    input.pipe(parser)\n\n    return (0,duplex_to_readable_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(parser)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (ParserStream);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/parser-n3/lib/ParserStream.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/prefix-map/Factory.js":
/*!***************************************************!*\
  !*** ./node_modules/@rdfjs/prefix-map/Factory.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _PrefixMap_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./PrefixMap.js */ \"./node_modules/@rdfjs/prefix-map/PrefixMap.js\");\n\n\nclass Factory {\n  init () {\n    this.prefixes = new _PrefixMap_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]([], { factory: this })\n  }\n\n  clone (original) {\n    if (original.prefixes) {\n      for (const [prefix, term] of original.prefixes) {\n        this.prefixes.set(prefix, term)\n      }\n    }\n  }\n\n  prefixMap (prefixes) {\n    return new _PrefixMap_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"](prefixes, { factory: this })\n  }\n}\n\nFactory.exports = ['prefixMap']\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Factory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/prefix-map/Factory.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/prefix-map/PrefixMap.js":
/*!*****************************************************!*\
  !*** ./node_modules/@rdfjs/prefix-map/PrefixMap.js ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n\n\nclass PrefixMap extends Map {\n  constructor (prefixes = [], { factory }) {\n    super(prefixes)\n\n    this.factory = factory\n  }\n\n  resolve (term) {\n    if (term.value.includes('://')) {\n      return null\n    }\n\n    const [prefix, path] = term.value.split(':', 2)\n\n    if (path === undefined) {\n      return null\n    }\n\n    if (!this.has(prefix)) {\n      return null\n    }\n\n    return this.factory.namedNode(`${this.get(prefix).value}${path}`)\n  }\n\n  shrink (term) {\n    if (!term) {\n      return null\n    }\n\n    const [pair] = [...this]\n      .filter(([, namespace]) => term.value.startsWith(namespace.value))\n      .sort((a, b) => b[1].value.length - a[1].value.length)\n\n    if (pair === undefined) {\n      return null\n    }\n\n    return this.factory.namedNode(`${pair[0]}:${term.value.slice(pair[1].value.length)}`)\n  }\n\n  import (stream) {\n    stream.on('prefix', (prefix, namespace) => {\n      this.set(prefix, namespace)\n    })\n\n    return new Promise((resolve, reject) => {\n      ;(0,readable_stream__WEBPACK_IMPORTED_MODULE_0__.finished)(stream, err => {\n        if (err) {\n          reject(err)\n        } else {\n          resolve(this)\n        }\n      })\n    })\n  }\n\n  export (stream) {\n    for (const [prefix, namespace] of this) {\n      stream.emit('prefix', prefix, namespace)\n    }\n\n    return this\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (PrefixMap);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/prefix-map/PrefixMap.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/Factory.js":
/*!**********************************************!*\
  !*** ./node_modules/@rdfjs/score/Factory.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _combine_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./combine.js */ \"./node_modules/@rdfjs/score/combine.js\");\n/* harmony import */ var _concat_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./concat.js */ \"./node_modules/@rdfjs/score/concat.js\");\n/* harmony import */ var _count_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./count.js */ \"./node_modules/@rdfjs/score/count.js\");\n/* harmony import */ var _distinct_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./distinct.js */ \"./node_modules/@rdfjs/score/distinct.js\");\n/* harmony import */ var _exists_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./exists.js */ \"./node_modules/@rdfjs/score/exists.js\");\n/* harmony import */ var _fallback_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./fallback.js */ \"./node_modules/@rdfjs/score/fallback.js\");\n/* harmony import */ var _fixed_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./fixed.js */ \"./node_modules/@rdfjs/score/fixed.js\");\n/* harmony import */ var _language_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./language.js */ \"./node_modules/@rdfjs/score/language.js\");\n/* harmony import */ var _pageRank_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./pageRank.js */ \"./node_modules/@rdfjs/score/pageRank.js\");\n/* harmony import */ var _pathDepth_js__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./pathDepth.js */ \"./node_modules/@rdfjs/score/pathDepth.js\");\n/* harmony import */ var _prioritized_js__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./prioritized.js */ \"./node_modules/@rdfjs/score/prioritized.js\");\n/* harmony import */ var _product_js__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./product.js */ \"./node_modules/@rdfjs/score/product.js\");\n/* harmony import */ var _scale_js__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./scale.js */ \"./node_modules/@rdfjs/score/scale.js\");\n/* harmony import */ var _sort_js__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./sort.js */ \"./node_modules/@rdfjs/score/sort.js\");\n/* harmony import */ var _sortObjects_js__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./sortObjects.js */ \"./node_modules/@rdfjs/score/sortObjects.js\");\n/* harmony import */ var _sum_js__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./sum.js */ \"./node_modules/@rdfjs/score/sum.js\");\n/* harmony import */ var _type_js__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./type.js */ \"./node_modules/@rdfjs/score/type.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass Factory {\n  init () {\n    this.score = {\n      combine: _combine_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"],\n      concat: _concat_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"],\n      count: _count_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"],\n      distinct: _distinct_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"],\n      exists: _exists_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"],\n      fallback: _fallback_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"],\n      fixed: _fixed_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"],\n      language: _language_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"],\n      pageRank: _pageRank_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"],\n      pathDepth: _pathDepth_js__WEBPACK_IMPORTED_MODULE_9__[\"default\"],\n      prioritized: _prioritized_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"],\n      product: _product_js__WEBPACK_IMPORTED_MODULE_11__[\"default\"],\n      scale: _scale_js__WEBPACK_IMPORTED_MODULE_12__[\"default\"],\n      sort: _sort_js__WEBPACK_IMPORTED_MODULE_13__[\"default\"],\n      sortObjects: _sortObjects_js__WEBPACK_IMPORTED_MODULE_14__[\"default\"],\n      sum: _sum_js__WEBPACK_IMPORTED_MODULE_15__[\"default\"],\n      type: _type_js__WEBPACK_IMPORTED_MODULE_16__[\"default\"]\n    }\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Factory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/Factory.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/combine.js":
/*!**********************************************!*\
  !*** ./node_modules/@rdfjs/score/combine.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   prioritized: () => (/* binding */ prioritized)\n/* harmony export */ });\n/* harmony import */ var _scale_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./scale.js */ \"./node_modules/@rdfjs/score/scale.js\");\n/* harmony import */ var _sum_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./sum.js */ \"./node_modules/@rdfjs/score/sum.js\");\n\n\n\nfunction combine (list) {\n  const factor = 1 / list.length\n\n  return (0,_sum_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(list.map(score => (0,_scale_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])({ factor, score })))\n}\n\nfunction prioritized (list) {\n  const step = 2 / (list.length * (list.length + 1))\n\n  const scaled = list.map((score, index) => {\n    const factor = (list.length - index) * step\n\n    return (0,_scale_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])({ factor, score })\n  })\n\n  return (0,_sum_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(scaled)\n}\n\ncombine.prioritized = prioritized\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (combine);\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/combine.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/concat.js":
/*!*********************************************!*\
  !*** ./node_modules/@rdfjs/score/concat.js ***!
  \*********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction concat (list) {\n  return ({ dataset, graph, terms = [] }) => {\n    return list.flatMap(score => {\n      return score({ dataset, graph, terms })\n    })\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (concat);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/concat.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/count.js":
/*!********************************************!*\
  !*** ./node_modules/@rdfjs/score/count.js ***!
  \********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/term-map */ \"./node_modules/@rdfjs/term-map/TermMap.js\");\n\n\nfunction count ({ graph, object, predicate, subject = true } = {}) {\n  const test = { subject, predicate, object, graph }\n\n  return ({ dataset, graph, terms = [] }) => {\n    const counts = new _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n    let total = 0\n\n    const countPart = part => {\n      for (const term of terms) {\n        const pattern = [\n          part === 'subject' && term,\n          part === 'predicate' && term,\n          part === 'object' && term,\n          graph || (part === 'graph' && term)\n        ]\n        const quads = dataset.match(...pattern)\n\n        for (const quad of quads) {\n          const partTerm = quad[part]\n          const meta = counts.get(partTerm) || { count: 0 }\n\n          if (!counts.has(partTerm)) {\n            counts.set(partTerm, meta)\n          }\n\n          meta.count++\n          total++\n        }\n      }\n    }\n\n    for (const part of ['subject', 'predicate', 'object', 'graph']) {\n      if (test[part]) {\n        countPart(part)\n      }\n    }\n\n    const results = []\n\n    for (const [term, meta] of counts) {\n      results.push({ dataset, graph, term, score: meta.count / total })\n    }\n\n    return results\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (count);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/count.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/distinct.js":
/*!***********************************************!*\
  !*** ./node_modules/@rdfjs/score/distinct.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _lib_TupleMap_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/TupleMap.js */ \"./node_modules/@rdfjs/score/lib/TupleMap.js\");\n\n\nfunction distinct (results) {\n  const all = new _lib_TupleMap_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n\n  for (const result of results) {\n    const current = all.get([result.term, result.graph])\n\n    if (!current) {\n      all.set([result.term, result.graph], result)\n    } else if (current.score < result.score) {\n      all.delete([result.term, result.graph])\n      all.set([result.term, result.graph], result)\n    }\n  }\n\n  return [...all.values()]\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (distinct);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/distinct.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/exists.js":
/*!*********************************************!*\
  !*** ./node_modules/@rdfjs/score/exists.js ***!
  \*********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction exists ({ graph, object, predicate, subject }) {\n  const test = { subject, predicate, object, graph }\n\n  return ({ dataset, graph, terms = [] }) => {\n    for (const term of terms) {\n      const found = [{ dataset, graph, term, score: 1 }]\n\n      if (test.subject) {\n        if (test.subject.equals(term) && dataset.match(term, null, null, graph).size > 0) {\n          return found\n        }\n      }\n\n      if (test.predicate) {\n        if (test.predicate.equals(term) && dataset.match(null, term, null, graph).size > 0) {\n          return found\n        }\n      }\n\n      if (test.object) {\n        if (test.object.equals(term) && dataset.match(null, null, term, graph).size > 0) {\n          return found\n        }\n      }\n\n      if (test.graph) {\n        if (test.graph.equals(term) && (!graph || test.graph.equals(graph)) && dataset.match(null, null, null, graph).size > 0) {\n          return found\n        }\n      }\n    }\n\n    return []\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (exists);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/exists.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/fallback.js":
/*!***********************************************!*\
  !*** ./node_modules/@rdfjs/score/fallback.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction fallback (list) {\n  return ({ dataset, graph, terms = [] }) => {\n    for (const score of list) {\n      const current = score({ dataset, graph, terms })\n\n      if (current.length > 0) {\n        return current\n      }\n    }\n\n    return []\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (fallback);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/fallback.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/fixed.js":
/*!********************************************!*\
  !*** ./node_modules/@rdfjs/score/fixed.js ***!
  \********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction fixed (term) {\n  const given = term\n\n  return ({ dataset, graph, terms = [] }) => {\n    for (const term of terms) {\n      if (term.equals(given)) {\n        return [{ dataset, graph, term, score: 1 }]\n      }\n    }\n\n    return []\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (fixed);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/fixed.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/language.js":
/*!***********************************************!*\
  !*** ./node_modules/@rdfjs/score/language.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction language (languages) {\n  const scoreMap = new Map()\n  let wildcardScore\n\n  for (const [index, language] of Object.entries(languages)) {\n    const score = 1 - (index / languages.length)\n\n    if (language === '*') {\n      wildcardScore = score\n    } else {\n      scoreMap.set(language, score)\n    }\n  }\n\n  return ({ dataset, graph, terms = [] }) => {\n    const results = []\n\n    for (const term of terms) {\n      let score = scoreMap.get(term.language)\n\n      if (typeof score === 'undefined' && typeof term.language === 'string' && wildcardScore) {\n        score = wildcardScore\n      }\n\n      if (typeof score !== 'undefined') {\n        results.push({ dataset, graph, term, score })\n      }\n    }\n\n    return results\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (language);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/language.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/lib/TupleMap.js":
/*!***************************************************!*\
  !*** ./node_modules/@rdfjs/score/lib/TupleMap.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n/* harmony import */ var _TupleSet_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TupleSet.js */ \"./node_modules/@rdfjs/score/lib/TupleSet.js\");\n\n\n\nclass TupleMap extends Map {\n  constructor (entries = []) {\n    super()\n\n    this._keys = new Map()\n\n    for (const [terms, value] of entries) {\n      this.set(terms, value)\n    }\n  }\n\n  delete (terms) {\n    const key = TupleMap.key(terms)\n\n    this._keys.delete(key)\n\n    return super.delete(key)\n  }\n\n  get (terms) {\n    return super.get(TupleMap.key(terms))\n  }\n\n  has (terms) {\n    return super.has(TupleMap.key(terms))\n  }\n\n  keys () {\n    return new _TupleSet_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"](this._keys.values())\n  }\n\n  set (terms, value) {\n    const key = TupleMap.key(terms)\n\n    this._keys.set(key, terms)\n\n    return super.set(key, value)\n  }\n\n  static key (terms) {\n    return terms.map(term => (term && (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(term)) || 'undefined').join(' ')\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (TupleMap);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/lib/TupleMap.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/lib/TupleSet.js":
/*!***************************************************!*\
  !*** ./node_modules/@rdfjs/score/lib/TupleSet.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n\n\nclass TupleSet extends Set {\n  constructor (entries = []) {\n    super()\n\n    this._index = new Map()\n\n    for (const terms of entries) {\n      this.add(terms)\n    }\n  }\n\n  add (terms) {\n    this._index.set(TupleSet.key(terms), terms)\n\n    return super.add(terms)\n  }\n\n  delete (terms) {\n    const item = this._index.get(TupleSet.key(terms))\n\n    return super.delete(item)\n  }\n\n  has (terms) {\n    return this._index.has(TupleSet.key(terms))\n  }\n\n  static key (terms) {\n    return terms.map(term => (term && (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(term)) || 'undefined').join(' ')\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (TupleSet);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/lib/TupleSet.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/pageRank.js":
/*!***********************************************!*\
  !*** ./node_modules/@rdfjs/score/pageRank.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/term-map */ \"./node_modules/@rdfjs/term-map/TermMap.js\");\n/* harmony import */ var _rdfjs_term_set__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/term-set */ \"./node_modules/@rdfjs/term-set/TermSet.js\");\n\n\n\nfunction pageRank ({ alpha = 0.85, epsilon = 0.000001 } = {}) {\n  return ({ dataset, graph, terms }) => {\n    terms = new _rdfjs_term_set__WEBPACK_IMPORTED_MODULE_1__[\"default\"](terms)\n\n    const nodes = new _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n    const inverse = 1 / terms.size\n    let delta = 1\n\n    for (const term of terms) {\n      const quads = dataset.match(null, null, term, graph)\n\n      nodes.set(term, {\n        weight: inverse,\n        outbound: quads.size,\n        subjects: [...quads].map(quad => quad.subject).filter(subject => terms.has(subject))\n      })\n    }\n\n    while (delta > epsilon) {\n      const weights = new _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n      let leak = 0\n\n      for (const [term, data] of nodes) {\n        weights.set(term, data.weight)\n\n        if (data.outbound === 0) {\n          leak += data.weight\n        }\n\n        data.weight = 0\n      }\n\n      leak *= alpha\n\n      for (const [term, data] of nodes) {\n        for (const subject of data.subjects) {\n          nodes.get(subject).weight += alpha * weights.get(term) / data.outbound\n        }\n\n        data.weight += (1 - alpha) * inverse + leak * inverse\n      }\n\n      delta = 0\n\n      for (const [term, data] of nodes) {\n        delta += Math.abs(data.weight - weights.get(term))\n      }\n    }\n\n    const results = []\n\n    for (const [term, data] of nodes) {\n      results.push({ dataset, graph, term, score: data.weight })\n    }\n\n    return results\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (pageRank);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/pageRank.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/pathDepth.js":
/*!************************************************!*\
  !*** ./node_modules/@rdfjs/score/pathDepth.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction pathDepth () {\n  return ({ dataset, graph, terms = [] }) => {\n    const results = []\n\n    for (const term of terms) {\n      let score = Number.EPSILON\n\n      if (term.termType === 'NamedNode') {\n        let pathname = (new URL(term.value)).pathname\n\n        if (pathname.endsWith('/')) {\n          pathname = pathname.slice(0, -1)\n        }\n\n        const pathDepth = pathname.split('/').length\n\n        score = 1 / pathDepth\n      }\n\n      results.push({ dataset, graph, term, score })\n    }\n\n    return results\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (pathDepth);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/pathDepth.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/prioritized.js":
/*!**************************************************!*\
  !*** ./node_modules/@rdfjs/score/prioritized.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _scale_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./scale.js */ \"./node_modules/@rdfjs/score/scale.js\");\n\n\nfunction prioritized (list) {\n  return ({ dataset, graph, terms = [] }) => {\n    const all = []\n    const step = 2 / (list.length * (list.length + 1))\n\n    for (let index = 0; index < list.length; index++) {\n      const factor = (list.length - index) * step\n      const score = (0,_scale_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])({ factor, score: list[index] })\n\n      for (const result of score({ dataset, graph, terms })) {\n        all.push(result)\n      }\n    }\n\n    return all\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (prioritized);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/prioritized.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/product.js":
/*!**********************************************!*\
  !*** ./node_modules/@rdfjs/score/product.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _lib_TupleMap_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/TupleMap.js */ \"./node_modules/@rdfjs/score/lib/TupleMap.js\");\n\n\nfunction product (list) {\n  return ({ dataset, graph, terms = [] }) => {\n    if (list.length === 0) {\n      return []\n    }\n\n    const results = list[0]({ dataset, graph, terms })\n    const all = new _lib_TupleMap_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"](results.map(result => [[result.term, graph], result]))\n\n    for (let i = 1; i < list.length; i++) {\n      const score = list[i]\n      const keys = all.keys()\n      const current = score({ dataset, graph, terms })\n\n      for (const result of current) {\n        const total = all.get([result.term, graph])\n\n        if (total) {\n          total.score *= result.score\n        }\n\n        keys.delete([result.term, graph])\n      }\n\n      for (const key of keys) {\n        all.delete(key)\n      }\n    }\n\n    return [...all.values()]\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (product);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/product.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/scale.js":
/*!********************************************!*\
  !*** ./node_modules/@rdfjs/score/scale.js ***!
  \********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction scale ({ factor, score }) {\n  return ({ dataset, graph, terms = [] }) => {\n    return score({ dataset, graph, terms }).map(result => {\n      result.score *= factor\n\n      return result\n    })\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (scale);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/scale.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/sort.js":
/*!*******************************************!*\
  !*** ./node_modules/@rdfjs/score/sort.js ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction sort (results) {\n  return results.slice().sort((a, b) => {\n    const diff = b.score - a.score\n\n    if (diff !== 0) {\n      return diff\n    }\n\n    return a.term.value.localeCompare(b.term.value)\n  })\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (sort);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/sort.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/sortObjects.js":
/*!**************************************************!*\
  !*** ./node_modules/@rdfjs/score/sortObjects.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/term-map */ \"./node_modules/@rdfjs/term-map/TermMap.js\");\n/* harmony import */ var _distinct_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./distinct.js */ \"./node_modules/@rdfjs/score/distinct.js\");\n/* harmony import */ var _sort_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./sort.js */ \"./node_modules/@rdfjs/score/sort.js\");\n\n\n\n\nfunction sortObjects ({\n  dataset,\n  objects,\n  score,\n  termCallback = object => object.term\n} = {}) {\n  const objectMap = new _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"](objects.map(object => [termCallback(object), object]))\n  const terms = objects.map(object => termCallback(object))\n  const toSort = { dataset, terms }\n  const sorted = (0,_sort_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"])((0,_distinct_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(score(toSort)))\n  const sortedObjects = sorted.map(({ term }) => objectMap.get(term))\n\n  return sortedObjects\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (sortObjects);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/sortObjects.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/sum.js":
/*!******************************************!*\
  !*** ./node_modules/@rdfjs/score/sum.js ***!
  \******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _lib_TupleMap_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/TupleMap.js */ \"./node_modules/@rdfjs/score/lib/TupleMap.js\");\n\n\nfunction sum (list) {\n  return ({ dataset, graph, terms = [] }) => {\n    const all = new _lib_TupleMap_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n\n    for (let i = 0; i < list.length; i++) {\n      const score = list[i]\n\n      const current = score({ dataset, graph, terms })\n\n      for (const result of current) {\n        const total = all.get([result.term, graph])\n\n        if (!total) {\n          all.set([result.term, graph], result)\n        } else {\n          total.score += result.score\n        }\n      }\n    }\n\n    return [...all.values()]\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (sum);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/sum.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/score/type.js":
/*!*******************************************!*\
  !*** ./node_modules/@rdfjs/score/type.js ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_data_model__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/data-model */ \"./node_modules/@rdfjs/data-model/index.js\");\n\n\nfunction type (type) {\n  const ns = {\n    rdf: {\n      type: _rdfjs_data_model__WEBPACK_IMPORTED_MODULE_0__[\"default\"].namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#type')\n    }\n  }\n\n  return ({ dataset, graph, terms = [] }) => {\n    const results = []\n\n    for (const term of terms) {\n      for (const quad of dataset.match(term, ns.rdf.type, type, graph)) {\n        results.push({ dataset, graph: quad.graph, term, score: 1 })\n      }\n    }\n\n    return results\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (type);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/score/type.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-jsonld-ext/index.js":
/*!************************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-jsonld-ext/index.js ***!
  \************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_sink__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/sink */ \"./node_modules/@rdfjs/sink/index.js\");\n/* harmony import */ var _lib_SerializerStream_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/SerializerStream.js */ \"./node_modules/@rdfjs/serializer-jsonld-ext/lib/SerializerStream.js\");\n\n\n\nclass Serializer extends _rdfjs_sink__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  constructor (options) {\n    super(_lib_SerializerStream_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"], options)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Serializer);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-jsonld-ext/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-jsonld-ext/lib/SerializerStream.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-jsonld-ext/lib/SerializerStream.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var jsonld__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! jsonld */ \"./node_modules/jsonld/lib/jsonld.js\");\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n/* harmony import */ var stream_chunks_chunks_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! stream-chunks/chunks.js */ \"./node_modules/stream-chunks/chunks.js\");\n\n\n\n\nclass SerializerStream extends readable_stream__WEBPACK_IMPORTED_MODULE_1__.Readable {\n  constructor (input, {\n    baseIRI,\n    compact,\n    context = {},\n    encoding = 'object',\n    flatten,\n    frame,\n    prettyPrint,\n    skipContext\n  } = {}) {\n    super({\n      objectMode: true,\n      read: () => {}\n    })\n\n    this.compact = compact\n    this.context = context\n    this.encoding = encoding\n    this.flatten = flatten\n    this.frame = frame\n    this.prettyPrint = prettyPrint\n    this.skipContext = skipContext\n\n    if (baseIRI) {\n      this.context['@base'] = baseIRI.value || baseIRI.toString()\n    }\n\n    input.on('prefix', (prefix, namespace) => {\n      if (!this.context[prefix]) {\n        this.context[prefix] = namespace.value\n      }\n    })\n\n    this.handleData(input)\n  }\n\n  async handleData (input) {\n    try {\n      const quadArray = (await (0,stream_chunks_chunks_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(input)).map(SerializerStream.toJsonldQuad)\n      const rawJsonld = await jsonld__WEBPACK_IMPORTED_MODULE_0__.fromRDF(quadArray)\n      const transformedJsonld = await this.transform(rawJsonld, this.options)\n\n      this.push(transformedJsonld)\n      this.push(null)\n    } catch (err) {\n      this.emit('error', err)\n    }\n  }\n\n  async transform (data) {\n    if (this.compact) {\n      data = await jsonld__WEBPACK_IMPORTED_MODULE_0__.compact(data, this.context)\n    }\n\n    if (this.flatten) {\n      data = await jsonld__WEBPACK_IMPORTED_MODULE_0__.flatten(data, this.context)\n    }\n\n    if (this.frame) {\n      data = await jsonld__WEBPACK_IMPORTED_MODULE_0__.frame(data, this.context)\n    }\n\n    if (this.skipContext && data['@context']) {\n      delete data['@context']\n    }\n\n    if (this.encoding === 'string') {\n      if (this.prettyPrint) {\n        return JSON.stringify(data, null, 2)\n      } else {\n        return JSON.stringify(data)\n      }\n    }\n\n    return data\n  }\n\n  static toJsonldQuad (quad) {\n    return {\n      subject: SerializerStream.toJsonldTerm(quad.subject),\n      predicate: SerializerStream.toJsonldTerm(quad.predicate),\n      object: SerializerStream.toJsonldTerm(quad.object),\n      graph: SerializerStream.toJsonldTerm(quad.graph)\n    }\n  }\n\n  static toJsonldTerm (term) {\n    if (term.termType === 'BlankNode') {\n      return {\n        termType: 'BlankNode',\n        value: `_:${term.value}`\n      }\n    }\n\n    return term\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (SerializerStream);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-jsonld-ext/lib/SerializerStream.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-jsonld/index.js":
/*!********************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-jsonld/index.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_sink__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/sink */ \"./node_modules/@rdfjs/sink/index.js\");\n/* harmony import */ var _lib_SerializerStream_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/SerializerStream.js */ \"./node_modules/@rdfjs/serializer-jsonld/lib/SerializerStream.js\");\n\n\n\nclass Serializer extends _rdfjs_sink__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  constructor (options) {\n    super(_lib_SerializerStream_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"], options)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Serializer);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-jsonld/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-jsonld/lib/ObjectEncoder.js":
/*!********************************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-jsonld/lib/ObjectEncoder.js ***!
  \********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass ObjectEncoder {\n  constructor (stream) {\n    this.stream = stream\n    this.array = []\n  }\n\n  push (jsonld) {\n    this.array.push(jsonld)\n  }\n\n  end () {\n    this.stream.push(this.array)\n    this.stream.push(null)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (ObjectEncoder);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-jsonld/lib/ObjectEncoder.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-jsonld/lib/SerializerStream.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-jsonld/lib/SerializerStream.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n/* harmony import */ var _ObjectEncoder_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ObjectEncoder.js */ \"./node_modules/@rdfjs/serializer-jsonld/lib/ObjectEncoder.js\");\n/* harmony import */ var _StringEncoder_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./StringEncoder.js */ \"./node_modules/@rdfjs/serializer-jsonld/lib/StringEncoder.js\");\n\n\n\n\nclass SerializerStream extends readable_stream__WEBPACK_IMPORTED_MODULE_0__.Readable {\n  constructor (input, { encoding = 'object' } = {}) {\n    super({\n      objectMode: true,\n      read: () => {}\n    })\n\n    if (encoding === 'object') {\n      this.encoder = new _ObjectEncoder_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"](this)\n    }\n\n    if (encoding === 'string') {\n      this.encoder = new _StringEncoder_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"](this)\n    }\n\n    if (!this.encoder) {\n      throw new Error(`unknown encoding: ${encoding}`)\n    }\n\n    input.on('data', quad => {\n      const jsonld = {}\n      let triple = jsonld\n\n      if (quad.graph.termType !== 'DefaultGraph') {\n        jsonld['@id'] = quad.graph.value\n        jsonld['@graph'] = {}\n        triple = jsonld['@graph']\n      }\n\n      triple['@id'] = SerializerStream.subjectValue(quad.subject)\n\n      if (quad.predicate.value === 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type') {\n        triple['@type'] = SerializerStream.subjectValue(quad.object)\n      } else {\n        triple[quad.predicate.value] = SerializerStream.objectValue(quad.object)\n      }\n\n      this.encoder.push(jsonld)\n    })\n\n    input.on('end', () => this.encoder.end())\n\n    input.on('error', err => this.emit('error', err))\n  }\n\n  static subjectValue (subject) {\n    return subject.termType === 'BlankNode' ? '_:' + subject.value : subject.value\n  }\n\n  static objectValue (object) {\n    if (object.termType === 'NamedNode') {\n      return { '@id': object.value }\n    }\n\n    if (object.termType === 'BlankNode') {\n      return { '@id': '_:' + object.value }\n    }\n\n    if (object.language) {\n      return { '@language': object.language, '@value': object.value }\n    } else if (object.datatype && object.datatype.value !== 'http://www.w3.org/2001/XMLSchema#string') {\n      return { '@type': object.datatype.value, '@value': object.value }\n    } else {\n      return object.value\n    }\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (SerializerStream);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-jsonld/lib/SerializerStream.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-jsonld/lib/StringEncoder.js":
/*!********************************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-jsonld/lib/StringEncoder.js ***!
  \********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass StringEncoder {\n  constructor (stream) {\n    this.stream = stream\n    this.first = true\n\n    this.stream.push('[')\n  }\n\n  push (jsonld) {\n    if (this.first) {\n      this.first = false\n    } else {\n      this.stream.push(',')\n    }\n\n    this.stream.push(JSON.stringify(jsonld))\n  }\n\n  end () {\n    this.stream.push(']')\n    this.stream.push(null)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (StringEncoder);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-jsonld/lib/StringEncoder.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-ntriples/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-ntriples/index.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_sink__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/sink */ \"./node_modules/@rdfjs/sink/index.js\");\n/* harmony import */ var _lib_SerializerStream_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/SerializerStream.js */ \"./node_modules/@rdfjs/serializer-ntriples/lib/SerializerStream.js\");\n\n\n\nclass Serializer extends _rdfjs_sink__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  constructor () {\n    super(_lib_SerializerStream_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Serializer);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-ntriples/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-ntriples/lib/SerializerStream.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-ntriples/lib/SerializerStream.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n/* harmony import */ var duplex_to_readable_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! duplex-to/readable.js */ \"./node_modules/duplex-to/readable.js\");\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n\n\n\n\nclass SerializerStream {\n  constructor (input) {\n    const stream = new readable_stream__WEBPACK_IMPORTED_MODULE_2__.Transform({\n      objectMode: true,\n      transform: (quad, encoding, callback) => {\n        callback(null, `${(0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(quad)}\\n`)\n      }\n    })\n\n    input.pipe(stream)\n\n    return (0,duplex_to_readable_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(stream)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (SerializerStream);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-ntriples/lib/SerializerStream.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-turtle/index.js":
/*!********************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-turtle/index.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_sink__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/sink */ \"./node_modules/@rdfjs/sink/index.js\");\n/* harmony import */ var _lib_SerializerStream_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/SerializerStream.js */ \"./node_modules/@rdfjs/serializer-turtle/lib/SerializerStream.js\");\n/* harmony import */ var _lib_TurtleSerializer_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/TurtleSerializer.js */ \"./node_modules/@rdfjs/serializer-turtle/lib/TurtleSerializer.js\");\n\n\n\n\nclass Serializer extends _rdfjs_sink__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  constructor (options = {}) {\n    // support for legacy option base\n    options.baseIRI = options.baseIRI || options.base\n\n    super(_lib_SerializerStream_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"], options)\n  }\n\n  transform (quads) {\n    return _lib_TurtleSerializer_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].serialize(quads, this.options).join('')\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Serializer);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-turtle/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-turtle/lib/SerializerStream.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-turtle/lib/SerializerStream.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n/* harmony import */ var stream_chunks_chunks_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! stream-chunks/chunks.js */ \"./node_modules/stream-chunks/chunks.js\");\n/* harmony import */ var _TurtleSerializer_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./TurtleSerializer.js */ \"./node_modules/@rdfjs/serializer-turtle/lib/TurtleSerializer.js\");\n\n\n\n\nclass SerializerStream extends readable_stream__WEBPACK_IMPORTED_MODULE_0__.Readable {\n  constructor (input, { baseIRI, prefixes = new Map() } = {}) {\n    super({\n      objectMode: true,\n      read: () => {}\n    })\n\n    this._init(input, { baseIRI, prefixes })\n  }\n\n  async _init (input, { baseIRI, prefixes }) {\n    try {\n      input.on('prefix', (prefix, namespace) => prefixes.set(prefix, namespace))\n\n      const quads = await (0,stream_chunks_chunks_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(input)\n\n      _TurtleSerializer_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].serialize(quads, { baseIRI, output: this, prefixes })\n\n      this.push(null)\n    } catch (err) {\n      this.destroy(err)\n    }\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (SerializerStream);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-turtle/lib/SerializerStream.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-turtle/lib/TermSerializer.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-turtle/lib/TermSerializer.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/term-map */ \"./node_modules/@rdfjs/term-map/TermMap.js\");\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./utils.js */ \"./node_modules/@rdfjs/serializer-turtle/lib/utils.js\");\n\n\n\n\nclass TermSerializer {\n  constructor ({ baseIRI, prefixes }) {\n    this.baseIRI = baseIRI && (baseIRI.value || baseIRI.toString())\n    this.prefixes = prefixes\n\n    this.bnodeIds = new _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n  }\n\n  serialize (term) {\n    if (term.termType === 'BlankNode') {\n      if (!this.bnodeIds.has(term)) {\n        this.bnodeIds.set(term, this.bnodeIds.size + 1)\n      }\n\n      return `_:b${this.bnodeIds.get(term)}`\n    }\n\n    if (term.termType === 'Literal') {\n      if ((0,_utils_js__WEBPACK_IMPORTED_MODULE_2__.isBoolean)(term)) {\n        if (term.value === 'true' || term.value === 'false') {\n          return term.value\n        }\n      } else if ((0,_utils_js__WEBPACK_IMPORTED_MODULE_2__.isDecimal)(term)) {\n        if (/^[+-]?[0-9]*\\.[0-9]+$/.test(term.value)) {\n          return term.value\n        }\n      } else if ((0,_utils_js__WEBPACK_IMPORTED_MODULE_2__.isDouble)(term)) {\n        if (/^[+-]?(?:[0-9]+\\.[0-9]*|\\.?[0-9]+)[eE][+-]?[0-9]+$/.test(term.value)) {\n          return term.value\n        }\n      } else if ((0,_utils_js__WEBPACK_IMPORTED_MODULE_2__.isInteger)(term)) {\n        if (/^[+-]?[0-9]+$/.test(term.value)) {\n          return term.value\n        }\n      } else if (!(0,_utils_js__WEBPACK_IMPORTED_MODULE_2__.isLangString)(term) && !(0,_utils_js__WEBPACK_IMPORTED_MODULE_2__.isString)(term)) {\n        const shrinked = this.prefixes.shrink(term.datatype)\n\n        if (shrinked) {\n          return `\"${term.value}\"^^${shrinked.value}`\n        }\n      }\n    }\n\n    if (term.termType === 'NamedNode') {\n      if (this.baseIRI && term.value.startsWith(this.baseIRI)) {\n        return `<${term.value.slice(this.baseIRI.length)}>`\n      }\n\n      const shrinked = this.prefixes.shrink(term)\n\n      if (shrinked) {\n        return shrinked.value\n      }\n    }\n\n    return (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(term)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (TermSerializer);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-turtle/lib/TermSerializer.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-turtle/lib/TurtleSerializer.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-turtle/lib/TurtleSerializer.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_data_model__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/data-model */ \"./node_modules/@rdfjs/data-model/index.js\");\n/* harmony import */ var _rdfjs_prefix_map__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/prefix-map */ \"./node_modules/@rdfjs/prefix-map/PrefixMap.js\");\n/* harmony import */ var _rdfjs_tree__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @rdfjs/tree */ \"./node_modules/@rdfjs/tree/index.js\");\n/* harmony import */ var _termCompare_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./termCompare.js */ \"./node_modules/@rdfjs/serializer-turtle/lib/termCompare.js\");\n/* harmony import */ var _TermSerializer_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./TermSerializer.js */ \"./node_modules/@rdfjs/serializer-turtle/lib/TermSerializer.js\");\n/* harmony import */ var _utils_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./utils.js */ \"./node_modules/@rdfjs/serializer-turtle/lib/utils.js\");\n\n\n\n\n\n\n\nfunction loop ({ each, filter, items, join }) {\n  let first = true\n\n  for (const item of items) {\n    if (filter && !filter(item)) {\n      continue\n    }\n\n    if (!first) {\n      join()\n    }\n\n    each(item)\n\n    first = false\n  }\n}\n\nclass TurtleSerializer {\n  constructor (quads, { baseIRI, output = [], prefixes } = {}) {\n    this.baseIRI = baseIRI\n    this.output = output\n    this.prefixes = new _rdfjs_prefix_map__WEBPACK_IMPORTED_MODULE_1__[\"default\"](prefixes, { factory: _rdfjs_data_model__WEBPACK_IMPORTED_MODULE_0__[\"default\"] })\n    this.tree = new _rdfjs_tree__WEBPACK_IMPORTED_MODULE_2__[\"default\"](quads)\n\n    this.termSerializer = new _TermSerializer_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]({\n      baseIRI: this.baseIRI,\n      prefixes: this.prefixes\n    })\n  }\n\n  serialize () {\n    this.state = {}\n\n    this.serializeBase()\n    this.serializePrefixes()\n\n    if (this.state.serializedBase || this.state.serializedPrefixes) {\n      this.output.push('\\n')\n    }\n\n    loop({\n      items: [...this.tree.subjects.values()].sort((a, b) => (0,_termCompare_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(a, b)),\n      each: subject => this.serializeSubject(subject),\n      filter: subject => subject.term.termType !== 'BlankNode' || subject.isListValue || subject.refs.length !== 1,\n      join: () => this.output.push('\\n')\n    })\n\n    return this.output\n  }\n\n  serializeBase () {\n    if (!this.baseIRI) {\n      return\n    }\n\n    this.state.serializedBase = true\n\n    this.output.push(`@base <${this.termSerializer.baseIRI}>.\\n`)\n  }\n\n  serializeList (objectNode) {\n    if (!objectNode.items) {\n      return this.output.push('()')\n    }\n\n    this.output.push('(')\n\n    loop({\n      items: objectNode.items,\n      each: node => this.output.push(this.toNT(node.item.term)),\n      join: () => this.output.push(' ')\n    })\n\n    this.output.push(')')\n  }\n\n  serializeObject (objectNode, { isList, level, multiple }) {\n    if (isList && objectNode.refs.length === 1) {\n      return this.serializeList(objectNode, { level })\n    }\n\n    if (objectNode.term.termType === 'BlankNode' && objectNode.refs.length === 1) {\n      if (objectNode.quads.length === 0) {\n        return this.output.push('[]')\n      }\n\n      if (multiple) {\n        this.output.push(' ')\n      }\n\n      this.output.push('[')\n\n      this.serializeTypes(objectNode)\n\n      this.output.push('\\n')\n\n      this.serializePredicates([...objectNode.predicates.values()], { level: level + 2 })\n\n      return this.output.push(`\\n${this.spaces(level + 1)}]`)\n    }\n\n    if (multiple) {\n      this.output.push(`\\n${this.spaces(level + 1)}`)\n    }\n\n    this.output.push(`${this.toNT(objectNode.term)}`)\n  }\n\n  serializeObjects (predicate, { level }) {\n    if (predicate.objects.size === 1) {\n      this.output.push(' ')\n\n      const objectNode = [...predicate.objects.values()][0]\n      const isList = predicate.lists.has(objectNode.term)\n\n      this.serializeObject(objectNode, { isList, level })\n    } else {\n      loop({\n        items: [...predicate.objects.values()].sort((a, b) => (0,_termCompare_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(a, b)),\n        each: objectNode => {\n          const isList = predicate.lists.has(objectNode.term)\n\n          this.serializeObject(objectNode, { isList, level, multiple: true })\n        },\n        join: () => this.output.push(',')\n      })\n    }\n  }\n\n  serializePredicate (predicate, { level }) {\n    this.output.push(this.spaces(level, 1) + this.toNT(predicate.term))\n\n    this.serializeObjects(predicate, { level })\n  }\n\n  serializePredicates (predicates, { level }) {\n    loop({\n      items: predicates.filter(predicate => !predicate.isType).sort((a, b) => (0,_termCompare_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(a, b)),\n      each: predicate => this.serializePredicate(predicate, { level }),\n      join: () => this.output.push(';\\n')\n    })\n  }\n\n  serializePrefixes () {\n    const active = (0,_utils_js__WEBPACK_IMPORTED_MODULE_5__.activeNamespaces)(this.tree, this.prefixes)\n\n    if (active.size === 0) {\n      return\n    }\n\n    this.state.serializedPrefixes = true\n\n    for (const prefix of [...active].sort()) {\n      this.output.push(`@prefix ${prefix}: <${this.prefixes.get(prefix).value}>.\\n`)\n    }\n  }\n\n  serializeSubject (node, { level = 0 } = {}) {\n    const unlabeledBlankNode = node.term.termType === 'BlankNode' && node.refs.length <= 1 && !node.isListValue\n\n    if (unlabeledBlankNode) {\n      this.output.push('[')\n    } else {\n      this.output.push(this.toNT(node.term))\n    }\n\n    this.serializeTypes(node)\n\n    this.output.push('\\n')\n\n    this.serializePredicates([...node.predicates.values()], { level: level + 1 })\n\n    if (unlabeledBlankNode) {\n      this.output.push('\\n]')\n    }\n\n    this.output.push('.\\n')\n  }\n\n  serializeTypes (node) {\n    if (!node.type) {\n      return\n    }\n\n    this.output.push(' a ')\n\n    loop({\n      items: [...node.type.objects.values()].sort((a, b) => (0,_termCompare_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(a, b)),\n      each: type => this.output.push((this.toNT(type.term))),\n      join: () => this.output.push(', ')\n    })\n\n    this.output.push(';')\n  }\n\n  spaces (level) {\n    return ' '.repeat(level * 2)\n  }\n\n  toNT (term) {\n    return this.termSerializer.serialize(term)\n  }\n\n  static serialize (quads, { baseIRI, output, prefixes } = {}) {\n    return new TurtleSerializer(quads, { baseIRI, output, prefixes }).serialize()\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (TurtleSerializer);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-turtle/lib/TurtleSerializer.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-turtle/lib/namespaces.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-turtle/lib/namespaces.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   rdf: () => (/* binding */ rdf),\n/* harmony export */   xsd: () => (/* binding */ xsd)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_namespace__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/namespace */ \"./node_modules/@rdfjs/namespace/index.js\");\n\n\nconst rdf = (0,_rdfjs_namespace__WEBPACK_IMPORTED_MODULE_0__[\"default\"])('http://www.w3.org/1999/02/22-rdf-syntax-ns#')\nconst xsd = (0,_rdfjs_namespace__WEBPACK_IMPORTED_MODULE_0__[\"default\"])('http://www.w3.org/2001/XMLSchema#')\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-turtle/lib/namespaces.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-turtle/lib/termCompare.js":
/*!******************************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-turtle/lib/termCompare.js ***!
  \******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nconst termTypeOrder = ['Literal', 'NamedNode', 'BlankNode']\n\nfunction literalId (term) {\n  return `${term.language || ''}@${term.datatype.value || ''}@${term.value}`\n}\n\nfunction termCompare (a, b) {\n  const indexTypeA = termTypeOrder.indexOf(a.term.termType)\n  const indexTypeB = termTypeOrder.indexOf(b.term.termType)\n\n  const typeCompare = indexTypeA - indexTypeB\n\n  if (typeCompare !== 0) {\n    return typeCompare\n  }\n\n  if (a.term.termType === 'Literal') {\n    const isLangA = a.term.language ? 1 : 0\n    const isLangB = b.term.language ? 1 : 0\n\n    const isLangCompare = isLangB - isLangA\n\n    if (isLangCompare !== 0) {\n      return isLangCompare\n    }\n\n    return literalId(a.term).localeCompare(literalId(b.term))\n  }\n\n  return a.term.value.localeCompare(b.term.value)\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (termCompare);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-turtle/lib/termCompare.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/serializer-turtle/lib/utils.js":
/*!************************************************************!*\
  !*** ./node_modules/@rdfjs/serializer-turtle/lib/utils.js ***!
  \************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   activeNamespaces: () => (/* binding */ activeNamespaces),\n/* harmony export */   isBoolean: () => (/* binding */ isBoolean),\n/* harmony export */   isDecimal: () => (/* binding */ isDecimal),\n/* harmony export */   isDouble: () => (/* binding */ isDouble),\n/* harmony export */   isInteger: () => (/* binding */ isInteger),\n/* harmony export */   isLangString: () => (/* binding */ isLangString),\n/* harmony export */   isString: () => (/* binding */ isString)\n/* harmony export */ });\n/* harmony import */ var _namespaces_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./namespaces.js */ \"./node_modules/@rdfjs/serializer-turtle/lib/namespaces.js\");\n\n\nfunction activeNamespaces (tree, namespaces) {\n  const active = new Set()\n\n  const check = term => {\n    const shrinked = namespaces.shrink(term)\n\n    if (shrinked) {\n      active.add(shrinked.value.split(':')[0])\n    }\n\n    if (term.datatype) {\n      if (\n        !isBoolean(term) &&\n        !isDecimal(term) &&\n        !isDouble(term) &&\n        !isInteger(term) &&\n        !isLangString(term) &&\n        !isString(term)\n      ) {\n        check(term.datatype)\n      }\n    }\n  }\n\n  for (const node of tree.nodes.values()) {\n    check(node.term)\n\n    for (const predicate of node.predicates.keys()) {\n      check(predicate)\n    }\n  }\n\n  return active\n}\n\nfunction isBoolean (term) {\n  return _namespaces_js__WEBPACK_IMPORTED_MODULE_0__.xsd.boolean.equals(term.datatype)\n}\n\nfunction isDecimal (term) {\n  return _namespaces_js__WEBPACK_IMPORTED_MODULE_0__.xsd.decimal.equals(term.datatype)\n}\n\nfunction isDouble (term) {\n  return _namespaces_js__WEBPACK_IMPORTED_MODULE_0__.xsd.double.equals(term.datatype)\n}\n\nfunction isInteger (term) {\n  return _namespaces_js__WEBPACK_IMPORTED_MODULE_0__.xsd.integer.equals(term.datatype)\n}\n\nfunction isLangString (term) {\n  return _namespaces_js__WEBPACK_IMPORTED_MODULE_0__.rdf.langString.equals(term.datatype)\n}\n\nfunction isString (term) {\n  return _namespaces_js__WEBPACK_IMPORTED_MODULE_0__.xsd.string.equals(term.datatype)\n}\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/serializer-turtle/lib/utils.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/sink-map/index.js":
/*!***********************************************!*\
  !*** ./node_modules/@rdfjs/sink-map/index.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass SinkMap extends Map {\n  import (key, input, options) {\n    const parser = this.get(key)\n\n    if (!parser) {\n      return null\n    }\n\n    return parser.import(input, options)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (SinkMap);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/sink-map/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/sink/index.js":
/*!*******************************************!*\
  !*** ./node_modules/@rdfjs/sink/index.js ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass Sink {\n  constructor (Impl, options) {\n    this.Impl = Impl\n    this.options = options\n  }\n\n  import (input, options) {\n    const output = new this.Impl(input, { ...this.options, ...options })\n\n    input.on('end', () => {\n      if (!output.readable) {\n        output.emit('end')\n      }\n    })\n\n    input.on('error', err => {\n      output.emit('error', err)\n    })\n\n    return output\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Sink);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/sink/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/term-map/Factory.js":
/*!*************************************************!*\
  !*** ./node_modules/@rdfjs/term-map/Factory.js ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _TermMap_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TermMap.js */ \"./node_modules/@rdfjs/term-map/TermMap.js\");\n\n\nclass Factory {\n  termMap (entries) {\n    return new _TermMap_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"](entries)\n  }\n}\n\nFactory.exports = ['termMap']\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Factory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/term-map/Factory.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/term-map/TermMap.js":
/*!*************************************************!*\
  !*** ./node_modules/@rdfjs/term-map/TermMap.js ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n\n\nclass TermMap {\n  constructor (entries) {\n    this.index = new Map()\n\n    if (entries) {\n      for (const [term, value] of entries) {\n        this.set(term, value)\n      }\n    }\n  }\n\n  get size () {\n    return this.index.size\n  }\n\n  clear () {\n    this.index.clear()\n  }\n\n  delete (term) {\n    return this.index.delete((0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(term))\n  }\n\n  * entries () {\n    for (const [, { term, value }] of this.index) {\n      yield [term, value]\n    }\n  }\n\n  forEach (callback, thisArg) {\n    for (const entry of this.entries()) {\n      callback.call(thisArg, entry[1], entry[0], this)\n    }\n  }\n\n  get (term) {\n    const item = this.index.get((0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(term))\n\n    return item && item.value\n  }\n\n  has (term) {\n    return this.index.has((0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(term))\n  }\n\n  * keys () {\n    for (const [, { term }] of this.index) {\n      yield term\n    }\n  }\n\n  set (term, value) {\n    const key = (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(term)\n\n    this.index.set(key, { term, value })\n\n    return this\n  }\n\n  * values () {\n    for (const [, { value }] of this.index) {\n      yield value\n    }\n  }\n\n  [Symbol.iterator] () {\n    return this.entries()[Symbol.iterator]()\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (TermMap);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/term-map/TermMap.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/term-set/Factory.js":
/*!*************************************************!*\
  !*** ./node_modules/@rdfjs/term-set/Factory.js ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _TermSet_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TermSet.js */ \"./node_modules/@rdfjs/term-set/TermSet.js\");\n\n\nclass Factory {\n  termSet (terms) {\n    return new _TermSet_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"](terms)\n  }\n}\n\nFactory.exports = ['termSet']\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Factory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/term-set/Factory.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/term-set/TermSet.js":
/*!*************************************************!*\
  !*** ./node_modules/@rdfjs/term-set/TermSet.js ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n\n\nfunction quietToNT (term) {\n  try {\n    return (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(term)\n  } catch (err) {\n    return null\n  }\n}\n\nclass TermSet {\n  constructor (terms) {\n    this.index = new Map()\n\n    if (terms) {\n      for (const term of terms) {\n        this.add(term)\n      }\n    }\n  }\n\n  get size () {\n    return this.index.size\n  }\n\n  add (term) {\n    const key = (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(term)\n\n    if (!this.index.has(key)) {\n      this.index.set(key, term)\n    }\n\n    return this\n  }\n\n  clear () {\n    this.index.clear()\n  }\n\n  delete (term) {\n    if (!term) {\n      return false\n    }\n\n    return this.index.delete(quietToNT(term))\n  }\n\n  entries () {\n    return this.values().entries()\n  }\n\n  forEach (callbackfn, thisArg) {\n    return this.values().forEach(callbackfn, thisArg)\n  }\n\n  has (term) {\n    if (!term) {\n      return false\n    }\n\n    return this.index.has(quietToNT(term))\n  }\n\n  values () {\n    return new Set(this.index.values())\n  }\n\n  keys () {\n    return this.values()\n  }\n\n  [Symbol.iterator] () {\n    return this.index.values()\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (TermSet);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/term-set/TermSet.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/to-ntriples/index.js":
/*!**************************************************!*\
  !*** ./node_modules/@rdfjs/to-ntriples/index.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _lib_blankNode_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/blankNode.js */ \"./node_modules/@rdfjs/to-ntriples/lib/blankNode.js\");\n/* harmony import */ var _lib_dataset_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/dataset.js */ \"./node_modules/@rdfjs/to-ntriples/lib/dataset.js\");\n/* harmony import */ var _lib_defaultGraph_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/defaultGraph.js */ \"./node_modules/@rdfjs/to-ntriples/lib/defaultGraph.js\");\n/* harmony import */ var _lib_literal_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./lib/literal.js */ \"./node_modules/@rdfjs/to-ntriples/lib/literal.js\");\n/* harmony import */ var _lib_namedNode_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./lib/namedNode.js */ \"./node_modules/@rdfjs/to-ntriples/lib/namedNode.js\");\n/* harmony import */ var _lib_quad_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./lib/quad.js */ \"./node_modules/@rdfjs/to-ntriples/lib/quad.js\");\n/* harmony import */ var _lib_variable_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./lib/variable.js */ \"./node_modules/@rdfjs/to-ntriples/lib/variable.js\");\n\n\n\n\n\n\n\n\nfunction toNT (term) {\n  if (!term) {\n    return null\n  }\n\n  if (term.termType === 'BlankNode') {\n    return (0,_lib_blankNode_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(term)\n  }\n\n  if (term.termType === 'DefaultGraph') {\n    return (0,_lib_defaultGraph_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"])()\n  }\n\n  if (term.termType === 'Literal') {\n    return (0,_lib_literal_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(term)\n  }\n\n  if (term.termType === 'NamedNode') {\n    return (0,_lib_namedNode_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(term)\n  }\n\n  // legacy quad support without .termType\n  if (term.termType === 'Quad' || (term.subject && term.predicate && term.object && term.graph)) {\n    return (0,_lib_quad_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"])(term, toNT)\n  }\n\n  if (term.termType === 'Variable') {\n    return (0,_lib_variable_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"])(term)\n  }\n\n  if (term[Symbol.iterator]) {\n    return (0,_lib_dataset_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(term, toNT)\n  }\n\n  throw new Error(`unknown termType ${term.termType}`)\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (toNT);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/to-ntriples/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/to-ntriples/lib/blankNode.js":
/*!**********************************************************!*\
  !*** ./node_modules/@rdfjs/to-ntriples/lib/blankNode.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction blankNode (blankNode) {\n  return '_:' + blankNode.value // TODO: escape special chars\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (blankNode);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/to-ntriples/lib/blankNode.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/to-ntriples/lib/dataset.js":
/*!********************************************************!*\
  !*** ./node_modules/@rdfjs/to-ntriples/lib/dataset.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction dataset (dataset, toNT) {\n  return [...dataset].map(quad => toNT(quad)).join('\\n') + '\\n'\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (dataset);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/to-ntriples/lib/dataset.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/to-ntriples/lib/defaultGraph.js":
/*!*************************************************************!*\
  !*** ./node_modules/@rdfjs/to-ntriples/lib/defaultGraph.js ***!
  \*************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction defaultGraph () {\n  return ''\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (defaultGraph);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/to-ntriples/lib/defaultGraph.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/to-ntriples/lib/literal.js":
/*!********************************************************!*\
  !*** ./node_modules/@rdfjs/to-ntriples/lib/literal.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _namedNode_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./namedNode.js */ \"./node_modules/@rdfjs/to-ntriples/lib/namedNode.js\");\n\n\nconst echarRegEx = /[\"\\\\\\\\\\n\\r]/\nconst echarRegExAll = /[\"\\\\\\\\\\n\\r]/g\n\nconst echarReplacement = {\n  '\"': '\\\\\"',\n  '\\\\': '\\\\\\\\',\n  '\\n': '\\\\n',\n  '\\r': '\\\\r'\n}\n\nfunction echarReplacer (char) {\n  return echarReplacement[char]\n}\n\nfunction escapeValue (value) {\n  if (echarRegEx.test(value)) {\n    return value.replace(echarRegExAll, echarReplacer)\n  }\n\n  return value\n}\n\nfunction literal (literal) {\n  const escapedValue = escapeValue(literal.value)\n\n  if (literal.datatype.value === 'http://www.w3.org/2001/XMLSchema#string') {\n    return '\"' + escapedValue + '\"'\n  }\n\n  if (literal.datatype.value === 'http://www.w3.org/1999/02/22-rdf-syntax-ns#langString') {\n    return '\"' + escapedValue + '\"@' + literal.language\n  }\n\n  return '\"' + escapedValue + '\"^^' + (0,_namedNode_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(literal.datatype)\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (literal);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/to-ntriples/lib/literal.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/to-ntriples/lib/namedNode.js":
/*!**********************************************************!*\
  !*** ./node_modules/@rdfjs/to-ntriples/lib/namedNode.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction namedNode (namedNode) {\n  return '<' + namedNode.value + '>'\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (namedNode);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/to-ntriples/lib/namedNode.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/to-ntriples/lib/quad.js":
/*!*****************************************************!*\
  !*** ./node_modules/@rdfjs/to-ntriples/lib/quad.js ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction quad (quad, toNT) {\n  const subjectString = toNT(quad.subject)\n  const predicateString = toNT(quad.predicate)\n  const objectString = toNT(quad.object)\n  const graphString = toNT(quad.graph)\n\n  return `${subjectString} ${predicateString} ${objectString} ${graphString ? graphString + ' ' : ''}.`\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (quad);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/to-ntriples/lib/quad.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/to-ntriples/lib/variable.js":
/*!*********************************************************!*\
  !*** ./node_modules/@rdfjs/to-ntriples/lib/variable.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction variable (variable) {\n  return '?' + variable.value\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (variable);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/to-ntriples/lib/variable.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/traverser/Factory.js":
/*!**************************************************!*\
  !*** ./node_modules/@rdfjs/traverser/Factory.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _Traverser_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Traverser.js */ \"./node_modules/@rdfjs/traverser/Traverser.js\");\n\n\nclass Factory {\n  traverser (filter, { backward = false, forward = true } = {}) {\n    return new _Traverser_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"](filter, { backward, factory: this, forward })\n  }\n}\n\nFactory.exports = ['traverser']\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Factory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/traverser/Factory.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/traverser/Traverser.js":
/*!****************************************************!*\
  !*** ./node_modules/@rdfjs/traverser/Traverser.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n\n\nclass Visisted {\n  constructor () {\n    this.quadLevel = new Map()\n  }\n\n  add (quad, level) {\n    this.quadLevel.set((0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(quad), level)\n  }\n\n  has (quad, level) {\n    const seenAt = this.quadLevel.get((0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(quad))\n\n    if (seenAt === undefined) {\n      return false\n    }\n\n    return seenAt <= level\n  }\n}\n\nfunction forEach ({ backward, callback, dataset, filter, forward, term, visited = new Visisted() }) {\n  const next = (term, level) => {\n    const checkMatches = matches => {\n      for (const quad of matches) {\n        if (visited.has(quad, level)) {\n          continue\n        }\n\n        visited.add(quad, level)\n\n        const args = { dataset, level, quad }\n\n        if (filter(args)) {\n          callback(args)\n\n          if (forward) {\n            next(quad.object, level + 1)\n          }\n\n          if (backward) {\n            next(quad.subject, level + 1)\n          }\n        }\n      }\n    }\n\n    if (forward) {\n      checkMatches(dataset.match(term))\n    }\n\n    if (backward) {\n      checkMatches(dataset.match(null, null, term))\n    }\n  }\n\n  next(term, 0)\n}\n\nclass Traverser {\n  constructor (filter, { backward = false, factory, forward = true }) {\n    this.backward = backward\n    this.factory = factory\n    this.filter = filter\n    this.forward = forward\n  }\n\n  forEach ({ term, dataset }, callback) {\n    forEach({\n      backward: this.backward,\n      callback,\n      dataset,\n      filter: this.filter,\n      forward: this.forward,\n      term\n    })\n  }\n\n  match ({ term, dataset }) {\n    const result = this.factory.dataset()\n\n    forEach({\n      backward: this.backward,\n      callback: ({ quad }) => result.add(quad),\n      dataset,\n      filter: this.filter,\n      forward: this.forward,\n      term\n    })\n\n    return result\n  }\n\n  reduce ({ term, dataset }, callback, initialValue) {\n    let result = initialValue\n\n    forEach({\n      backward: this.backward,\n      callback: args => {\n        result = callback(args, result)\n      },\n      dataset,\n      filter: this.filter,\n      forward: this.forward,\n      term\n    })\n\n    return result\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Traverser);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/traverser/Traverser.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/tree/index.js":
/*!*******************************************!*\
  !*** ./node_modules/@rdfjs/tree/index.js ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _lib_Tree_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/Tree.js */ \"./node_modules/@rdfjs/tree/lib/Tree.js\");\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (_lib_Tree_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/tree/index.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/tree/lib/Node.js":
/*!**********************************************!*\
  !*** ./node_modules/@rdfjs/tree/lib/Node.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/term-map */ \"./node_modules/@rdfjs/term-map/TermMap.js\");\n/* harmony import */ var _namespaces_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./namespaces.js */ \"./node_modules/@rdfjs/tree/lib/namespaces.js\");\n\n\n\nclass Node {\n  constructor ({ isObject = false, isSubject = false, term, tree } = {}) {\n    this.items = null\n    this.isListItem = false\n    this.isListValue = false\n    this.predicates = new _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n    this.quads = []\n    this.refs = []\n    this.term = term\n    this.tree = tree\n    this.type = null\n\n    if (this.tree && this.term) {\n      if (this.term) {\n        this.tree.nodes.set(this.term, this)\n      }\n    }\n\n    this.isObject = isObject\n    this.isSubject = isSubject\n  }\n\n  get isObject () {\n    return this._isObject\n  }\n\n  set isObject (value) {\n    if (value) {\n      this._isObject = true\n\n      if (this.tree) {\n        this.tree.objects.set(this.term, this)\n      }\n    } else {\n      this._isObject = false\n\n      if (this.tree) {\n        this.tree.objects.delete(this.term)\n      }\n    }\n  }\n\n  get isSubject () {\n    return this._isSubject\n  }\n\n  set isSubject (value) {\n    if (value) {\n      this._isSubject = true\n\n      if (this.tree) {\n        this.tree.subjects.set(this.term, this)\n      }\n    } else {\n      this._isSubject = false\n\n      if (this.tree) {\n        this.tree.subjects.delete(this.term)\n      }\n    }\n  }\n\n  get item () {\n    const predicate = this.predicates.get(_namespaces_js__WEBPACK_IMPORTED_MODULE_1__.rdf.first)\n\n    if (!predicate || predicate.objects.size !== 1) {\n      return undefined\n    }\n\n    return [...predicate.objects.values()][0]\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Node);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/tree/lib/Node.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/tree/lib/Parser.js":
/*!************************************************!*\
  !*** ./node_modules/@rdfjs/tree/lib/Parser.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/term-map */ \"./node_modules/@rdfjs/term-map/TermMap.js\");\n/* harmony import */ var _rdfjs_term_set__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/term-set */ \"./node_modules/@rdfjs/term-set/TermSet.js\");\n/* harmony import */ var _namespaces_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./namespaces.js */ \"./node_modules/@rdfjs/tree/lib/namespaces.js\");\n/* harmony import */ var _Node_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Node.js */ \"./node_modules/@rdfjs/tree/lib/Node.js\");\n/* harmony import */ var _Predicate_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Predicate.js */ \"./node_modules/@rdfjs/tree/lib/Predicate.js\");\n\n\n\n\n\n\nclass Parser {\n  constructor (tree) {\n    this.tree = tree\n    this.listItems = new _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n    this.listItemsSeen = new _rdfjs_term_set__WEBPACK_IMPORTED_MODULE_1__[\"default\"]()\n    this.listValues = new _rdfjs_term_set__WEBPACK_IMPORTED_MODULE_1__[\"default\"]()\n  }\n\n  _findListItems (node) {\n    const list = []\n\n    do {\n      this.listItemsSeen.add(node.term)\n      list.push(node)\n      node = this._findNextItem(node)\n    } while (node)\n\n    return list\n  }\n\n  _findNextItem (node) {\n    const rests = node.predicates.get(_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.rest)\n\n    if (!rests || rests.objects.size !== 1) {\n      return null\n    }\n\n    const rest = [...rests.objects.values()][0]\n\n    if (!_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.nil.equals(rest.term)) {\n      return rest\n    }\n\n    return null\n  }\n\n  _findPreviousItem (node) {\n    const refs = node.refs.filter(ref => ref.quads.some(quad => quad.object.equals(node.term)))\n\n    if (refs.length === 1 && refs[0].isListItem) {\n      return this.tree.nodes.get(refs[0].term)\n    }\n\n    return null\n  }\n\n  _findRootItem (node) {\n    while (node.isListItem) {\n      this.listItemsSeen.add(node.term)\n\n      const previous = this._findPreviousItem(node)\n\n      if (!previous) {\n        return node\n      }\n\n      node = previous\n    }\n\n    return null\n  }\n\n  _addQuadNode (node, quad) {\n    node.isSubject = true\n    node.quads.push(quad)\n\n    let object\n\n    if (!this.tree.nodes.has(quad.object)) {\n      object = new _Node_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]({\n        isObject: true,\n        term: quad.object,\n        tree: this.tree\n      })\n\n      this.tree.nodes.set(quad.object, object)\n    } else {\n      object = this.tree.nodes.get(quad.object)\n    }\n\n    object.refs.push(node)\n\n    let predicate\n\n    if (!node.predicates.has(quad.predicate)) {\n      predicate = new _Predicate_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]({\n        objects: [[quad.object, object]],\n        quads: [quad],\n        term: quad.predicate\n      })\n\n      node.predicates.set(quad.predicate, predicate)\n\n      if (predicate.isType) {\n        node.type = predicate\n      }\n    } else {\n      predicate = node.predicates.get(quad.predicate)\n\n      predicate.objects.set(quad.object, object)\n      predicate.quads.push(quad)\n    }\n\n    if (quad.predicate.equals(_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.first) || quad.predicate.equals(_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.rest)) {\n      node.isListItem = true\n\n      if (quad.predicate.equals(_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.first)) {\n        this.listValues.add(quad.object)\n      }\n\n      this.listItems.set(node.term, node)\n    } else if (quad.object.equals(_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.nil)) {\n      predicate.lists.add(quad.object)\n    }\n  }\n\n  addQuad (quad) {\n    let subject\n\n    if (!this.tree.nodes.has(quad.subject)) {\n      subject = new _Node_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]({\n        isSubject: true,\n        term: quad.subject,\n        tree: this.tree\n      })\n    } else {\n      subject = this.tree.nodes.get(quad.subject)\n    }\n\n    this._addQuadNode(subject, quad)\n  }\n\n  addQuads (quads) {\n    for (const quad of quads) {\n      this.addQuad(quad)\n    }\n  }\n\n  flush () {\n    for (const listItem of this.listItems.values()) {\n      if (this.listItemsSeen.has(listItem.term)) {\n        continue\n      }\n\n      const root = this._findRootItem(listItem)\n\n      if (root) {\n        for (const ref of root.refs) {\n          for (const predicate of ref.predicates.values()) {\n            if (predicate.objects.has(root.term)) {\n              predicate.lists.add(root.term)\n            }\n          }\n        }\n\n        root.items = this._findListItems(root)\n      }\n    }\n\n    for (const term of this.listValues.values()) {\n      this.tree.nodes.get(term).isListValue = true\n    }\n  }\n\n  parse (quads) {\n    this.addQuads(quads)\n    this.flush()\n\n    return this.tree\n  }\n\n  static parse (tree, quads) {\n    return (new Parser(tree)).parse(quads)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Parser);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/tree/lib/Parser.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/tree/lib/Predicate.js":
/*!***************************************************!*\
  !*** ./node_modules/@rdfjs/tree/lib/Predicate.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/term-map */ \"./node_modules/@rdfjs/term-map/TermMap.js\");\n/* harmony import */ var _rdfjs_term_set__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/term-set */ \"./node_modules/@rdfjs/term-set/TermSet.js\");\n/* harmony import */ var _namespaces_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./namespaces.js */ \"./node_modules/@rdfjs/tree/lib/namespaces.js\");\n\n\n\n\nclass Predicate {\n  constructor ({ objects, quads, term }) {\n    this.isType = _namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.type.equals(term)\n    this.lists = new _rdfjs_term_set__WEBPACK_IMPORTED_MODULE_1__[\"default\"]()\n    this.objects = new _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"](objects)\n    this.quads = quads\n    this.term = term\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Predicate);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/tree/lib/Predicate.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/tree/lib/Tree.js":
/*!**********************************************!*\
  !*** ./node_modules/@rdfjs/tree/lib/Tree.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/term-map */ \"./node_modules/@rdfjs/term-map/TermMap.js\");\n/* harmony import */ var _Parser_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Parser.js */ \"./node_modules/@rdfjs/tree/lib/Parser.js\");\n\n\n\nclass Tree {\n  constructor (quads) {\n    this.nodes = new _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n    this.objects = new _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n    this.subjects = new _rdfjs_term_map__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n    this.parser = new _Parser_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"](this)\n\n    if (quads) {\n      this.parser.parse(quads)\n    }\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Tree);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/tree/lib/Tree.js?");

/***/ }),

/***/ "./node_modules/@rdfjs/tree/lib/namespaces.js":
/*!****************************************************!*\
  !*** ./node_modules/@rdfjs/tree/lib/namespaces.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   rdf: () => (/* binding */ rdf)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_namespace__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/namespace */ \"./node_modules/@rdfjs/namespace/index.js\");\n\n\nconst rdf = (0,_rdfjs_namespace__WEBPACK_IMPORTED_MODULE_0__[\"default\"])('http://www.w3.org/1999/02/22-rdf-syntax-ns#')\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/@rdfjs/tree/lib/namespaces.js?");

/***/ }),

/***/ "./src/browser-entry.js":
/*!******************************!*\
  !*** ./src/browser-entry.js ***!
  \******************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _public_extractor_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./public/extractor.js */ \"./src/public/extractor.js\");\n\nvar FormAMatic = {\n  extract: _public_extractor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]\n};\nif (typeof window !== 'undefined') {\n  window.FormAMatic = FormAMatic;\n  window.extract = _public_extractor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"];\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (FormAMatic);\n\n//# sourceURL=webpack://FormAMatic/./src/browser-entry.js?");

/***/ }),

/***/ "./src/public/extractor.js":
/*!*********************************!*\
  !*** ./src/public/extractor.js ***!
  \*********************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DatasetBuilder: () => (/* binding */ DatasetBuilder),\n/* harmony export */   FormDataExtractor: () => (/* binding */ FormDataExtractor),\n/* harmony export */   RDFExtractor: () => (/* binding */ RDFExtractor),\n/* harmony export */   RDFNodeCreator: () => (/* binding */ RDFNodeCreator),\n/* harmony export */   TurtleSerializer: () => (/* binding */ TurtleSerializer),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var rdf_ext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! rdf-ext */ \"./node_modules/rdf-ext/index.js\");\n/* harmony import */ var _rdfjs_parser_n3__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/parser-n3 */ \"./node_modules/@rdfjs/parser-n3/index.js\");\n/* harmony import */ var _rdfjs_formats_pretty_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @rdfjs/formats/pretty.js */ \"./node_modules/@rdfjs/formats/pretty.js\");\n/* harmony import */ var _rdfjs_serializer_turtle__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @rdfjs/serializer-turtle */ \"./node_modules/@rdfjs/serializer-turtle/index.js\");\nfunction _typeof(o) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o; }, _typeof(o); }\nfunction _regeneratorRuntime() { \"use strict\"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return e; }; var t, e = {}, r = Object.prototype, n = r.hasOwnProperty, o = Object.defineProperty || function (t, e, r) { t[e] = r.value; }, i = \"function\" == typeof Symbol ? Symbol : {}, a = i.iterator || \"@@iterator\", c = i.asyncIterator || \"@@asyncIterator\", u = i.toStringTag || \"@@toStringTag\"; function define(t, e, r) { return Object.defineProperty(t, e, { value: r, enumerable: !0, configurable: !0, writable: !0 }), t[e]; } try { define({}, \"\"); } catch (t) { define = function define(t, e, r) { return t[e] = r; }; } function wrap(t, e, r, n) { var i = e && e.prototype instanceof Generator ? e : Generator, a = Object.create(i.prototype), c = new Context(n || []); return o(a, \"_invoke\", { value: makeInvokeMethod(t, r, c) }), a; } function tryCatch(t, e, r) { try { return { type: \"normal\", arg: t.call(e, r) }; } catch (t) { return { type: \"throw\", arg: t }; } } e.wrap = wrap; var h = \"suspendedStart\", l = \"suspendedYield\", f = \"executing\", s = \"completed\", y = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var p = {}; define(p, a, function () { return this; }); var d = Object.getPrototypeOf, v = d && d(d(values([]))); v && v !== r && n.call(v, a) && (p = v); var g = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(p); function defineIteratorMethods(t) { [\"next\", \"throw\", \"return\"].forEach(function (e) { define(t, e, function (t) { return this._invoke(e, t); }); }); } function AsyncIterator(t, e) { function invoke(r, o, i, a) { var c = tryCatch(t[r], t, o); if (\"throw\" !== c.type) { var u = c.arg, h = u.value; return h && \"object\" == _typeof(h) && n.call(h, \"__await\") ? e.resolve(h.__await).then(function (t) { invoke(\"next\", t, i, a); }, function (t) { invoke(\"throw\", t, i, a); }) : e.resolve(h).then(function (t) { u.value = t, i(u); }, function (t) { return invoke(\"throw\", t, i, a); }); } a(c.arg); } var r; o(this, \"_invoke\", { value: function value(t, n) { function callInvokeWithMethodAndArg() { return new e(function (e, r) { invoke(t, n, e, r); }); } return r = r ? r.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); } }); } function makeInvokeMethod(e, r, n) { var o = h; return function (i, a) { if (o === f) throw Error(\"Generator is already running\"); if (o === s) { if (\"throw\" === i) throw a; return { value: t, done: !0 }; } for (n.method = i, n.arg = a;;) { var c = n.delegate; if (c) { var u = maybeInvokeDelegate(c, n); if (u) { if (u === y) continue; return u; } } if (\"next\" === n.method) n.sent = n._sent = n.arg;else if (\"throw\" === n.method) { if (o === h) throw o = s, n.arg; n.dispatchException(n.arg); } else \"return\" === n.method && n.abrupt(\"return\", n.arg); o = f; var p = tryCatch(e, r, n); if (\"normal\" === p.type) { if (o = n.done ? s : l, p.arg === y) continue; return { value: p.arg, done: n.done }; } \"throw\" === p.type && (o = s, n.method = \"throw\", n.arg = p.arg); } }; } function maybeInvokeDelegate(e, r) { var n = r.method, o = e.iterator[n]; if (o === t) return r.delegate = null, \"throw\" === n && e.iterator[\"return\"] && (r.method = \"return\", r.arg = t, maybeInvokeDelegate(e, r), \"throw\" === r.method) || \"return\" !== n && (r.method = \"throw\", r.arg = new TypeError(\"The iterator does not provide a '\" + n + \"' method\")), y; var i = tryCatch(o, e.iterator, r.arg); if (\"throw\" === i.type) return r.method = \"throw\", r.arg = i.arg, r.delegate = null, y; var a = i.arg; return a ? a.done ? (r[e.resultName] = a.value, r.next = e.nextLoc, \"return\" !== r.method && (r.method = \"next\", r.arg = t), r.delegate = null, y) : a : (r.method = \"throw\", r.arg = new TypeError(\"iterator result is not an object\"), r.delegate = null, y); } function pushTryEntry(t) { var e = { tryLoc: t[0] }; 1 in t && (e.catchLoc = t[1]), 2 in t && (e.finallyLoc = t[2], e.afterLoc = t[3]), this.tryEntries.push(e); } function resetTryEntry(t) { var e = t.completion || {}; e.type = \"normal\", delete e.arg, t.completion = e; } function Context(t) { this.tryEntries = [{ tryLoc: \"root\" }], t.forEach(pushTryEntry, this), this.reset(!0); } function values(e) { if (e || \"\" === e) { var r = e[a]; if (r) return r.call(e); if (\"function\" == typeof e.next) return e; if (!isNaN(e.length)) { var o = -1, i = function next() { for (; ++o < e.length;) if (n.call(e, o)) return next.value = e[o], next.done = !1, next; return next.value = t, next.done = !0, next; }; return i.next = i; } } throw new TypeError(_typeof(e) + \" is not iterable\"); } return GeneratorFunction.prototype = GeneratorFunctionPrototype, o(g, \"constructor\", { value: GeneratorFunctionPrototype, configurable: !0 }), o(GeneratorFunctionPrototype, \"constructor\", { value: GeneratorFunction, configurable: !0 }), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, u, \"GeneratorFunction\"), e.isGeneratorFunction = function (t) { var e = \"function\" == typeof t && t.constructor; return !!e && (e === GeneratorFunction || \"GeneratorFunction\" === (e.displayName || e.name)); }, e.mark = function (t) { return Object.setPrototypeOf ? Object.setPrototypeOf(t, GeneratorFunctionPrototype) : (t.__proto__ = GeneratorFunctionPrototype, define(t, u, \"GeneratorFunction\")), t.prototype = Object.create(g), t; }, e.awrap = function (t) { return { __await: t }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, c, function () { return this; }), e.AsyncIterator = AsyncIterator, e.async = function (t, r, n, o, i) { void 0 === i && (i = Promise); var a = new AsyncIterator(wrap(t, r, n, o), i); return e.isGeneratorFunction(r) ? a : a.next().then(function (t) { return t.done ? t.value : a.next(); }); }, defineIteratorMethods(g), define(g, u, \"Generator\"), define(g, a, function () { return this; }), define(g, \"toString\", function () { return \"[object Generator]\"; }), e.keys = function (t) { var e = Object(t), r = []; for (var n in e) r.push(n); return r.reverse(), function next() { for (; r.length;) { var t = r.pop(); if (t in e) return next.value = t, next.done = !1, next; } return next.done = !0, next; }; }, e.values = values, Context.prototype = { constructor: Context, reset: function reset(e) { if (this.prev = 0, this.next = 0, this.sent = this._sent = t, this.done = !1, this.delegate = null, this.method = \"next\", this.arg = t, this.tryEntries.forEach(resetTryEntry), !e) for (var r in this) \"t\" === r.charAt(0) && n.call(this, r) && !isNaN(+r.slice(1)) && (this[r] = t); }, stop: function stop() { this.done = !0; var t = this.tryEntries[0].completion; if (\"throw\" === t.type) throw t.arg; return this.rval; }, dispatchException: function dispatchException(e) { if (this.done) throw e; var r = this; function handle(n, o) { return a.type = \"throw\", a.arg = e, r.next = n, o && (r.method = \"next\", r.arg = t), !!o; } for (var o = this.tryEntries.length - 1; o >= 0; --o) { var i = this.tryEntries[o], a = i.completion; if (\"root\" === i.tryLoc) return handle(\"end\"); if (i.tryLoc <= this.prev) { var c = n.call(i, \"catchLoc\"), u = n.call(i, \"finallyLoc\"); if (c && u) { if (this.prev < i.catchLoc) return handle(i.catchLoc, !0); if (this.prev < i.finallyLoc) return handle(i.finallyLoc); } else if (c) { if (this.prev < i.catchLoc) return handle(i.catchLoc, !0); } else { if (!u) throw Error(\"try statement without catch or finally\"); if (this.prev < i.finallyLoc) return handle(i.finallyLoc); } } } }, abrupt: function abrupt(t, e) { for (var r = this.tryEntries.length - 1; r >= 0; --r) { var o = this.tryEntries[r]; if (o.tryLoc <= this.prev && n.call(o, \"finallyLoc\") && this.prev < o.finallyLoc) { var i = o; break; } } i && (\"break\" === t || \"continue\" === t) && i.tryLoc <= e && e <= i.finallyLoc && (i = null); var a = i ? i.completion : {}; return a.type = t, a.arg = e, i ? (this.method = \"next\", this.next = i.finallyLoc, y) : this.complete(a); }, complete: function complete(t, e) { if (\"throw\" === t.type) throw t.arg; return \"break\" === t.type || \"continue\" === t.type ? this.next = t.arg : \"return\" === t.type ? (this.rval = this.arg = t.arg, this.method = \"return\", this.next = \"end\") : \"normal\" === t.type && e && (this.next = e), y; }, finish: function finish(t) { for (var e = this.tryEntries.length - 1; e >= 0; --e) { var r = this.tryEntries[e]; if (r.finallyLoc === t) return this.complete(r.completion, r.afterLoc), resetTryEntry(r), y; } }, \"catch\": function _catch(t) { for (var e = this.tryEntries.length - 1; e >= 0; --e) { var r = this.tryEntries[e]; if (r.tryLoc === t) { var n = r.completion; if (\"throw\" === n.type) { var o = n.arg; resetTryEntry(r); } return o; } } throw Error(\"illegal catch attempt\"); }, delegateYield: function delegateYield(e, r, n) { return this.delegate = { iterator: values(e), resultName: r, nextLoc: n }, \"next\" === this.method && (this.arg = t), y; } }, e; }\nfunction asyncGeneratorStep(n, t, e, r, o, a, c) { try { var i = n[a](c), u = i.value; } catch (n) { return void e(n); } i.done ? t(u) : Promise.resolve(u).then(r, o); }\nfunction _asyncToGenerator(n) { return function () { var t = this, e = arguments; return new Promise(function (r, o) { var a = n.apply(t, e); function _next(n) { asyncGeneratorStep(a, r, o, _next, _throw, \"next\", n); } function _throw(n) { asyncGeneratorStep(a, r, o, _next, _throw, \"throw\", n); } _next(void 0); }); }; }\nfunction _createForOfIteratorHelper(r, e) { var t = \"undefined\" != typeof Symbol && r[Symbol.iterator] || r[\"@@iterator\"]; if (!t) { if (Array.isArray(r) || (t = _unsupportedIterableToArray(r)) || e && r && \"number\" == typeof r.length) { t && (r = t); var _n = 0, F = function F() {}; return { s: F, n: function n() { return _n >= r.length ? { done: !0 } : { done: !1, value: r[_n++] }; }, e: function e(r) { throw r; }, f: F }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } var o, a = !0, u = !1; return { s: function s() { t = t.call(r); }, n: function n() { var r = t.next(); return a = r.done, r; }, e: function e(r) { u = !0, o = r; }, f: function f() { try { a || null == t[\"return\"] || t[\"return\"](); } finally { if (u) throw o; } } }; }\nfunction _unsupportedIterableToArray(r, a) { if (r) { if (\"string\" == typeof r) return _arrayLikeToArray(r, a); var t = {}.toString.call(r).slice(8, -1); return \"Object\" === t && r.constructor && (t = r.constructor.name), \"Map\" === t || \"Set\" === t ? Array.from(r) : \"Arguments\" === t || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t) ? _arrayLikeToArray(r, a) : void 0; } }\nfunction _arrayLikeToArray(r, a) { (null == a || a > r.length) && (a = r.length); for (var e = 0, n = Array(a); e < a; e++) n[e] = r[e]; return n; }\nfunction _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError(\"Cannot call a class as a function\"); }\nfunction _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, \"value\" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }\nfunction _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, \"prototype\", { writable: !1 }), e; }\nfunction _toPropertyKey(t) { var i = _toPrimitive(t, \"string\"); return \"symbol\" == _typeof(i) ? i : i + \"\"; }\nfunction _toPrimitive(t, r) { if (\"object\" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || \"default\"); if (\"object\" != _typeof(i)) return i; throw new TypeError(\"@@toPrimitive must return a primitive value.\"); } return (\"string\" === r ? String : Number)(t); }\n\n\n\n\n/*\n/home/danny/github-other/rdf-ext/rdf-ext-examples/examples/browser/io-dataset.js\n*/\nvar RDFNodeCreator = /*#__PURE__*/function () {\n  function RDFNodeCreator(rdf) {\n    _classCallCheck(this, RDFNodeCreator);\n    this.rdf = rdf;\n  }\n  return _createClass(RDFNodeCreator, [{\n    key: \"createNode\",\n    value: function createNode(item) {\n      console.log('Creating node for item:', item);\n      var node;\n      if (item.type === 'LITERAL') {\n        node = this.rdf.literal(item.value);\n      } else if (item.type === 'URI') {\n        node = this.rdf.namedNode(item.value);\n      } else {\n        node = this.rdf.blankNode();\n      }\n      console.log('Created node:', node.toString());\n      return node;\n    }\n  }]);\n}();\nvar DatasetBuilder = /*#__PURE__*/function () {\n  function DatasetBuilder(rdf, nodeCreator) {\n    _classCallCheck(this, DatasetBuilder);\n    this.rdf = rdf;\n    this.nodeCreator = nodeCreator;\n  }\n  return _createClass(DatasetBuilder, [{\n    key: \"build\",\n    value: function build(data) {\n      var _this = this;\n      var parentSubject = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n      var dataset = this.rdf.dataset();\n      var subject = parentSubject || this.rdf.blankNode();\n      data.forEach(function (item) {\n        var predicate = _this.rdf.namedNode(item.namespace + item.term);\n        var object = _this.nodeCreator.createNode(item);\n        var quad = _this.rdf.quad(subject, predicate, object);\n        console.log('Adding quad:', quad.toString());\n        dataset.add(quad);\n      });\n      return dataset;\n    }\n  }]);\n}();\nvar FormDataExtractor = /*#__PURE__*/function () {\n  function FormDataExtractor() {\n    _classCallCheck(this, FormDataExtractor);\n  }\n  return _createClass(FormDataExtractor, [{\n    key: \"extract\",\n    value: function extract(form) {\n      var _this2 = this;\n      var elements = form.querySelectorAll('input, textarea');\n      console.log('Found form elements:', elements);\n      var data = Array.from(elements).map(function (element) {\n        return _this2.extractElementData(element);\n      });\n      console.log('Extracted form data:', data);\n      return this.groupData(data);\n    }\n  }, {\n    key: \"extractElementData\",\n    value: function extractElementData(element) {\n      var data = this.extractDataAttributes(element);\n      data.value = element.value;\n      data.type = element.type === 'number' ? 'LITERAL' : 'LITERAL'; // You might want to add more specific type handling here\n      console.log('Extracted element data:', data);\n      return data;\n    }\n  }, {\n    key: \"extractDataAttributes\",\n    value: function extractDataAttributes(element) {\n      console.log(\"element = \" + element);\n      var data = {};\n      var _iterator = _createForOfIteratorHelper(element.attributes),\n        _step;\n      try {\n        for (_iterator.s(); !(_step = _iterator.n()).done;) {\n          var attr = _step.value;\n          if (attr.name.startsWith('data-')) {\n            var key = attr.name.slice(5);\n            console.log(\"key = \" + key);\n            console.log(\"attr.value = \" + attr.value);\n            data[key] = attr.value;\n          }\n        }\n      } catch (err) {\n        _iterator.e(err);\n      } finally {\n        _iterator.f();\n      }\n      return data;\n    }\n  }, {\n    key: \"parseAttributeValue\",\n    value: function parseAttributeValue(value) {\n      try {\n        return JSON.parse(value);\n      } catch (_unused) {\n        return value;\n      }\n    }\n  }, {\n    key: \"extractFieldsetEntries\",\n    value: function extractFieldsetEntries(fieldset) {\n      var _this3 = this;\n      return Array.from(fieldset.querySelectorAll('.nested-entry')).map(function (entry) {\n        var entryData = {};\n        entry.querySelectorAll('input, textarea').forEach(function (input) {\n          var inputData = _this3.extractElementData(input);\n          entryData[inputData.term] = inputData;\n        });\n        return entryData;\n      });\n    }\n  }, {\n    key: \"groupData\",\n    value: function groupData(data) {\n      return data.reduce(function (acc, item) {\n        if (item.children) {\n          var parentIndex = acc.findIndex(function (d) {\n            return d.term === item.term;\n          });\n          if (parentIndex !== -1) {\n            acc[parentIndex].children = item.children;\n          } else {\n            acc.push(item);\n          }\n        } else {\n          acc.push(item);\n        }\n        return acc;\n      }, []);\n    }\n  }]);\n}();\n\nvar TurtleSerializer = /*#__PURE__*/function () {\n  function TurtleSerializer() {\n    _classCallCheck(this, TurtleSerializer);\n  }\n  return _createClass(TurtleSerializer, [{\n    key: \"serialize\",\n    value: function () {\n      var _serialize = _asyncToGenerator(/*#__PURE__*/_regeneratorRuntime().mark(function _callee(dataset) {\n        var rdfPretty, ttl;\n        return _regeneratorRuntime().wrap(function _callee$(_context) {\n          while (1) switch (_context.prev = _context.next) {\n            case 0:\n              /*\n              const serializer = new Serializer()\n              const output = serializer.import(dataset.stream)\n               output.pipe(process.stdout)\n              */\n              /////////////////////////////////////////////////////////\n              // clone the default environment\n              rdfPretty = rdf_ext__WEBPACK_IMPORTED_MODULE_0__[\"default\"].clone(); // import pretty print serializers\n              rdfPretty.formats[\"import\"](_rdfjs_formats_pretty_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]);\n              _context.next = 4;\n              return rdfPretty.io.dataset.toText('text/turtle', dataset);\n            case 4:\n              ttl = _context.sent;\n              console.log('**********************');\n              // console.log(ttl)\n              console.log('**********************');\n              return _context.abrupt(\"return\", ttl);\n            case 8:\n            case \"end\":\n              return _context.stop();\n          }\n        }, _callee);\n      }));\n      function serialize(_x) {\n        return _serialize.apply(this, arguments);\n      }\n      return serialize;\n    }()\n  }, {\n    key: \"serializeQuad\",\n    value: function serializeQuad(quad) {\n      return \"\".concat(this.serializeTerm(quad.subject), \" \").concat(this.serializeTerm(quad.predicate), \" \").concat(this.serializeTerm(quad.object), \" .\");\n    }\n  }, {\n    key: \"serializeTerm\",\n    value: function serializeTerm(term) {\n      if (term.termType === 'NamedNode') {\n        return \"<\".concat(term.value, \">\");\n      } else if (term.termType === 'BlankNode') {\n        return \"_:\".concat(term.value);\n      } else if (term.termType === 'Literal') {\n        return \"\\\"\".concat(term.value, \"\\\"\");\n      }\n    }\n  }]);\n}();\nvar RDFExtractor = /*#__PURE__*/function () {\n  function RDFExtractor(rdf, N3Writer) {\n    _classCallCheck(this, RDFExtractor);\n    this.rdf = rdf;\n    this.formDataExtractor = new FormDataExtractor();\n    this.nodeCreator = new RDFNodeCreator(rdf);\n    this.datasetBuilder = new DatasetBuilder(rdf, this.nodeCreator);\n    this.turtleSerializer = new TurtleSerializer();\n  }\n  return _createClass(RDFExtractor, [{\n    key: \"extract\",\n    value: function () {\n      var _extract = _asyncToGenerator(/*#__PURE__*/_regeneratorRuntime().mark(function _callee2(document) {\n        var form, data, dataset, serialized;\n        return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n          while (1) switch (_context2.prev = _context2.next) {\n            case 0:\n              console.log('Extract called');\n              _context2.prev = 1;\n              form = document.querySelector('form');\n              console.log('Form found:', form);\n              data = this.formDataExtractor.extract(form);\n              console.log('Extracted data:', data);\n              dataset = this.datasetBuilder.build(data);\n              console.log('Built dataset:', dataset);\n              _context2.next = 10;\n              return this.turtleSerializer.serialize(dataset);\n            case 10:\n              serialized = _context2.sent;\n              console.log('Serialized data:', serialized);\n              return _context2.abrupt(\"return\", serialized);\n            case 15:\n              _context2.prev = 15;\n              _context2.t0 = _context2[\"catch\"](1);\n              console.error('Extraction failed:', _context2.t0);\n              throw _context2.t0;\n            case 19:\n            case \"end\":\n              return _context2.stop();\n          }\n        }, _callee2, this, [[1, 15]]);\n      }));\n      function extract(_x2) {\n        return _extract.apply(this, arguments);\n      }\n      return extract;\n    }()\n  }]);\n}();\n\n/*\nexport extract = extract(document){\n\n\n    extractor.extract(document).then((value) => {\n        console.log(value);\n        return value\n        // Expected output: 123\n    });\n}\n    */\nfunction extract(_x3) {\n  return _extract2.apply(this, arguments);\n}\nfunction _extract2() {\n  _extract2 = _asyncToGenerator(/*#__PURE__*/_regeneratorRuntime().mark(function _callee3(document) {\n    var extractor, turtle;\n    return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n      while (1) switch (_context3.prev = _context3.next) {\n        case 0:\n          extractor = new RDFExtractor(rdf_ext__WEBPACK_IMPORTED_MODULE_0__[\"default\"], _rdfjs_parser_n3__WEBPACK_IMPORTED_MODULE_1__[\"default\"]);\n          _context3.next = 3;\n          return extractor.extract(document);\n        case 3:\n          turtle = _context3.sent;\n          return _context3.abrupt(\"return\", turtle);\n        case 5:\n        case \"end\":\n          return _context3.stop();\n      }\n    }, _callee3);\n  }));\n  return _extract2.apply(this, arguments);\n}\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (extract);\n\n//# sourceURL=webpack://FormAMatic/./src/public/extractor.js?");

/***/ }),

/***/ "./node_modules/duplex-to/readable.js":
/*!********************************************!*\
  !*** ./node_modules/duplex-to/readable.js ***!
  \********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nconst blackList = new Set(['_write', '_writableState', 'writable'])\n\nfunction readable (duplex) {\n  return new Proxy(duplex, {\n    has (target, key) {\n      if (blackList.has(key)) {\n        return false\n      }\n\n      return Reflect.has(...arguments)\n    },\n    get (target, key) {\n      if (blackList.has(key)) {\n        return undefined\n      }\n\n      const result = Reflect.get(...arguments)\n\n      if (result && typeof result.bind === 'function') {\n        return result.bind(target)\n      }\n\n      return result\n    },\n    set (target, key, value) {\n      if (blackList.has(key)) {\n        return undefined\n      }\n\n      return Reflect.set(...arguments)\n    }\n  })\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (readable);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/duplex-to/readable.js?");

/***/ }),

/***/ "./node_modules/grapoi/Edge.js":
/*!*************************************!*\
  !*** ./node_modules/grapoi/Edge.js ***!
  \*************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass Edge {\n  constructor ({ dataset, end, quad, start }) {\n    this.dataset = dataset\n    this.end = end\n    this.quad = quad\n    this.start = start\n  }\n\n  get term () {\n    return this.quad[this.end]\n  }\n\n  get graph () {\n    return this.quad.graph\n  }\n\n  get startTerm () {\n    return this.quad[this.start]\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Edge);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/Edge.js?");

/***/ }),

/***/ "./node_modules/grapoi/Factory.js":
/*!****************************************!*\
  !*** ./node_modules/grapoi/Factory.js ***!
  \****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./index.js */ \"./node_modules/grapoi/index.js\");\n\n\nclass Factory {\n  grapoi ({ ...args } = {}) {\n    if (!args.dataset && typeof this.dataset === 'function') {\n      args.dataset = this.dataset()\n    }\n\n    return (0,_index_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])({ ...args, factory: this })\n  }\n}\n\nFactory.exports = ['grapoi']\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Factory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/Factory.js?");

/***/ }),

/***/ "./node_modules/grapoi/Grapoi.js":
/*!***************************************!*\
  !*** ./node_modules/grapoi/Grapoi.js ***!
  \***************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _lib_base_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/base.js */ \"./node_modules/grapoi/lib/base.js\");\n/* harmony import */ var _lib_rebase_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/rebase.js */ \"./node_modules/grapoi/lib/rebase.js\");\n/* harmony import */ var _lib_replace_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/replace.js */ \"./node_modules/grapoi/lib/replace.js\");\n/* harmony import */ var _lib_sortByScore_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./lib/sortByScore.js */ \"./node_modules/grapoi/lib/sortByScore.js\");\n/* harmony import */ var _lib_toPathArray_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./lib/toPathArray.js */ \"./node_modules/grapoi/lib/toPathArray.js\");\n/* harmony import */ var _lib_toTerm_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./lib/toTerm.js */ \"./node_modules/grapoi/lib/toTerm.js\");\n/* harmony import */ var _lib_toTermArray_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./lib/toTermArray.js */ \"./node_modules/grapoi/lib/toTermArray.js\");\n/* harmony import */ var _Path_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Path.js */ \"./node_modules/grapoi/Path.js\");\n/* harmony import */ var _PathList_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./PathList.js */ \"./node_modules/grapoi/PathList.js\");\n\n\n\n\n\n\n\n\n\n\n/**\n * A graph pointer object\n * @extends PathList\n */\nclass Grapoi extends _PathList_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"] {\n  /**\n   * Create a new instance\n   * @param {DatasetCore} dataset Dataset for the pointers\n   * @param {Environment} factory Factory for new quads\n   * @param {Path[]} ptrs Use existing pointers\n   * @param {Term} term Term for the pointers\n   * @param {Term[]} terms Terms for the pointers\n   * @param {Term} graph Graph for the pointers\n   * @param {Term[]} graphs Graphs for graph pointers\n   */\n  constructor ({ dataset, factory, ptrs, term, terms, graph, graphs }) {\n    if (term || terms) {\n      terms = terms || term\n    }\n\n    if (graph || graphs) {\n      graphs = graphs || graph\n    }\n\n    if (!ptrs && terms) {\n      ptrs = (0,_lib_toPathArray_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"])(terms, { dataset, factory, graph: graphs })\n    }\n\n    super({ dataset, factory, ptrs, graphs })\n  }\n\n  _toTerm (value) {\n    return (0,_lib_toTerm_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"])(value, { factory: this.factory })\n  }\n\n  _toTermArray (values) {\n    return (0,_lib_toTermArray_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"])(values, { factory: this.factory })\n  }\n\n  /**\n   * Add quad(s) with the current terms as the object\n   * @param {Grapoi|Grapoi[]|Term|Term[]} predicates Predicates of the quads\n   * @param {Grapoi|Grapoi[]|Term|Term[]} [subjects] Subjects of the quads\n   * @param {function} [callback] Function called for each subject as a pointer argument\n   * @returns {Grapoi} this\n   */\n  addIn (predicates, subjects, callback) {\n    if (typeof subjects === 'function') {\n      callback = subjects\n      subjects = null\n    }\n\n    if (!subjects) {\n      subjects = [this.factory.blankNode()]\n    }\n\n    return super.addIn(this._toTermArray(predicates), this._toTermArray(subjects), callback)\n  }\n\n  /**\n   * Add list(s) with the given items\n   * @param {Grapoi|Grapoi[]|Term|Term[]} predicates Predicates of the lists\n   * @param {Grapoi|Grapoi[]|Term|Term[]} [items] List items\n   * @returns {Grapoi} this\n   */\n  addList (predicates, items) {\n    return super.addList(this._toTermArray(predicates), this._toTermArray(items))\n  }\n\n  /**\n   * Add quad(s) with the current terms as the subject\n   * @param {Grapoi|Grapoi[]|Term|Term[]} predicates Predicates of the quads\n   * @param {Grapoi|Grapoi[]|Term|Term[]} [objects] Objects of the quads\n   * @param {function} [callback] Function called for each subject as a pointer argument\n   * @returns {Grapoi} this\n   */\n  addOut (predicates, objects, callback) {\n    if (typeof objects === 'function') {\n      callback = objects\n      objects = null\n    }\n\n    if (!objects) {\n      objects = [this.factory.blankNode()]\n    }\n\n    return super.addOut(this._toTermArray(predicates), this._toTermArray(objects), callback)\n  }\n\n  /**\n   * Base all terms with a relative IRI with the given base.\n   * @param {Grapoi|Grapoi[]|Term|Term[]} base Base of the terms\n   * @returns {Constructor} Instance with a single pointer with the term based\n   */\n  base (base) {\n    if (!base) {\n      throw new Error('base parameter is required')\n    }\n\n    base = this._toTerm(base)\n\n    for (const ptr of this.ptrs) {\n      ;(0,_lib_base_js__WEBPACK_IMPORTED_MODULE_0__.baseDataset)(base, { factory: this.factory })(ptr.dataset)\n    }\n\n    return this.node((0,_lib_base_js__WEBPACK_IMPORTED_MODULE_0__.baseTerm)(base, { factory: this.factory })(this.term))\n  }\n\n  /**\n   * Use the given score function on all pointers and return the pointer with the best score.\n   * @param {function} score Score function\n   * @returns {Constructor} Instance with a single pointer with the best score\n   */\n  best (score) {\n    return this.score(score, { limit: 1 })\n  }\n\n  /**\n   * Delete quad(s) with the current terms as the object.\n   * @param {Grapoi|Grapoi[]|Term|Term[]} predicates Predicates of the quads\n   * @param {Grapoi|Grapoi[]|Term|Term[]} [subjects] Subjects of the quads\n   * @returns {Grapoi} this\n   */\n  deleteIn (predicates, subjects) {\n    return super.deleteIn(this._toTermArray(predicates), this._toTermArray(subjects))\n  }\n\n  /**\n   * Delete list(s).\n   * @param {Grapoi|Grapoi[]|Term|Term[]} predicates Predicates of the lists\n   * @returns {Grapoi} this\n   */\n  deleteList (predicates) {\n    return super.deleteList(this._toTermArray(predicates))\n  }\n\n  /**\n   * Delete quad(s) with the current terms as the subject.\n   * @param {Grapoi|Grapoi[]|Term|Term[]} predicates Predicates of the quads\n   * @param {Grapoi|Grapoi[]|Term|Term[]} [objects] Objects of the quads\n   * @returns {Constructor} this\n   */\n  deleteOut (predicates, objects) {\n    return super.deleteOut(this._toTermArray(predicates), this._toTermArray(objects))\n  }\n\n  /**\n   * Filter the pointers based on matching quad(s) with the current terms as the object.\n   * @param {Grapoi|Grapoi[]|Term|Term[]} predicates Predicates of the quads\n   * @param {Grapoi|Grapoi[]|Term|Term[]} [subjects] Subjects of the quads\n   * @returns {Constructor} Instance that contains only the filtered pointers\n   */\n  hasIn (predicates, subjects) {\n    return super.hasIn(this._toTermArray(predicates), this._toTermArray(subjects))\n  }\n\n  /**\n   * Filter the pointers based on matching quad(s) with the current terms as the subject.\n   * @param {Grapoi|Grapoi[]|Term|Term[]} predicates Predicates of the quads\n   * @param {Grapoi|Grapoi[]|Term|Term[]} [objects] Objects of the quads\n   * @returns {Constructor} Instance that contains only the filtered pointers\n   */\n  hasOut (predicates, objects) {\n    return super.hasOut(this._toTermArray(predicates), this._toTermArray(objects))\n  }\n\n  /**\n   * Traverse the graph with the current terms as the object.\n   * @param {Grapoi|Grapoi[]|Term|Term[]} predicates Predicates of the quads\n   * @param {Grapoi|Grapoi[]|Term|Term[]} [subjects] Subjects of the quads\n   * @returns {Constructor} Instance with pointers of the traversed target terms\n   */\n  in (predicates, subjects) {\n    return super.in(this._toTermArray(predicates), this._toTermArray(subjects))\n  }\n\n  /**\n   * Traverse the graph with the current terms as the subject.\n   * @param {Grapoi|Grapoi[]|Term|Term[]} predicates Predicates of the quads\n   * @param {Grapoi|Grapoi[]|Term|Term[]} [objects] Objects of the quads\n   * @returns {Constructor} Instance with pointers of the traversed target terms\n   */\n  out (predicates, objects) {\n    return super.out(this._toTermArray(predicates), this._toTermArray(objects))\n  }\n\n  /**\n   * Jump to random terms.\n   * @param {Grapoi|Grapoi[]|Term|Term[]} predicates Terms for the new pointers\n   * @returns {Constructor} Instance with pointers of the selected terms\n   */\n  node (terms = null) {\n    return super.node(this._toTermArray(terms))\n  }\n\n  /**\n   * Rebase all terms of the current pointers with a new base.\n   * @param {Grapoi|Grapoi[]|Term|Term[]} base New base of the terms\n   * @returns {Constructor} Instance with a single pointer with the new base as the term\n   */\n  rebase (base) {\n    if (!base) {\n      throw new Error('base parameter is required')\n    }\n\n    base = this._toTerm(base)\n\n    for (const ptr of this.ptrs) {\n      ;(0,_lib_rebase_js__WEBPACK_IMPORTED_MODULE_1__.rebaseDataset)(ptr.term, base, { factory: this.factory })(ptr.dataset)\n    }\n\n    return this.node(base)\n  }\n\n  /**\n   * Replace all terms of the current pointers with another term.\n   * @param {Grapoi|Grapoi[]|Term|Term[]} replacement Term used as replacement\n   * @returns {Constructor} Instance with a single pointer with the replacement as the term\n   */\n  replace (replacement) {\n    if (!replacement) {\n      throw new Error('replacement parameter is required')\n    }\n\n    replacement = this._toTerm(replacement)\n\n    for (const ptr of this.ptrs) {\n      ;(0,_lib_replace_js__WEBPACK_IMPORTED_MODULE_2__.replaceDataset)(ptr.term, replacement, { factory: this.factory })(ptr.dataset)\n    }\n\n    return this.node(replacement)\n  }\n\n  /**\n   * Score the pointers and sort them by score value.\n   * @param {Function} score @rdfjs/score compatible score function\n   * @param {Number} [limit] Limit for the result pointers\n   * @param {Number} [offset] Offset for the result pointers\n   * @returns {Constructor} Instance of the scored pointers, sorted and sliced.\n   */\n  score (score, { limit = Infinity, offset = 0 } = {}) {\n    const ptrs = (0,_lib_sortByScore_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(score(this))\n      .slice(offset, offset + limit)\n      .map(ptr => new _Path_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"]({ ...ptr, factory: this.factory }))\n\n    return this.clone({ ptrs })\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Grapoi);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/Grapoi.js?");

/***/ }),

/***/ "./node_modules/grapoi/Path.js":
/*!*************************************!*\
  !*** ./node_modules/grapoi/Path.js ***!
  \*************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _Processor_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Processor.js */ \"./node_modules/grapoi/Processor.js\");\n\n\nfunction createEdgeCallback (context, callback) {\n  if (!callback) {\n    return () => {}\n  }\n\n  return edge => callback(context.extend(edge))\n}\n\nclass Path {\n  constructor ({ dataset, edges = [], factory, graph, term }) {\n    if (!dataset && edges.length === 0) {\n      throw new Error('dataset or edges is required')\n    }\n\n    if (edges.length === 0 && typeof term === 'undefined') {\n      throw new Error('edges or term must be given')\n    }\n\n    if (edges.length > 0 && term) {\n      throw new Error('edges or term must be given')\n    }\n\n    this.dataset = dataset || edges[edges.length - 1].dataset\n    this.edges = edges\n    this.factory = factory\n    this._graph = graph\n\n    if (edges.length === 0) {\n      this._term = term\n    }\n  }\n\n  get edge () {\n    return this.edges[this.edges.length - 1]\n  }\n\n  get graph () {\n    if (typeof this._graph === 'object') {\n      return this._graph\n    }\n\n    return this.edge && this.edge.graph\n  }\n\n  get length () {\n    if (this._term !== undefined) {\n      return 1\n    }\n\n    return this.edges.length + 1\n  }\n\n  get startTerm () {\n    return this._term || this.edges[0].startTerm\n  }\n\n  get term () {\n    if (this._term !== undefined) {\n      return this._term\n    }\n\n    return this.edge.term\n  }\n\n  get value () {\n    const term = this.term\n\n    return term === null ? undefined : term.value\n  }\n\n  addIn (predicates, subjects, callback) {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].add({\n      ptr: this,\n      start: 'object',\n      end: 'subject',\n      subjects,\n      predicates,\n      graphs: [this.graph || this.factory.defaultGraph()],\n      callback: createEdgeCallback(this, callback)\n    })\n  }\n\n  addList (predicates, items) {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].addList({\n      ptr: this,\n      predicates,\n      graphs: [this.graph || this.factory.defaultGraph()],\n      items\n    })\n  }\n\n  addOut (predicates, objects, callback) {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].add({\n      ptr: this,\n      start: 'subject',\n      end: 'object',\n      predicates,\n      objects,\n      graphs: [this.graph || this.factory.defaultGraph()],\n      callback: createEdgeCallback(this, callback)\n    })\n  }\n\n  deleteIn (predicates, subjects) {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].delete({\n      ptr: this,\n      start: 'object',\n      subjects,\n      predicates\n    })\n  }\n\n  deleteList (predicates) {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].deleteList({\n      ptr: this,\n      predicates\n    })\n  }\n\n  deleteOut (predicates, objects) {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].delete({\n      ptr: this,\n      start: 'subject',\n      predicates,\n      objects\n    })\n  }\n\n  execute ({ operation, quantifier, start, end, subjects, predicates, objects, graphs, items, callback }) {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].execute({\n      ptr: this,\n      operation,\n      quantifier,\n      start,\n      end,\n      subjects,\n      predicates,\n      objects,\n      graphs,\n      items,\n      callback\n    })\n  }\n\n  extend (edge) {\n    return new this.constructor({\n      dataset: this.dataset,\n      edges: [...this.edges, edge],\n      factory: this.factory,\n      graph: this._graph\n    })\n  }\n\n  hasIn (predicates, subjects) {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].traverse({\n      ptr: this,\n      start: 'object',\n      end: 'object',\n      subjects,\n      predicates,\n      graphs: [this.graph]\n    })\n  }\n\n  hasOut (predicates, objects) {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].traverse({\n      ptr: this,\n      start: 'subject',\n      end: 'subject',\n      predicates,\n      objects,\n      graphs: [this.graph]\n    })\n  }\n\n  in (predicates, subjects) {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].traverse({\n      ptr: this,\n      start: 'object',\n      end: 'subject',\n      subjects,\n      predicates,\n      graphs: [this.graph]\n    })\n  }\n\n  isAny () {\n    return !this.term\n  }\n\n  isList () {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].isList({ ptr: this })\n  }\n\n  list () {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].list({ ptr: this })\n  }\n\n  nodes () {\n    const path = this\n\n    const at = index => {\n      if (this._term !== undefined) {\n        return {\n          dataset: this.dataset,\n          term: this._term\n        }\n      }\n\n      if (this.edges.length > index) {\n        return {\n          dataset: this.edges[index].dataset,\n          term: this.edges[index].startTerm\n        }\n      }\n\n      if (this.edges.length === index) {\n        return {\n          dataset: this.edges[index - 1].dataset,\n          term: this.edges[index - 1].term\n        }\n      }\n    }\n\n    return {\n      * [Symbol.iterator] () {\n        for (let index = 0; index < path.length; index++) {\n          yield at(index)\n        }\n      }\n    }\n  }\n\n  out (predicates, objects) {\n    return _Processor_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"].traverse({\n      ptr: this,\n      predicates,\n      objects,\n      graphs: [this.graph]\n    })\n  }\n\n  quads () {\n    const path = this\n\n    return {\n      * [Symbol.iterator] () {\n        for (const edge of path.edges) {\n          yield edge.quad\n        }\n      }\n    }\n  }\n\n  trim () {\n    return new this.constructor({\n      dataset: this.dataset,\n      factory: this.factory,\n      graph: this.graph,\n      term: this.term\n    })\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Path);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/Path.js?");

/***/ }),

/***/ "./node_modules/grapoi/PathList.js":
/*!*****************************************!*\
  !*** ./node_modules/grapoi/PathList.js ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_term_set__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/term-set */ \"./node_modules/@rdfjs/term-set/TermSet.js\");\n/* harmony import */ var _lib_ptrIsEqual_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/ptrIsEqual.js */ \"./node_modules/grapoi/lib/ptrIsEqual.js\");\n/* harmony import */ var _Path_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Path.js */ \"./node_modules/grapoi/Path.js\");\n\n\n\n\nfunction createExtendCallback (ptrList, callback) {\n  if (!callback) {\n    return () => {}\n  }\n\n  return ptr => {\n    return callback(new ptrList.constructor({\n      factory: ptrList.factory,\n      ptrs: [ptr]\n    }))\n  }\n}\n\n/**\n * List of paths\n * @property {Array} ptrs All paths of this list\n */\nclass PathList {\n  /**\n   * Create a new instance\n   * @param {DatasetCore} dataset Dataset for the pointers\n   * @param {Environment} factory Factory for new quads\n   * @param {Path[]} ptrs Use existing pointers\n   * @param {Term[]} terms Terms for the pointers\n   * @param {Term[]} graphs Graphs for the pointers\n   */\n  constructor ({ dataset, factory, ptrs, terms, graphs }) {\n    this.factory = factory\n\n    if (ptrs) {\n      this.ptrs = [...ptrs]\n    } else {\n      this.ptrs = []\n\n      for (const term of (terms || [null])) {\n        for (const graph of (graphs || [null])) {\n          this.ptrs.push(new _Path_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]({ dataset, factory, graph, term }))\n        }\n      }\n    }\n  }\n\n  /**\n   * Dataset of the pointer or null if there is no unique dataset.\n   * @returns {DatasetCore|null} Unique dataset or null\n   */\n  get dataset () {\n    const datasets = new Set(this.datasets)\n\n    if (datasets.size !== 1) {\n      return null\n    }\n\n    return datasets[Symbol.iterator]().next().value\n  }\n\n  /**\n   * An array of all datasets of all pointers.\n   * @returns {DatasetCore[]} Array of datasets.\n   */\n  get datasets () {\n    return this.ptrs.map(ptr => ptr.dataset)\n  }\n\n  /**\n   * The term of the pointers if all pointers refer to a unique term.\n   * @returns {Term|undefined} Term of undefined\n   */\n  get term () {\n    const terms = new _rdfjs_term_set__WEBPACK_IMPORTED_MODULE_0__[\"default\"](this.terms)\n\n    if (terms.size !== 1) {\n      return undefined\n    }\n\n    return terms[Symbol.iterator]().next().value\n  }\n\n  /**\n   * An array of all terms of all pointers.\n   * @returns {Term[]} Array of all terms\n   */\n  get terms () {\n    return this.ptrs.map(ptr => ptr.term)\n  }\n\n  /**\n   * The value of the pointers if all pointers refer to a unique term.\n   * @returns {String|undefined} Value or undefined\n   */\n  get value () {\n    const term = this.term\n\n    return (term === undefined || term === null) ? undefined : term.value\n  }\n\n  /**\n   * An array of all values of all pointers.\n   * @returns {String[]} Array of all values\n   */\n  get values () {\n    return this.ptrs.map(ptr => ptr.value)\n  }\n\n  /**\n   * Add quads with the current terms as the object\n   * @param {Term[]} predicates Predicates of the quads\n   * @param {Term[]} subjects Subjects of the quads\n   * @param {function} [callback] Function called for each subject as a pointer argument\n   * @returns {PathList} this\n   */\n  addIn (predicates, subjects, callback) {\n    const extendCallback = createExtendCallback(this, callback)\n\n    for (const ptr of this.ptrs) {\n      ptr.addIn(predicates, subjects, extendCallback)\n    }\n\n    return this\n  }\n\n  /**\n   * Add lists with the given items\n   * @param {Term[]} predicates Predicates of the lists\n   * @param {Term[]} items List items\n   * @returns {PathList} this\n   */\n  addList (predicates, items) {\n    if (this.isAny()) {\n      throw new Error('can\\'t attach a list to an any ptr')\n    }\n\n    for (const ptr of this.ptrs) {\n      ptr.addList(predicates, items)\n    }\n\n    return this\n  }\n\n  /**\n   * Add quads with the current terms as the subject\n   * @param {Term[]} predicates Predicates of the quads\n   * @param {Term[]} objects Objects of the quads\n   * @param {function} [callback] Function called for each subject as a pointer argument\n   * @returns {PathList} this\n   */\n  addOut (predicates, objects, callback) {\n    const extendCallback = createExtendCallback(this, callback)\n\n    for (const ptr of this.ptrs) {\n      ptr.addOut(predicates, objects, extendCallback)\n    }\n\n    return this\n  }\n\n  /**\n   * Create a new instance of the Constructor with a cloned list of pointers.\n   * @param args Additional arguments for the constructor\n   * @returns {Constructor} Cloned instance\n   */\n  clone (args) {\n    return new this.constructor({ factory: this.factory, ptrs: this.ptrs, ...args })\n  }\n\n  /**\n   * Delete quads with the current terms as the object.\n   * @param {Term[]} predicates Predicates of the quads\n   * @param {Term[]} subjects Subjects of the quads\n   * @returns {PathList} this\n   */\n  deleteIn (predicates, subjects) {\n    for (const ptr of this.ptrs) {\n      ptr.deleteIn(predicates, subjects)\n    }\n\n    return this\n  }\n\n  /**\n   * Delete lists.\n   * @param {Term[]} predicates Predicates of the lists\n   * @returns {PathList} this\n   */\n  deleteList (predicates) {\n    for (const ptr of this.ptrs) {\n      ptr.deleteList(predicates)\n    }\n\n    return this\n  }\n\n  /**\n   * Delete quads with the current terms as the subject.\n   * @param {Term[]} predicates Predicates of the quads\n   * @param {Term[]} objects Objects of the quads\n   * @returns {PathList} this\n   */\n  deleteOut (predicates, objects) {\n    for (const ptr of this.ptrs) {\n      ptr.deleteOut(predicates, objects)\n    }\n\n    return this\n  }\n\n  /**\n   * Create a new instance with a unique set of pointers.\n   * The path of the pointers is trimmed.\n   * @returns {Constructor} Instance with unique pointers\n   */\n  distinct () {\n    const ptrs = this.ptrs.reduce((unique, ptr) => {\n      if (!unique.some(uPtr => (0,_lib_ptrIsEqual_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(uPtr, ptr))) {\n        unique.push(ptr.trim())\n      }\n\n      return unique\n    }, [])\n\n    return this.clone({ ptrs })\n  }\n\n  /**\n   * Executes a single instruction.\n   * @param instruction The instruction to execute\n   * @returns {Constructor} Instance with the result pointers.\n   */\n  execute (instruction) {\n    return this.clone({ ptrs: this.ptrs.flatMap(ptr => ptr.execute(instruction)) })\n  }\n\n  /**\n   * Executes an array of instructions.\n   * @param instruction The instructions to execute\n   * @returns {Constructor} Instance with the result pointers.\n   */\n  executeAll (instructions) {\n    let output = this\n\n    for (const instruction of instructions) {\n      output = output.execute(instruction)\n    }\n\n    return output\n  }\n\n  /**\n   * Filter the pointers based on the result of the given callback function.\n   * @param callback\n   * @returns {Constructor} Instance with the filtered pointers.\n   */\n  filter (callback) {\n    return this.clone({ ptrs: [...this].filter(callback).map(ptr => ptr.ptrs[0]) })\n  }\n\n  /**\n   * Filter the pointers based on matching quad(s) with the current terms as the object.\n   * @param {Term[]} predicates Predicates of the quads\n   * @param {Term[]} subjects Subjects of the quads\n   * @returns {Constructor} Instance that contains only the filtered pointers\n   */\n  hasIn (predicates, subjects) {\n    return this.clone({ ptrs: this.ptrs.flatMap(ptr => ptr.hasIn(predicates, subjects)) })\n  }\n\n  /**\n   * Filter the pointers based on matching quad(s) with the current terms as the subject.\n   * @param {Term[]} predicates Predicates of the quads\n   * @param {Term[]} objects Objects of the quads\n   * @returns {Constructor} Instance that contains only the filtered pointers\n   */\n  hasOut (predicates, objects) {\n    return this.clone({ ptrs: this.ptrs.flatMap(ptr => ptr.hasOut(predicates, objects)) })\n  }\n\n  /**\n   * Traverse the graph with the current terms as the object.\n   * @param {Term[]} predicates Predicates of the quads\n   * @param {Term[]} subjects Subjects of the quads\n   * @returns {Constructor} Instance with pointers of the traversed target terms\n   */\n  in (predicates, subjects) {\n    return this.clone({ ptrs: this.ptrs.flatMap(ptr => ptr.in(predicates, subjects)) })\n  }\n\n  /**\n   * Check if any pointer is an any-pointer.\n   * @returns {boolean} True if any any-pointer was found\n   */\n  isAny () {\n    return this.ptrs.length > 0 && this.ptrs.some(ptr => ptr.isAny())\n  }\n\n  /**\n   * Check if there is only one pointer and whether that pointer is a list.\n   * @returns {boolean} True if the pointer is a list\n   */\n  isList () {\n    if (this.ptrs.length !== 1) {\n      return false\n    }\n\n    return this.ptrs[0].isList()\n  }\n\n  /**\n   * Create an iterator for the list if the instance is a list; otherwise, return undefined.\n   * @returns {Iterator<Constructor>|undefined} Iterator or undefined\n   */\n  list () {\n    if (!this.isList()) {\n      return undefined\n    }\n\n    const iterator = this.ptrs[0].list()[Symbol.iterator]()\n\n    const next = () => {\n      const { done, value } = iterator.next()\n\n      if (done) {\n        return { done: true }\n      }\n\n      return { done: false, value: this.clone({ ptrs: [value] }) }\n    }\n\n    return {\n      [Symbol.iterator]: () => {\n        return { next }\n      }\n    }\n  }\n\n  /**\n   * Map each pointer using the given callback function.\n   * @param callback\n   * @returns {Array} Array of mapped results\n   */\n  map (callback) {\n    return [...this].map(callback)\n  }\n\n  /**\n   * Create a new instance with pointers using the given terms.\n   * @param terms Array of terms for the pointers\n   * @returns {Constructor} Instance with pointers of the given terms\n   */\n  node (terms) {\n    const dataset = this.dataset\n    const ptrs = [...terms].map(term => new _Path_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]({ dataset, factory: this.factory, term }))\n\n    return this.clone({ ptrs })\n  }\n\n  /**\n   * Traverse the graph with the current terms as the subject.\n   * @param {Term[]} predicates Predicates of the quads\n   * @param {Term[]} objects Objects of the quads\n   * @returns {Constructor} Instance with pointers of the traversed target terms\n   */\n  out (predicates, objects) {\n    return this.clone({ ptrs: this.ptrs.flatMap(ptr => ptr.out(predicates, objects)) })\n  }\n\n  /**\n   * Create an iterator of all quads of all pointer paths.\n   * @returns {Iterator<Quad>} Iterator for the quads\n   */\n  quads () {\n    const pathList = this\n\n    return {\n      * [Symbol.iterator] () {\n        for (const path of pathList.ptrs) {\n          for (const edge of path.edges) {\n            yield edge.quad\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * Trim the path of all pointers and create a new instance for the result.\n   * @returns {Constructor} Instance of the trimmed pointers\n   */\n  trim () {\n    return this.clone({\n      ptrs: this.ptrs.map(ptr => ptr.trim())\n    })\n  }\n\n  /**\n   * Iterator for each pointer wrapped into a new instance.\n   * @returns {Iterator<Constructor>}} Iterator for the wrapped pointers\n   */\n  * [Symbol.iterator] () {\n    for (const ptr of this.ptrs) {\n      yield this.clone({ ptrs: [ptr] })\n    }\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (PathList);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/PathList.js?");

/***/ }),

/***/ "./node_modules/grapoi/Processor.js":
/*!******************************************!*\
  !*** ./node_modules/grapoi/Processor.js ***!
  \******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_term_set__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/term-set */ \"./node_modules/@rdfjs/term-set/TermSet.js\");\n/* harmony import */ var _Edge_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Edge.js */ \"./node_modules/grapoi/Edge.js\");\n/* harmony import */ var _lib_namespaces_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/namespaces.js */ \"./node_modules/grapoi/lib/namespaces.js\");\n\n\n\n\nclass Processor {\n  static add ({ ptr, start, end, subjects = [null], predicates = [null], objects = [null], graphs, callback } = {}) {\n    if (!ptr.factory) {\n      throw new Error('add operation requires a factory')\n    }\n\n    let edgeCallback = () => {}\n\n    if (callback) {\n      edgeCallback = quad => {\n        callback(new _Edge_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]({ dataset: ptr.dataset, start, end, quad }))\n      }\n    }\n\n    for (const subject of subjects) {\n      for (const predicate of predicates) {\n        for (const object of objects) {\n          for (const graph of graphs) {\n            const pattern = { subject, predicate, object, graph }\n\n            pattern[start] = ptr.term\n\n            const quad = ptr.factory.quad(\n              pattern.subject,\n              pattern.predicate,\n              pattern.object,\n              pattern.graph\n            )\n\n            ptr.dataset.add(quad)\n\n            edgeCallback(quad)\n          }\n        }\n      }\n    }\n\n    return ptr\n  }\n\n  static addList ({ ptr, predicates, items, graphs }) {\n    if (ptr.isAny()) {\n      throw new Error('can\\'t attach a list to an any ptr')\n    }\n\n    for (const predicate of predicates) {\n      for (const graph of graphs) {\n        const nodes = items.map(() => ptr.factory.blankNode())\n\n        ptr.dataset.add(ptr.factory.quad(ptr.term, predicate, nodes[0] || _lib_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.nil, graph))\n\n        for (let index = 0; index < nodes.length; index++) {\n          ptr.dataset.add(ptr.factory.quad(nodes[index], _lib_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.first, items[index], graph))\n          ptr.dataset.add(ptr.factory.quad(nodes[index], _lib_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.rest, nodes[index + 1] || _lib_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.nil, graph))\n        }\n      }\n    }\n\n    return ptr\n  }\n\n  static delete ({\n    ptr,\n    start,\n    subjects = [null],\n    predicates = [null],\n    objects = [null]\n  }) {\n    for (const subject of subjects) {\n      for (const predicate of predicates) {\n        for (const object of objects) {\n          const pattern = { subject, predicate, object }\n\n          pattern[start] = ptr.term\n\n          const matches = ptr.dataset.match(pattern.subject, pattern.predicate, pattern.object)\n\n          for (const quad of matches) {\n            ptr.dataset.delete(quad)\n          }\n        }\n      }\n    }\n\n    return ptr\n  }\n\n  static deleteList ({ ptr, predicates }) {\n    const toDelete = []\n\n    for (const predicate of predicates) {\n      for (const quad of ptr.dataset.match(ptr.term, predicate)) {\n        let link = quad.object\n\n        toDelete.push(quad)\n\n        while (!_lib_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.nil.equals(link)) {\n          link = toDelete[toDelete.length - 1].object\n\n          const matches = ptr.dataset.match(link)\n\n          if (matches.size === 0) {\n            break\n          }\n\n          for (const quad of matches) {\n            toDelete.push(quad)\n          }\n        }\n      }\n    }\n\n    for (const quad of toDelete) {\n      ptr.dataset.delete(quad)\n    }\n\n    return ptr\n  }\n\n  static execute ({\n    ptr,\n    operation = 'traverse',\n    quantifier,\n    start,\n    end,\n    subjects,\n    predicates,\n    objects,\n    graphs,\n    items,\n    callback\n  } = {}) {\n    if (operation === 'add') {\n      return Processor.add({ ptr, start, end, subjects, predicates, objects, graphs, callback })\n    }\n\n    if (operation === 'addList') {\n      return Processor.addList({ ptr, predicates, items, graphs })\n    }\n\n    if (operation === 'delete') {\n      return Processor.delete({ ptr, start, subjects, predicates, objects })\n    }\n\n    if (operation === 'deleteList') {\n      return Processor.deleteList({ ptr, predicates })\n    }\n\n    if (operation === 'isList') {\n      return Processor.isList({ ptr })\n    }\n\n    if (operation === 'list') {\n      return Processor.list({ ptr })\n    }\n\n    if (operation === 'traverse') {\n      return Processor.traverse({ ptr, quantifier, start, end, subjects, predicates, objects, graphs })\n    }\n\n    throw new Error(`unknown operation ${operation}`)\n  }\n\n  static isList ({ ptr }) {\n    // only test if there is a term\n    if (ptr.isAny()) {\n      return false\n    }\n\n    // test if it's an empty list\n    if (_lib_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.nil.equals(ptr.term)) {\n      return true\n    }\n\n    // test if there is a linked item\n    const item = Processor.traverse({ ptr, predicates: [_lib_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.first] })\n\n    if (item.length === 1) {\n      return true\n    }\n\n    return false\n  }\n\n  static list ({ ptr }) {\n    if (!ptr.isList()) {\n      return undefined\n    }\n\n    return {\n      * [Symbol.iterator] () {\n        while (ptr && !ptr.term.equals(_lib_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.nil)) {\n          const value = ptr.out([_lib_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.first])\n\n          if (value.length !== 1) {\n            throw new Error(`Invalid list: rdf:first count not equals one on ${ptr.value}`)\n          }\n\n          const rest = ptr.out([_lib_namespaces_js__WEBPACK_IMPORTED_MODULE_2__.rdf.rest])\n\n          if (rest.length !== 1) {\n            throw new Error(`Invalid list: rdf:rest count not equals one on ${ptr.value}`)\n          }\n\n          yield value[0]\n\n          ptr = rest[0]\n        }\n      }\n    }\n  }\n\n  static traverse ({\n    ptr,\n    quantifier = 'one',\n    start = 'subject',\n    end = 'object',\n    subjects = [null],\n    predicates = [null],\n    objects = [null],\n    graphs = [null],\n    callback\n  }) {\n    if (quantifier === 'one') {\n      return Processor.traverseOne({ ptr, start, end, subjects, predicates, objects, graphs, callback })\n    }\n\n    if (quantifier === 'oneOrMore') {\n      const ptrs = Processor.traverse({ ptr, end, start, subjects, predicates, objects, graphs, callback })\n\n      return Processor.traverseMore({ ptrs, end, start, subjects, predicates, objects, graphs, callback })\n    }\n\n    if (quantifier === 'zeroOrMore') {\n      return Processor.traverseMore({ ptrs: [ptr], end, start, subjects, predicates, objects, graphs, callback })\n    }\n\n    if (quantifier === 'zeroOrOne') {\n      return [ptr, ...Processor.traverse({ ptr, end, start, subjects, predicates, objects, graphs, callback })]\n    }\n\n    throw new Error(`unknown quantifier ${quantifier}`)\n  }\n\n  static traverseMore ({ ptrs, end, start, subjects, predicates, objects, graphs, callback } = {}) {\n    let result = [...ptrs]\n    let current\n    let last\n\n    do {\n      current = []\n\n      for (const ptr of ptrs) {\n        current = [\n          ...current,\n          ...Processor.traverseOne({ ptr, end, start, subjects, predicates, objects, graphs, callback })\n        ]\n      }\n\n      if (last) {\n        current = current.filter(ptr => !last.has(ptr.term))\n      }\n\n      ptrs = current\n      result = [...result, ...current]\n\n      last = new _rdfjs_term_set__WEBPACK_IMPORTED_MODULE_0__[\"default\"](result.map(ptr => ptr.term))\n    } while (current.length > 0)\n\n    return result\n  }\n\n  static traverseOne ({ ptr, start, end, subjects, predicates, objects, graphs, callback = (edge, ptr) => ptr.extend(edge) } = {}) {\n    const results = []\n\n    for (const subject of subjects) {\n      for (const predicate of predicates) {\n        for (const object of objects) {\n          for (const graph of graphs) {\n            const pattern = { subject, predicate, object, graph }\n\n            pattern[start] = ptr.term\n\n            for (const quad of ptr.dataset.match(pattern.subject, pattern.predicate, pattern.object, pattern.graph)) {\n              results.push(callback(new _Edge_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]({ dataset: ptr.dataset, end, quad, start }), ptr))\n            }\n          }\n        }\n      }\n    }\n\n    return results\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Processor);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/Processor.js?");

/***/ }),

/***/ "./node_modules/grapoi/index.js":
/*!**************************************!*\
  !*** ./node_modules/grapoi/index.js ***!
  \**************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Edge: () => (/* reexport safe */ _Edge_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]),\n/* harmony export */   Grapoi: () => (/* reexport safe */ _Grapoi_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]),\n/* harmony export */   Path: () => (/* reexport safe */ _Path_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]),\n/* harmony export */   PathList: () => (/* reexport safe */ _PathList_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]),\n/* harmony export */   \"default\": () => (/* binding */ grapoi)\n/* harmony export */ });\n/* harmony import */ var _Edge_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Edge.js */ \"./node_modules/grapoi/Edge.js\");\n/* harmony import */ var _Grapoi_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Grapoi.js */ \"./node_modules/grapoi/Grapoi.js\");\n/* harmony import */ var _Path_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Path.js */ \"./node_modules/grapoi/Path.js\");\n/* harmony import */ var _PathList_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./PathList.js */ \"./node_modules/grapoi/PathList.js\");\n\n\n\n\n\nfunction grapoi (args) {\n  return new _Grapoi_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"](args)\n}\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/index.js?");

/***/ }),

/***/ "./node_modules/grapoi/lib/base.js":
/*!*****************************************!*\
  !*** ./node_modules/grapoi/lib/base.js ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   baseDataset: () => (/* binding */ baseDataset),\n/* harmony export */   baseQuad: () => (/* binding */ baseQuad),\n/* harmony export */   baseTerm: () => (/* binding */ baseTerm)\n/* harmony export */ });\nfunction baseDataset (newBaseTerm, { factory }) {\n  const base = baseQuad(newBaseTerm, { factory })\n\n  return dataset => {\n    for (const quad of [...dataset]) {\n      const newQuad = base(quad)\n\n      if (newQuad !== quad) {\n        dataset.delete(quad)\n        dataset.add(newQuad)\n      }\n    }\n  }\n}\n\nfunction baseQuad (newBaseTerm, { factory }) {\n  const base = baseTerm(newBaseTerm, { factory })\n\n  return quad => {\n    const subject = base(quad.subject)\n    const predicate = base(quad.predicate)\n    const object = base(quad.object)\n\n    if (subject === quad.subject && predicate === quad.predicate && object === quad.object) {\n      return quad\n    }\n\n    return factory.quad(subject, predicate, object, quad.graph)\n  }\n}\n\nfunction baseTerm (newBaseTerm, { factory }) {\n  return term => {\n    if (term.termType !== 'NamedNode') {\n      return term\n    }\n\n    if (/^[a-z]+:\\/\\//.test(term.value)) {\n      return term\n    }\n\n    return factory.namedNode(new URL(term.value, newBaseTerm.value).toString())\n  }\n}\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/lib/base.js?");

/***/ }),

/***/ "./node_modules/grapoi/lib/namespaces.js":
/*!***********************************************!*\
  !*** ./node_modules/grapoi/lib/namespaces.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   rdf: () => (/* binding */ rdfns),\n/* harmony export */   rdfs: () => (/* binding */ rdfs),\n/* harmony export */   xsd: () => (/* binding */ xsd)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_namespace__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/namespace */ \"./node_modules/@rdfjs/namespace/index.js\");\n\n\nconst xsd = (0,_rdfjs_namespace__WEBPACK_IMPORTED_MODULE_0__[\"default\"])('http://www.w3.org/2001/XMLSchema#')\nconst rdfns = (0,_rdfjs_namespace__WEBPACK_IMPORTED_MODULE_0__[\"default\"])('http://www.w3.org/1999/02/22-rdf-syntax-ns#')\nconst rdfs = (0,_rdfjs_namespace__WEBPACK_IMPORTED_MODULE_0__[\"default\"])('http://www.w3.org/2000/01/rdf-schema#')\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/lib/namespaces.js?");

/***/ }),

/***/ "./node_modules/grapoi/lib/ptrIsEqual.js":
/*!***********************************************!*\
  !*** ./node_modules/grapoi/lib/ptrIsEqual.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _termIsEqual_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./termIsEqual.js */ \"./node_modules/grapoi/lib/termIsEqual.js\");\n\n\nfunction ptrIsEqual (a, b) {\n  if (a.dataset !== b.dataset) {\n    return false\n  }\n\n  if (!(0,_termIsEqual_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(a.graph, b.graph)) {\n    return false\n  }\n\n  if (!(0,_termIsEqual_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(a.term, b.term)) {\n    return false\n  }\n\n  return true\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (ptrIsEqual);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/lib/ptrIsEqual.js?");

/***/ }),

/***/ "./node_modules/grapoi/lib/rebase.js":
/*!*******************************************!*\
  !*** ./node_modules/grapoi/lib/rebase.js ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   rebaseDataset: () => (/* binding */ rebaseDataset),\n/* harmony export */   rebaseQuad: () => (/* binding */ rebaseQuad),\n/* harmony export */   rebaseTerm: () => (/* binding */ rebaseTerm)\n/* harmony export */ });\nconst isIriRegExp = /^[a-z][a-z0-9+.-]*:/\n\nfunction rebaseDataset (oldTerm, newTerm, { factory }) {\n  const rebase = rebaseQuad(oldTerm, newTerm, { factory })\n\n  return dataset => {\n    for (const quad of [...dataset]) {\n      const newQuad = rebase(quad)\n\n      if (newQuad !== quad) {\n        dataset.delete(quad)\n        dataset.add(newQuad)\n      }\n    }\n  }\n}\n\nfunction rebaseQuad (oldTerm, newTerm, { factory }) {\n  const rebase = rebaseTerm(oldTerm, newTerm, { factory })\n\n  return quad => {\n    const subject = rebase(quad.subject)\n    const predicate = rebase(quad.predicate)\n    const object = rebase(quad.object)\n\n    if (subject === quad.subject && predicate === quad.predicate && object === quad.object) {\n      return quad\n    }\n\n    return factory.quad(subject, predicate, object, quad.graph)\n  }\n}\n\nfunction rebaseTerm (oldTerm, newTerm, { factory }) {\n  return term => {\n    if (term.termType !== 'NamedNode') {\n      return term\n    }\n\n    if (!term.value.startsWith(oldTerm.value)) {\n      return term\n    }\n\n    if (isIriRegExp.test(term.value) !== isIriRegExp.test(oldTerm.value)) {\n      return term\n    }\n\n    return factory.namedNode(newTerm.value + term.value.slice(oldTerm.value.length))\n  }\n}\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/lib/rebase.js?");

/***/ }),

/***/ "./node_modules/grapoi/lib/replace.js":
/*!********************************************!*\
  !*** ./node_modules/grapoi/lib/replace.js ***!
  \********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   replaceDataset: () => (/* binding */ replaceDataset),\n/* harmony export */   replaceQuad: () => (/* binding */ replaceQuad),\n/* harmony export */   replaceTerm: () => (/* binding */ replaceTerm)\n/* harmony export */ });\nfunction replaceDataset (oldTerm, newTerm, { factory }) {\n  const rebase = replaceQuad(oldTerm, newTerm, { factory })\n\n  return dataset => {\n    const quads = [\n      ...[...dataset.match(oldTerm)],\n      ...[...dataset.match(null, oldTerm)],\n      ...[...dataset.match(null, null, oldTerm)]\n    ]\n\n    for (const quad of quads) {\n      const newQuad = rebase(quad)\n\n      if (newQuad !== quad) {\n        dataset.delete(quad)\n        dataset.add(newQuad)\n      }\n    }\n  }\n}\n\nfunction replaceQuad (oldTerm, newTerm, { factory }) {\n  const replace = replaceTerm(oldTerm, newTerm)\n\n  return quad => {\n    const subject = replace(quad.subject)\n    const predicate = replace(quad.predicate)\n    const object = replace(quad.object)\n\n    if (subject === quad.subject && predicate === quad.predicate && object === quad.object) {\n      return quad\n    }\n\n    return factory.quad(subject, predicate, object, quad.graph)\n  }\n}\n\nfunction replaceTerm (oldTerm, newTerm) {\n  return term => {\n    if (term.equals(oldTerm)) {\n      return newTerm\n    }\n\n    return term\n  }\n}\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/lib/replace.js?");

/***/ }),

/***/ "./node_modules/grapoi/lib/sortByScore.js":
/*!************************************************!*\
  !*** ./node_modules/grapoi/lib/sortByScore.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction sortByScore (results) {\n  return results.slice().sort((a, b) => {\n    const diff = b.score - a.score\n\n    if (diff !== 0) {\n      return diff\n    }\n\n    return a.term.value.localeCompare(b.term.value)\n  })\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (sortByScore);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/lib/sortByScore.js?");

/***/ }),

/***/ "./node_modules/grapoi/lib/termIsEqual.js":
/*!************************************************!*\
  !*** ./node_modules/grapoi/lib/termIsEqual.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction termIsEqual (a, b) {\n  if (a) {\n    return a.equals(b)\n  }\n\n  return a === b\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (termIsEqual);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/lib/termIsEqual.js?");

/***/ }),

/***/ "./node_modules/grapoi/lib/toPath.js":
/*!*******************************************!*\
  !*** ./node_modules/grapoi/lib/toPath.js ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _Path_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Path.js */ \"./node_modules/grapoi/Path.js\");\n/* harmony import */ var _toTerm_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./toTerm.js */ \"./node_modules/grapoi/lib/toTerm.js\");\n\n\n\nfunction isPtr (value) {\n  return typeof value.term === 'object' && typeof value.dataset === 'object'\n}\n\nfunction isPath (value) {\n  return value instanceof _Path_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]\n}\n\nfunction toPath (value, { dataset, factory, graph }) {\n  if (value === null) {\n    return null\n  }\n\n  if (value === undefined) {\n    return undefined\n  }\n\n  if (isPath(value)) {\n    return value\n  }\n\n  if (isPtr(value)) {\n    return new _Path_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]({\n      dataset: value.dataset,\n      graph: value.graph,\n      term: value.term,\n      factory: value.factory || factory\n    })\n  }\n\n  return new _Path_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]({\n    dataset,\n    graph,\n    term: (0,_toTerm_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(value, { factory }),\n    factory\n  })\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (toPath);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/lib/toPath.js?");

/***/ }),

/***/ "./node_modules/grapoi/lib/toPathArray.js":
/*!************************************************!*\
  !*** ./node_modules/grapoi/lib/toPathArray.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _toPath_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./toPath.js */ \"./node_modules/grapoi/lib/toPath.js\");\n/* harmony import */ var _toTermArray_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./toTermArray.js */ \"./node_modules/grapoi/lib/toTermArray.js\");\n\n\n\nfunction toPathArray (values, { dataset, factory, graph }) {\n  try {\n    values = [(0,_toPath_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(values, { dataset, factory, graph })]\n  } catch (err) {}\n\n  if (values[Symbol.iterator]) {\n    values = [...values]\n  }\n\n  return values.flatMap(value => {\n    return (0,_toTermArray_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(graph, { factory }).flatMap(graph => {\n      return (0,_toPath_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(value, { dataset, factory, graph })\n    })\n  })\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (toPathArray);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/lib/toPathArray.js?");

/***/ }),

/***/ "./node_modules/grapoi/lib/toTerm.js":
/*!*******************************************!*\
  !*** ./node_modules/grapoi/lib/toTerm.js ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction toTerm (value, { factory }) {\n  if (value === null) {\n    return null\n  }\n\n  if (value === undefined) {\n    return undefined\n  }\n\n  if (typeof value === 'string') {\n    return factory.literal(value)\n  }\n\n  if (value.constructor.name === 'URL') {\n    return factory.namedNode(value.toString())\n  }\n\n  if (value.termType) {\n    return value\n  }\n\n  const term = value.term\n\n  if (term !== undefined) {\n    return term\n  }\n\n  throw new Error(`can't convert ${value.toString()} to a Term object`)\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (toTerm);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/lib/toTerm.js?");

/***/ }),

/***/ "./node_modules/grapoi/lib/toTermArray.js":
/*!************************************************!*\
  !*** ./node_modules/grapoi/lib/toTermArray.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _toTerm_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./toTerm.js */ \"./node_modules/grapoi/lib/toTerm.js\");\n\n\nfunction toTermArray (values, { factory }) {\n  try {\n    values = [(0,_toTerm_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(values, { factory })]\n  } catch (err) {}\n\n  if (values[Symbol.iterator]) {\n    values = [...values]\n  }\n\n  values = values.map(value => (0,_toTerm_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(value, { factory }))\n\n  return values\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (toTermArray);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/grapoi/lib/toTermArray.js?");

/***/ }),

/***/ "./node_modules/is-stream/index.js":
/*!*****************************************!*\
  !*** ./node_modules/is-stream/index.js ***!
  \*****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   isDuplexStream: () => (/* binding */ isDuplexStream),\n/* harmony export */   isReadableStream: () => (/* binding */ isReadableStream),\n/* harmony export */   isStream: () => (/* binding */ isStream),\n/* harmony export */   isTransformStream: () => (/* binding */ isTransformStream),\n/* harmony export */   isWritableStream: () => (/* binding */ isWritableStream)\n/* harmony export */ });\nfunction isStream(stream, {checkOpen = true} = {}) {\n\treturn stream !== null\n\t\t&& typeof stream === 'object'\n\t\t&& (stream.writable || stream.readable || !checkOpen || (stream.writable === undefined && stream.readable === undefined))\n\t\t&& typeof stream.pipe === 'function';\n}\n\nfunction isWritableStream(stream, {checkOpen = true} = {}) {\n\treturn isStream(stream, {checkOpen})\n\t\t&& (stream.writable || !checkOpen)\n\t\t&& typeof stream.write === 'function'\n\t\t&& typeof stream.end === 'function'\n\t\t&& typeof stream.writable === 'boolean'\n\t\t&& typeof stream.writableObjectMode === 'boolean'\n\t\t&& typeof stream.destroy === 'function'\n\t\t&& typeof stream.destroyed === 'boolean';\n}\n\nfunction isReadableStream(stream, {checkOpen = true} = {}) {\n\treturn isStream(stream, {checkOpen})\n\t\t&& (stream.readable || !checkOpen)\n\t\t&& typeof stream.read === 'function'\n\t\t&& typeof stream.readable === 'boolean'\n\t\t&& typeof stream.readableObjectMode === 'boolean'\n\t\t&& typeof stream.destroy === 'function'\n\t\t&& typeof stream.destroyed === 'boolean';\n}\n\nfunction isDuplexStream(stream, options) {\n\treturn isWritableStream(stream, options)\n\t\t&& isReadableStream(stream, options);\n}\n\nfunction isTransformStream(stream, options) {\n\treturn isDuplexStream(stream, options)\n\t\t&& typeof stream._transform === 'function';\n}\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/is-stream/index.js?");

/***/ }),

/***/ "./node_modules/nodeify-fetch/browser.js":
/*!***********************************************!*\
  !*** ./node_modules/nodeify-fetch/browser.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Headers: () => (/* binding */ Headers),\n/* harmony export */   \"default\": () => (/* binding */ nodeifyFetch)\n/* harmony export */ });\n/* harmony import */ var _lib_patchRequest_browser_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/patchRequest.browser.js */ \"./node_modules/nodeify-fetch/lib/patchRequest.browser.js\");\n/* harmony import */ var _lib_patchResponse_browser_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/patchResponse.browser.js */ \"./node_modules/nodeify-fetch/lib/patchResponse.browser.js\");\n/* global fetch */\n\n\n\n\nconst Headers = window.Headers\n\nfunction nodeifyFetch (url, options) {\n  return (0,_lib_patchRequest_browser_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(options).then(options => {\n    return fetch(url, options).then(res => {\n      return (0,_lib_patchResponse_browser_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(res)\n    })\n  })\n}\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/nodeify-fetch/browser.js?");

/***/ }),

/***/ "./node_modules/nodeify-fetch/lib/Patchable.js":
/*!*****************************************************!*\
  !*** ./node_modules/nodeify-fetch/lib/Patchable.js ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nclass Patchable {\n  constructor (obj, patch) {\n    this.obj = obj\n\n    for (const [key, value] of Object.entries(patch)) {\n      this[key] = value\n    }\n\n    for (const key of Patchable.properties(obj)) {\n      if (key in this) {\n        continue\n      }\n\n      if (typeof this.obj[key] === 'function') {\n        this[key] = (...args) => this.obj[key].call(obj, args)\n      } else {\n        Object.defineProperty(this, key, {\n          get: () => {\n            return this.obj[key]\n          },\n          set: value => {\n            this.obj[key] = value\n          },\n          enumerable: true,\n          configurable: true\n        })\n      }\n    }\n  }\n\n  static properties (obj) {\n    return Object.getOwnPropertyNames(Object.getPrototypeOf(obj))\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Patchable);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/nodeify-fetch/lib/Patchable.js?");

/***/ }),

/***/ "./node_modules/nodeify-fetch/lib/arrayBufferToReadable.js":
/*!*****************************************************************!*\
  !*** ./node_modules/nodeify-fetch/lib/arrayBufferToReadable.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var lodash_once_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! lodash/once.js */ \"./node_modules/lodash/once.js\");\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n\n\n\nfunction arrayBufferToReadable (callback) {\n  return new readable_stream__WEBPACK_IMPORTED_MODULE_1__.Readable({\n    read: lodash_once_js__WEBPACK_IMPORTED_MODULE_0__(async function () {\n      try {\n        this.push(new Uint8Array(await callback()))\n        this.push(null)\n      } catch (err) {\n        this.destroy(err)\n      }\n    })\n  })\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (arrayBufferToReadable);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/nodeify-fetch/lib/arrayBufferToReadable.js?");

/***/ }),

/***/ "./node_modules/nodeify-fetch/lib/patchRequest.browser.js":
/*!****************************************************************!*\
  !*** ./node_modules/nodeify-fetch/lib/patchRequest.browser.js ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var stream_chunks_chunks_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! stream-chunks/chunks.js */ \"./node_modules/stream-chunks/chunks.js\");\n/* harmony import */ var stream_chunks_concatChunks_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! stream-chunks/concatChunks.js */ \"./node_modules/stream-chunks/concatChunks.js\");\n\n\n\nasync function patch (options = {}) {\n  if (!options.body || !options.body.readable) {\n    return options\n  }\n\n  // read the whole input stream...\n  const content = await (0,stream_chunks_chunks_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(options.body)\n\n  // ...and if there is any content convert it to a single Uint8Array or string\n  if (content.length > 0) {\n    if (content[0].BYTES_PER_ELEMENT === 1) {\n      options.body = (0,stream_chunks_concatChunks_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(content)\n    } else {\n      options.body = content.join('')\n    }\n  } else {\n    options.body = ''\n  }\n\n  return options\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (patch);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/nodeify-fetch/lib/patchRequest.browser.js?");

/***/ }),

/***/ "./node_modules/nodeify-fetch/lib/patchResponse.browser.js":
/*!*****************************************************************!*\
  !*** ./node_modules/nodeify-fetch/lib/patchResponse.browser.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n/* harmony import */ var _arrayBufferToReadable_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./arrayBufferToReadable.js */ \"./node_modules/nodeify-fetch/lib/arrayBufferToReadable.js\");\n/* harmony import */ var _Patchable_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Patchable.js */ \"./node_modules/nodeify-fetch/lib/Patchable.js\");\n/* harmony import */ var _whatwgToReadable_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./whatwgToReadable.js */ \"./node_modules/nodeify-fetch/lib/whatwgToReadable.js\");\n\n\n\n\n\nfunction patch (res) {\n  if (res.bodyUsed) {\n    const body = new readable_stream__WEBPACK_IMPORTED_MODULE_0__.Readable({\n      read: () => body.destroy(new Error('body already in use'))\n    })\n\n    res.body = body\n\n    return res\n  }\n\n  // body is already a readable\n  if (res.body && res.body.readable) {\n    return res\n  }\n\n  // body is a WHATWG stream\n  if (res.body && typeof res.body.getReader === 'function') {\n    // replace response with a patchable object...\n    return new _Patchable_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"](res, {\n      // ...and replace the body with a readable stream\n      body: (0,_whatwgToReadable_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])(res.body.getReader())\n    })\n  }\n\n  // for all other cases, read the whole arrayBuffer and wrap it with a readable stream\n  res.body = (0,_arrayBufferToReadable_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(() => res.arrayBuffer())\n\n  return res\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (patch);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/nodeify-fetch/lib/patchResponse.browser.js?");

/***/ }),

/***/ "./node_modules/nodeify-fetch/lib/whatwgToReadable.js":
/*!************************************************************!*\
  !*** ./node_modules/nodeify-fetch/lib/whatwgToReadable.js ***!
  \************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n\n\nfunction whatwgToReadable (whatwg) {\n  return new readable_stream__WEBPACK_IMPORTED_MODULE_0__.Readable({\n    read: async function () {\n      try {\n        let chunk, full\n\n        do {\n          chunk = await whatwg.read()\n\n          if (chunk.done) {\n            this.push(null)\n          } else {\n            full = !this.push(chunk.value)\n          }\n        } while (!chunk.done && !full)\n      } catch (err) {\n        this.destroy(err)\n      }\n    }\n  })\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (whatwgToReadable);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/nodeify-fetch/lib/whatwgToReadable.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/DataFactory.js":
/*!*********************************************!*\
  !*** ./node_modules/rdf-ext/DataFactory.js ***!
  \*********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_data_model_lib_fromTerm_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/data-model/lib/fromTerm.js */ \"./node_modules/@rdfjs/data-model/lib/fromTerm.js\");\n/* harmony import */ var _lib_BlankNode_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/BlankNode.js */ \"./node_modules/rdf-ext/lib/BlankNode.js\");\n/* harmony import */ var _lib_DefaultGraph_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/DefaultGraph.js */ \"./node_modules/rdf-ext/lib/DefaultGraph.js\");\n/* harmony import */ var _lib_Literal_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./lib/Literal.js */ \"./node_modules/rdf-ext/lib/Literal.js\");\n/* harmony import */ var _lib_NamedNode_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./lib/NamedNode.js */ \"./node_modules/rdf-ext/lib/NamedNode.js\");\n/* harmony import */ var _lib_Quad_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./lib/Quad.js */ \"./node_modules/rdf-ext/lib/Quad.js\");\n/* harmony import */ var _lib_Variable_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./lib/Variable.js */ \"./node_modules/rdf-ext/lib/Variable.js\");\n\n\n\n\n\n\n\n\nconst langStringDatatype = new _lib_NamedNode_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]('http://www.w3.org/1999/02/22-rdf-syntax-ns#langString')\nconst stringDatatype = new _lib_NamedNode_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]('http://www.w3.org/2001/XMLSchema#string')\n\nclass DataFactory {\n  init () {\n    this._data = {\n      blankNodeCounter: 0,\n      defaultGraph: new _lib_DefaultGraph_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]()\n    }\n  }\n\n  namedNode (value) {\n    if (typeof value !== 'string') {\n      value = value.toString()\n    }\n\n    return new _lib_NamedNode_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"](value)\n  }\n\n  blankNode (value) {\n    value = value || ('b' + (++this._data.blankNodeCounter))\n\n    return new _lib_BlankNode_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"](value)\n  }\n\n  literal (value, languageOrDatatype) {\n    if (typeof languageOrDatatype === 'string') {\n      return new _lib_Literal_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"](value, languageOrDatatype, langStringDatatype)\n    } else {\n      return new _lib_Literal_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"](value, '', languageOrDatatype || stringDatatype)\n    }\n  }\n\n  variable (value) {\n    return new _lib_Variable_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"](value)\n  }\n\n  defaultGraph () {\n    return this._data.defaultGraph\n  }\n\n  quad (subject, predicate, object, graph = this.defaultGraph()) {\n    return new _lib_Quad_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"](subject, predicate, object, graph)\n  }\n\n  fromTerm (original) {\n    return (0,_rdfjs_data_model_lib_fromTerm_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, original)\n  }\n\n  fromQuad (original) {\n    return (0,_rdfjs_data_model_lib_fromTerm_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(this, original)\n  }\n}\n\nDataFactory.exports = [\n  'namedNode',\n  'blankNode',\n  'literal',\n  'variable',\n  'defaultGraph',\n  'quad',\n  'fromTerm',\n  'fromQuad'\n]\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (DataFactory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/DataFactory.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/DatasetFactory.js":
/*!************************************************!*\
  !*** ./node_modules/rdf-ext/DatasetFactory.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _lib_Dataset_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/Dataset.js */ \"./node_modules/rdf-ext/lib/Dataset.js\");\n\n\nclass DatasetFactory {\n  dataset (quads, graph) {\n    const dataset = new _lib_Dataset_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]()\n\n    if (quads) {\n      if (graph) {\n        for (const quad of quads) {\n          dataset.add(this.quad(quad.subject, quad.predicate, quad.object, graph))\n        }\n      } else {\n        dataset.addAll(quads)\n      }\n    }\n\n    return dataset\n  }\n}\n\nDatasetFactory.exports = ['dataset']\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (DatasetFactory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/DatasetFactory.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/FetchFactory.js":
/*!**********************************************!*\
  !*** ./node_modules/rdf-ext/FetchFactory.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_fetch_lite_Factory_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/fetch-lite/Factory.js */ \"./node_modules/@rdfjs/fetch-lite/Factory.js\");\n/* harmony import */ var _lib_fetch_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/fetch.js */ \"./node_modules/rdf-ext/lib/fetch.browser.js\");\n\n\n\nclass FetchFactory extends _rdfjs_fetch_lite_Factory_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  init () {\n    super.init()\n\n    this.fetch.config('fetch', _lib_fetch_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (FetchFactory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/FetchFactory.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/FormatsFactory.js":
/*!************************************************!*\
  !*** ./node_modules/rdf-ext/FormatsFactory.js ***!
  \************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_formats__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/formats */ \"./node_modules/@rdfjs/formats/index.js\");\n/* harmony import */ var _rdfjs_formats_Factory_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/formats/Factory.js */ \"./node_modules/@rdfjs/formats/Factory.js\");\n\n\n\nclass FormatsFactory extends _rdfjs_formats_Factory_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"] {\n  init () {\n    super.init()\n\n    this.formats.import(_rdfjs_formats__WEBPACK_IMPORTED_MODULE_0__[\"default\"])\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (FormatsFactory);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/FormatsFactory.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/index.js":
/*!***************************************!*\
  !*** ./node_modules/rdf-ext/index.js ***!
  \***************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DataFactory: () => (/* reexport safe */ _DataFactory_js__WEBPACK_IMPORTED_MODULE_9__[\"default\"]),\n/* harmony export */   DatasetFactory: () => (/* reexport safe */ _DatasetFactory_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"]),\n/* harmony export */   Environment: () => (/* reexport safe */ _rdfjs_environment_Environment_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]),\n/* harmony export */   FetchFactory: () => (/* reexport safe */ _FetchFactory_js__WEBPACK_IMPORTED_MODULE_11__[\"default\"]),\n/* harmony export */   FormatsFactory: () => (/* reexport safe */ _FormatsFactory_js__WEBPACK_IMPORTED_MODULE_12__[\"default\"]),\n/* harmony export */   GrapoiFactory: () => (/* reexport safe */ grapoi_Factory_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"]),\n/* harmony export */   NamespaceFactory: () => (/* reexport safe */ _rdfjs_namespace_Factory_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]),\n/* harmony export */   PrefixMapFactory: () => (/* reexport safe */ _rdfjs_prefix_map_Factory_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"]),\n/* harmony export */   ScoreFactory: () => (/* reexport safe */ _rdfjs_score_Factory_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"]),\n/* harmony export */   TermMapFactory: () => (/* reexport safe */ _rdfjs_term_map_Factory_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"]),\n/* harmony export */   TermSetFactory: () => (/* reexport safe */ _rdfjs_term_set_Factory_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"]),\n/* harmony export */   TraverserFactory: () => (/* reexport safe */ _rdfjs_traverser_Factory_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"]),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_environment_Environment_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/environment/Environment.js */ \"./node_modules/@rdfjs/environment/Environment.js\");\n/* harmony import */ var _rdfjs_io_Factory_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/io/Factory.js */ \"./node_modules/@rdfjs/io/Factory.js\");\n/* harmony import */ var _rdfjs_namespace_Factory_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @rdfjs/namespace/Factory.js */ \"./node_modules/@rdfjs/namespace/Factory.js\");\n/* harmony import */ var _rdfjs_prefix_map_Factory_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! @rdfjs/prefix-map/Factory.js */ \"./node_modules/@rdfjs/prefix-map/Factory.js\");\n/* harmony import */ var _rdfjs_score_Factory_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @rdfjs/score/Factory.js */ \"./node_modules/@rdfjs/score/Factory.js\");\n/* harmony import */ var _rdfjs_term_map_Factory_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @rdfjs/term-map/Factory.js */ \"./node_modules/@rdfjs/term-map/Factory.js\");\n/* harmony import */ var _rdfjs_term_set_Factory_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @rdfjs/term-set/Factory.js */ \"./node_modules/@rdfjs/term-set/Factory.js\");\n/* harmony import */ var _rdfjs_traverser_Factory_js__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! @rdfjs/traverser/Factory.js */ \"./node_modules/@rdfjs/traverser/Factory.js\");\n/* harmony import */ var grapoi_Factory_js__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! grapoi/Factory.js */ \"./node_modules/grapoi/Factory.js\");\n/* harmony import */ var _DataFactory_js__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./DataFactory.js */ \"./node_modules/rdf-ext/DataFactory.js\");\n/* harmony import */ var _DatasetFactory_js__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./DatasetFactory.js */ \"./node_modules/rdf-ext/DatasetFactory.js\");\n/* harmony import */ var _FetchFactory_js__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./FetchFactory.js */ \"./node_modules/rdf-ext/FetchFactory.js\");\n/* harmony import */ var _FormatsFactory_js__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./FormatsFactory.js */ \"./node_modules/rdf-ext/FormatsFactory.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst defaultEnv = new _rdfjs_environment_Environment_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]([\n  _DataFactory_js__WEBPACK_IMPORTED_MODULE_9__[\"default\"],\n  _DatasetFactory_js__WEBPACK_IMPORTED_MODULE_10__[\"default\"],\n  _FetchFactory_js__WEBPACK_IMPORTED_MODULE_11__[\"default\"],\n  _FormatsFactory_js__WEBPACK_IMPORTED_MODULE_12__[\"default\"],\n  grapoi_Factory_js__WEBPACK_IMPORTED_MODULE_8__[\"default\"],\n  _rdfjs_io_Factory_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"],\n  _rdfjs_namespace_Factory_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"],\n  _rdfjs_prefix_map_Factory_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"],\n  _rdfjs_score_Factory_js__WEBPACK_IMPORTED_MODULE_4__[\"default\"],\n  _rdfjs_term_map_Factory_js__WEBPACK_IMPORTED_MODULE_5__[\"default\"],\n  _rdfjs_term_set_Factory_js__WEBPACK_IMPORTED_MODULE_6__[\"default\"],\n  _rdfjs_traverser_Factory_js__WEBPACK_IMPORTED_MODULE_7__[\"default\"]\n], { bind: true })\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (defaultEnv);\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/index.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/lib/BlankNode.js":
/*!***********************************************!*\
  !*** ./node_modules/rdf-ext/lib/BlankNode.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_data_model_lib_BlankNode_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/data-model/lib/BlankNode.js */ \"./node_modules/@rdfjs/data-model/lib/BlankNode.js\");\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n\n\n\nclass BlankNode extends _rdfjs_data_model_lib_BlankNode_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  toCanonical () {\n    return (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(this)\n  }\n\n  toString () {\n    return this.toCanonical()\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (BlankNode);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/lib/BlankNode.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/lib/Dataset.js":
/*!*********************************************!*\
  !*** ./node_modules/rdf-ext/lib/Dataset.js ***!
  \*********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_dataset_DatasetCore_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/dataset/DatasetCore.js */ \"./node_modules/@rdfjs/dataset/DatasetCore.js\");\n/* harmony import */ var _rdfjs_normalize__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/normalize */ \"./node_modules/@rdfjs/normalize/index.js\");\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n/* harmony import */ var readable_stream__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/lib/ours/browser.js\");\n\n\n\n\n\nfunction createDataset (obj, quads) {\n  return new obj.constructor(quads)\n}\n\nclass DatasetExt extends _rdfjs_dataset_DatasetCore_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  addAll (quads) {\n    for (const quad of quads) {\n      this.add(quad)\n    }\n\n    return this\n  }\n\n  clone () {\n    return createDataset(this, this)\n  }\n\n  deleteMatches (subject, predicate, object, graph) {\n    for (const quad of this.match(subject, predicate, object, graph)) {\n      this.delete(quad)\n    }\n\n    return this\n  }\n\n  difference (other) {\n    return this.filter(quad => !other.has(quad))\n  }\n\n  equals (other) {\n    return this.toCanonical() === other.toCanonical()\n  }\n\n  every (callback) {\n    return Array.from(this).every(quad => callback(quad, this))\n  }\n\n  filter (callback) {\n    return createDataset(this, Array.from(this).filter(quad => callback(quad, this)))\n  }\n\n  forEach (callback) {\n    Array.from(this).forEach(quad => callback(quad, this))\n  }\n\n  import (stream) {\n    stream.on('data', quad => this.add(quad))\n\n    return new Promise((resolve, reject) => {\n      ;(0,readable_stream__WEBPACK_IMPORTED_MODULE_3__.finished)(stream, err => {\n        if (err) {\n          reject(err)\n        } else {\n          resolve(this)\n        }\n      })\n    })\n  }\n\n  intersection (other) {\n    return this.filter(quad => other.has(quad))\n  }\n\n  map (callback) {\n    return createDataset(this, Array.from(this).map(quad => callback(quad, this)))\n  }\n\n  merge (other) {\n    return (this.clone()).addAll(other)\n  }\n\n  reduce (callback, initialValue) {\n    return Array.from(this).reduce((value, quad, index) => callback(value, quad, index, this), initialValue)\n  }\n\n  some (callback) {\n    return Array.from(this).some(quad => callback(quad, this))\n  }\n\n  toCanonical () {\n    return (0,_rdfjs_normalize__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(this)\n  }\n\n  toStream () {\n    return readable_stream__WEBPACK_IMPORTED_MODULE_3__.Readable.from(this)\n  }\n\n  toString () {\n    return (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_2__[\"default\"])(this)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (DatasetExt);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/lib/Dataset.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/lib/DefaultGraph.js":
/*!**************************************************!*\
  !*** ./node_modules/rdf-ext/lib/DefaultGraph.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_data_model_lib_DefaultGraph_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/data-model/lib/DefaultGraph.js */ \"./node_modules/@rdfjs/data-model/lib/DefaultGraph.js\");\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n\n\n\nclass DefaultGraph extends _rdfjs_data_model_lib_DefaultGraph_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  toCanonical () {\n    return (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(this)\n  }\n\n  toString () {\n    return this.toCanonical()\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (DefaultGraph);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/lib/DefaultGraph.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/lib/Literal.js":
/*!*********************************************!*\
  !*** ./node_modules/rdf-ext/lib/Literal.js ***!
  \*********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_data_model_lib_Literal_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/data-model/lib/Literal.js */ \"./node_modules/@rdfjs/data-model/lib/Literal.js\");\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n\n\n\nclass Literal extends _rdfjs_data_model_lib_Literal_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  toCanonical () {\n    return (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(this)\n  }\n\n  toString () {\n    return this.value\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Literal);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/lib/Literal.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/lib/NamedNode.js":
/*!***********************************************!*\
  !*** ./node_modules/rdf-ext/lib/NamedNode.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_data_model_lib_NamedNode_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/data-model/lib/NamedNode.js */ \"./node_modules/@rdfjs/data-model/lib/NamedNode.js\");\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n\n\n\nclass NamedNode extends _rdfjs_data_model_lib_NamedNode_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  toCanonical () {\n    return (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(this)\n  }\n\n  toString () {\n    return this.value\n  }\n\n  toURL () {\n    return new URL(this.value)\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (NamedNode);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/lib/NamedNode.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/lib/Quad.js":
/*!******************************************!*\
  !*** ./node_modules/rdf-ext/lib/Quad.js ***!
  \******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_data_model_lib_Quad_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/data-model/lib/Quad.js */ \"./node_modules/@rdfjs/data-model/lib/Quad.js\");\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n\n\n\nclass Quad extends _rdfjs_data_model_lib_Quad_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  toCanonical () {\n    return (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(this)\n  }\n\n  toString () {\n    return this.toCanonical()\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Quad);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/lib/Quad.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/lib/Variable.js":
/*!**********************************************!*\
  !*** ./node_modules/rdf-ext/lib/Variable.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _rdfjs_data_model_lib_Variable_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @rdfjs/data-model/lib/Variable.js */ \"./node_modules/@rdfjs/data-model/lib/Variable.js\");\n/* harmony import */ var _rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @rdfjs/to-ntriples */ \"./node_modules/@rdfjs/to-ntriples/index.js\");\n\n\n\nclass Variable extends _rdfjs_data_model_lib_Variable_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n  toCanonical () {\n    return (0,_rdfjs_to_ntriples__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(this)\n  }\n\n  toString () {\n    return this.toCanonical()\n  }\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (Variable);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/lib/Variable.js?");

/***/ }),

/***/ "./node_modules/rdf-ext/lib/fetch.browser.js":
/*!***************************************************!*\
  !*** ./node_modules/rdf-ext/lib/fetch.browser.js ***!
  \***************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var nodeify_fetch__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! nodeify-fetch */ \"./node_modules/nodeify-fetch/browser.js\");\n\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (nodeify_fetch__WEBPACK_IMPORTED_MODULE_0__[\"default\"]);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/rdf-ext/lib/fetch.browser.js?");

/***/ }),

/***/ "./node_modules/stream-chunks/chunks.js":
/*!**********************************************!*\
  !*** ./node_modules/stream-chunks/chunks.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nasync function chunks (stream) {\n  const chunks = []\n\n  for await (const chunk of stream) {\n    chunks.push(chunk)\n  }\n\n  return chunks\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (chunks);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/stream-chunks/chunks.js?");

/***/ }),

/***/ "./node_modules/stream-chunks/concat.js":
/*!**********************************************!*\
  !*** ./node_modules/stream-chunks/concat.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _chunks_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./chunks.js */ \"./node_modules/stream-chunks/chunks.js\");\n/* harmony import */ var _concatChunks_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./concatChunks.js */ \"./node_modules/stream-chunks/concatChunks.js\");\n\n\n\nasync function concat (stream) {\n  return (0,_concatChunks_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"])(await (0,_chunks_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"])(stream))\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (concat);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/stream-chunks/concat.js?");

/***/ }),

/***/ "./node_modules/stream-chunks/concatChunks.js":
/*!****************************************************!*\
  !*** ./node_modules/stream-chunks/concatChunks.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nfunction concatChunks (chunks) {\n  const length = chunks.reduce((length, chunk) => length + chunk.length, 0)\n  const merged = new Uint8Array(length)\n\n  let offset = 0\n\n  for (const chunk of chunks) {\n    merged.set(chunk, offset)\n    offset += chunk.length\n  }\n\n  return merged\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (concatChunks);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/stream-chunks/concatChunks.js?");

/***/ }),

/***/ "./node_modules/stream-chunks/decode.js":
/*!**********************************************!*\
  !*** ./node_modules/stream-chunks/decode.js ***!
  \**********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var string_decoder__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! string_decoder */ \"./node_modules/string_decoder/lib/string_decoder.js\");\n\n\nasync function decode (stream, encoding) {\n  const decoder = new string_decoder__WEBPACK_IMPORTED_MODULE_0__.StringDecoder(encoding)\n  let str = ''\n\n  for await (const chunk of stream) {\n    str += decoder.write(chunk)\n  }\n\n  str += decoder.end()\n\n  return str\n}\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (decode);\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/stream-chunks/decode.js?");

/***/ }),

/***/ "./node_modules/stream-chunks/index.js":
/*!*********************************************!*\
  !*** ./node_modules/stream-chunks/index.js ***!
  \*********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   chunks: () => (/* reexport safe */ _chunks_js__WEBPACK_IMPORTED_MODULE_0__[\"default\"]),\n/* harmony export */   concat: () => (/* reexport safe */ _concat_js__WEBPACK_IMPORTED_MODULE_1__[\"default\"]),\n/* harmony export */   concatChunks: () => (/* reexport safe */ _concatChunks_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]),\n/* harmony export */   decode: () => (/* reexport safe */ _decode_js__WEBPACK_IMPORTED_MODULE_3__[\"default\"])\n/* harmony export */ });\n/* harmony import */ var _chunks_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./chunks.js */ \"./node_modules/stream-chunks/chunks.js\");\n/* harmony import */ var _concat_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./concat.js */ \"./node_modules/stream-chunks/concat.js\");\n/* harmony import */ var _concatChunks_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./concatChunks.js */ \"./node_modules/stream-chunks/concatChunks.js\");\n/* harmony import */ var _decode_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./decode.js */ \"./node_modules/stream-chunks/decode.js\");\n\n\n\n\n\n\n\n\n//# sourceURL=webpack://FormAMatic/./node_modules/stream-chunks/index.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/browser-entry.js");
/******/ 	__webpack_exports__ = __webpack_exports__["default"];
/******/ 	
/******/ 	return __webpack_exports__;
/******/ })()
;
});